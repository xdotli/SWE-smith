{"instance_id": "triggerdotdev__trigger.dev.pr_mirror.2515", "repo": "triggerdotdev/trigger.dev", "base_commit": "a70ab1080999097090c6c6fd3e8d58c242c8af48", "head_commit": "23930b605089e00145b0973b5fa2233446db982b", "title": "feat(sdk): replace onStart lifecycle hook with onStartAttempt", "merged_at": "2025-11-13T14:51:13Z", "html_url": "https://github.com/triggerdotdev/trigger.dev/pull/2515", "test_files": ["packages/core/test/taskExecutor.test.ts"], "code_files": ["apps/webapp/app/components/runs/v3/RunIcon.tsx", "packages/core/src/v3/lifecycle-hooks-api.ts", "packages/core/src/v3/lifecycleHooks/index.ts", "packages/core/src/v3/lifecycleHooks/manager.ts", "packages/core/src/v3/lifecycleHooks/types.ts", "packages/core/src/v3/types/tasks.ts", "packages/core/src/v3/workers/taskExecutor.ts", "packages/trigger-sdk/src/v3/hooks.ts", "packages/trigger-sdk/src/v3/shared.ts", "packages/trigger-sdk/src/v3/tasks.ts", "references/hello-world/src/trigger/example.ts"], "total_changes": 764, "num_files": 15, "pull_number": 2515, "patch": "diff --git a/.changeset/tiny-carrots-rest.md b/.changeset/tiny-carrots-rest.md\nnew file mode 100644\nindex 0000000000..5c1c7b8942\n--- /dev/null\n+++ b/.changeset/tiny-carrots-rest.md\n@@ -0,0 +1,41 @@\n+---\n+\"@trigger.dev/sdk\": minor\n+---\n+\n+Prevent uncaught errors in the `onSuccess`, `onComplete`, and `onFailure` lifecycle hooks from failing attempts/runs.\n+\n+Deprecated the `onStart` lifecycle hook (which only fires before the `run` function on the first attempt). Replaced with `onStartAttempt` that fires before the run function on every attempt:\n+\n+```ts\n+export const taskWithOnStartAttempt = task({\n+  id: \"task-with-on-start-attempt\",\n+  onStartAttempt: async ({ payload, ctx }) => {\n+    //...\n+  },\n+  run: async (payload: any, { ctx }) => {\n+    //...\n+  },\n+});\n+\n+// Default a global lifecycle hook using tasks\n+tasks.onStartAttempt(({ ctx, payload, task }) => {\n+  console.log(\n+    `Run ${ctx.run.id} started on task ${task} attempt ${ctx.run.attempt.number}`,\n+    ctx.run\n+  );\n+});\n+```\n+\n+If you want to execute code before just the first attempt, you can use the `onStartAttempt` function and check `ctx.run.attempt.number === 1`:\n+\n+```ts /trigger/on-start-attempt.ts\n+export const taskWithOnStartAttempt = task({\n+  id: \"task-with-on-start-attempt\",\n+  onStartAttempt: async ({ payload, ctx }) => {\n+    if (ctx.run.attempt.number === 1) {\n+      console.log(\"Run started on attempt 1\", ctx.run);\n+    }\n+  },\n+});\n+```\n+\ndiff --git a/apps/webapp/app/components/runs/v3/RunIcon.tsx b/apps/webapp/app/components/runs/v3/RunIcon.tsx\nindex a66d62efc2..615def59cd 100644\n--- a/apps/webapp/app/components/runs/v3/RunIcon.tsx\n+++ b/apps/webapp/app/components/runs/v3/RunIcon.tsx\n@@ -98,6 +98,7 @@ export function RunIcon({ name, className, spanName }: TaskIconProps) {\n       return <RunFunctionIcon className={cn(className, \"text-text-dimmed\")} />;\n     case \"task-hook-init\":\n     case \"task-hook-onStart\":\n+    case \"task-hook-onStartAttempt\":\n     case \"task-hook-onSuccess\":\n     case \"task-hook-onWait\":\n     case \"task-hook-onResume\":\ndiff --git a/docs/images/lifecycle-functions.png b/docs/images/lifecycle-functions.png\nindex d27936600d..7aafd3faec 100644\nBinary files a/docs/images/lifecycle-functions.png and b/docs/images/lifecycle-functions.png differ\ndiff --git a/docs/tasks/overview.mdx b/docs/tasks/overview.mdx\nindex 2b3452c87a..fe2e7ce5c7 100644\n--- a/docs/tasks/overview.mdx\n+++ b/docs/tasks/overview.mdx\n@@ -174,63 +174,14 @@ tasks.onStart(({ ctx, payload, task }) => {\n \n ![Lifecycle functions](/images/lifecycle-functions.png)\n \n-### `init` function\n-\n-This function is called before a run attempt:\n-\n-```ts /trigger/init.ts\n-export const taskWithInit = task({\n-  id: \"task-with-init\",\n-  init: async ({ payload, ctx }) => {\n-    //...\n-  },\n-  run: async (payload: any, { ctx }) => {\n-    //...\n-  },\n-});\n-```\n-\n-You can also return data from the `init` function that will be available in the params of the `run`, `cleanup`, `onSuccess`, and `onFailure` functions.\n-\n-```ts /trigger/init-return.ts\n-export const taskWithInitReturn = task({\n-  id: \"task-with-init-return\",\n-  init: async ({ payload, ctx }) => {\n-    return { someData: \"someValue\" };\n-  },\n-  run: async (payload: any, { ctx, init }) => {\n-    console.log(init.someData); // \"someValue\"\n-  },\n-});\n-```\n-\n-<Info>Errors thrown in the `init` function are ignored.</Info>\n-\n-### `cleanup` function\n-\n-This function is called after the `run` function is executed, regardless of whether the run was successful or not. It's useful for cleaning up resources, logging, or other side effects.\n-\n-```ts /trigger/cleanup.ts\n-export const taskWithCleanup = task({\n-  id: \"task-with-cleanup\",\n-  cleanup: async ({ payload, ctx }) => {\n-    //...\n-  },\n-  run: async (payload: any, { ctx }) => {\n-    //...\n-  },\n-});\n-```\n-\n-<Info>Errors thrown in the `cleanup` function will fail the attempt.</Info>\n-\n ### `middleware` and `locals` functions\n \n Our task middleware system runs at the top level, executing before and after all lifecycle hooks. This allows you to wrap the entire task execution lifecycle with custom logic.\n \n <Info>\n   An error thrown in `middleware` is just like an uncaught error in the run function: it will\n-  propagate through to `catchError()` function and then will fail the attempt (causing a retry).\n+  propagate through to `catchError()` function and then will fail the attempt (either causing a\n+  retry or failing the run).\n </Info>\n \n The `locals` API allows you to share data between middleware and hooks.\n@@ -296,14 +247,16 @@ export const myTask = task({\n });\n ```\n \n-### `onStart` function\n+### `onStartAttempt` function\n+\n+<Info>The `onStartAttempt` function was introduced in v4.1.0</Info>\n \n-When a task run starts, the `onStart` function is called. It's useful for sending notifications, logging, and other side effects. This function will only be called one per run (not per retry). If you want to run code before each retry, use the `init` function.\n+Before a task run attempt starts, the `onStartAttempt` function is called. It's useful for sending notifications, logging, and other side effects.\n \n ```ts /trigger/on-start.ts\n-export const taskWithOnStart = task({\n-  id: \"task-with-on-start\",\n-  onStart: async ({ payload, ctx }) => {\n+export const taskWithOnStartAttempt = task({\n+  id: \"task-with-on-start-attempt\",\n+  onStartAttempt: async ({ payload, ctx }) => {\n     //...\n   },\n   run: async (payload: any, { ctx }) => {\n@@ -312,20 +265,33 @@ export const taskWithOnStart = task({\n });\n ```\n \n-You can also define an `onStart` function in your `trigger.config.ts` file to get notified when any task starts.\n+You can also define a global `onStartAttempt` function using `tasks.onStartAttempt()`.\n \n-```ts trigger.config.ts\n-import { defineConfig } from \"@trigger.dev/sdk\";\n+```ts init.ts\n+import { tasks } from \"@trigger.dev/sdk\";\n \n-export default defineConfig({\n-  project: \"proj_1234\",\n-  onStart: async ({ payload, ctx }) => {\n-    console.log(\"Task started\", ctx.task.id);\n-  },\n+tasks.onStartAttempt(({ ctx, payload, task }) => {\n+  console.log(\n+    `Run ${ctx.run.id} started on task ${task} attempt ${ctx.run.attempt.number}`,\n+    ctx.run\n+  );\n });\n ```\n \n-<Info>Errors thrown in the `onStart` function are ignored.</Info>\n+<Info>Errors thrown in the `onStartAttempt` function will cause the attempt to fail.</Info>\n+\n+If you want to execute code before just the first attempt, you can use the `onStartAttempt` function and check `ctx.run.attempt.number === 1`:\n+\n+```ts /trigger/on-start-attempt.ts\n+export const taskWithOnStartAttempt = task({\n+  id: \"task-with-on-start-attempt\",\n+  onStartAttempt: async ({ payload, ctx }) => {\n+    if (ctx.run.attempt.number === 1) {\n+      console.log(\"Run started on attempt 1\", ctx.run);\n+    }\n+  },\n+});\n+```\n \n ### `onWait` and `onResume` functions\n \n@@ -350,6 +316,20 @@ export const myTask = task({\n });\n ```\n \n+You can also define global `onWait` and `onResume` functions using `tasks.onWait()` and `tasks.onResume()`:\n+\n+```ts init.ts\n+import { tasks } from \"@trigger.dev/sdk\";\n+\n+tasks.onWait(({ ctx, payload, wait, task }) => {\n+  console.log(\"Run paused\", ctx.run, wait);\n+});\n+\n+tasks.onResume(({ ctx, payload, wait, task }) => {\n+  console.log(\"Run resumed\", ctx.run, wait);\n+});\n+```\n+\n ### `onSuccess` function\n \n When a task run succeeds, the `onSuccess` function is called. It's useful for sending notifications, logging, syncing state to your database, or other side effects.\n@@ -366,20 +346,20 @@ export const taskWithOnSuccess = task({\n });\n ```\n \n-You can also define an `onSuccess` function in your `trigger.config.ts` file to get notified when any task succeeds.\n+You can also define a global `onSuccess` function using `tasks.onSuccess()`.\n \n-```ts trigger.config.ts\n-import { defineConfig } from \"@trigger.dev/sdk\";\n+```ts init.ts\n+import { tasks } from \"@trigger.dev/sdk\";\n \n-export default defineConfig({\n-  project: \"proj_1234\",\n-  onSuccess: async ({ payload, output, ctx }) => {\n-    console.log(\"Task succeeded\", ctx.task.id);\n-  },\n+tasks.onSuccess(({ ctx, payload, output }) => {\n+  console.log(\"Task succeeded\", ctx.task.id);\n });\n ```\n \n-<Info>Errors thrown in the `onSuccess` function are ignored.</Info>\n+<Info>\n+  Errors thrown in the `onSuccess` function will be ignored, but you will still be able to see them\n+  in the dashboard.\n+</Info>\n \n ### `onComplete` function\n \n@@ -397,6 +377,21 @@ export const taskWithOnComplete = task({\n });\n ```\n \n+You can also define a global `onComplete` function using `tasks.onComplete()`.\n+\n+```ts init.ts\n+import { tasks } from \"@trigger.dev/sdk\";\n+\n+tasks.onComplete(({ ctx, payload, output }) => {\n+  console.log(\"Task completed\", ctx.task.id);\n+});\n+```\n+\n+<Info>\n+  Errors thrown in the `onComplete` function will be ignored, but you will still be able to see them\n+  in the dashboard.\n+</Info>\n+\n ### `onFailure` function\n \n When a task run fails, the `onFailure` function is called. It's useful for sending notifications, logging, or other side effects. It will only be executed once the task run has exhausted all its retries.\n@@ -413,20 +408,20 @@ export const taskWithOnFailure = task({\n });\n ```\n \n-You can also define an `onFailure` function in your `trigger.config.ts` file to get notified when any task fails.\n+You can also define a global `onFailure` function using `tasks.onFailure()`.\n \n-```ts trigger.config.ts\n-import { defineConfig } from \"@trigger.dev/sdk\";\n+```ts init.ts\n+import { tasks } from \"@trigger.dev/sdk\";\n \n-export default defineConfig({\n-  project: \"proj_1234\",\n-  onFailure: async ({ payload, error, ctx }) => {\n-    console.log(\"Task failed\", ctx.task.id);\n-  },\n+tasks.onFailure(({ ctx, payload, error }) => {\n+  console.log(\"Task failed\", ctx.task.id);\n });\n ```\n \n-<Info>Errors thrown in the `onFailure` function are ignored.</Info>\n+<Info>\n+  Errors thrown in the `onFailure` function will be ignored, but you will still be able to see them\n+  in the dashboard.\n+</Info>\n \n <Note>\n   `onFailure` doesn\u2019t fire for some of the run statuses like `Crashed`, `System failures`, and\n@@ -441,7 +436,7 @@ Read more about `catchError` in our [Errors and Retrying guide](/errors-retrying\n \n <Info>Uncaught errors will throw a special internal error of the type `HANDLE_ERROR_ERROR`.</Info>\n \n-### onCancel\n+### `onCancel` function\n \n You can define an `onCancel` hook that is called when a run is cancelled. This is useful if you want to clean up any resources that were allocated for the run.\n \n@@ -540,6 +535,101 @@ export const cancelExampleTask = task({\n   point the process will be killed.\n </Note>\n \n+### `onStart` function (deprecated)\n+\n+<Info>The `onStart` function was deprecated in v4.1.0. Use `onStartAttempt` instead.</Info>\n+\n+When a task run starts, the `onStart` function is called. It's useful for sending notifications, logging, and other side effects.\n+\n+<Warning>\n+  This function will only be called once per run (not per attempt). If you want to run code before\n+  each attempt, use a middleware function or the `onStartAttempt` function.\n+</Warning>\n+\n+```ts /trigger/on-start.ts\n+export const taskWithOnStart = task({\n+  id: \"task-with-on-start\",\n+  onStart: async ({ payload, ctx }) => {\n+    //...\n+  },\n+  run: async (payload: any, { ctx }) => {\n+    //...\n+  },\n+});\n+```\n+\n+You can also define a global `onStart` function using `tasks.onStart()`.\n+\n+```ts init.ts\n+import { tasks } from \"@trigger.dev/sdk\";\n+\n+tasks.onStart(({ ctx, payload, task }) => {\n+  console.log(`Run ${ctx.run.id} started on task ${task}`, ctx.run);\n+});\n+```\n+\n+<Info>Errors thrown in the `onStart` function will cause the attempt to fail.</Info>\n+\n+### `init` function (deprecated)\n+\n+<Warning>\n+  The `init` hook is deprecated and will be removed in the future. Use\n+  [middleware](/tasks/overview#middleware-and-locals-functions) instead.\n+</Warning>\n+\n+This function is called before a run attempt:\n+\n+```ts /trigger/init.ts\n+export const taskWithInit = task({\n+  id: \"task-with-init\",\n+  init: async ({ payload, ctx }) => {\n+    //...\n+  },\n+  run: async (payload: any, { ctx }) => {\n+    //...\n+  },\n+});\n+```\n+\n+You can also return data from the `init` function that will be available in the params of the `run`, `cleanup`, `onSuccess`, and `onFailure` functions.\n+\n+```ts /trigger/init-return.ts\n+export const taskWithInitReturn = task({\n+  id: \"task-with-init-return\",\n+  init: async ({ payload, ctx }) => {\n+    return { someData: \"someValue\" };\n+  },\n+  run: async (payload: any, { ctx, init }) => {\n+    console.log(init.someData); // \"someValue\"\n+  },\n+});\n+```\n+\n+<Info>Errors thrown in the `init` function will cause the attempt to fail.</Info>\n+\n+### `cleanup` function (deprecated)\n+\n+<Warning>\n+  The `cleanup` hook is deprecated and will be removed in the future. Use\n+  [middleware](/tasks/overview#middleware-and-locals-functions) instead.\n+</Warning>\n+\n+This function is called after the `run` function is executed, regardless of whether the run was successful or not. It's useful for cleaning up resources, logging, or other side effects.\n+\n+```ts /trigger/cleanup.ts\n+export const taskWithCleanup = task({\n+  id: \"task-with-cleanup\",\n+  cleanup: async ({ payload, ctx }) => {\n+    //...\n+  },\n+  run: async (payload: any, { ctx }) => {\n+    //...\n+  },\n+});\n+```\n+\n+<Info>Errors thrown in the `cleanup` function will cause the attempt to fail.</Info>\n+\n ## Next steps\n \n <CardGroup>\ndiff --git a/packages/core/src/v3/lifecycle-hooks-api.ts b/packages/core/src/v3/lifecycle-hooks-api.ts\nindex 3c74f719cb..e08bd66671 100644\n--- a/packages/core/src/v3/lifecycle-hooks-api.ts\n+++ b/packages/core/src/v3/lifecycle-hooks-api.ts\n@@ -35,4 +35,5 @@ export type {\n   TaskCancelHookParams,\n   OnCancelHookFunction,\n   AnyOnCancelHookFunction,\n+  AnyOnStartAttemptHookFunction,\n } from \"./lifecycleHooks/types.js\";\ndiff --git a/packages/core/src/v3/lifecycleHooks/index.ts b/packages/core/src/v3/lifecycleHooks/index.ts\nindex 99ed47ae60..0011bd5d5a 100644\n--- a/packages/core/src/v3/lifecycleHooks/index.ts\n+++ b/packages/core/src/v3/lifecycleHooks/index.ts\n@@ -18,6 +18,7 @@ import {\n   RegisterHookFunctionParams,\n   TaskWait,\n   type LifecycleHooksManager,\n+  AnyOnStartAttemptHookFunction,\n } from \"./types.js\";\n \n const NOOP_LIFECYCLE_HOOKS_MANAGER = new NoopLifecycleHooksManager();\n@@ -81,6 +82,27 @@ export class LifecycleHooksAPI {\n     return this.#getManager().getGlobalStartHooks();\n   }\n \n+  public registerTaskStartAttemptHook(\n+    taskId: string,\n+    hook: RegisterHookFunctionParams<AnyOnStartAttemptHookFunction>\n+  ): void {\n+    this.#getManager().registerTaskStartAttemptHook(taskId, hook);\n+  }\n+\n+  public registerGlobalStartAttemptHook(\n+    hook: RegisterHookFunctionParams<AnyOnStartAttemptHookFunction>\n+  ): void {\n+    this.#getManager().registerGlobalStartAttemptHook(hook);\n+  }\n+\n+  public getTaskStartAttemptHook(taskId: string): AnyOnStartAttemptHookFunction | undefined {\n+    return this.#getManager().getTaskStartAttemptHook(taskId);\n+  }\n+\n+  public getGlobalStartAttemptHooks(): RegisteredHookFunction<AnyOnStartAttemptHookFunction>[] {\n+    return this.#getManager().getGlobalStartAttemptHooks();\n+  }\n+\n   public registerGlobalFailureHook(\n     hook: RegisterHookFunctionParams<AnyOnFailureHookFunction>\n   ): void {\ndiff --git a/packages/core/src/v3/lifecycleHooks/manager.ts b/packages/core/src/v3/lifecycleHooks/manager.ts\nindex 282d2fe16c..e755e66d3f 100644\n--- a/packages/core/src/v3/lifecycleHooks/manager.ts\n+++ b/packages/core/src/v3/lifecycleHooks/manager.ts\n@@ -14,6 +14,7 @@ import {\n   AnyOnCleanupHookFunction,\n   TaskWait,\n   AnyOnCancelHookFunction,\n+  AnyOnStartAttemptHookFunction,\n } from \"./types.js\";\n \n export class StandardLifecycleHooksManager implements LifecycleHooksManager {\n@@ -23,6 +24,15 @@ export class StandardLifecycleHooksManager implements LifecycleHooksManager {\n   private globalStartHooks: Map<string, RegisteredHookFunction<AnyOnStartHookFunction>> = new Map();\n   private taskStartHooks: Map<string, RegisteredHookFunction<AnyOnStartHookFunction>> = new Map();\n \n+  private globalStartAttemptHooks: Map<\n+    string,\n+    RegisteredHookFunction<AnyOnStartAttemptHookFunction>\n+  > = new Map();\n+  private taskStartAttemptHooks: Map<\n+    string,\n+    RegisteredHookFunction<AnyOnStartAttemptHookFunction>\n+  > = new Map();\n+\n   private globalFailureHooks: Map<string, RegisteredHookFunction<AnyOnFailureHookFunction>> =\n     new Map();\n   private taskFailureHooks: Map<string, RegisteredHookFunction<AnyOnFailureHookFunction>> =\n@@ -129,6 +139,37 @@ export class StandardLifecycleHooksManager implements LifecycleHooksManager {\n     return Array.from(this.globalStartHooks.values());\n   }\n \n+  registerGlobalStartAttemptHook(\n+    hook: RegisterHookFunctionParams<AnyOnStartAttemptHookFunction>\n+  ): void {\n+    const id = generateHookId(hook);\n+    this.globalStartAttemptHooks.set(id, {\n+      id,\n+      name: hook.id,\n+      fn: hook.fn,\n+    });\n+  }\n+\n+  registerTaskStartAttemptHook(\n+    taskId: string,\n+    hook: RegisterHookFunctionParams<AnyOnStartAttemptHookFunction>\n+  ): void {\n+    const id = generateHookId(hook);\n+    this.taskStartAttemptHooks.set(taskId, {\n+      id,\n+      name: hook.id,\n+      fn: hook.fn,\n+    });\n+  }\n+\n+  getTaskStartAttemptHook(taskId: string): AnyOnStartAttemptHookFunction | undefined {\n+    return this.taskStartAttemptHooks.get(taskId)?.fn;\n+  }\n+\n+  getGlobalStartAttemptHooks(): RegisteredHookFunction<AnyOnStartAttemptHookFunction>[] {\n+    return Array.from(this.globalStartAttemptHooks.values());\n+  }\n+\n   registerGlobalInitHook(hook: RegisterHookFunctionParams<AnyOnInitHookFunction>): void {\n     // if there is no id, lets generate one based on the contents of the function\n     const id = generateHookId(hook);\n@@ -527,6 +568,22 @@ export class NoopLifecycleHooksManager implements LifecycleHooksManager {\n     return [];\n   }\n \n+  registerGlobalStartAttemptHook(): void {\n+    // Noop\n+  }\n+\n+  registerTaskStartAttemptHook(): void {\n+    // Noop\n+  }\n+\n+  getTaskStartAttemptHook(): undefined {\n+    return undefined;\n+  }\n+\n+  getGlobalStartAttemptHooks(): RegisteredHookFunction<AnyOnStartAttemptHookFunction>[] {\n+    return [];\n+  }\n+\n   registerGlobalFailureHook(hook: RegisterHookFunctionParams<AnyOnFailureHookFunction>): void {\n     // Noop\n   }\ndiff --git a/packages/core/src/v3/lifecycleHooks/types.ts b/packages/core/src/v3/lifecycleHooks/types.ts\nindex 9501216546..51518a165a 100644\n--- a/packages/core/src/v3/lifecycleHooks/types.ts\n+++ b/packages/core/src/v3/lifecycleHooks/types.ts\n@@ -33,6 +33,19 @@ export type OnStartHookFunction<TPayload, TInitOutput extends TaskInitOutput = T\n \n export type AnyOnStartHookFunction = OnStartHookFunction<unknown, TaskInitOutput>;\n \n+export type TaskStartAttemptHookParams<TPayload = unknown> = {\n+  ctx: TaskRunContext;\n+  payload: TPayload;\n+  task: string;\n+  signal: AbortSignal;\n+};\n+\n+export type OnStartAttemptHookFunction<TPayload> = (\n+  params: TaskStartAttemptHookParams<TPayload>\n+) => undefined | void | Promise<undefined | void>;\n+\n+export type AnyOnStartAttemptHookFunction = OnStartAttemptHookFunction<unknown>;\n+\n export type TaskWait =\n   | {\n       type: \"duration\";\n@@ -268,6 +281,17 @@ export interface LifecycleHooksManager {\n   ): void;\n   getTaskStartHook(taskId: string): AnyOnStartHookFunction | undefined;\n   getGlobalStartHooks(): RegisteredHookFunction<AnyOnStartHookFunction>[];\n+\n+  registerGlobalStartAttemptHook(\n+    hook: RegisterHookFunctionParams<AnyOnStartAttemptHookFunction>\n+  ): void;\n+  registerTaskStartAttemptHook(\n+    taskId: string,\n+    hook: RegisterHookFunctionParams<AnyOnStartAttemptHookFunction>\n+  ): void;\n+  getTaskStartAttemptHook(taskId: string): AnyOnStartAttemptHookFunction | undefined;\n+  getGlobalStartAttemptHooks(): RegisteredHookFunction<AnyOnStartAttemptHookFunction>[];\n+\n   registerGlobalFailureHook(hook: RegisterHookFunctionParams<AnyOnFailureHookFunction>): void;\n   registerTaskFailureHook(\n     taskId: string,\ndiff --git a/packages/core/src/v3/types/tasks.ts b/packages/core/src/v3/types/tasks.ts\nindex 7000d2ab93..8500ee9f09 100644\n--- a/packages/core/src/v3/types/tasks.ts\n+++ b/packages/core/src/v3/types/tasks.ts\n@@ -13,6 +13,7 @@ import {\n   OnSuccessHookFunction,\n   OnWaitHookFunction,\n   OnCancelHookFunction,\n+  OnStartAttemptHookFunction,\n } from \"../lifecycleHooks/types.js\";\n import { RunTags } from \"../schemas/api.js\";\n import {\n@@ -114,6 +115,13 @@ export type StartFnParams = Prettify<{\n   signal: AbortSignal;\n }>;\n \n+export type StartAttemptFnParams = Prettify<{\n+  ctx: Context;\n+  init?: InitOutput;\n+  /** Abort signal that is aborted when a task run exceeds it's maxDuration or if the task run is cancelled. Can be used to automatically cancel downstream requests */\n+  signal: AbortSignal;\n+}>;\n+\n export type CancelFnParams = Prettify<{\n   ctx: Context;\n   /** Abort signal that is aborted when a task run exceeds it's maxDuration or if the task run is cancelled. Can be used to automatically cancel downstream requests */\n@@ -328,9 +336,18 @@ type CommonTaskOptions<\n \n   /**\n    * onStart is called the first time a task is executed in a run (not before every retry)\n+   *\n+   * @deprecated Use onStartAttempt instead\n    */\n   onStart?: OnStartHookFunction<TPayload, TInitOutput>;\n \n+  /**\n+   * onStartAttempt is called before each attempt of a task is executed.\n+   *\n+   * You can detect the first attempt by checking `ctx.attempt.number === 1`.\n+   */\n+  onStartAttempt?: OnStartAttemptHookFunction<TPayload>;\n+\n   /**\n    * onSuccess is called after the run function has successfully completed.\n    */\n@@ -913,6 +930,7 @@ export type TaskMetadataWithFunctions = TaskMetadata & {\n     onSuccess?: (payload: any, output: any, params: SuccessFnParams<any>) => Promise<void>;\n     onFailure?: (payload: any, error: unknown, params: FailureFnParams<any>) => Promise<void>;\n     onStart?: (payload: any, params: StartFnParams) => Promise<void>;\n+    onStartAttempt?: (payload: any, params: StartAttemptFnParams) => Promise<void>;\n     parsePayload?: AnySchemaParseFn;\n   };\n   schema?: TaskSchema;\ndiff --git a/packages/core/src/v3/workers/taskExecutor.ts b/packages/core/src/v3/workers/taskExecutor.ts\nindex b8972d2fb3..c232864884 100644\n--- a/packages/core/src/v3/workers/taskExecutor.ts\n+++ b/packages/core/src/v3/workers/taskExecutor.ts\n@@ -182,6 +182,8 @@ export class TaskExecutor {\n                   await this.#callOnStartFunctions(payload, ctx, initOutput, signal);\n                 }\n \n+                await this.#callOnStartAttemptFunctions(payload, ctx, signal);\n+\n                 try {\n                   return await this.#callRun(payload, ctx, initOutput, signal);\n                 } catch (error) {\n@@ -777,7 +779,7 @@ export class TaskExecutor {\n \n     return await runTimelineMetrics.measureMetric(\"trigger.dev/execution\", \"success\", async () => {\n       for (const hook of globalSuccessHooks) {\n-        const [hookError] = await tryCatch(\n+        await tryCatch(\n           this._tracer.startActiveSpan(\n             \"onSuccess()\",\n             async (span) => {\n@@ -799,14 +801,10 @@ export class TaskExecutor {\n             }\n           )\n         );\n-\n-        if (hookError) {\n-          throw hookError;\n-        }\n       }\n \n       if (taskSuccessHook) {\n-        const [hookError] = await tryCatch(\n+        await tryCatch(\n           this._tracer.startActiveSpan(\n             \"onSuccess()\",\n             async (span) => {\n@@ -828,10 +826,6 @@ export class TaskExecutor {\n             }\n           )\n         );\n-\n-        if (hookError) {\n-          throw hookError;\n-        }\n       }\n     });\n   }\n@@ -852,7 +846,7 @@ export class TaskExecutor {\n \n     return await runTimelineMetrics.measureMetric(\"trigger.dev/execution\", \"failure\", async () => {\n       for (const hook of globalFailureHooks) {\n-        const [hookError] = await tryCatch(\n+        await tryCatch(\n           this._tracer.startActiveSpan(\n             \"onFailure()\",\n             async (span) => {\n@@ -874,14 +868,10 @@ export class TaskExecutor {\n             }\n           )\n         );\n-\n-        if (hookError) {\n-          throw hookError;\n-        }\n       }\n \n       if (taskFailureHook) {\n-        const [hookError] = await tryCatch(\n+        await tryCatch(\n           this._tracer.startActiveSpan(\n             \"onFailure()\",\n             async (span) => {\n@@ -903,10 +893,6 @@ export class TaskExecutor {\n             }\n           )\n         );\n-\n-        if (hookError) {\n-          throw hookError;\n-        }\n       }\n     });\n   }\n@@ -989,6 +975,70 @@ export class TaskExecutor {\n     });\n   }\n \n+  async #callOnStartAttemptFunctions(payload: unknown, ctx: TaskRunContext, signal: AbortSignal) {\n+    const globalStartHooks = lifecycleHooks.getGlobalStartAttemptHooks();\n+    const taskStartHook = lifecycleHooks.getTaskStartAttemptHook(this.task.id);\n+\n+    if (globalStartHooks.length === 0 && !taskStartHook) {\n+      return;\n+    }\n+\n+    return await runTimelineMetrics.measureMetric(\n+      \"trigger.dev/execution\",\n+      \"startAttempt\",\n+      async () => {\n+        for (const hook of globalStartHooks) {\n+          const [hookError] = await tryCatch(\n+            this._tracer.startActiveSpan(\n+              \"onStartAttempt()\",\n+              async (span) => {\n+                await hook.fn({ payload, ctx, signal, task: this.task.id });\n+              },\n+              {\n+                attributes: {\n+                  [SemanticInternalAttributes.STYLE_ICON]: \"task-hook-onStartAttempt\",\n+                  [SemanticInternalAttributes.COLLAPSED]: true,\n+                  ...this.#lifecycleHookAccessoryAttributes(hook.name),\n+                },\n+              }\n+            )\n+          );\n+\n+          if (hookError) {\n+            throw hookError;\n+          }\n+        }\n+\n+        if (taskStartHook) {\n+          const [hookError] = await tryCatch(\n+            this._tracer.startActiveSpan(\n+              \"onStartAttempt()\",\n+              async (span) => {\n+                await taskStartHook({\n+                  payload,\n+                  ctx,\n+                  signal,\n+                  task: this.task.id,\n+                });\n+              },\n+              {\n+                attributes: {\n+                  [SemanticInternalAttributes.STYLE_ICON]: \"task-hook-onStartAttempt\",\n+                  [SemanticInternalAttributes.COLLAPSED]: true,\n+                  ...this.#lifecycleHookAccessoryAttributes(\"task\"),\n+                },\n+              }\n+            )\n+          );\n+\n+          if (hookError) {\n+            throw hookError;\n+          }\n+        }\n+      }\n+    );\n+  }\n+\n   async #cleanupAndWaitUntil(\n     payload: unknown,\n     ctx: TaskRunContext,\n@@ -1297,7 +1347,7 @@ export class TaskExecutor {\n \n     return await runTimelineMetrics.measureMetric(\"trigger.dev/execution\", \"complete\", async () => {\n       for (const hook of globalCompleteHooks) {\n-        const [hookError] = await tryCatch(\n+        await tryCatch(\n           this._tracer.startActiveSpan(\n             \"onComplete()\",\n             async (span) => {\n@@ -1319,14 +1369,10 @@ export class TaskExecutor {\n             }\n           )\n         );\n-\n-        if (hookError) {\n-          throw hookError;\n-        }\n       }\n \n       if (taskCompleteHook) {\n-        const [hookError] = await tryCatch(\n+        await tryCatch(\n           this._tracer.startActiveSpan(\n             \"onComplete()\",\n             async (span) => {\n@@ -1348,10 +1394,6 @@ export class TaskExecutor {\n             }\n           )\n         );\n-\n-        if (hookError) {\n-          throw hookError;\n-        }\n       }\n     });\n   }\ndiff --git a/packages/core/test/taskExecutor.test.ts b/packages/core/test/taskExecutor.test.ts\nindex 0bb4b51bf8..f7d14f5ba1 100644\n--- a/packages/core/test/taskExecutor.test.ts\n+++ b/packages/core/test/taskExecutor.test.ts\n@@ -269,6 +269,91 @@ describe(\"TaskExecutor\", () => {\n     });\n   });\n \n+  test(\"should call onStartAttempt hooks in correct order with proper data\", async () => {\n+    const globalStartOrder: string[] = [];\n+    const startPayloads: any[] = [];\n+\n+    // Register global init hook to provide init data\n+    lifecycleHooks.registerGlobalInitHook({\n+      id: \"test-init\",\n+      fn: async () => {\n+        return {\n+          foo: \"bar\",\n+        };\n+      },\n+    });\n+\n+    // Register two global start hooks\n+    lifecycleHooks.registerGlobalStartAttemptHook({\n+      id: \"global-start-1\",\n+      fn: async ({ payload, ctx }) => {\n+        console.log(\"Executing global start hook 1\");\n+        globalStartOrder.push(\"global-1\");\n+        startPayloads.push(payload);\n+      },\n+    });\n+\n+    lifecycleHooks.registerGlobalStartAttemptHook({\n+      id: \"global-start-2\",\n+      fn: async ({ payload, ctx }) => {\n+        console.log(\"Executing global start hook 2\");\n+        globalStartOrder.push(\"global-2\");\n+        startPayloads.push(payload);\n+      },\n+    });\n+\n+    // Register task-specific start hook\n+    lifecycleHooks.registerTaskStartAttemptHook(\"test-task\", {\n+      id: \"task-start\",\n+      fn: async ({ payload, ctx }) => {\n+        console.log(\"Executing task start hook\");\n+        globalStartOrder.push(\"task\");\n+        startPayloads.push(payload);\n+      },\n+    });\n+\n+    // Verify hooks are registered\n+    const globalHooks = lifecycleHooks.getGlobalStartAttemptHooks();\n+    console.log(\n+      \"Registered global hooks:\",\n+      globalHooks.map((h) => h.id)\n+    );\n+    const taskHook = lifecycleHooks.getTaskStartAttemptHook(\"test-task\");\n+    console.log(\"Registered task hook:\", taskHook ? \"yes\" : \"no\");\n+\n+    const task = {\n+      id: \"test-task\",\n+      fns: {\n+        run: async (payload: any, params: RunFnParams<any>) => {\n+          return {\n+            output: \"test-output\",\n+            init: params.init,\n+          };\n+        },\n+      },\n+    };\n+\n+    const result = await executeTask(task, { test: \"data\" }, undefined);\n+\n+    // Verify hooks were called in correct order\n+    expect(globalStartOrder).toEqual([\"global-1\", \"global-2\", \"task\"]);\n+\n+    // Verify each hook received the correct payload\n+    startPayloads.forEach((payload) => {\n+      expect(payload).toEqual({ test: \"data\" });\n+    });\n+\n+    // Verify the final result\n+    expect(result).toEqual({\n+      result: {\n+        ok: true,\n+        id: \"test-run-id\",\n+        output: '{\"json\":{\"output\":\"test-output\",\"init\":{\"foo\":\"bar\"}}}',\n+        outputType: \"application/super+json\",\n+      },\n+    });\n+  });\n+\n   test(\"should call onFailure hooks with error when task fails\", async () => {\n     const globalFailureOrder: string[] = [];\n     const failurePayloads: any[] = [];\n@@ -1246,6 +1331,48 @@ describe(\"TaskExecutor\", () => {\n     });\n   });\n \n+  test(\"should NOT propagate errors from onSuccess hooks\", async () => {\n+    const executionOrder: string[] = [];\n+    const expectedError = new Error(\"On success hook error\");\n+\n+    // Register global on success hook that throws an error\n+    lifecycleHooks.registerGlobalSuccessHook({\n+      id: \"global-success\",\n+      fn: async () => {\n+        executionOrder.push(\"global-success\");\n+        throw expectedError;\n+      },\n+    });\n+\n+    const task = {\n+      id: \"test-task\",\n+      fns: {\n+        run: async (payload: any, params: RunFnParams<any>) => {\n+          executionOrder.push(\"run\");\n+          return {\n+            output: \"test-output\",\n+          };\n+        },\n+      },\n+    };\n+\n+    // Expect that this does not throw an error\n+    const result = await executeTask(task, { test: \"data\" }, undefined);\n+\n+    // Verify that run was called and on success hook was called\n+    expect(executionOrder).toEqual([\"run\", \"global-success\"]);\n+\n+    // Verify the error result\n+    expect(result).toEqual({\n+      result: {\n+        ok: true,\n+        id: \"test-run-id\",\n+        output: '{\"json\":{\"output\":\"test-output\"}}',\n+        outputType: \"application/super+json\",\n+      },\n+    });\n+  });\n+\n   test(\"should call cleanup hooks in correct order after other hooks but before middleware completion\", async () => {\n     const executionOrder: string[] = [];\n \ndiff --git a/packages/trigger-sdk/src/v3/hooks.ts b/packages/trigger-sdk/src/v3/hooks.ts\nindex b4e9cd0988..c6811ca6e9 100644\n--- a/packages/trigger-sdk/src/v3/hooks.ts\n+++ b/packages/trigger-sdk/src/v3/hooks.ts\n@@ -12,6 +12,7 @@ import {\n   type AnyOnCatchErrorHookFunction,\n   type AnyOnMiddlewareHookFunction,\n   type AnyOnCancelHookFunction,\n+  type AnyOnStartAttemptHookFunction,\n } from \"@trigger.dev/core/v3\";\n \n export type {\n@@ -41,6 +42,18 @@ export function onStart(\n   });\n }\n \n+export function onStartAttempt(name: string, fn: AnyOnStartAttemptHookFunction): void;\n+export function onStartAttempt(fn: AnyOnStartAttemptHookFunction): void;\n+export function onStartAttempt(\n+  fnOrName: string | AnyOnStartAttemptHookFunction,\n+  fn?: AnyOnStartAttemptHookFunction\n+): void {\n+  lifecycleHooks.registerGlobalStartAttemptHook({\n+    id: typeof fnOrName === \"string\" ? fnOrName : fnOrName.name ? fnOrName.name : undefined,\n+    fn: typeof fnOrName === \"function\" ? fnOrName : fn!,\n+  });\n+}\n+\n export function onFailure(name: string, fn: AnyOnFailureHookFunction): void;\n export function onFailure(fn: AnyOnFailureHookFunction): void;\n export function onFailure(\ndiff --git a/packages/trigger-sdk/src/v3/shared.ts b/packages/trigger-sdk/src/v3/shared.ts\nindex e874c207d9..0990a04ce9 100644\n--- a/packages/trigger-sdk/src/v3/shared.ts\n+++ b/packages/trigger-sdk/src/v3/shared.ts\n@@ -90,6 +90,7 @@ import type {\n   TriggerAndWaitOptions,\n   TriggerApiRequestOptions,\n   TriggerOptions,\n+  AnyOnStartAttemptHookFunction,\n } from \"@trigger.dev/core/v3\";\n \n export type {\n@@ -1588,6 +1589,12 @@ function registerTaskLifecycleHooks<\n     });\n   }\n \n+  if (params.onStartAttempt) {\n+    lifecycleHooks.registerTaskStartAttemptHook(taskId, {\n+      fn: params.onStartAttempt as AnyOnStartAttemptHookFunction,\n+    });\n+  }\n+\n   if (params.onFailure) {\n     lifecycleHooks.registerTaskFailureHook(taskId, {\n       fn: params.onFailure as AnyOnFailureHookFunction,\ndiff --git a/packages/trigger-sdk/src/v3/tasks.ts b/packages/trigger-sdk/src/v3/tasks.ts\nindex 078666dc68..c8b3fbd4fe 100644\n--- a/packages/trigger-sdk/src/v3/tasks.ts\n+++ b/packages/trigger-sdk/src/v3/tasks.ts\n@@ -1,5 +1,6 @@\n import {\n   onStart,\n+  onStartAttempt,\n   onFailure,\n   onSuccess,\n   onComplete,\n@@ -88,7 +89,9 @@ export const tasks = {\n   batchTrigger,\n   triggerAndWait,\n   batchTriggerAndWait,\n+  /** @deprecated Use onStartAttempt instead */\n   onStart,\n+  onStartAttempt,\n   onFailure,\n   onSuccess,\n   onComplete,\ndiff --git a/references/hello-world/src/trigger/example.ts b/references/hello-world/src/trigger/example.ts\nindex b329faa741..4deb1476f7 100644\n--- a/references/hello-world/src/trigger/example.ts\n+++ b/references/hello-world/src/trigger/example.ts\n@@ -439,3 +439,93 @@ export const lotsOfLogsTask = task({\n     }\n   },\n });\n+\n+export const throwErrorInOnSuccessHookTask = task({\n+  id: \"throw-error-in-on-success-hook\",\n+  run: async (payload: { message: string }, { ctx }) => {\n+    logger.info(\"Hello, world from the throw error in on success hook task\", {\n+      message: payload.message,\n+    });\n+  },\n+  onSuccess: async ({ payload, output, ctx }) => {\n+    logger.info(\"Hello, world from the on success hook\", { payload, output });\n+    throw new Error(\"Forced error to cause a retry\");\n+  },\n+});\n+\n+export const throwErrorInOnStartHookTask = task({\n+  id: \"throw-error-in-on-start-hook\",\n+  run: async (payload: { message: string }, { ctx }) => {\n+    logger.info(\"Hello, world from the throw error in on start hook task\", {\n+      message: payload.message,\n+    });\n+  },\n+  onStart: async ({ payload, ctx }) => {\n+    logger.info(\"Hello, world from the on start hook\", { payload });\n+    throw new Error(\"Forced error to cause a retry\");\n+  },\n+});\n+\n+export const throwErrorInOnCompleteHookTask = task({\n+  id: \"throw-error-in-on-complete-hook\",\n+  run: async (payload: { message: string }, { ctx }) => {\n+    logger.info(\"Hello, world from the throw error in on complete hook task\", {\n+      message: payload.message,\n+    });\n+  },\n+  onComplete: async ({ payload, result, ctx }) => {\n+    logger.info(\"Hello, world from the on complete hook\", { payload, result });\n+    throw new Error(\"Forced error to cause a retry\");\n+  },\n+});\n+\n+export const throwErrorInOnFailureHookTask = task({\n+  id: \"throw-error-in-on-failure-hook\",\n+  retry: {\n+    maxAttempts: 1,\n+  },\n+  run: async (payload: { message: string }, { ctx }) => {\n+    logger.info(\"Hello, world from the throw error in on failure hook task\", {\n+      message: payload.message,\n+    });\n+    throw new Error(\"Forced error to cause a retry\");\n+  },\n+  onFailure: async ({ payload, error, ctx }) => {\n+    logger.info(\"Hello, world from the on failure hook\", { payload, error });\n+    throw new Error(\"Forced error to cause a retry in on failure hook\");\n+  },\n+});\n+\n+export const throwErrorInInitHookTask = task({\n+  id: \"throw-error-in-init-hook\",\n+  run: async (payload: { message: string }, { ctx }) => {\n+    logger.info(\"Hello, world from the throw error in init hook task\", {\n+      message: payload.message,\n+    });\n+  },\n+  init: async ({ payload, ctx }) => {\n+    logger.info(\"Hello, world from the init hook\", { payload });\n+    throw new Error(\"Forced error to cause a retry\");\n+  },\n+});\n+\n+export const testStartAttemptHookTask = task({\n+  id: \"test-start-attempt-hook\",\n+  retry: {\n+    maxAttempts: 3,\n+  },\n+  run: async (payload: { message: string }, { ctx }) => {\n+    logger.info(\"Hello, world from the test start attempt hook task\", { message: payload.message });\n+\n+    if (ctx.attempt.number === 1) {\n+      throw new Error(\"Forced error to cause a retry so we can test the onStartAttempt hook\");\n+    }\n+  },\n+  onStartAttempt: async ({ payload, ctx }) => {\n+    console.log(`onStartAttempt hook called ${ctx.attempt.number}`);\n+  },\n+});\n+\n+tasks.onStartAttempt(({ payload, ctx }) => {\n+  console.log(`global onStartAttempt hook called ${ctx.attempt.number}`);\n+});\n", "test_patch": "", "problem_statement": "", "hints_text": ""}
{"instance_id": "triggerdotdev__trigger.dev.pr_mirror.2669", "repo": "triggerdotdev/trigger.dev", "base_commit": "d0ad38d684dda13c2accdd81a818822e4d985f88", "head_commit": "1289a3150d3791a3527aeb6b7823d8ea415177e3", "title": "fix(streams): buffer v1 streams on read to prevent split chunks", "merged_at": "2025-11-11T21:08:49Z", "html_url": "https://github.com/triggerdotdev/trigger.dev/pull/2669", "test_files": ["apps/webapp/test/redisRealtimeStreams.test.ts"], "code_files": ["apps/webapp/app/services/realtime/redisRealtimeStreams.server.ts", "references/realtime-streams/src/trigger/streams.ts"], "total_changes": 163, "num_files": 3, "pull_number": 2669, "patch": "diff --git a/apps/webapp/app/services/realtime/redisRealtimeStreams.server.ts b/apps/webapp/app/services/realtime/redisRealtimeStreams.server.ts\nindex 9db3809b52..b5c8c57322 100644\n--- a/apps/webapp/app/services/realtime/redisRealtimeStreams.server.ts\n+++ b/apps/webapp/app/services/realtime/redisRealtimeStreams.server.ts\n@@ -204,20 +204,52 @@ export class RedisRealtimeStreams implements StreamIngestor, StreamResponder {\n       },\n     })\n       .pipeThrough(\n-        // Transform 1: Split data content by newlines, preserving metadata\n-        new TransformStream<StreamChunk, StreamChunk & { line?: string }>({\n-          transform(chunk, controller) {\n-            if (chunk.type === \"ping\") {\n-              controller.enqueue(chunk);\n-            } else if (chunk.type === \"data\" || chunk.type === \"legacy-data\") {\n-              // Split data by newlines, emit separate chunks with same metadata\n-              const lines = chunk.data.split(\"\\n\").filter((line) => line.trim().length > 0);\n-              for (const line of lines) {\n-                controller.enqueue({ ...chunk, line });\n+        // Transform 1: Buffer partial lines across Redis entries\n+        (() => {\n+          let buffer = \"\";\n+          let lastRedisId = \"0\";\n+\n+          return new TransformStream<StreamChunk, StreamChunk & { line: string }>({\n+            transform(chunk, controller) {\n+              if (chunk.type === \"ping\") {\n+                controller.enqueue(chunk as any);\n+              } else if (chunk.type === \"data\" || chunk.type === \"legacy-data\") {\n+                // Buffer partial lines: accumulate until we see newlines\n+                buffer += chunk.data;\n+\n+                // Split on newlines\n+                const lines = buffer.split(\"\\n\");\n+\n+                // The last element might be incomplete, hold it back in buffer\n+                buffer = lines.pop() || \"\";\n+\n+                // Emit complete lines with the Redis ID of the chunk that completed them\n+                for (const line of lines) {\n+                  if (line.trim().length > 0) {\n+                    controller.enqueue({\n+                      ...chunk,\n+                      line,\n+                    });\n+                  }\n+                }\n+\n+                // Update last Redis ID for next iteration\n+                lastRedisId = chunk.redisId;\n               }\n-            }\n-          },\n-        })\n+            },\n+            flush(controller) {\n+              // On stream end, emit any leftover buffered text\n+              if (buffer.trim().length > 0) {\n+                controller.enqueue({\n+                  type: \"data\",\n+                  redisId: lastRedisId,\n+                  data: \"\",\n+                  line: buffer.trim(),\n+                });\n+              }\n+            },\n+          });\n+        })()\n       )\n       .pipeThrough(\n         // Transform 2: Format as SSE\ndiff --git a/apps/webapp/test/redisRealtimeStreams.test.ts b/apps/webapp/test/redisRealtimeStreams.test.ts\nindex e441e4ace6..0511754393 100644\n--- a/apps/webapp/test/redisRealtimeStreams.test.ts\n+++ b/apps/webapp/test/redisRealtimeStreams.test.ts\n@@ -1417,4 +1417,108 @@ describe(\"RedisRealtimeStreams\", () => {\n       await redis.quit();\n     }\n   );\n+\n+  redisTest(\n+    \"Should handle chunks split mid-line (regression test)\",\n+    { timeout: 30_000 },\n+    async ({ redisOptions }) => {\n+      const redis = new Redis(redisOptions);\n+      const redisRealtimeStreams = new RedisRealtimeStreams({\n+        redis: redisOptions,\n+      });\n+\n+      const runId = \"run_split_test\";\n+      const streamId = \"test-split-stream\";\n+\n+      // Simulate what happens in production: a JSON line split across multiple network chunks\n+      // This reproduces the issue where we see partial chunks like:\n+      // - \"{\\\"timestamp\\\":\"\n+      // - \"1762880245493,\\\"chunkIndex\\\":780,\\\"data\\\":\\\"Chunk 781/1000\\\"}\"\n+      const fullLine = JSON.stringify({\n+        timestamp: 1762880245493,\n+        chunkIndex: 780,\n+        data: \"Chunk 781/1000\",\n+      });\n+\n+      // Split the line at an arbitrary position (in the middle of the JSON)\n+      const splitPoint = 16; // Splits after '{\"timestamp\":'\n+      const chunk1 = fullLine.substring(0, splitPoint);\n+      const chunk2 = fullLine.substring(splitPoint);\n+\n+      // Create a ReadableStream that sends split chunks\n+      const encoder = new TextEncoder();\n+      const stream = new ReadableStream({\n+        start(controller) {\n+          controller.enqueue(encoder.encode(chunk1));\n+          controller.enqueue(encoder.encode(chunk2 + \"\\n\")); // Add newline at end\n+          controller.close();\n+        },\n+      });\n+\n+      // Ingest the split data\n+      await redisRealtimeStreams.ingestData(stream, runId, streamId, \"client1\");\n+\n+      // Now consume the stream and verify we get the complete line, not split chunks\n+      const abortController = new AbortController();\n+      const response = await redisRealtimeStreams.streamResponse(\n+        new Request(\"http://localhost/test\"),\n+        runId,\n+        streamId,\n+        abortController.signal\n+      );\n+\n+      const reader = response.body!.getReader();\n+      const decoder = new TextDecoder();\n+      let receivedData = \"\";\n+\n+      // Read all chunks from the response\n+      const readTimeout = setTimeout(() => {\n+        abortController.abort();\n+      }, 5000);\n+\n+      try {\n+        while (true) {\n+          const { done, value } = await reader.read();\n+          if (done) break;\n+\n+          receivedData += decoder.decode(value, { stream: true });\n+\n+          // Once we have data, we can stop\n+          if (receivedData.includes(\"data: \")) {\n+            break;\n+          }\n+        }\n+      } finally {\n+        clearTimeout(readTimeout);\n+        abortController.abort();\n+        reader.releaseLock();\n+      }\n+\n+      // Parse the SSE data\n+      const lines = receivedData.split(\"\\n\").filter((line) => line.startsWith(\"data: \"));\n+\n+      // We should receive exactly ONE complete line, not two partial lines\n+      expect(lines.length).toBe(1);\n+\n+      // Extract the data (remove \"data: \" prefix)\n+      const dataLine = lines[0].substring(6);\n+\n+      // Verify it's the complete, valid JSON\n+      expect(dataLine).toBe(fullLine);\n+\n+      // Verify it parses correctly as JSON\n+      const parsed = JSON.parse(dataLine) as {\n+        timestamp: number;\n+        chunkIndex: number;\n+        data: string;\n+      };\n+      expect(parsed.timestamp).toBe(1762880245493);\n+      expect(parsed.chunkIndex).toBe(780);\n+      expect(parsed.data).toBe(\"Chunk 781/1000\");\n+\n+      // Cleanup\n+      await redis.del(`stream:${runId}:${streamId}`);\n+      await redis.quit();\n+    }\n+  );\n });\ndiff --git a/references/realtime-streams/src/trigger/streams.ts b/references/realtime-streams/src/trigger/streams.ts\nindex cfa64618ce..388ff960aa 100644\n--- a/references/realtime-streams/src/trigger/streams.ts\n+++ b/references/realtime-streams/src/trigger/streams.ts\n@@ -822,7 +822,6 @@ const streamsStressTesterTask = task({\n \n     switch (payload.streamsVersion) {\n       case \"v1\": {\n-        assert.ok(chunks.length < 2000, \"Expected less than 2000 chunks\");\n         break;\n       }\n       case \"v2\": {\n", "test_patch": "", "problem_statement": "", "hints_text": ""}
{"instance_id": "triggerdotdev__trigger.dev.pr_mirror.2637", "repo": "triggerdotdev/trigger.dev", "base_commit": "8fdbbeb02f3d022c2900e79f75f3e8cfa6be81b0", "head_commit": "ed87c1e1dc831f329382c7a8108153dad006e5b7", "title": "chore(runner): move max duration logic into parent process", "merged_at": "2025-10-28T13:49:59Z", "html_url": "https://github.com/triggerdotdev/trigger.dev/pull/2637", "test_files": ["packages/core/test/taskExecutor.test.ts"], "code_files": ["packages/cli-v3/src/entryPoints/dev-run-worker.ts", "packages/cli-v3/src/entryPoints/managed-run-worker.ts", "packages/cli-v3/src/executions/taskRunProcess.ts", "packages/core/src/v3/errors.ts", "packages/core/src/v3/schemas/messages.ts", "packages/core/src/v3/timeout/api.ts", "packages/core/src/v3/timeout/types.ts", "packages/core/src/v3/timeout/usageTimeoutManager.ts", "packages/core/src/v3/workers/taskExecutor.ts"], "total_changes": 234, "num_files": 12, "pull_number": 2637, "patch": "diff --git a/.changeset/big-ants-act.md b/.changeset/big-ants-act.md\nnew file mode 100644\nindex 0000000000..653c97ed44\n--- /dev/null\n+++ b/.changeset/big-ants-act.md\n@@ -0,0 +1,6 @@\n+---\n+\"trigger.dev\": patch\n+\"@trigger.dev/core\": patch\n+---\n+\n+Move max duration handling into the parent process\ndiff --git a/packages/cli-v3/src/entryPoints/dev-run-worker.ts b/packages/cli-v3/src/entryPoints/dev-run-worker.ts\nindex 9239f2b2bd..e02d9f8e44 100644\n--- a/packages/cli-v3/src/entryPoints/dev-run-worker.ts\n+++ b/packages/cli-v3/src/entryPoints/dev-run-worker.ts\n@@ -128,6 +128,17 @@ usage.setGlobalUsageManager(devUsageManager);\n const usageTimeoutManager = new UsageTimeoutManager(devUsageManager);\n timeout.setGlobalManager(usageTimeoutManager);\n \n+// Register listener to send IPC message when max duration is exceeded\n+timeout.registerListener(async (maxDurationInSeconds, elapsedTimeInSeconds) => {\n+  log(\n+    `[${new Date().toISOString()}] Max duration exceeded: ${maxDurationInSeconds}s, elapsed: ${elapsedTimeInSeconds}s`\n+  );\n+  await zodIpc.send(\"MAX_DURATION_EXCEEDED\", {\n+    maxDurationInSeconds,\n+    elapsedTimeInSeconds,\n+  });\n+});\n+\n const standardResourceCatalog = new StandardResourceCatalog();\n resourceCatalog.setGlobalResourceCatalog(standardResourceCatalog);\n \ndiff --git a/packages/cli-v3/src/entryPoints/managed-run-worker.ts b/packages/cli-v3/src/entryPoints/managed-run-worker.ts\nindex a9c593d720..09138fb82a 100644\n--- a/packages/cli-v3/src/entryPoints/managed-run-worker.ts\n+++ b/packages/cli-v3/src/entryPoints/managed-run-worker.ts\n@@ -726,6 +726,17 @@ function initializeUsageManager({\n   usage.setGlobalUsageManager(prodUsageManager);\n   timeout.setGlobalManager(new UsageTimeoutManager(devUsageManager));\n \n+  // Register listener to send IPC message when max duration is exceeded\n+  timeout.registerListener(async (maxDurationInSeconds, elapsedTimeInSeconds) => {\n+    console.log(\n+      `[${new Date().toISOString()}] Max duration exceeded: ${maxDurationInSeconds}s, elapsed: ${elapsedTimeInSeconds}s`\n+    );\n+    await zodIpc.send(\"MAX_DURATION_EXCEEDED\", {\n+      maxDurationInSeconds,\n+      elapsedTimeInSeconds,\n+    });\n+  });\n+\n   return prodUsageManager;\n }\n \ndiff --git a/packages/cli-v3/src/executions/taskRunProcess.ts b/packages/cli-v3/src/executions/taskRunProcess.ts\nindex be971294aa..6be1488aee 100644\n--- a/packages/cli-v3/src/executions/taskRunProcess.ts\n+++ b/packages/cli-v3/src/executions/taskRunProcess.ts\n@@ -30,6 +30,7 @@ import {\n   CleanupProcessError,\n   internalErrorFromUnexpectedExit,\n   GracefulExitTimeoutError,\n+  MaxDurationExceededError,\n   UnexpectedExitError,\n   SuspendedProcessError,\n } from \"@trigger.dev/core/v3/errors\";\n@@ -74,6 +75,8 @@ export class TaskRunProcess {\n   private _isBeingKilled: boolean = false;\n   private _isBeingCancelled: boolean = false;\n   private _isBeingSuspended: boolean = false;\n+  private _isMaxDurationExceeded: boolean = false;\n+  private _maxDurationInfo?: { maxDurationInSeconds: number; elapsedTimeInSeconds: number };\n   private _stderr: Array<string> = [];\n \n   public onTaskRunHeartbeat: Evt<string> = new Evt();\n@@ -209,6 +212,23 @@ export class TaskRunProcess {\n         SET_SUSPENDABLE: async (message) => {\n           this.onSetSuspendable.post(message);\n         },\n+        MAX_DURATION_EXCEEDED: async (message) => {\n+          logger.debug(\"max duration exceeded, gracefully terminating child process\", {\n+            maxDurationInSeconds: message.maxDurationInSeconds,\n+            elapsedTimeInSeconds: message.elapsedTimeInSeconds,\n+            pid: this.pid,\n+          });\n+\n+          // Set flag and store duration info for error reporting in #handleExit\n+          this._isMaxDurationExceeded = true;\n+          this._maxDurationInfo = {\n+            maxDurationInSeconds: message.maxDurationInSeconds,\n+            elapsedTimeInSeconds: message.elapsedTimeInSeconds,\n+          };\n+\n+          // Use the same graceful termination approach as cancel\n+          await this.#gracefullyTerminate(this.options.gracefulTerminationTimeoutInMs);\n+        },\n       },\n     });\n \n@@ -319,7 +339,25 @@ export class TaskRunProcess {\n \n         const { rejecter } = attemptPromise;\n \n-        if (this._isBeingCancelled) {\n+        if (this._isMaxDurationExceeded) {\n+          if (!this._maxDurationInfo) {\n+            rejecter(\n+              new UnexpectedExitError(\n+                code ?? -1,\n+                signal,\n+                \"MaxDuration flag set but duration info missing\"\n+              )\n+            );\n+            continue;\n+          }\n+\n+          rejecter(\n+            new MaxDurationExceededError(\n+              this._maxDurationInfo.maxDurationInSeconds,\n+              this._maxDurationInfo.elapsedTimeInSeconds\n+            )\n+          );\n+        } else if (this._isBeingCancelled) {\n           rejecter(new CancelledProcessError());\n         } else if (this._gracefulExitTimeoutElapsed) {\n           // Order matters, this has to be before the graceful exit timeout\n@@ -477,6 +515,14 @@ export class TaskRunProcess {\n       };\n     }\n \n+    if (error instanceof MaxDurationExceededError) {\n+      return {\n+        type: \"INTERNAL_ERROR\",\n+        code: TaskRunErrorCodes.MAX_DURATION_EXCEEDED,\n+        message: error.message,\n+      };\n+    }\n+\n     if (error instanceof CleanupProcessError) {\n       return {\n         type: \"INTERNAL_ERROR\",\ndiff --git a/packages/core/src/v3/errors.ts b/packages/core/src/v3/errors.ts\nindex 077289a659..fd03bf445f 100644\n--- a/packages/core/src/v3/errors.ts\n+++ b/packages/core/src/v3/errors.ts\n@@ -557,6 +557,17 @@ export class GracefulExitTimeoutError extends Error {\n   }\n }\n \n+export class MaxDurationExceededError extends Error {\n+  constructor(\n+    public readonly maxDurationInSeconds: number,\n+    public readonly elapsedTimeInSeconds: number\n+  ) {\n+    super(`Run exceeded maximum compute time (maxDuration) of ${maxDurationInSeconds} seconds`);\n+\n+    this.name = \"MaxDurationExceededError\";\n+  }\n+}\n+\n type ErrorLink = {\n   name: string;\n   href: string;\ndiff --git a/packages/core/src/v3/schemas/messages.ts b/packages/core/src/v3/schemas/messages.ts\nindex ebe3dc39b3..c635e57445 100644\n--- a/packages/core/src/v3/schemas/messages.ts\n+++ b/packages/core/src/v3/schemas/messages.ts\n@@ -189,6 +189,13 @@ export const ExecutorToWorkerMessageCatalog = {\n       suspendable: z.boolean(),\n     }),\n   },\n+  MAX_DURATION_EXCEEDED: {\n+    message: z.object({\n+      version: z.literal(\"v1\").default(\"v1\"),\n+      maxDurationInSeconds: z.number(),\n+      elapsedTimeInSeconds: z.number(),\n+    }),\n+  },\n };\n \n export const WorkerToExecutorMessageCatalog = {\ndiff --git a/packages/core/src/v3/timeout/api.ts b/packages/core/src/v3/timeout/api.ts\nindex 63ddb48db3..dd211bc42c 100644\n--- a/packages/core/src/v3/timeout/api.ts\n+++ b/packages/core/src/v3/timeout/api.ts\n@@ -47,6 +47,13 @@ export class TimeoutAPI implements TimeoutManager {\n     this.disable();\n   }\n \n+  public registerListener(listener: (timeoutInSeconds: number, elapsedTimeInSeconds: number) => void | Promise<void>) {\n+    const manager = this.#getManager();\n+    if (manager.registerListener) {\n+      manager.registerListener(listener);\n+    }\n+  }\n+\n   #getManager(): TimeoutManager {\n     return getGlobal(API_NAME) ?? NOOP_TIMEOUT_MANAGER;\n   }\ndiff --git a/packages/core/src/v3/timeout/types.ts b/packages/core/src/v3/timeout/types.ts\nindex 0ea0b8fe34..6978689676 100644\n--- a/packages/core/src/v3/timeout/types.ts\n+++ b/packages/core/src/v3/timeout/types.ts\n@@ -2,6 +2,7 @@ export interface TimeoutManager {\n   abortAfterTimeout: (timeoutInSeconds?: number) => AbortController;\n   signal?: AbortSignal;\n   reset: () => void;\n+  registerListener?: (listener: (timeoutInSeconds: number, elapsedTimeInSeconds: number) => void | Promise<void>) => void;\n }\n \n export class TaskRunExceededMaxDuration extends Error {\ndiff --git a/packages/core/src/v3/timeout/usageTimeoutManager.ts b/packages/core/src/v3/timeout/usageTimeoutManager.ts\nindex ec14ffe6cc..3a6a196dce 100644\n--- a/packages/core/src/v3/timeout/usageTimeoutManager.ts\n+++ b/packages/core/src/v3/timeout/usageTimeoutManager.ts\n@@ -5,11 +5,21 @@ export class UsageTimeoutManager implements TimeoutManager {\n   private _abortController: AbortController;\n   private _abortSignal: AbortSignal | undefined;\n   private _intervalId: NodeJS.Timeout | undefined;\n+  private _listener?: (\n+    timeoutInSeconds: number,\n+    elapsedTimeInSeconds: number\n+  ) => void | Promise<void>;\n \n   constructor(private readonly usageManager: UsageManager) {\n     this._abortController = new AbortController();\n   }\n \n+  registerListener(\n+    listener: (timeoutInSeconds: number, elapsedTimeInSeconds: number) => void | Promise<void>\n+  ): void {\n+    this._listener = listener;\n+  }\n+\n   get signal(): AbortSignal | undefined {\n     return this._abortSignal;\n   }\n@@ -42,8 +52,15 @@ export class UsageTimeoutManager implements TimeoutManager {\n         if (sample.cpuTime > timeoutInSeconds * 1000) {\n           clearInterval(this._intervalId);\n \n+          const elapsedTimeInSeconds = sample.cpuTime / 1000;\n+\n+          // Call the listener if registered\n+          if (this._listener) {\n+            void this._listener(timeoutInSeconds, elapsedTimeInSeconds);\n+          }\n+\n           this._abortController.abort(\n-            new TaskRunExceededMaxDuration(timeoutInSeconds, sample.cpuTime / 1000)\n+            new TaskRunExceededMaxDuration(timeoutInSeconds, elapsedTimeInSeconds)\n           );\n         }\n       }\ndiff --git a/packages/core/src/v3/workers/taskExecutor.ts b/packages/core/src/v3/workers/taskExecutor.ts\nindex 6de4c77a5f..ca724744a5 100644\n--- a/packages/core/src/v3/workers/taskExecutor.ts\n+++ b/packages/core/src/v3/workers/taskExecutor.ts\n@@ -3,7 +3,6 @@ import { promiseWithResolvers } from \"../../utils.js\";\n import { ApiError, RateLimitError } from \"../apiClient/errors.js\";\n import { ConsoleInterceptor } from \"../consoleInterceptor.js\";\n import {\n-  InternalError,\n   isCompleteTaskWithOutput,\n   isInternalError,\n   parseError,\n@@ -419,29 +418,13 @@ export class TaskExecutor {\n       throw new Error(\"Task does not have a run function\");\n     }\n \n-    // Create a promise that rejects when the signal aborts\n-    const abortPromise = new Promise((_, reject) => {\n-      signal.addEventListener(\"abort\", () => {\n-        if (typeof signal.reason === \"string\" && signal.reason.includes(\"cancel\")) {\n-          return;\n-        }\n-\n-        const maxDuration = ctx.run.maxDuration;\n-        reject(\n-          new InternalError({\n-            code: TaskRunErrorCodes.MAX_DURATION_EXCEEDED,\n-            message: `Run exceeded maximum compute time (maxDuration) of ${maxDuration} seconds`,\n-          })\n-        );\n-      });\n-    });\n-\n     return runTimelineMetrics.measureMetric(\"trigger.dev/execution\", \"run\", async () => {\n       return await this._tracer.startActiveSpan(\n         \"run()\",\n         async (span) => {\n-          // Race between the run function and the abort promise\n-          return await Promise.race([runFn(payload, { ctx, init, signal }), abortPromise]);\n+          // maxDuration is now enforced by killing the process, not by Promise.race\n+          // The signal is still passed to runFn for cancellation and other abort conditions\n+          return await runFn(payload, { ctx, init, signal });\n         },\n         {\n           attributes: { [SemanticInternalAttributes.STYLE_ICON]: \"task-fn-run\" },\ndiff --git a/packages/core/test/taskExecutor.test.ts b/packages/core/test/taskExecutor.test.ts\nindex 229a952fff..0bb4b51bf8 100644\n--- a/packages/core/test/taskExecutor.test.ts\n+++ b/packages/core/test/taskExecutor.test.ts\n@@ -1459,93 +1459,6 @@ describe(\"TaskExecutor\", () => {\n     });\n   });\n \n-  test(\"should handle max duration abort signal and call hooks in correct order\", async () => {\n-    const executionOrder: string[] = [];\n-    const maxDurationSeconds = 1000;\n-\n-    // Create an abort controller that we'll trigger manually\n-    const controller = new AbortController();\n-\n-    // Register global init hook\n-    lifecycleHooks.registerGlobalInitHook({\n-      id: \"test-init\",\n-      fn: async () => {\n-        executionOrder.push(\"init\");\n-        return {\n-          foo: \"bar\",\n-        };\n-      },\n-    });\n-\n-    // Register failure hook\n-    lifecycleHooks.registerGlobalFailureHook({\n-      id: \"global-failure\",\n-      fn: async ({ error }) => {\n-        executionOrder.push(\"failure\");\n-        expect((error as Error).message).toBe(\n-          `Run exceeded maximum compute time (maxDuration) of ${maxDurationSeconds} seconds`\n-        );\n-      },\n-    });\n-\n-    // Register complete hook\n-    lifecycleHooks.registerGlobalCompleteHook({\n-      id: \"global-complete\",\n-      fn: async ({ result }) => {\n-        executionOrder.push(\"complete\");\n-        expect(result.ok).toBe(false);\n-      },\n-    });\n-\n-    // Register cleanup hook\n-    lifecycleHooks.registerGlobalCleanupHook({\n-      id: \"global-cleanup\",\n-      fn: async () => {\n-        executionOrder.push(\"cleanup\");\n-      },\n-    });\n-\n-    const task = {\n-      id: \"test-task\",\n-      fns: {\n-        run: async (payload: any, params: RunFnParams<any>) => {\n-          executionOrder.push(\"run-start\");\n-\n-          // Create a promise that never resolves\n-          await new Promise((resolve) => {\n-            // Trigger abort after a small delay\n-            setTimeout(() => {\n-              controller.abort();\n-            }, 10);\n-          });\n-\n-          // This should never be reached\n-          executionOrder.push(\"run-end\");\n-        },\n-      },\n-    };\n-\n-    const result = await executeTask(task, { test: \"data\" }, controller.signal);\n-\n-    // Verify hooks were called in correct order\n-    expect(executionOrder).toEqual([\"init\", \"run-start\", \"failure\", \"complete\", \"cleanup\"]);\n-\n-    // Verify the error result\n-    expect(result).toEqual({\n-      result: {\n-        ok: false,\n-        id: \"test-run-id\",\n-        error: {\n-          type: \"INTERNAL_ERROR\",\n-          code: TaskRunErrorCodes.MAX_DURATION_EXCEEDED,\n-          message: \"Run exceeded maximum compute time (maxDuration) of 1000 seconds\",\n-          stackTrace: expect.any(String),\n-        },\n-        skippedRetrying: false,\n-      },\n-    });\n-  });\n-\n   test(\"should call onWait and onResume hooks in correct order with proper data\", async () => {\n     const executionOrder: string[] = [];\n     const waitData = { type: \"task\", runId: \"test-run-id\" } as const;\ndiff --git a/packages/rsc/src/package.json b/packages/rsc/src/package.json\ndeleted file mode 100644\nindex 3dbc1ca591..0000000000\n--- a/packages/rsc/src/package.json\n+++ /dev/null\n@@ -1,3 +0,0 @@\n-{\n-  \"type\": \"module\"\n-}\n", "test_patch": "", "problem_statement": "", "hints_text": ""}
{"instance_id": "triggerdotdev__trigger.dev.pr_mirror.2583", "repo": "triggerdotdev/trigger.dev", "base_commit": "cdd1a8838cc24c489997ea50a294e60b1ed41c0b", "head_commit": "efe15f5804649ac233ad85dee5eff18ed624c94d", "title": "fix(otel): propagate the task event store to run descendants", "merged_at": "2025-10-04T14:28:17Z", "html_url": "https://github.com/triggerdotdev/trigger.dev/pull/2583", "test_files": ["apps/webapp/test/engine/triggerTask.test.ts"], "code_files": ["apps/webapp/app/runEngine/concerns/idempotencyKeys.server.ts", "apps/webapp/app/runEngine/concerns/traceEvents.server.ts", "apps/webapp/app/runEngine/services/triggerTask.server.ts", "apps/webapp/app/runEngine/types.ts", "apps/webapp/app/v3/eventRepository/index.server.ts", "apps/webapp/app/v3/services/triggerTask.server.ts", "apps/webapp/app/v3/services/triggerTaskV1.server.ts"], "total_changes": 265, "num_files": 8, "pull_number": 2583, "patch": "diff --git a/apps/webapp/app/runEngine/concerns/idempotencyKeys.server.ts b/apps/webapp/app/runEngine/concerns/idempotencyKeys.server.ts\nindex 3080ae871a..d22c8020d2 100644\n--- a/apps/webapp/app/runEngine/concerns/idempotencyKeys.server.ts\n+++ b/apps/webapp/app/runEngine/concerns/idempotencyKeys.server.ts\n@@ -17,7 +17,10 @@ export class IdempotencyKeyConcern {\n     private readonly traceEventConcern: TraceEventConcern\n   ) {}\n \n-  async handleTriggerRequest(request: TriggerTaskRequest): Promise<IdempotencyKeyConcernResult> {\n+  async handleTriggerRequest(\n+    request: TriggerTaskRequest,\n+    parentStore: string | undefined\n+  ): Promise<IdempotencyKeyConcernResult> {\n     const idempotencyKey = request.options?.idempotencyKey ?? request.body.options?.idempotencyKey;\n     const idempotencyKeyExpiresAt =\n       request.options?.idempotencyKeyExpiresAt ??\n@@ -83,6 +86,7 @@ export class IdempotencyKeyConcern {\n       if (associatedWaitpoint && resumeParentOnCompletion && parentRunId) {\n         await this.traceEventConcern.traceIdempotentRun(\n           request,\n+          parentStore,\n           {\n             existingRun,\n             idempotencyKey,\ndiff --git a/apps/webapp/app/runEngine/concerns/traceEvents.server.ts b/apps/webapp/app/runEngine/concerns/traceEvents.server.ts\nindex 7d880a5e57..634df34e4a 100644\n--- a/apps/webapp/app/runEngine/concerns/traceEvents.server.ts\n+++ b/apps/webapp/app/runEngine/concerns/traceEvents.server.ts\n@@ -1,39 +1,26 @@\n-import { EventRepository } from \"~/v3/eventRepository/eventRepository.server\";\n-import { TracedEventSpan, TraceEventConcern, TriggerTaskRequest } from \"../types\";\n import { SemanticInternalAttributes } from \"@trigger.dev/core/v3/semanticInternalAttributes\";\n import { TaskRun } from \"@trigger.dev/database\";\n-import { getTaskEventStore } from \"~/v3/taskEventStore.server\";\n-import { ClickhouseEventRepository } from \"~/v3/eventRepository/clickhouseEventRepository.server\";\n import { IEventRepository } from \"~/v3/eventRepository/eventRepository.types\";\n-import { FEATURE_FLAG, flags } from \"~/v3/featureFlags.server\";\n-import { env } from \"~/env.server\";\n import { getEventRepository } from \"~/v3/eventRepository/index.server\";\n+import { TracedEventSpan, TraceEventConcern, TriggerTaskRequest } from \"../types\";\n \n export class DefaultTraceEventsConcern implements TraceEventConcern {\n-  private readonly eventRepository: EventRepository;\n-  private readonly clickhouseEventRepository: ClickhouseEventRepository;\n-\n-  constructor(\n-    eventRepository: EventRepository,\n-    clickhouseEventRepository: ClickhouseEventRepository\n-  ) {\n-    this.eventRepository = eventRepository;\n-    this.clickhouseEventRepository = clickhouseEventRepository;\n-  }\n-\n   async #getEventRepository(\n-    request: TriggerTaskRequest\n+    request: TriggerTaskRequest,\n+    parentStore: string | undefined\n   ): Promise<{ repository: IEventRepository; store: string }> {\n     return await getEventRepository(\n-      request.environment.organization.featureFlags as Record<string, unknown>\n+      request.environment.organization.featureFlags as Record<string, unknown>,\n+      parentStore\n     );\n   }\n \n   async traceRun<T>(\n     request: TriggerTaskRequest,\n+    parentStore: string | undefined,\n     callback: (span: TracedEventSpan, store: string) => Promise<T>\n   ): Promise<T> {\n-    const { repository, store } = await this.#getEventRepository(request);\n+    const { repository, store } = await this.#getEventRepository(request, parentStore);\n \n     return await repository.traceEvent(\n       request.taskId,\n@@ -73,6 +60,7 @@ export class DefaultTraceEventsConcern implements TraceEventConcern {\n \n   async traceIdempotentRun<T>(\n     request: TriggerTaskRequest,\n+    parentStore: string | undefined,\n     options: {\n       existingRun: TaskRun;\n       idempotencyKey: string;\n@@ -82,7 +70,7 @@ export class DefaultTraceEventsConcern implements TraceEventConcern {\n     callback: (span: TracedEventSpan, store: string) => Promise<T>\n   ): Promise<T> {\n     const { existingRun, idempotencyKey, incomplete, isError } = options;\n-    const { repository, store } = await this.#getEventRepository(request);\n+    const { repository, store } = await this.#getEventRepository(request, parentStore);\n \n     return await repository.traceEvent(\n       `${request.taskId} (cached)`,\n@@ -107,7 +95,7 @@ export class DefaultTraceEventsConcern implements TraceEventConcern {\n       },\n       async (event, traceContext, traceparent) => {\n         //log a message\n-        await this.eventRepository.recordEvent(\n+        await repository.recordEvent(\n           `There's an existing run for idempotencyKey: ${idempotencyKey}`,\n           {\n             taskSlug: request.taskId,\ndiff --git a/apps/webapp/app/runEngine/services/triggerTask.server.ts b/apps/webapp/app/runEngine/services/triggerTask.server.ts\nindex 4916e237bb..144d9b3178 100644\n--- a/apps/webapp/app/runEngine/services/triggerTask.server.ts\n+++ b/apps/webapp/app/runEngine/services/triggerTask.server.ts\n@@ -197,7 +197,8 @@ export class RunEngineTriggerTaskService {\n       }\n \n       const idempotencyKeyConcernResult = await this.idempotencyKeyConcern.handleTriggerRequest(\n-        triggerRequest\n+        triggerRequest,\n+        parentRun?.taskEventStore\n       );\n \n       if (idempotencyKeyConcernResult.isCached) {\n@@ -266,105 +267,109 @@ export class RunEngineTriggerTaskService {\n       const workerQueue = await this.queueConcern.getWorkerQueue(environment, body.options?.region);\n \n       try {\n-        return await this.traceEventConcern.traceRun(triggerRequest, async (event, store) => {\n-          const result = await this.runNumberIncrementer.incrementRunNumber(\n-            triggerRequest,\n-            async (num) => {\n-              event.setAttribute(\"queueName\", queueName);\n-              span.setAttribute(\"queueName\", queueName);\n-              event.setAttribute(\"runId\", runFriendlyId);\n-              span.setAttribute(\"runId\", runFriendlyId);\n-\n-              const payloadPacket = await this.payloadProcessor.process(triggerRequest);\n-\n-              const taskRun = await this.engine.trigger(\n-                {\n-                  number: num,\n-                  friendlyId: runFriendlyId,\n-                  environment: environment,\n-                  idempotencyKey,\n-                  idempotencyKeyExpiresAt: idempotencyKey ? idempotencyKeyExpiresAt : undefined,\n-                  taskIdentifier: taskId,\n-                  payload: payloadPacket.data ?? \"\",\n-                  payloadType: payloadPacket.dataType,\n-                  context: body.context,\n-                  traceContext: this.#propagateExternalTraceContext(\n-                    event.traceContext,\n-                    parentRun?.traceContext,\n-                    event.traceparent?.spanId\n-                  ),\n-                  traceId: event.traceId,\n-                  spanId: event.spanId,\n-                  parentSpanId:\n-                    options.parentAsLinkType === \"replay\" ? undefined : event.traceparent?.spanId,\n-                  replayedFromTaskRunFriendlyId: options.replayedFromTaskRunFriendlyId,\n-                  lockedToVersionId: lockedToBackgroundWorker?.id,\n-                  taskVersion: lockedToBackgroundWorker?.version,\n-                  sdkVersion: lockedToBackgroundWorker?.sdkVersion,\n-                  cliVersion: lockedToBackgroundWorker?.cliVersion,\n-                  concurrencyKey: body.options?.concurrencyKey,\n-                  queue: queueName,\n-                  lockedQueueId,\n-                  workerQueue,\n-                  isTest: body.options?.test ?? false,\n-                  delayUntil,\n-                  queuedAt: delayUntil ? undefined : new Date(),\n-                  maxAttempts: body.options?.maxAttempts,\n-                  taskEventStore: store,\n-                  ttl,\n-                  tags,\n-                  oneTimeUseToken: options.oneTimeUseToken,\n-                  parentTaskRunId: parentRun?.id,\n-                  rootTaskRunId: parentRun?.rootTaskRunId ?? parentRun?.id,\n-                  batch: options?.batchId\n-                    ? {\n-                        id: options.batchId,\n-                        index: options.batchIndex ?? 0,\n-                      }\n-                    : undefined,\n-                  resumeParentOnCompletion: body.options?.resumeParentOnCompletion,\n-                  depth,\n-                  metadata: metadataPacket?.data,\n-                  metadataType: metadataPacket?.dataType,\n-                  seedMetadata: metadataPacket?.data,\n-                  seedMetadataType: metadataPacket?.dataType,\n-                  maxDurationInSeconds: body.options?.maxDuration\n-                    ? clampMaxDuration(body.options.maxDuration)\n-                    : undefined,\n-                  machine: body.options?.machine,\n-                  priorityMs: body.options?.priority ? body.options.priority * 1_000 : undefined,\n-                  queueTimestamp:\n-                    options.queueTimestamp ??\n-                    (parentRun && body.options?.resumeParentOnCompletion\n-                      ? parentRun.queueTimestamp ?? undefined\n-                      : undefined),\n-                  scheduleId: options.scheduleId,\n-                  scheduleInstanceId: options.scheduleInstanceId,\n-                  createdAt: options.overrideCreatedAt,\n-                  bulkActionId: body.options?.bulkActionId,\n-                  planType,\n-                },\n-                this.prisma\n-              );\n-\n-              const error = taskRun.error ? TaskRunError.parse(taskRun.error) : undefined;\n-\n-              if (error) {\n-                event.failWithError(error);\n+        return await this.traceEventConcern.traceRun(\n+          triggerRequest,\n+          parentRun?.taskEventStore,\n+          async (event, store) => {\n+            const result = await this.runNumberIncrementer.incrementRunNumber(\n+              triggerRequest,\n+              async (num) => {\n+                event.setAttribute(\"queueName\", queueName);\n+                span.setAttribute(\"queueName\", queueName);\n+                event.setAttribute(\"runId\", runFriendlyId);\n+                span.setAttribute(\"runId\", runFriendlyId);\n+\n+                const payloadPacket = await this.payloadProcessor.process(triggerRequest);\n+\n+                const taskRun = await this.engine.trigger(\n+                  {\n+                    number: num,\n+                    friendlyId: runFriendlyId,\n+                    environment: environment,\n+                    idempotencyKey,\n+                    idempotencyKeyExpiresAt: idempotencyKey ? idempotencyKeyExpiresAt : undefined,\n+                    taskIdentifier: taskId,\n+                    payload: payloadPacket.data ?? \"\",\n+                    payloadType: payloadPacket.dataType,\n+                    context: body.context,\n+                    traceContext: this.#propagateExternalTraceContext(\n+                      event.traceContext,\n+                      parentRun?.traceContext,\n+                      event.traceparent?.spanId\n+                    ),\n+                    traceId: event.traceId,\n+                    spanId: event.spanId,\n+                    parentSpanId:\n+                      options.parentAsLinkType === \"replay\" ? undefined : event.traceparent?.spanId,\n+                    replayedFromTaskRunFriendlyId: options.replayedFromTaskRunFriendlyId,\n+                    lockedToVersionId: lockedToBackgroundWorker?.id,\n+                    taskVersion: lockedToBackgroundWorker?.version,\n+                    sdkVersion: lockedToBackgroundWorker?.sdkVersion,\n+                    cliVersion: lockedToBackgroundWorker?.cliVersion,\n+                    concurrencyKey: body.options?.concurrencyKey,\n+                    queue: queueName,\n+                    lockedQueueId,\n+                    workerQueue,\n+                    isTest: body.options?.test ?? false,\n+                    delayUntil,\n+                    queuedAt: delayUntil ? undefined : new Date(),\n+                    maxAttempts: body.options?.maxAttempts,\n+                    taskEventStore: store,\n+                    ttl,\n+                    tags,\n+                    oneTimeUseToken: options.oneTimeUseToken,\n+                    parentTaskRunId: parentRun?.id,\n+                    rootTaskRunId: parentRun?.rootTaskRunId ?? parentRun?.id,\n+                    batch: options?.batchId\n+                      ? {\n+                          id: options.batchId,\n+                          index: options.batchIndex ?? 0,\n+                        }\n+                      : undefined,\n+                    resumeParentOnCompletion: body.options?.resumeParentOnCompletion,\n+                    depth,\n+                    metadata: metadataPacket?.data,\n+                    metadataType: metadataPacket?.dataType,\n+                    seedMetadata: metadataPacket?.data,\n+                    seedMetadataType: metadataPacket?.dataType,\n+                    maxDurationInSeconds: body.options?.maxDuration\n+                      ? clampMaxDuration(body.options.maxDuration)\n+                      : undefined,\n+                    machine: body.options?.machine,\n+                    priorityMs: body.options?.priority ? body.options.priority * 1_000 : undefined,\n+                    queueTimestamp:\n+                      options.queueTimestamp ??\n+                      (parentRun && body.options?.resumeParentOnCompletion\n+                        ? parentRun.queueTimestamp ?? undefined\n+                        : undefined),\n+                    scheduleId: options.scheduleId,\n+                    scheduleInstanceId: options.scheduleInstanceId,\n+                    createdAt: options.overrideCreatedAt,\n+                    bulkActionId: body.options?.bulkActionId,\n+                    planType,\n+                  },\n+                  this.prisma\n+                );\n+\n+                const error = taskRun.error ? TaskRunError.parse(taskRun.error) : undefined;\n+\n+                if (error) {\n+                  event.failWithError(error);\n+                }\n+\n+                return { run: taskRun, error, isCached: false };\n               }\n+            );\n \n-              return { run: taskRun, error, isCached: false };\n+            if (result?.error) {\n+              throw new ServiceValidationError(\n+                taskRunErrorToString(taskRunErrorEnhancer(result.error))\n+              );\n             }\n-          );\n \n-          if (result?.error) {\n-            throw new ServiceValidationError(\n-              taskRunErrorToString(taskRunErrorEnhancer(result.error))\n-            );\n+            return result;\n           }\n-\n-          return result;\n-        });\n+        );\n       } catch (error) {\n         if (error instanceof RunDuplicateIdempotencyKeyError) {\n           //retry calling this function, because this time it will return the idempotent run\ndiff --git a/apps/webapp/app/runEngine/types.ts b/apps/webapp/app/runEngine/types.ts\nindex 2324edc6b8..0aa52d0a40 100644\n--- a/apps/webapp/app/runEngine/types.ts\n+++ b/apps/webapp/app/runEngine/types.ts\n@@ -143,10 +143,12 @@ export type TracedEventSpan = {\n export interface TraceEventConcern {\n   traceRun<T>(\n     request: TriggerTaskRequest,\n+    parentStore: string | undefined,\n     callback: (span: TracedEventSpan, store: string) => Promise<T>\n   ): Promise<T>;\n   traceIdempotentRun<T>(\n     request: TriggerTaskRequest,\n+    parentStore: string | undefined,\n     options: {\n       existingRun: TaskRun;\n       idempotencyKey: string;\ndiff --git a/apps/webapp/app/v3/eventRepository/index.server.ts b/apps/webapp/app/v3/eventRepository/index.server.ts\nindex cda9e58940..3bf77fcd76 100644\n--- a/apps/webapp/app/v3/eventRepository/index.server.ts\n+++ b/apps/webapp/app/v3/eventRepository/index.server.ts\n@@ -18,8 +18,17 @@ export function resolveEventRepositoryForStore(store: string | undefined): IEven\n }\n \n export async function getEventRepository(\n-  featureFlags: Record<string, unknown> | undefined\n+  featureFlags: Record<string, unknown> | undefined,\n+  parentStore: string | undefined\n ): Promise<{ repository: IEventRepository; store: string }> {\n+  if (typeof parentStore === \"string\") {\n+    if (parentStore === \"clickhouse\") {\n+      return { repository: clickhouseEventRepository, store: \"clickhouse\" };\n+    } else {\n+      return { repository: eventRepository, store: getTaskEventStore() };\n+    }\n+  }\n+\n   const taskEventRepository = await resolveTaskEventRepositoryFlag(featureFlags);\n \n   if (taskEventRepository === \"clickhouse\") {\ndiff --git a/apps/webapp/app/v3/services/triggerTask.server.ts b/apps/webapp/app/v3/services/triggerTask.server.ts\nindex 5f56a35af2..235dddd7d6 100644\n--- a/apps/webapp/app/v3/services/triggerTask.server.ts\n+++ b/apps/webapp/app/v3/services/triggerTask.server.ts\n@@ -1,5 +1,6 @@\n import { TriggerTaskRequestBody } from \"@trigger.dev/core/v3\";\n import { RunEngineVersion, TaskRun } from \"@trigger.dev/database\";\n+import { env } from \"~/env.server\";\n import { IdempotencyKeyConcern } from \"~/runEngine/concerns/idempotencyKeys.server\";\n import { DefaultPayloadProcessor } from \"~/runEngine/concerns/payloads.server\";\n import { DefaultQueueManager } from \"~/runEngine/concerns/queues.server\";\n@@ -9,12 +10,9 @@ import { RunEngineTriggerTaskService } from \"~/runEngine/services/triggerTask.se\n import { DefaultTriggerTaskValidator } from \"~/runEngine/validators/triggerTaskValidator\";\n import { AuthenticatedEnvironment } from \"~/services/apiAuth.server\";\n import { determineEngineVersion } from \"../engineVersion.server\";\n-import { eventRepository } from \"../eventRepository/eventRepository.server\";\n import { tracer } from \"../tracer.server\";\n import { WithRunEngine } from \"./baseService.server\";\n import { TriggerTaskServiceV1 } from \"./triggerTaskV1.server\";\n-import { env } from \"~/env.server\";\n-import { clickhouseEventRepository } from \"../eventRepository/clickhouseEventRepositoryInstance.server\";\n \n export type TriggerTaskServiceOptions = {\n   idempotencyKey?: string;\n@@ -94,10 +92,7 @@ export class TriggerTaskService extends WithRunEngine {\n     body: TriggerTaskRequestBody,\n     options: TriggerTaskServiceOptions = {}\n   ): Promise<TriggerTaskServiceResult | undefined> {\n-    const traceEventConcern = new DefaultTraceEventsConcern(\n-      eventRepository,\n-      clickhouseEventRepository\n-    );\n+    const traceEventConcern = new DefaultTraceEventsConcern();\n \n     const service = new RunEngineTriggerTaskService({\n       prisma: this._prisma,\ndiff --git a/apps/webapp/app/v3/services/triggerTaskV1.server.ts b/apps/webapp/app/v3/services/triggerTaskV1.server.ts\nindex c193f142d6..5e6ac7c9f1 100644\n--- a/apps/webapp/app/v3/services/triggerTaskV1.server.ts\n+++ b/apps/webapp/app/v3/services/triggerTaskV1.server.ts\n@@ -179,6 +179,7 @@ export class TriggerTaskServiceV1 extends BaseService {\n                   depth: true,\n                   queueTimestamp: true,\n                   queue: true,\n+                  taskEventStore: true,\n                 },\n               },\n             },\n@@ -216,6 +217,7 @@ export class TriggerTaskServiceV1 extends BaseService {\n                   taskIdentifier: true,\n                   rootTaskRunId: true,\n                   depth: true,\n+                  taskEventStore: true,\n                 },\n               },\n             },\n@@ -237,6 +239,7 @@ export class TriggerTaskServiceV1 extends BaseService {\n                       depth: true,\n                       queueTimestamp: true,\n                       queue: true,\n+                      taskEventStore: true,\n                     },\n                   },\n                 },\n@@ -289,7 +292,10 @@ export class TriggerTaskServiceV1 extends BaseService {\n         : undefined;\n \n       const { repository, store } = await getEventRepository(\n-        environment.organization.featureFlags as Record<string, unknown>\n+        environment.organization.featureFlags as Record<string, unknown>,\n+        dependentAttempt?.taskRun.taskEventStore ??\n+          parentAttempt?.taskRun.taskEventStore ??\n+          dependentBatchRun?.dependentTaskAttempt?.taskRun.taskEventStore\n       );\n \n       try {\ndiff --git a/apps/webapp/test/engine/triggerTask.test.ts b/apps/webapp/test/engine/triggerTask.test.ts\nindex 36dabd008c..aa0e059156 100644\n--- a/apps/webapp/test/engine/triggerTask.test.ts\n+++ b/apps/webapp/test/engine/triggerTask.test.ts\n@@ -79,6 +79,7 @@ class MockTriggerTaskValidator implements TriggerTaskValidator {\n class MockTraceEventConcern implements TraceEventConcern {\n   async traceRun<T>(\n     request: TriggerTaskRequest,\n+    parentStore: string | undefined,\n     callback: (span: TracedEventSpan, store: string) => Promise<T>\n   ): Promise<T> {\n     return await callback(\n@@ -96,6 +97,7 @@ class MockTraceEventConcern implements TraceEventConcern {\n \n   async traceIdempotentRun<T>(\n     request: TriggerTaskRequest,\n+    parentStore: string | undefined,\n     options: {\n       existingRun: TaskRun;\n       idempotencyKey: string;\n", "test_patch": "", "problem_statement": "", "hints_text": ""}
{"instance_id": "triggerdotdev__trigger.dev.pr_mirror.2483", "repo": "triggerdotdev/trigger.dev", "base_commit": "5db583b6cd5e8aa898b08604efcd7697f6ae31ef", "head_commit": "92cb7a3a760ef1a663eb2acd330603b8b0544577", "title": "fix(core): Improves our schema to JSON Schema conversion (fix for zod 4)", "merged_at": "2025-09-15T13:11:40Z", "html_url": "https://github.com/triggerdotdev/trigger.dev/pull/2483", "test_files": ["packages/schema-to-json/tests/index.test.ts"], "code_files": ["packages/cli-v3/src/entryPoints/dev-index-worker.ts", "packages/cli-v3/src/entryPoints/managed-index-worker.ts", "packages/schema-to-json/src/index.ts", "references/hello-world/src/trigger/jsonSchema.ts"], "total_changes": 544, "num_files": 8, "pull_number": 2483, "patch": "diff --git a/.changeset/angry-files-yawn.md b/.changeset/angry-files-yawn.md\nnew file mode 100644\nindex 0000000000..cd8c76fbde\n--- /dev/null\n+++ b/.changeset/angry-files-yawn.md\n@@ -0,0 +1,5 @@\n+---\n+\"trigger.dev\": patch\n+---\n+\n+Improves our schema to JSON Schema conversion, fixes zod 4 and a few other schema libraries, also correctly sets the dependencies\ndiff --git a/packages/cli-v3/src/entryPoints/dev-index-worker.ts b/packages/cli-v3/src/entryPoints/dev-index-worker.ts\nindex 7b40ecf9d4..da5c6ee750 100644\n--- a/packages/cli-v3/src/entryPoints/dev-index-worker.ts\n+++ b/packages/cli-v3/src/entryPoints/dev-index-worker.ts\n@@ -18,7 +18,7 @@ import { registerResources } from \"../indexing/registerResources.js\";\n import { env } from \"std-env\";\n import { normalizeImportPath } from \"../utilities/normalizeImportPath.js\";\n import { detectRuntimeVersion } from \"@trigger.dev/core/v3/build\";\n-import { schemaToJsonSchema, initializeSchemaConverters } from \"@trigger.dev/schema-to-json\";\n+import { schemaToJsonSchema } from \"@trigger.dev/schema-to-json\";\n \n sourceMapSupport.install({\n   handleUncaughtExceptions: false,\n@@ -193,8 +193,6 @@ await new Promise<void>((resolve) => {\n });\n \n async function convertSchemasToJsonSchemas(tasks: TaskManifest[]): Promise<TaskManifest[]> {\n-  await initializeSchemaConverters();\n-\n   const convertedTasks = tasks.map((task) => {\n     const schema = resourceCatalog.getTaskSchema(task.id);\n \ndiff --git a/packages/cli-v3/src/entryPoints/managed-index-worker.ts b/packages/cli-v3/src/entryPoints/managed-index-worker.ts\nindex 98593cfc6e..5ff9f1b62e 100644\n--- a/packages/cli-v3/src/entryPoints/managed-index-worker.ts\n+++ b/packages/cli-v3/src/entryPoints/managed-index-worker.ts\n@@ -18,7 +18,7 @@ import { registerResources } from \"../indexing/registerResources.js\";\n import { env } from \"std-env\";\n import { normalizeImportPath } from \"../utilities/normalizeImportPath.js\";\n import { detectRuntimeVersion } from \"@trigger.dev/core/v3/build\";\n-import { schemaToJsonSchema, initializeSchemaConverters } from \"@trigger.dev/schema-to-json\";\n+import { schemaToJsonSchema } from \"@trigger.dev/schema-to-json\";\n \n sourceMapSupport.install({\n   handleUncaughtExceptions: false,\n@@ -201,8 +201,6 @@ await new Promise<void>((resolve) => {\n });\n \n async function convertSchemasToJsonSchemas(tasks: TaskManifest[]): Promise<TaskManifest[]> {\n-  await initializeSchemaConverters();\n-\n   const convertedTasks = tasks.map((task) => {\n     const schema = resourceCatalog.getTaskSchema(task.id);\n \ndiff --git a/packages/schema-to-json/package.json b/packages/schema-to-json/package.json\nindex ecda598986..f4c7044e74 100644\n--- a/packages/schema-to-json/package.json\n+++ b/packages/schema-to-json/package.json\n@@ -42,19 +42,19 @@\n   },\n   \"dependencies\": {\n     \"@trigger.dev/core\": \"workspace:*\",\n-    \"zod-to-json-schema\": \"^3.24.5\",\n-    \"@sodaru/yup-to-json-schema\": \"^2.0.1\"\n+    \"zod-to-json-schema\": \"^3.24.0\",\n+    \"@sodaru/yup-to-json-schema\": \"^2\",\n+    \"zod\": \"3.25.76\",\n+    \"effect\": \"^3\"\n   },\n   \"devDependencies\": {\n     \"arktype\": \"^2.0.0\",\n-    \"effect\": \"^3.11.11\",\n     \"runtypes\": \"^6.7.0\",\n     \"superstruct\": \"^2.0.2\",\n     \"tshy\": \"^3.0.2\",\n     \"@sinclair/typebox\": \"^0.34.3\",\n     \"valibot\": \"^1.1.0\",\n     \"yup\": \"^1.7.0\",\n-    \"zod\": \"^3.24.1 || ^4.0.0\",\n     \"rimraf\": \"6.0.1\",\n     \"@arethetypeswrong/cli\": \"^0.15.4\"\n   },\n@@ -66,7 +66,7 @@\n     \"@sinclair/typebox\": \">=0.34.30\",\n     \"valibot\": \">=0.41.0\",\n     \"yup\": \">=1.0.0\",\n-    \"zod\": \"^3.24.1 || ^4.0.0\"\n+    \"zod\": \"^3.25.76 || ^4\"\n   },\n   \"peerDependenciesMeta\": {\n     \"arktype\": {\ndiff --git a/packages/schema-to-json/src/index.ts b/packages/schema-to-json/src/index.ts\nindex 604ec8d78c..8631060db3 100644\n--- a/packages/schema-to-json/src/index.ts\n+++ b/packages/schema-to-json/src/index.ts\n@@ -1,18 +1,21 @@\n // Import JSONSchema from core to ensure compatibility\n import type { JSONSchema } from \"@trigger.dev/core/v3\";\n+import { zodToJsonSchema } from \"zod-to-json-schema\";\n+import * as z4 from \"zod/v4\";\n+import { convertSchema } from \"@sodaru/yup-to-json-schema\";\n+import { JSONSchema as EffectJSONSchema } from \"effect\";\n \n export type Schema = unknown;\n export type { JSONSchema };\n \n export interface ConversionOptions {\n   /**\n-   * The name to use for the schema in the JSON Schema\n+   * Enables support for references in the schema.\n+   * This is required for recursive schemas, e.g. with `z.lazy`.\n+   * However, not all language models and providers support such references.\n+   * Defaults to `false`.\n    */\n-  name?: string;\n-  /**\n-   * Additional JSON Schema properties to merge\n-   */\n-  additionalProperties?: Record<string, unknown>;\n+  useReferences?: boolean;\n }\n \n export interface ConversionResult {\n@@ -20,19 +23,6 @@ export interface ConversionResult {\n    * The JSON Schema representation (JSON Schema Draft 7)\n    */\n   jsonSchema: JSONSchema;\n-  /**\n-   * The detected schema type\n-   */\n-  schemaType:\n-    | \"zod\"\n-    | \"yup\"\n-    | \"arktype\"\n-    | \"effect\"\n-    | \"valibot\"\n-    | \"superstruct\"\n-    | \"runtypes\"\n-    | \"typebox\"\n-    | \"unknown\";\n }\n \n /**\n@@ -57,107 +47,48 @@ export function schemaToJsonSchema(\n   if (typeof parser.toJsonSchema === \"function\") {\n     try {\n       const jsonSchema = parser.toJsonSchema();\n-      // Determine if it's Zod or ArkType based on other methods\n-      const schemaType =\n-        typeof parser.parseAsync === \"function\" || typeof parser.parse === \"function\"\n-          ? \"zod\"\n-          : \"arktype\";\n+\n       return {\n-        jsonSchema: options?.additionalProperties\n-          ? { ...jsonSchema, ...options.additionalProperties }\n-          : jsonSchema,\n-        schemaType,\n+        jsonSchema,\n       };\n     } catch (error) {\n       // If toJsonSchema fails, continue to other checks\n     }\n   }\n \n+  if (isZodSchema(parser)) {\n+    const jsonSchema = convertZodSchema(parser, options);\n+\n+    if (jsonSchema) {\n+      return {\n+        jsonSchema: jsonSchema,\n+      };\n+    }\n+  }\n+\n   // Check if it's a TypeBox schema (has Static and Kind symbols)\n   if (parser[Symbol.for(\"TypeBox.Kind\")] !== undefined) {\n     // TypeBox schemas are already JSON Schema compliant\n     return {\n-      jsonSchema: options?.additionalProperties\n-        ? { ...parser, ...options.additionalProperties }\n-        : parser,\n-      schemaType: \"typebox\",\n+      jsonSchema: parser,\n     };\n   }\n \n-  // For schemas that need external libraries, we need to check if they're available\n-  // This approach avoids bundling the dependencies while still allowing runtime usage\n-\n-  // Check if it's a Zod schema (without built-in toJsonSchema)\n-  if (typeof parser.parseAsync === \"function\" || typeof parser.parse === \"function\") {\n-    try {\n-      // Try to access zod-to-json-schema if it's available\n-      // @ts-ignore - This is intentionally dynamic\n-      if (typeof globalThis.__zodToJsonSchema !== \"undefined\") {\n-        // @ts-ignore\n-        const { zodToJsonSchema } = globalThis.__zodToJsonSchema;\n-        const jsonSchema = options?.name\n-          ? zodToJsonSchema(parser, options.name)\n-          : zodToJsonSchema(parser);\n-\n-        if (jsonSchema && typeof jsonSchema === \"object\" && \"$schema\" in jsonSchema) {\n-          const { $schema, ...rest } = jsonSchema as any;\n-          return {\n-            jsonSchema: options?.additionalProperties\n-              ? { ...rest, ...options.additionalProperties }\n-              : rest,\n-            schemaType: \"zod\",\n-          };\n-        }\n-\n-        return {\n-          jsonSchema: options?.additionalProperties\n-            ? { ...jsonSchema, ...options.additionalProperties }\n-            : jsonSchema,\n-          schemaType: \"zod\",\n-        };\n-      }\n-    } catch (error) {\n-      // Library not available\n-    }\n-  }\n-\n-  // Check if it's a Yup schema\n-  if (typeof parser.validateSync === \"function\" && typeof parser.describe === \"function\") {\n-    try {\n-      // @ts-ignore\n-      if (typeof globalThis.__yupToJsonSchema !== \"undefined\") {\n-        // @ts-ignore\n-        const { convertSchema } = globalThis.__yupToJsonSchema;\n-        const jsonSchema = convertSchema(parser);\n-        return {\n-          jsonSchema: options?.additionalProperties\n-            ? { ...jsonSchema, ...options.additionalProperties }\n-            : jsonSchema,\n-          schemaType: \"yup\",\n-        };\n-      }\n-    } catch (error) {\n-      // Library not available\n+  if (isYupSchema(parser)) {\n+    const jsonSchema = convertYupSchema(parser);\n+    if (jsonSchema) {\n+      return {\n+        jsonSchema: jsonSchema,\n+      };\n     }\n   }\n \n-  // Check if it's an Effect schema\n-  if (typeof parser.ast === \"object\" && typeof parser.ast._tag === \"string\") {\n-    try {\n-      // @ts-ignore\n-      if (typeof globalThis.__effectJsonSchema !== \"undefined\") {\n-        // @ts-ignore\n-        const { JSONSchema } = globalThis.__effectJsonSchema;\n-        const jsonSchema = JSONSchema.make(parser);\n-        return {\n-          jsonSchema: options?.additionalProperties\n-            ? { ...jsonSchema, ...options.additionalProperties }\n-            : jsonSchema,\n-          schemaType: \"effect\",\n-        };\n-      }\n-    } catch (error) {\n-      // Library not available\n+  if (isEffectSchema(parser)) {\n+    const jsonSchema = convertEffectSchema(parser);\n+    if (jsonSchema) {\n+      return {\n+        jsonSchema: jsonSchema,\n+      };\n     }\n   }\n \n@@ -168,71 +99,75 @@ export function schemaToJsonSchema(\n }\n \n /**\n- * Initialize the schema conversion libraries\n- * This should be called by the consuming application if they want to enable\n- * conversion for schemas that don't have built-in JSON Schema support\n+ * Check if a schema can be converted to JSON Schema\n  */\n-export async function initializeSchemaConverters(): Promise<void> {\n-  try {\n-    // @ts-ignore\n-    globalThis.__zodToJsonSchema = await import(\"zod-to-json-schema\");\n-  } catch {\n-    // Zod conversion not available\n+export function canConvertSchema(schema: Schema): boolean {\n+  const result = schemaToJsonSchema(schema);\n+  return result !== undefined;\n+}\n+\n+export function isZodSchema(schema: any): boolean {\n+  return isZod3Schema(schema) || isZod4Schema(schema);\n+}\n+\n+function isZod3Schema(schema: any): boolean {\n+  return \"_def\" in schema && \"parse\" in schema && \"parseAsync\" in schema && \"safeParse\" in schema;\n+}\n+\n+function isZod4Schema(schema: any): boolean {\n+  return \"_zod\" in schema;\n+}\n+\n+function convertZodSchema(schema: any, options?: ConversionOptions): JSONSchema | undefined {\n+  if (isZod4Schema(schema)) {\n+    return convertZod4Schema(schema, options);\n   }\n \n-  try {\n-    // @ts-ignore\n-    globalThis.__yupToJsonSchema = await import(\"@sodaru/yup-to-json-schema\");\n-  } catch {\n-    // Yup conversion not available\n+  if (isZod3Schema(schema)) {\n+    return convertZod3Schema(schema, options);\n   }\n \n-  try {\n-    // Try Effect first, then @effect/schema\n-    let module;\n-    try {\n-      module = await import(\"effect\");\n-    } catch {}\n+  return undefined;\n+}\n \n-    if (module?.JSONSchema) {\n-      // @ts-ignore\n-      globalThis.__effectJsonSchema = { JSONSchema: module.JSONSchema };\n-    }\n-  } catch {\n-    // Effect conversion not available\n-  }\n+function convertZod3Schema(schema: any, options?: ConversionOptions): JSONSchema | undefined {\n+  const useReferences = options?.useReferences ?? false;\n+\n+  return zodToJsonSchema(schema, {\n+    $refStrategy: useReferences ? \"root\" : \"none\",\n+  }) as JSONSchema;\n }\n \n-/**\n- * Check if a schema can be converted to JSON Schema\n- */\n-export function canConvertSchema(schema: Schema): boolean {\n-  const result = schemaToJsonSchema(schema);\n-  return result !== undefined;\n+function convertZod4Schema(schema: any, options?: ConversionOptions): JSONSchema | undefined {\n+  const useReferences = options?.useReferences ?? false;\n+\n+  return z4.toJSONSchema(schema, {\n+    target: \"draft-7\",\n+    io: \"output\",\n+    reused: useReferences ? \"ref\" : \"inline\",\n+  }) as JSONSchema;\n }\n \n-/**\n- * Get the detected schema type\n- */\n-export function detectSchemaType(schema: Schema): ConversionResult[\"schemaType\"] {\n-  const result = schemaToJsonSchema(schema);\n-  return result?.schemaType ?? \"unknown\";\n+function isYupSchema(schema: any): boolean {\n+  return \"spec\" in schema && \"_typeCheck\" in schema;\n }\n \n-/**\n- * Check if the conversion libraries are initialized\n- */\n-export function areConvertersInitialized(): {\n-  zod: boolean;\n-  yup: boolean;\n-  effect: boolean;\n-} {\n-  return {\n-    // @ts-ignore\n-    zod: typeof globalThis.__zodToJsonSchema !== \"undefined\",\n-    // @ts-ignore\n-    yup: typeof globalThis.__yupToJsonSchema !== \"undefined\",\n-    // @ts-ignore\n-    effect: typeof globalThis.__effectJsonSchema !== \"undefined\",\n-  };\n+function convertYupSchema(schema: any): JSONSchema | undefined {\n+  try {\n+    return convertSchema(schema) as JSONSchema;\n+  } catch {\n+    return undefined;\n+  }\n+}\n+\n+function isEffectSchema(schema: any): boolean {\n+  return \"ast\" in schema && typeof schema.ast === \"object\" && typeof schema.ast._tag === \"string\";\n+}\n+\n+function convertEffectSchema(schema: any): JSONSchema | undefined {\n+  try {\n+    return EffectJSONSchema.make(schema) as JSONSchema;\n+  } catch {\n+    return undefined;\n+  }\n }\ndiff --git a/packages/schema-to-json/tests/index.test.ts b/packages/schema-to-json/tests/index.test.ts\nindex e64ddc96a5..b266a42b3b 100644\n--- a/packages/schema-to-json/tests/index.test.ts\n+++ b/packages/schema-to-json/tests/index.test.ts\n@@ -1,44 +1,45 @@\n-import { z } from \"zod\";\n+import * as z3 from \"zod/v3\";\n+import * as z4 from \"zod/v4\";\n import * as y from \"yup\";\n // @ts-ignore\n import { type } from \"arktype\";\n import { Schema } from \"effect\";\n import { Type } from \"@sinclair/typebox\";\n-import {\n-  schemaToJsonSchema,\n-  canConvertSchema,\n-  detectSchemaType,\n-  initializeSchemaConverters,\n-  areConvertersInitialized,\n-} from \"../src/index.js\";\n-\n-// Initialize converters before running tests\n-beforeAll(async () => {\n-  await initializeSchemaConverters();\n-});\n+import { schemaToJsonSchema, canConvertSchema } from \"../src/index.js\";\n \n describe(\"schemaToJsonSchema\", () => {\n-  describe(\"Initialization\", () => {\n-    it(\"should have converters initialized\", () => {\n-      const status = areConvertersInitialized();\n-      expect(status.zod).toBe(true);\n-      expect(status.yup).toBe(true);\n-      expect(status.effect).toBe(true);\n-    });\n-  });\n-\n   describe(\"Zod schemas\", () => {\n     it(\"should convert a simple Zod object schema\", () => {\n-      const schema = z.object({\n-        name: z.string(),\n-        age: z.number(),\n-        email: z.string().email(),\n+      const schema = z3.object({\n+        name: z3.string(),\n+        age: z3.number(),\n+        email: z3.string().email(),\n+      });\n+\n+      const result = schemaToJsonSchema(schema);\n+\n+      expect(result).toBeDefined();\n+      expect(result?.jsonSchema).toMatchObject({\n+        type: \"object\",\n+        properties: {\n+          name: { type: \"string\" },\n+          age: { type: \"number\" },\n+          email: { type: \"string\", format: \"email\" },\n+        },\n+        required: [\"name\", \"age\", \"email\"],\n+      });\n+    });\n+\n+    it(\"should convert a simple Zod 4 object schema\", () => {\n+      const schema = z4.object({\n+        name: z4.string(),\n+        age: z4.number(),\n+        email: z4.email(),\n       });\n \n       const result = schemaToJsonSchema(schema);\n \n       expect(result).toBeDefined();\n-      expect(result?.schemaType).toBe(\"zod\");\n       expect(result?.jsonSchema).toMatchObject({\n         type: \"object\",\n         properties: {\n@@ -51,10 +52,10 @@ describe(\"schemaToJsonSchema\", () => {\n     });\n \n     it(\"should convert a Zod schema with optional fields\", () => {\n-      const schema = z.object({\n-        id: z.string(),\n-        description: z.string().optional(),\n-        tags: z.array(z.string()).optional(),\n+      const schema = z3.object({\n+        id: z3.string(),\n+        description: z3.string().optional(),\n+        tags: z3.array(z3.string()).optional(),\n       });\n \n       const result = schemaToJsonSchema(schema);\n@@ -72,45 +73,16 @@ describe(\"schemaToJsonSchema\", () => {\n     });\n \n     it(\"should handle Zod schema with name option\", () => {\n-      const schema = z.object({\n-        value: z.number(),\n+      const schema = z3.object({\n+        value: z3.number(),\n       });\n \n-      const result = schemaToJsonSchema(schema, { name: \"MySchema\" });\n+      const result = schemaToJsonSchema(schema, { useReferences: true });\n \n       expect(result).toBeDefined();\n       expect(result?.jsonSchema).toBeDefined();\n       // The exact structure depends on zod-to-json-schema implementation\n     });\n-\n-    it(\"should handle Zod 4 schema with built-in toJsonSchema method\", () => {\n-      // Mock a Zod 4 schema with toJsonSchema method\n-      const mockZod4Schema = {\n-        parse: (val: unknown) => val,\n-        parseAsync: async (val: unknown) => val,\n-        toJsonSchema: () => ({\n-          type: \"object\",\n-          properties: {\n-            id: { type: \"string\" },\n-            count: { type: \"number\" },\n-          },\n-          required: [\"id\", \"count\"],\n-        }),\n-      };\n-\n-      const result = schemaToJsonSchema(mockZod4Schema);\n-\n-      expect(result).toBeDefined();\n-      expect(result?.schemaType).toBe(\"zod\");\n-      expect(result?.jsonSchema).toEqual({\n-        type: \"object\",\n-        properties: {\n-          id: { type: \"string\" },\n-          count: { type: \"number\" },\n-        },\n-        required: [\"id\", \"count\"],\n-      });\n-    });\n   });\n \n   describe(\"Yup schemas\", () => {\n@@ -124,7 +96,6 @@ describe(\"schemaToJsonSchema\", () => {\n       const result = schemaToJsonSchema(schema);\n \n       expect(result).toBeDefined();\n-      expect(result?.schemaType).toBe(\"yup\");\n       expect(result?.jsonSchema).toMatchObject({\n         type: \"object\",\n         properties: {\n@@ -169,7 +140,6 @@ describe(\"schemaToJsonSchema\", () => {\n       const result = schemaToJsonSchema(schema);\n \n       expect(result).toBeDefined();\n-      expect(result?.schemaType).toBe(\"arktype\");\n       expect(result?.jsonSchema).toBeDefined();\n       expect(result?.jsonSchema.type).toBe(\"object\");\n     });\n@@ -200,7 +170,6 @@ describe(\"schemaToJsonSchema\", () => {\n       const result = schemaToJsonSchema(schema);\n \n       expect(result).toBeDefined();\n-      expect(result?.schemaType).toBe(\"effect\");\n       expect(result?.jsonSchema).toMatchObject({\n         type: \"object\",\n         properties: {\n@@ -238,7 +207,6 @@ describe(\"schemaToJsonSchema\", () => {\n       const result = schemaToJsonSchema(schema);\n \n       expect(result).toBeDefined();\n-      expect(result?.schemaType).toBe(\"typebox\");\n       expect(result?.jsonSchema).toMatchObject({\n         type: \"object\",\n         properties: {\n@@ -272,27 +240,6 @@ describe(\"schemaToJsonSchema\", () => {\n     });\n   });\n \n-  describe(\"Additional options\", () => {\n-    it(\"should merge additional properties\", () => {\n-      const schema = z.object({\n-        value: z.number(),\n-      });\n-\n-      const result = schemaToJsonSchema(schema, {\n-        additionalProperties: {\n-          title: \"My Schema\",\n-          description: \"A test schema\",\n-          \"x-custom\": \"custom value\",\n-        },\n-      });\n-\n-      expect(result).toBeDefined();\n-      expect(result?.jsonSchema.title).toBe(\"My Schema\");\n-      expect(result?.jsonSchema.description).toBe(\"A test schema\");\n-      expect(result?.jsonSchema[\"x-custom\"]).toBe(\"custom value\");\n-    });\n-  });\n-\n   describe(\"Unsupported schemas\", () => {\n     it(\"should return undefined for unsupported schema types\", () => {\n       const invalidSchema = { notASchema: true };\n@@ -310,7 +257,7 @@ describe(\"schemaToJsonSchema\", () => {\n \n describe(\"canConvertSchema\", () => {\n   it(\"should return true for supported schemas\", () => {\n-    expect(canConvertSchema(z.string())).toBe(true);\n+    expect(canConvertSchema(z3.string())).toBe(true);\n     expect(canConvertSchema(y.string())).toBe(true);\n     expect(canConvertSchema(type(\"string\"))).toBe(true);\n     expect(canConvertSchema(Schema.String)).toBe(true);\n@@ -322,29 +269,3 @@ describe(\"canConvertSchema\", () => {\n     expect(canConvertSchema(() => true)).toBe(false);\n   });\n });\n-\n-describe(\"detectSchemaType\", () => {\n-  it(\"should detect Zod schemas\", () => {\n-    expect(detectSchemaType(z.string())).toBe(\"zod\");\n-  });\n-\n-  it(\"should detect Yup schemas\", () => {\n-    expect(detectSchemaType(y.string())).toBe(\"yup\");\n-  });\n-\n-  it(\"should detect ArkType schemas\", () => {\n-    expect(detectSchemaType(type(\"string\"))).toBe(\"arktype\");\n-  });\n-\n-  it(\"should detect Effect schemas\", () => {\n-    expect(detectSchemaType(Schema.String)).toBe(\"effect\");\n-  });\n-\n-  it(\"should detect TypeBox schemas\", () => {\n-    expect(detectSchemaType(Type.String())).toBe(\"typebox\");\n-  });\n-\n-  it(\"should return unknown for unsupported schemas\", () => {\n-    expect(detectSchemaType({ notASchema: true })).toBe(\"unknown\");\n-  });\n-});\ndiff --git a/pnpm-lock.yaml b/pnpm-lock.yaml\nindex c5111371c0..537d085716 100644\n--- a/pnpm-lock.yaml\n+++ b/pnpm-lock.yaml\n@@ -1837,14 +1837,20 @@ importers:\n   packages/schema-to-json:\n     dependencies:\n       '@sodaru/yup-to-json-schema':\n-        specifier: ^2.0.1\n+        specifier: ^2\n         version: 2.0.1\n       '@trigger.dev/core':\n         specifier: workspace:*\n         version: link:../core\n+      effect:\n+        specifier: ^3\n+        version: 3.17.1\n+      zod:\n+        specifier: 3.25.76\n+        version: 3.25.76\n       zod-to-json-schema:\n-        specifier: ^3.24.5\n-        version: 3.24.5(zod@3.25.76)\n+        specifier: ^3.24.0\n+        version: 3.24.6(zod@3.25.76)\n     devDependencies:\n       '@arethetypeswrong/cli':\n         specifier: ^0.15.4\n@@ -1855,9 +1861,6 @@ importers:\n       arktype:\n         specifier: ^2.0.0\n         version: 2.1.20\n-      effect:\n-        specifier: ^3.11.11\n-        version: 3.17.1\n       rimraf:\n         specifier: 6.0.1\n         version: 6.0.1\n@@ -1876,9 +1879,6 @@ importers:\n       yup:\n         specifier: ^1.7.0\n         version: 1.7.0\n-      zod:\n-        specifier: ^3.24.1 || ^4.0.0\n-        version: 3.25.76\n \n   packages/trigger-sdk:\n     dependencies:\n@@ -2530,7 +2530,7 @@ packages:\n       '@standard-schema/spec': 1.0.0\n       eventsource-parser: 3.0.3\n       zod: 3.25.76\n-      zod-to-json-schema: 3.24.5(zod@3.25.76)\n+      zod-to-json-schema: 3.24.6(zod@3.25.76)\n \n   /@ai-sdk/provider@0.0.26:\n     resolution: {integrity: sha512-dQkfBDs2lTYpKM8389oopPdQgIU007GQyCbuPPrV+K6MtSII3HBfE0stUIMXUb44L+LK1t6GXPP7wjSzjO6uKg==}\n@@ -2688,7 +2688,7 @@ packages:\n       json-schema: 0.4.0\n       secure-json-parse: 2.7.0\n       zod: 3.25.76\n-      zod-to-json-schema: 3.24.5(zod@3.25.76)\n+      zod-to-json-schema: 3.24.6(zod@3.25.76)\n     dev: true\n \n   /@ai-sdk/ui-utils@1.0.0(zod@3.25.76):\n@@ -2703,7 +2703,7 @@ packages:\n       '@ai-sdk/provider': 1.0.0\n       '@ai-sdk/provider-utils': 2.0.0(zod@3.25.76)\n       zod: 3.25.76\n-      zod-to-json-schema: 3.24.5(zod@3.25.76)\n+      zod-to-json-schema: 3.24.6(zod@3.25.76)\n     dev: false\n \n   /@ai-sdk/ui-utils@1.2.1(zod@3.25.76):\n@@ -2715,7 +2715,7 @@ packages:\n       '@ai-sdk/provider': 1.1.0\n       '@ai-sdk/provider-utils': 2.2.1(zod@3.25.76)\n       zod: 3.25.76\n-      zod-to-json-schema: 3.24.5(zod@3.25.76)\n+      zod-to-json-schema: 3.24.6(zod@3.25.76)\n     dev: false\n \n   /@ai-sdk/ui-utils@1.2.11(zod@3.25.76):\n@@ -2727,7 +2727,7 @@ packages:\n       '@ai-sdk/provider': 1.1.3\n       '@ai-sdk/provider-utils': 2.2.8(zod@3.25.76)\n       zod: 3.25.76\n-      zod-to-json-schema: 3.24.5(zod@3.25.76)\n+      zod-to-json-schema: 3.24.6(zod@3.25.76)\n     dev: false\n \n   /@ai-sdk/vue@0.0.59(vue@3.5.16)(zod@3.25.76):\n@@ -8871,16 +8871,6 @@ packages:\n       '@opentelemetry/api': 1.9.0\n     dev: false\n \n-  /@opentelemetry/core@1.25.1(@opentelemetry/api@1.9.0):\n-    resolution: {integrity: sha512-GeT/l6rBYWVQ4XArluLVB6WWQ8flHbdb6r2FCHC3smtdOAbrJBIv35tpV/yp9bmYUJf+xmZpu9DRTIeJVhFbEQ==}\n-    engines: {node: '>=14'}\n-    peerDependencies:\n-      '@opentelemetry/api': '>=1.0.0 <1.10.0'\n-    dependencies:\n-      '@opentelemetry/api': 1.9.0\n-      '@opentelemetry/semantic-conventions': 1.25.1\n-    dev: false\n-\n   /@opentelemetry/core@1.30.0(@opentelemetry/api@1.9.0):\n     resolution: {integrity: sha512-Q/3u/K73KUjTCnFUP97ZY+pBjQ1kPEgjOfXj/bJl8zW7GbXdkw6cwuyZk6ZTXkVgCBsYRYUzx4fvYK1jxdb9MA==}\n     engines: {node: '>=14'}\n@@ -9102,7 +9092,7 @@ packages:\n       '@opentelemetry/api': ^1.3.0\n     dependencies:\n       '@opentelemetry/api': 1.9.0\n-      '@opentelemetry/core': 1.25.1(@opentelemetry/api@1.9.0)\n+      '@opentelemetry/core': 1.30.1(@opentelemetry/api@1.9.0)\n       '@opentelemetry/instrumentation': 0.57.2(@opentelemetry/api@1.9.0)\n       '@opentelemetry/semantic-conventions': 1.36.0\n     transitivePeerDependencies:\n@@ -9131,7 +9121,7 @@ packages:\n       '@opentelemetry/api': ^1.3.0\n     dependencies:\n       '@opentelemetry/api': 1.9.0\n-      '@opentelemetry/core': 1.25.1(@opentelemetry/api@1.9.0)\n+      '@opentelemetry/core': 1.30.1(@opentelemetry/api@1.9.0)\n       '@opentelemetry/instrumentation': 0.57.2(@opentelemetry/api@1.9.0)\n       '@opentelemetry/semantic-conventions': 1.36.0\n       '@types/connect': 3.4.38\n@@ -9158,7 +9148,7 @@ packages:\n       '@opentelemetry/api': ^1.3.0\n     dependencies:\n       '@opentelemetry/api': 1.9.0\n-      '@opentelemetry/core': 1.25.1(@opentelemetry/api@1.9.0)\n+      '@opentelemetry/core': 1.30.1(@opentelemetry/api@1.9.0)\n       '@opentelemetry/instrumentation': 0.57.2(@opentelemetry/api@1.9.0)\n       '@opentelemetry/semantic-conventions': 1.36.0\n     transitivePeerDependencies:\n@@ -9201,7 +9191,7 @@ packages:\n       '@opentelemetry/api': ^1.3.0\n     dependencies:\n       '@opentelemetry/api': 1.9.0\n-      '@opentelemetry/core': 1.25.1(@opentelemetry/api@1.9.0)\n+      '@opentelemetry/core': 1.30.1(@opentelemetry/api@1.9.0)\n       '@opentelemetry/instrumentation': 0.57.2(@opentelemetry/api@1.9.0)\n     transitivePeerDependencies:\n       - supports-color\n@@ -9238,7 +9228,7 @@ packages:\n       '@opentelemetry/api': ^1.3.0\n     dependencies:\n       '@opentelemetry/api': 1.9.0\n-      '@opentelemetry/core': 1.25.1(@opentelemetry/api@1.9.0)\n+      '@opentelemetry/core': 1.30.1(@opentelemetry/api@1.9.0)\n       '@opentelemetry/instrumentation': 0.57.2(@opentelemetry/api@1.9.0)\n       '@opentelemetry/semantic-conventions': 1.36.0\n     transitivePeerDependencies:\n@@ -9323,7 +9313,7 @@ packages:\n       '@opentelemetry/api': ^1.3.0\n     dependencies:\n       '@opentelemetry/api': 1.9.0\n-      '@opentelemetry/core': 1.25.1(@opentelemetry/api@1.9.0)\n+      '@opentelemetry/core': 1.30.1(@opentelemetry/api@1.9.0)\n       '@opentelemetry/instrumentation': 0.57.2(@opentelemetry/api@1.9.0)\n       '@opentelemetry/semantic-conventions': 1.36.0\n     transitivePeerDependencies:\n@@ -9362,7 +9352,7 @@ packages:\n       '@opentelemetry/api': ^1.3.0\n     dependencies:\n       '@opentelemetry/api': 1.9.0\n-      '@opentelemetry/core': 1.25.1(@opentelemetry/api@1.9.0)\n+      '@opentelemetry/core': 1.30.1(@opentelemetry/api@1.9.0)\n       '@opentelemetry/instrumentation': 0.57.2(@opentelemetry/api@1.9.0)\n       '@opentelemetry/semantic-conventions': 1.36.0\n     transitivePeerDependencies:\n@@ -9449,7 +9439,7 @@ packages:\n       '@opentelemetry/api': ^1.7.0\n     dependencies:\n       '@opentelemetry/api': 1.9.0\n-      '@opentelemetry/core': 1.25.1(@opentelemetry/api@1.9.0)\n+      '@opentelemetry/core': 1.30.1(@opentelemetry/api@1.9.0)\n       '@opentelemetry/instrumentation': 0.57.2(@opentelemetry/api@1.9.0)\n     transitivePeerDependencies:\n       - supports-color\n@@ -9800,11 +9790,6 @@ packages:\n       '@opentelemetry/sdk-trace-base': 2.0.1(@opentelemetry/api@1.9.0)\n     dev: false\n \n-  /@opentelemetry/semantic-conventions@1.25.1:\n-    resolution: {integrity: sha512-ZDjMJJQRlyk8A1KZFCc+bCbsyrn1wTwdNt56F7twdfUfnHUZUq77/WfONCj8p72NZOyP7pNTdUWSTYC3GTbuuQ==}\n-    engines: {node: '>=14'}\n-    dev: false\n-\n   /@opentelemetry/semantic-conventions@1.28.0:\n     resolution: {integrity: sha512-lp4qAiMTD4sNWW4DbKLBkfiMZ4jbAboJIGOQr5DvciMRI494OapieI9qiODpOt0XBr1LjIDy1xAGAnVs5supTA==}\n     engines: {node: '>=14'}\n@@ -9822,7 +9807,7 @@ packages:\n       '@opentelemetry/api': ^1.1.0\n     dependencies:\n       '@opentelemetry/api': 1.9.0\n-      '@opentelemetry/core': 1.25.1(@opentelemetry/api@1.9.0)\n+      '@opentelemetry/core': 1.30.1(@opentelemetry/api@1.9.0)\n     dev: false\n \n   /@pkgjs/parseargs@0.11.0:\n@@ -9925,7 +9910,7 @@ packages:\n       '@opentelemetry/api': ^1.8\n     dependencies:\n       '@opentelemetry/api': 1.9.0\n-      '@opentelemetry/instrumentation': 0.52.1(@opentelemetry/api@1.9.0)\n+      '@opentelemetry/instrumentation': 0.57.2(@opentelemetry/api@1.9.0)\n     transitivePeerDependencies:\n       - supports-color\n     dev: false\n@@ -18068,10 +18053,10 @@ packages:\n \n   /@types/json-schema@7.0.13:\n     resolution: {integrity: sha512-RbSSoHliUbnXj3ny0CNFOoxrIDV6SUGyStHsvDqosw6CkdPV8TtWGlfecuK4ToyMEAql6pzNxgCFKanovUzlgQ==}\n+    dev: true\n \n   /@types/json-schema@7.0.15:\n     resolution: {integrity: sha512-5+fP8P8MFNC+AyZCDxrB2pkZFPGzqQWUzpSeuuVLvm8VMcorNYavBqoFcxK8bQz4Qsbn4oUEEem4wDLfcysGHA==}\n-    dev: true\n \n   /@types/json5@0.0.29:\n     resolution: {integrity: sha512-dRLjCWHYg4oaA77cxO64oO+7JwCwnIzkZPdrrC71jQmQtlhM556pwKo5bUzqvZndkVbeFLIIi+9TC40JNF5hNQ==}\n@@ -18202,6 +18187,7 @@ packages:\n     resolution: {integrity: sha512-acBjXdRJ3A6Pb3tqnw9HZmyR3Fiol3aGxRCK1x3d+6CDAMjl7I649wpSd+yNURCjbOUGu9tqtLKnTGxmK6CyGw==}\n     dependencies:\n       undici-types: 6.20.0\n+    dev: false\n \n   /@types/nodemailer@6.4.17:\n     resolution: {integrity: sha512-I9CCaIp6DTldEg7vyUTZi8+9Vo0hi1/T8gv3C89yk1rSAAzoKQ8H8ki/jBYJSFoH/BisgLP8tkZMlQ91CIquww==}\n@@ -19536,7 +19522,7 @@ packages:\n       jsondiffpatch: 0.6.0\n       react: 18.3.1\n       zod: 3.25.76\n-      zod-to-json-schema: 3.24.5(zod@3.25.76)\n+      zod-to-json-schema: 3.24.6(zod@3.25.76)\n     dev: false\n \n   /ai@4.2.5(react@19.0.0)(zod@3.25.76):\n@@ -22037,6 +22023,7 @@ packages:\n     dependencies:\n       '@standard-schema/spec': 1.0.0\n       fast-check: 3.23.2\n+    dev: false\n \n   /effect@3.7.2:\n     resolution: {integrity: sha512-pV7l1+LSZFvVObj4zuy4nYiBaC7qZOfrKV6s/Ef4p3KueiQwZFgamazklwyZ+x7Nyj2etRDFvHE/xkThTfQD1w==}\n@@ -23750,6 +23737,7 @@ packages:\n         optional: true\n     dependencies:\n       picomatch: 4.0.2\n+    dev: false\n \n   /fdir@6.4.4(picomatch@4.0.2):\n     resolution: {integrity: sha512-1NZP+GK4GfuAv3PqKvxQRDMjdSRZjnkq7KfhlNrCNNlZ0ygQFpebfrnfnq/W7fpUnAv9aGWmY1zKx7FYL3gwhg==}\n@@ -25428,7 +25416,7 @@ packages:\n     resolution: {integrity: sha512-7vuh85V5cdDofPyxn58nrPjBktZo0u9x1g8WtjQol+jZDaE+fhN+cIvTj11GndBnMnyfrUOG1sZQxCdjKh+DKg==}\n     engines: {node: '>= 10.13.0'}\n     dependencies:\n-      '@types/node': 22.13.9\n+      '@types/node': 20.14.14\n       merge-stream: 2.0.0\n       supports-color: 8.1.1\n \n@@ -31044,7 +31032,7 @@ packages:\n     resolution: {integrity: sha512-pN/yOAvcC+5rQ5nERGuwrjLlYvLTbCibnZ1I7B1LaiAz9BRBlE9GMgE/eqV30P7aJQUf7Ddimy/RsbYO/GrVGg==}\n     engines: {node: '>= 10.13.0'}\n     dependencies:\n-      '@types/json-schema': 7.0.13\n+      '@types/json-schema': 7.0.15\n       ajv: 6.12.6\n       ajv-keywords: 3.5.2(ajv@6.12.6)\n     dev: false\n@@ -32686,7 +32674,7 @@ packages:\n     resolution: {integrity: sha512-qkf4trmKSIiMTs/E63cxH+ojC2unam7rJ0WrauAzpT3ECNTxGRMlaXxVbfxMUC/w0LaYk6jQ4y/nGR9uBO3tww==}\n     engines: {node: '>=12.0.0'}\n     dependencies:\n-      fdir: 6.4.3(picomatch@4.0.2)\n+      fdir: 6.4.4(picomatch@4.0.2)\n       picomatch: 4.0.2\n     dev: true\n \n@@ -33381,6 +33369,7 @@ packages:\n \n   /undici-types@6.20.0:\n     resolution: {integrity: sha512-Ny6QZ2Nju20vw1SRHe3d9jVu6gJ+4e3+MMpqu7pqE5HT6WsTSlce++GQmK5UXS8mzV8DSYHrQH+Xrf2jVcuKNg==}\n+    dev: false\n \n   /undici@5.28.4:\n     resolution: {integrity: sha512-72RFADWFqKmUb2hmmvNODKL3p9hcB6Gt2DOQMis1SEBaV6a4MH8soBvzg+95CYhCKPFedut2JY9bMfrDl9D23g==}\n@@ -34698,6 +34687,13 @@ packages:\n     dependencies:\n       zod: 3.25.76\n \n+  /zod-to-json-schema@3.24.6(zod@3.25.76):\n+    resolution: {integrity: sha512-h/z3PKvcTcTetyjl1fkj79MHNEjm+HpD6NXheWjzOekY7kV+lwDYnHw+ivHkijnCSMz1yJaWBD9vu/Fcmk+vEg==}\n+    peerDependencies:\n+      zod: ^3.24.1\n+    dependencies:\n+      zod: 3.25.76\n+\n   /zod-validation-error@1.5.0(zod@3.25.76):\n     resolution: {integrity: sha512-/7eFkAI4qV0tcxMBB/3+d2c1P6jzzZYdYSlBuAklzMuCrJu5bzJfHS0yVAS87dRHVlhftd6RFJDIvv03JgkSbw==}\n     engines: {node: '>=16.0.0'}\ndiff --git a/references/hello-world/src/trigger/jsonSchema.ts b/references/hello-world/src/trigger/jsonSchema.ts\nindex f347f9d389..d4da2c783c 100644\n--- a/references/hello-world/src/trigger/jsonSchema.ts\n+++ b/references/hello-world/src/trigger/jsonSchema.ts\n@@ -1,5 +1,6 @@\n import { task, schemaTask, logger, type JSONSchema } from \"@trigger.dev/sdk/v3\";\n-import { z } from \"zod\";\n+import { z } from \"zod/v3\";\n+import * as z4 from \"zod/v4\";\n import * as y from \"yup\";\n import { type } from \"arktype\";\n import { Type, Static } from \"@sinclair/typebox\";\n@@ -39,6 +40,38 @@ export const processUserWithZod = schemaTask({\n   },\n });\n \n+const userSchema4 = z4.object({\n+  id: z4.uuid(),\n+  name: z4.string().min(1),\n+  email: z4.email(),\n+  age: z4.number().int().min(0).max(150),\n+  preferences: z4\n+    .object({\n+      newsletter: z4.boolean().default(false),\n+      theme: z4.enum([\"light\", \"dark\"]).default(\"light\"),\n+    })\n+    .optional(),\n+});\n+\n+export const processUserWithZod4 = schemaTask({\n+  id: \"json-schema-zod-example-4\",\n+  schema: userSchema4,\n+  run: async (payload, { ctx }) => {\n+    // payload is fully typed based on the Zod schema\n+    logger.info(\"Processing user with Zod schema\", {\n+      userId: payload.id,\n+      userName: payload.name,\n+    });\n+\n+    // The schema is automatically converted to JSON Schema and synced\n+    return {\n+      processed: true,\n+      userId: payload.id,\n+      welcomeMessage: `Welcome ${payload.name}!`,\n+    };\n+  },\n+});\n+\n // ===========================================\n // Example 2: Using plain task with manual JSON Schema\n // ===========================================\n", "test_patch": "", "problem_statement": "", "hints_text": ""}
{"instance_id": "triggerdotdev__trigger.dev.pr_mirror.2523", "repo": "triggerdotdev/trigger.dev", "base_commit": "a3ef6ea2363a6617296d6132a76c6d9a595f3a3e", "head_commit": "97160380d1ad0d7d49bed7b1d41e235c821daf51", "title": "fix(runner): reduce restore recovery time and deprecated runner false positives", "merged_at": "2025-09-18T15:59:44Z", "html_url": "https://github.com/triggerdotdev/trigger.dev/pull/2523", "test_files": ["packages/cli-v3/src/entryPoints/managed/snapshot.test.ts"], "code_files": ["apps/supervisor/src/workloadServer/index.ts", "packages/cli-v3/src/entryPoints/managed/controller.ts", "packages/cli-v3/src/entryPoints/managed/execution.ts", "packages/cli-v3/src/entryPoints/managed/snapshot.ts", "packages/core/src/v3/runEngineWorker/workload/http.ts"], "total_changes": 341, "num_files": 7, "pull_number": 2523, "patch": "diff --git a/.changeset/six-cougars-play.md b/.changeset/six-cougars-play.md\nnew file mode 100644\nindex 0000000000..75d128dddd\n--- /dev/null\n+++ b/.changeset/six-cougars-play.md\n@@ -0,0 +1,6 @@\n+---\n+\"trigger.dev\": patch\n+\"@trigger.dev/core\": patch\n+---\n+\n+Reduce restore recovery time and fix deprecated runner false positives\n\\ No newline at end of file\ndiff --git a/apps/supervisor/src/workloadServer/index.ts b/apps/supervisor/src/workloadServer/index.ts\nindex 6b24ffcf33..35d53d3609 100644\n--- a/apps/supervisor/src/workloadServer/index.ts\n+++ b/apps/supervisor/src/workloadServer/index.ts\n@@ -125,7 +125,7 @@ export class WorkloadServer extends EventEmitter<WorkloadServerEvents> {\n   }\n \n   private createHttpServer({ host, port }: { host: string; port: number }) {\n-    return new HttpServer({\n+    const httpServer = new HttpServer({\n       port,\n       host,\n       metrics: {\n@@ -346,23 +346,6 @@ export class WorkloadServer extends EventEmitter<WorkloadServerEvents> {\n           },\n         }\n       )\n-      .route(\"/api/v1/workload-actions/runs/:runFriendlyId/logs/debug\", \"POST\", {\n-        paramsSchema: WorkloadActionParams.pick({ runFriendlyId: true }),\n-        bodySchema: WorkloadDebugLogRequestBody,\n-        handler: async ({ req, reply, params, body }) => {\n-          reply.empty(204);\n-\n-          if (!env.SEND_RUN_DEBUG_LOGS) {\n-            return;\n-          }\n-\n-          await this.workerClient.sendDebugLog(\n-            params.runFriendlyId,\n-            body,\n-            this.runnerIdFromRequest(req)\n-          );\n-        },\n-      })\n       .route(\"/api/v1/workload-actions/deployments/:deploymentId/dequeue\", \"GET\", {\n         paramsSchema: z.object({\n           deploymentId: z.string(),\n@@ -387,6 +370,31 @@ export class WorkloadServer extends EventEmitter<WorkloadServerEvents> {\n           reply.json(dequeueResponse.data satisfies WorkloadDequeueFromVersionResponseBody);\n         },\n       });\n+\n+    if (env.SEND_RUN_DEBUG_LOGS) {\n+      httpServer.route(\"/api/v1/workload-actions/runs/:runFriendlyId/logs/debug\", \"POST\", {\n+        paramsSchema: WorkloadActionParams.pick({ runFriendlyId: true }),\n+        bodySchema: WorkloadDebugLogRequestBody,\n+        handler: async ({ req, reply, params, body }) => {\n+          reply.empty(204);\n+\n+          await this.workerClient.sendDebugLog(\n+            params.runFriendlyId,\n+            body,\n+            this.runnerIdFromRequest(req)\n+          );\n+        },\n+      });\n+    } else {\n+      // Lightweight mock route without schemas\n+      httpServer.route(\"/api/v1/workload-actions/runs/:runFriendlyId/logs/debug\", \"POST\", {\n+        handler: async ({ reply }) => {\n+          reply.empty(204);\n+        },\n+      });\n+    }\n+\n+    return httpServer;\n   }\n \n   private createWebsocketServer() {\ndiff --git a/packages/cli-v3/src/entryPoints/managed/controller.ts b/packages/cli-v3/src/entryPoints/managed/controller.ts\nindex 80bd744dfa..c721cefc56 100644\n--- a/packages/cli-v3/src/entryPoints/managed/controller.ts\n+++ b/packages/cli-v3/src/entryPoints/managed/controller.ts\n@@ -461,19 +461,6 @@ export class ManagedRunController {\n         runId: this.runFriendlyId,\n         message: \"Socket connected to supervisor\",\n       });\n-\n-      // This should handle the case where we reconnect after being restored\n-      if (\n-        this.runFriendlyId &&\n-        this.snapshotFriendlyId &&\n-        this.runFriendlyId !== this.env.TRIGGER_RUN_ID\n-      ) {\n-        this.sendDebugLog({\n-          runId: this.runFriendlyId,\n-          message: \"Subscribing to notifications for in-progress run\",\n-        });\n-        this.subscribeToRunNotifications(this.runFriendlyId, this.snapshotFriendlyId);\n-      }\n     });\n \n     socket.on(\"connect_error\", (error) => {\n@@ -514,7 +501,7 @@ export class ManagedRunController {\n           supervisorApiUrl: this.env.TRIGGER_SUPERVISOR_API_URL,\n         };\n \n-        await this.currentExecution.processEnvOverrides(\"socket disconnected\", true);\n+        const result = await this.currentExecution.processEnvOverrides(\"socket disconnected\", true);\n \n         const newEnv = {\n           workerInstanceName: this.env.TRIGGER_WORKER_INSTANCE_NAME,\n@@ -528,6 +515,43 @@ export class ManagedRunController {\n           properties: { reason, ...parseDescription(), currentEnv, newEnv },\n         });\n \n+        if (!result) {\n+          return;\n+        }\n+\n+        // If runner ID changed, we detected a restore\n+        if (result.runnerIdChanged) {\n+          this.sendDebugLog({\n+            runId: this.runFriendlyId,\n+            message: \"Runner ID changed - restore detected\",\n+            properties: {\n+              supervisorChanged: result.supervisorChanged,\n+            },\n+          });\n+\n+          if (!result.supervisorChanged) {\n+            return;\n+          }\n+\n+          // Only reconnect WebSocket if supervisor URL actually changed\n+          this.sendDebugLog({\n+            runId: this.runFriendlyId,\n+            message: \"Supervisor URL changed - creating new socket connection\",\n+          });\n+\n+          // First disconnect the old socket to avoid conflicts\n+          socket.removeAllListeners();\n+          socket.disconnect();\n+\n+          // Create a new socket with the updated URL and headers\n+          this.socket = this.createSupervisorSocket();\n+\n+          // Re-subscribe to notifications if we have an active execution\n+          if (this.runFriendlyId && this.snapshotFriendlyId) {\n+            this.subscribeToRunNotifications(this.runFriendlyId, this.snapshotFriendlyId);\n+          }\n+        }\n+\n         return;\n       }\n \ndiff --git a/packages/cli-v3/src/entryPoints/managed/execution.ts b/packages/cli-v3/src/entryPoints/managed/execution.ts\nindex 2b9e0c9c08..2dd3e6838e 100644\n--- a/packages/cli-v3/src/entryPoints/managed/execution.ts\n+++ b/packages/cli-v3/src/entryPoints/managed/execution.ts\n@@ -873,7 +873,23 @@ export class RunExecution {\n     );\n \n     if (!continuationResult.success) {\n-      throw new Error(continuationResult.error);\n+      // Check if we need to refresh metadata due to connection error\n+      if (continuationResult.isConnectionError) {\n+        this.sendDebugLog(\"restore: connection error detected, refreshing metadata\");\n+        await this.processEnvOverrides(\"restore connection error\");\n+\n+        // Retry the continuation after refreshing metadata\n+        const retryResult = await this.httpClient.continueRunExecution(\n+          this.runFriendlyId,\n+          this.snapshotManager.snapshotId\n+        );\n+\n+        if (!retryResult.success) {\n+          throw new Error(retryResult.error);\n+        }\n+      } else {\n+        throw new Error(continuationResult.error);\n+      }\n     }\n \n     // Track restore count\n@@ -899,11 +915,18 @@ export class RunExecution {\n   public async processEnvOverrides(\n     reason?: string,\n     shouldPollForSnapshotChanges?: boolean\n-  ): Promise<{ overrides: Metadata } | null> {\n+  ): Promise<{\n+    overrides: Metadata;\n+    runnerIdChanged?: boolean;\n+    supervisorChanged?: boolean;\n+  } | null> {\n     if (!this.metadataClient) {\n       return null;\n     }\n \n+    const previousRunnerId = this.env.TRIGGER_RUNNER_ID;\n+    const previousSupervisorUrl = this.env.TRIGGER_SUPERVISOR_API_URL;\n+\n     const [error, overrides] = await this.metadataClient.getEnvOverrides();\n \n     if (error) {\n@@ -931,6 +954,14 @@ export class RunExecution {\n     // Override the env with the new values\n     this.env.override(overrides);\n \n+    // Check if runner ID changed\n+    const newRunnerId = this.env.TRIGGER_RUNNER_ID;\n+    const runnerIdChanged = previousRunnerId !== newRunnerId;\n+\n+    // Check if supervisor URL changed\n+    const newSupervisorUrl = this.env.TRIGGER_SUPERVISOR_API_URL;\n+    const supervisorChanged = previousSupervisorUrl !== newSupervisorUrl;\n+\n     // Update services with new values\n     if (overrides.TRIGGER_SNAPSHOT_POLL_INTERVAL_SECONDS) {\n       this.snapshotPoller?.updateInterval(this.env.TRIGGER_SNAPSHOT_POLL_INTERVAL_SECONDS * 1000);\n@@ -954,6 +985,8 @@ export class RunExecution {\n \n     return {\n       overrides,\n+      runnerIdChanged,\n+      supervisorChanged,\n     };\n   }\n \n@@ -977,6 +1010,12 @@ export class RunExecution {\n \n     if (!response.success) {\n       this.sendDebugLog(\"heartbeat: failed\", { error: response.error });\n+\n+      // Check if we need to refresh metadata due to connection error\n+      if (response.isConnectionError) {\n+        this.sendDebugLog(\"heartbeat: connection error detected, refreshing metadata\");\n+        await this.processEnvOverrides(\"heartbeat connection error\");\n+      }\n     }\n \n     this.lastHeartbeat = new Date();\n@@ -1192,6 +1231,14 @@ export class RunExecution {\n         error: response.error,\n       });\n \n+      if (response.isConnectionError) {\n+        // Log this separately to make it more visible\n+        this.sendDebugLog(\n+          \"fetchAndProcessSnapshotChanges: connection error detected, refreshing metadata\"\n+        );\n+      }\n+\n+      // Always trigger metadata refresh on snapshot fetch errors\n       await this.processEnvOverrides(\"snapshots since error\");\n       return;\n     }\ndiff --git a/packages/cli-v3/src/entryPoints/managed/snapshot.test.ts b/packages/cli-v3/src/entryPoints/managed/snapshot.test.ts\nindex 05cba11f38..a3dbab3883 100644\n--- a/packages/cli-v3/src/entryPoints/managed/snapshot.test.ts\n+++ b/packages/cli-v3/src/entryPoints/managed/snapshot.test.ts\n@@ -697,6 +697,65 @@ describe(\"SnapshotManager\", () => {\n       true\n     );\n   });\n+\n+  it(\"should handle deprecated snapshot race condition - avoid false positives from stale polls\", async () => {\n+    const onSnapshotChange = vi.fn();\n+\n+    // Mock MetadataClient to simulate runner ID change (restore detected) on first call\n+    let isFirstCall = true;\n+    const mockMetadataClient = {\n+      getEnvOverrides: vi.fn().mockImplementation(() => {\n+        if (isFirstCall) {\n+          isFirstCall = false;\n+          return Promise.resolve([null, { TRIGGER_RUNNER_ID: \"test-runner-2\" }]); // Different runner ID = restore\n+        }\n+        return Promise.resolve([null, { TRIGGER_RUNNER_ID: \"test-runner-2\" }]); // Same runner ID afterward\n+      }),\n+    };\n+\n+    const manager = new SnapshotManager({\n+      runnerId: \"test-runner-1\",\n+      runFriendlyId: \"test-run-1\",\n+      initialSnapshotId: \"snapshot-1\",\n+      initialStatus: \"EXECUTING_WITH_WAITPOINTS\",\n+      logger: mockLogger,\n+      metadataClient: mockMetadataClient as any,\n+      onSnapshotChange,\n+      onSuspendable: mockSuspendableHandler,\n+    });\n+\n+    // First update: Process restore transition with deprecated statuses (normal case)\n+    // This simulates: EXECUTING_WITH_WAITPOINTS -> [SUSPENDED, QUEUED] -> PENDING_EXECUTING\n+    await manager.handleSnapshotChanges([\n+      createRunExecutionData({ snapshotId: \"snapshot-suspended\", executionStatus: \"SUSPENDED\" }),\n+      createRunExecutionData({ snapshotId: \"snapshot-queued\", executionStatus: \"QUEUED\" }),\n+      createRunExecutionData({ snapshotId: \"snapshot-2\", executionStatus: \"PENDING_EXECUTING\" }),\n+    ]);\n+\n+    // First call should be deprecated=false (restore detected)\n+    expect(onSnapshotChange).toHaveBeenCalledWith(\n+      expect.objectContaining({ snapshot: expect.objectContaining({ friendlyId: \"snapshot-2\" }) }),\n+      false\n+    );\n+\n+    onSnapshotChange.mockClear();\n+\n+    // Second update: Should only get new snapshot (race condition case)\n+    // This simulates a stale poll that returns: getSnapshotsSince(snapshot-1) -> [SUSPENDED, QUEUED, snapshot-2, snapshot-3]\n+    // The SUSPENDED/QUEUED should be ignored as already seen\n+    await manager.handleSnapshotChanges([\n+      createRunExecutionData({ snapshotId: \"snapshot-suspended\", executionStatus: \"SUSPENDED\" }), // Already seen\n+      createRunExecutionData({ snapshotId: \"snapshot-queued\", executionStatus: \"QUEUED\" }), // Already seen\n+      createRunExecutionData({ snapshotId: \"snapshot-2\", executionStatus: \"PENDING_EXECUTING\" }), // Already processed\n+      createRunExecutionData({ snapshotId: \"snapshot-3\", executionStatus: \"EXECUTING\" }), // New\n+    ]);\n+\n+    // Should call onSnapshotChange with deprecated = false (no new deprecated snapshots)\n+    expect(onSnapshotChange).toHaveBeenCalledWith(\n+      expect.objectContaining({ snapshot: expect.objectContaining({ friendlyId: \"snapshot-3\" }) }),\n+      false\n+    );\n+  });\n });\n \n // Helper to generate RunExecutionData with sensible defaults\ndiff --git a/packages/cli-v3/src/entryPoints/managed/snapshot.ts b/packages/cli-v3/src/entryPoints/managed/snapshot.ts\nindex 75d3d4b036..9703ea8f87 100644\n--- a/packages/cli-v3/src/entryPoints/managed/snapshot.ts\n+++ b/packages/cli-v3/src/entryPoints/managed/snapshot.ts\n@@ -49,6 +49,10 @@ export class SnapshotManager {\n   private changeQueue: QueuedChangeItem[] = [];\n   private isProcessingQueue = false;\n \n+  // Track seen deprecated snapshots to prevent false positives\n+  private seenDeprecatedSnapshotIds: string[] = [];\n+  private readonly maxSeenDeprecatedSnapshotIds = 50;\n+\n   constructor(opts: SnapshotManagerOptions) {\n     this.runFriendlyId = opts.runFriendlyId;\n     this.runnerId = opts.runnerId;\n@@ -284,9 +288,13 @@ export class SnapshotManager {\n \n         // Check if any previous snapshot is QUEUED or SUSPENDED\n         const deprecatedStatus: TaskRunExecutionStatus[] = [\"QUEUED\", \"SUSPENDED\"];\n-        const deprecatedSnapshots = previousSnapshots.filter((snap) =>\n-          deprecatedStatus.includes(snap.snapshot.executionStatus)\n-        );\n+        const deprecatedSnapshots = previousSnapshots.filter((snap) => {\n+          const isDeprecated = deprecatedStatus.includes(snap.snapshot.executionStatus);\n+          const previouslySeen = this.seenDeprecatedSnapshotIds.some(\n+            (s) => s === snap.snapshot.friendlyId\n+          );\n+          return isDeprecated && !previouslySeen;\n+        });\n \n         let deprecated = false;\n         if (deprecatedSnapshots.length > 0) {\n@@ -298,6 +306,18 @@ export class SnapshotManager {\n           } else {\n             deprecated = true;\n           }\n+\n+          // Add the deprecated snapshot IDs to the seen list\n+          this.seenDeprecatedSnapshotIds.push(\n+            ...deprecatedSnapshots.map((s) => s.snapshot.friendlyId)\n+          );\n+\n+          if (this.seenDeprecatedSnapshotIds.length > this.maxSeenDeprecatedSnapshotIds) {\n+            // Only keep the latest maxSeenDeprecatedSnapshotIds\n+            this.seenDeprecatedSnapshotIds = this.seenDeprecatedSnapshotIds.slice(\n+              -this.maxSeenDeprecatedSnapshotIds\n+            );\n+          }\n         }\n \n         const { snapshot } = latestSnapshot;\ndiff --git a/packages/core/src/v3/runEngineWorker/workload/http.ts b/packages/core/src/v3/runEngineWorker/workload/http.ts\nindex 57c7f06e35..93fa7bf03c 100644\n--- a/packages/core/src/v3/runEngineWorker/workload/http.ts\n+++ b/packages/core/src/v3/runEngineWorker/workload/http.ts\n@@ -52,18 +52,58 @@ export class WorkloadHttpClient {\n     });\n   }\n \n+  private isConnectionError(error: string): boolean {\n+    const connectionErrors = [\n+      \"Connection error\",\n+      \"ECONNREFUSED\",\n+      \"ETIMEDOUT\",\n+      \"ENOTFOUND\",\n+      \"ECONNRESET\",\n+      \"EHOSTUNREACH\",\n+      \"ENETUNREACH\",\n+      \"EPIPE\",\n+      \"ECONNABORTED\",\n+    ];\n+    return connectionErrors.some((errType) => error.includes(errType));\n+  }\n+\n+  private async withConnectionErrorDetection<T>(\n+    operation: () => Promise<{ success: true; data: T } | { success: false; error: string }>\n+  ): Promise<\n+    { success: true; data: T } | { success: false; error: string; isConnectionError?: boolean }\n+  > {\n+    const result = await operation();\n+\n+    if (result.success) {\n+      return result;\n+    }\n+\n+    // Check if this is a connection error\n+    if (this.isConnectionError(result.error)) {\n+      return {\n+        ...result,\n+        isConnectionError: true,\n+      };\n+    }\n+\n+    return result;\n+  }\n+\n   async heartbeatRun(runId: string, snapshotId: string, body?: WorkloadHeartbeatRequestBody) {\n-    return wrapZodFetch(\n-      WorkloadHeartbeatResponseBody,\n-      `${this.apiUrl}/api/v1/workload-actions/runs/${runId}/snapshots/${snapshotId}/heartbeat`,\n-      {\n-        method: \"POST\",\n-        headers: {\n-          ...this.defaultHeaders(),\n-          \"Content-Type\": \"application/json\",\n-        },\n-        body: JSON.stringify(body ?? {}),\n-      }\n+    return this.withConnectionErrorDetection(() =>\n+      wrapZodFetch(\n+        WorkloadHeartbeatResponseBody,\n+        `${this.apiUrl}/api/v1/workload-actions/runs/${runId}/snapshots/${snapshotId}/heartbeat`,\n+        {\n+          method: \"POST\",\n+          headers: {\n+            ...this.defaultHeaders(),\n+            \"Content-Type\": \"application/json\",\n+          },\n+          body: JSON.stringify(body ?? {}),\n+          signal: AbortSignal.timeout(10_000), // 10 second timeout\n+        }\n+      )\n     );\n   }\n \n@@ -81,15 +121,17 @@ export class WorkloadHttpClient {\n   }\n \n   async continueRunExecution(runId: string, snapshotId: string) {\n-    return wrapZodFetch(\n-      WorkloadContinueRunExecutionResponseBody,\n-      `${this.apiUrl}/api/v1/workload-actions/runs/${runId}/snapshots/${snapshotId}/continue`,\n-      {\n-        method: \"GET\",\n-        headers: {\n-          ...this.defaultHeaders(),\n-        },\n-      }\n+    return this.withConnectionErrorDetection(() =>\n+      wrapZodFetch(\n+        WorkloadContinueRunExecutionResponseBody,\n+        `${this.apiUrl}/api/v1/workload-actions/runs/${runId}/snapshots/${snapshotId}/continue`,\n+        {\n+          method: \"GET\",\n+          headers: {\n+            ...this.defaultHeaders(),\n+          },\n+        }\n+      )\n     );\n   }\n \n@@ -130,15 +172,18 @@ export class WorkloadHttpClient {\n   }\n \n   async getSnapshotsSince(runId: string, snapshotId: string) {\n-    return wrapZodFetch(\n-      WorkloadRunSnapshotsSinceResponseBody,\n-      `${this.apiUrl}/api/v1/workload-actions/runs/${runId}/snapshots/since/${snapshotId}`,\n-      {\n-        method: \"GET\",\n-        headers: {\n-          ...this.defaultHeaders(),\n-        },\n-      }\n+    return this.withConnectionErrorDetection(() =>\n+      wrapZodFetch(\n+        WorkloadRunSnapshotsSinceResponseBody,\n+        `${this.apiUrl}/api/v1/workload-actions/runs/${runId}/snapshots/since/${snapshotId}`,\n+        {\n+          method: \"GET\",\n+          headers: {\n+            ...this.defaultHeaders(),\n+          },\n+          signal: AbortSignal.timeout(10_000), // 10 second timeout\n+        }\n+      )\n     );\n   }\n \n", "test_patch": "", "problem_statement": "", "hints_text": ""}
{"instance_id": "triggerdotdev__trigger.dev.pr_mirror.2519", "repo": "triggerdotdev/trigger.dev", "base_commit": "691903cf580eeb4b19798318edab075d634caa9e", "head_commit": "2579d2f237cf3b01d936e71e61fce5e350ebcd56", "title": "fix(engine): prevent race condition that prevents triggerAndWait runs from resuming by atomically creating associated waitpoint records", "merged_at": "2025-09-17T12:58:17Z", "html_url": "https://github.com/triggerdotdev/trigger.dev/pull/2519", "test_files": ["apps/webapp/test/engine/triggerTask.test.ts", "internal-packages/run-engine/src/engine/tests/triggerAndWait.test.ts"], "code_files": ["apps/webapp/app/runEngine/services/triggerTask.server.ts", "apps/webapp/app/runEngine/types.ts", "internal-packages/run-engine/src/engine/index.ts", "internal-packages/run-engine/src/engine/systems/waitpointSystem.ts"], "total_changes": 508, "num_files": 6, "pull_number": 2519, "patch": "diff --git a/apps/webapp/app/runEngine/services/triggerTask.server.ts b/apps/webapp/app/runEngine/services/triggerTask.server.ts\nindex 0203ba0c76..1b598e592b 100644\n--- a/apps/webapp/app/runEngine/services/triggerTask.server.ts\n+++ b/apps/webapp/app/runEngine/services/triggerTask.server.ts\n@@ -37,11 +37,19 @@ import type {\n   QueueManager,\n   RunNumberIncrementer,\n   TraceEventConcern,\n+  TriggerRacepoints,\n+  TriggerRacepointSystem,\n   TriggerTaskRequest,\n   TriggerTaskValidator,\n } from \"../types\";\n import { ServiceValidationError } from \"~/v3/services/common.server\";\n \n+class NoopTriggerRacepointSystem implements TriggerRacepointSystem {\n+  async waitForRacepoint(options: { racepoint: TriggerRacepoints; id: string }): Promise<void> {\n+    return;\n+  }\n+}\n+\n export class RunEngineTriggerTaskService {\n   private readonly queueConcern: QueueManager;\n   private readonly validator: TriggerTaskValidator;\n@@ -52,6 +60,7 @@ export class RunEngineTriggerTaskService {\n   private readonly engine: RunEngine;\n   private readonly tracer: Tracer;\n   private readonly traceEventConcern: TraceEventConcern;\n+  private readonly triggerRacepointSystem: TriggerRacepointSystem;\n   private readonly metadataMaximumSize: number;\n \n   constructor(opts: {\n@@ -65,6 +74,7 @@ export class RunEngineTriggerTaskService {\n     traceEventConcern: TraceEventConcern;\n     tracer: Tracer;\n     metadataMaximumSize: number;\n+    triggerRacepointSystem?: TriggerRacepointSystem;\n   }) {\n     this.prisma = opts.prisma;\n     this.engine = opts.engine;\n@@ -76,6 +86,7 @@ export class RunEngineTriggerTaskService {\n     this.tracer = opts.tracer;\n     this.traceEventConcern = opts.traceEventConcern;\n     this.metadataMaximumSize = opts.metadataMaximumSize;\n+    this.triggerRacepointSystem = opts.triggerRacepointSystem ?? new NoopTriggerRacepointSystem();\n   }\n \n   public async call({\n@@ -196,19 +207,16 @@ export class RunEngineTriggerTaskService {\n \n       const { idempotencyKey, idempotencyKeyExpiresAt } = idempotencyKeyConcernResult;\n \n+      if (idempotencyKey) {\n+        await this.triggerRacepointSystem.waitForRacepoint({\n+          racepoint: \"idempotencyKey\",\n+          id: idempotencyKey,\n+        });\n+      }\n+\n       if (!options.skipChecks) {\n         const queueSizeGuard = await this.queueConcern.validateQueueLimits(environment);\n \n-        logger.debug(\"Queue size guard result\", {\n-          queueSizeGuard,\n-          environment: {\n-            id: environment.id,\n-            type: environment.type,\n-            organization: environment.organization,\n-            project: environment.project,\n-          },\n-        });\n-\n         if (!queueSizeGuard.ok) {\n           throw new ServiceValidationError(\n             `Cannot trigger ${taskId} as the queue size limit for this environment has been reached. The maximum size is ${queueSizeGuard.maximumSize}`\ndiff --git a/apps/webapp/app/runEngine/types.ts b/apps/webapp/app/runEngine/types.ts\nindex b1aa8b7715..10dcbd7a3d 100644\n--- a/apps/webapp/app/runEngine/types.ts\n+++ b/apps/webapp/app/runEngine/types.ts\n@@ -156,3 +156,9 @@ export interface TraceEventConcern {\n     callback: (span: TracedEventSpan) => Promise<T>\n   ): Promise<T>;\n }\n+\n+export type TriggerRacepoints = \"idempotencyKey\";\n+\n+export interface TriggerRacepointSystem {\n+  waitForRacepoint(options: { racepoint: TriggerRacepoints; id: string }): Promise<void>;\n+}\ndiff --git a/apps/webapp/test/engine/triggerTask.test.ts b/apps/webapp/test/engine/triggerTask.test.ts\nindex ad16be44e7..e21e0dbb2e 100644\n--- a/apps/webapp/test/engine/triggerTask.test.ts\n+++ b/apps/webapp/test/engine/triggerTask.test.ts\n@@ -16,7 +16,7 @@ vi.mock(\"~/services/platform.v3.server\", async (importOriginal) => {\n \n import { RunEngine } from \"@internal/run-engine\";\n import { setupAuthenticatedEnvironment, setupBackgroundWorker } from \"@internal/run-engine/tests\";\n-import { containerTest } from \"@internal/testcontainers\";\n+import { assertNonNullable, containerTest } from \"@internal/testcontainers\";\n import { trace } from \"@opentelemetry/api\";\n import { IOPacket } from \"@trigger.dev/core/v3\";\n import { TaskRun } from \"@trigger.dev/database\";\n@@ -31,11 +31,15 @@ import {\n   TagValidationParams,\n   TracedEventSpan,\n   TraceEventConcern,\n+  TriggerRacepoints,\n+  TriggerRacepointSystem,\n   TriggerTaskRequest,\n   TriggerTaskValidator,\n   ValidationResult,\n } from \"~/runEngine/types\";\n import { RunEngineTriggerTaskService } from \"../../app/runEngine/services/triggerTask.server\";\n+import { promiseWithResolvers } from \"@trigger.dev/core\";\n+import { setTimeout } from \"node:timers/promises\";\n \n vi.setConfig({ testTimeout: 30_000 }); // 30 seconds timeout\n \n@@ -108,6 +112,29 @@ class MockTraceEventConcern implements TraceEventConcern {\n   }\n }\n \n+type TriggerRacepoint = { promise: Promise<void>; resolve: (value: void) => void };\n+\n+class MockTriggerRacepointSystem implements TriggerRacepointSystem {\n+  private racepoints: Record<string, TriggerRacepoint | undefined> = {};\n+\n+  async waitForRacepoint({ id }: { racepoint: TriggerRacepoints; id: string }): Promise<void> {\n+    const racepoint = this.racepoints[id];\n+\n+    if (racepoint) {\n+      return racepoint.promise;\n+    }\n+\n+    return Promise.resolve();\n+  }\n+\n+  registerRacepoint(racepoint: TriggerRacepoints, id: string): TriggerRacepoint {\n+    const { promise, resolve } = promiseWithResolvers<void>();\n+    this.racepoints[id] = { promise, resolve };\n+\n+    return { promise, resolve };\n+  }\n+}\n+\n describe(\"RunEngineTriggerTaskService\", () => {\n   containerTest(\"should trigger a task with minimal options\", async ({ prisma, redisOptions }) => {\n     const engine = new RunEngine({\n@@ -312,6 +339,228 @@ describe(\"RunEngineTriggerTaskService\", () => {\n     await engine.quit();\n   });\n \n+  containerTest(\n+    \"should handle idempotency keys when the engine throws an RunDuplicateIdempotencyKeyError\",\n+    async ({ prisma, redisOptions }) => {\n+      const engine = new RunEngine({\n+        prisma,\n+        worker: {\n+          redis: redisOptions,\n+          workers: 1,\n+          tasksPerWorker: 10,\n+          pollIntervalMs: 100,\n+        },\n+        queue: {\n+          redis: redisOptions,\n+        },\n+        runLock: {\n+          redis: redisOptions,\n+        },\n+        machines: {\n+          defaultMachine: \"small-1x\",\n+          machines: {\n+            \"small-1x\": {\n+              name: \"small-1x\" as const,\n+              cpu: 0.5,\n+              memory: 0.5,\n+              centsPerMs: 0.0001,\n+            },\n+          },\n+          baseCostInCents: 0.0005,\n+        },\n+        tracer: trace.getTracer(\"test\", \"0.0.0\"),\n+        logLevel: \"debug\",\n+      });\n+\n+      const parentTask = \"parent-task\";\n+\n+      const authenticatedEnvironment = await setupAuthenticatedEnvironment(prisma, \"PRODUCTION\");\n+\n+      const taskIdentifier = \"test-task\";\n+\n+      //create background worker\n+      await setupBackgroundWorker(engine, authenticatedEnvironment, [parentTask, taskIdentifier]);\n+\n+      const parentRun1 = await engine.trigger(\n+        {\n+          number: 1,\n+          friendlyId: \"run_p1\",\n+          environment: authenticatedEnvironment,\n+          taskIdentifier: parentTask,\n+          payload: \"{}\",\n+          payloadType: \"application/json\",\n+          context: {},\n+          traceContext: {},\n+          traceId: \"t12345\",\n+          spanId: \"s12345\",\n+          queue: `task/${parentTask}`,\n+          isTest: false,\n+          tags: [],\n+          workerQueue: \"main\",\n+        },\n+        prisma\n+      );\n+\n+      //dequeue parent and create the attempt\n+      await setTimeout(500);\n+      const dequeued = await engine.dequeueFromWorkerQueue({\n+        consumerId: \"test_12345\",\n+        workerQueue: \"main\",\n+      });\n+      await engine.startRunAttempt({\n+        runId: parentRun1.id,\n+        snapshotId: dequeued[0].snapshot.id,\n+      });\n+\n+      const parentRun2 = await engine.trigger(\n+        {\n+          number: 2,\n+          friendlyId: \"run_p2\",\n+          environment: authenticatedEnvironment,\n+          taskIdentifier: parentTask,\n+          payload: \"{}\",\n+          payloadType: \"application/json\",\n+          context: {},\n+          traceContext: {},\n+          traceId: \"t12346\",\n+          spanId: \"s12346\",\n+          queue: `task/${parentTask}`,\n+          isTest: false,\n+          tags: [],\n+          workerQueue: \"main\",\n+        },\n+        prisma\n+      );\n+\n+      await setTimeout(500);\n+      const dequeued2 = await engine.dequeueFromWorkerQueue({\n+        consumerId: \"test_12345\",\n+        workerQueue: \"main\",\n+      });\n+      await engine.startRunAttempt({\n+        runId: parentRun2.id,\n+        snapshotId: dequeued2[0].snapshot.id,\n+      });\n+\n+      const queuesManager = new DefaultQueueManager(prisma, engine);\n+\n+      const idempotencyKeyConcern = new IdempotencyKeyConcern(\n+        prisma,\n+        engine,\n+        new MockTraceEventConcern()\n+      );\n+\n+      const triggerRacepointSystem = new MockTriggerRacepointSystem();\n+\n+      const triggerTaskService = new RunEngineTriggerTaskService({\n+        engine,\n+        prisma,\n+        runNumberIncrementer: new MockRunNumberIncrementer(),\n+        payloadProcessor: new MockPayloadProcessor(),\n+        queueConcern: queuesManager,\n+        idempotencyKeyConcern,\n+        validator: new MockTriggerTaskValidator(),\n+        traceEventConcern: new MockTraceEventConcern(),\n+        tracer: trace.getTracer(\"test\", \"0.0.0\"),\n+        metadataMaximumSize: 1024 * 1024 * 1, // 1MB\n+        triggerRacepointSystem,\n+      });\n+\n+      const idempotencyKey = \"test-idempotency-key\";\n+\n+      const racepoint = triggerRacepointSystem.registerRacepoint(\"idempotencyKey\", idempotencyKey);\n+\n+      const childTriggerPromise1 = triggerTaskService.call({\n+        taskId: taskIdentifier,\n+        environment: authenticatedEnvironment,\n+        body: {\n+          payload: { test: \"test\" },\n+          options: {\n+            idempotencyKey,\n+            parentRunId: parentRun1.friendlyId,\n+            resumeParentOnCompletion: true,\n+          },\n+        },\n+      });\n+\n+      const childTriggerPromise2 = triggerTaskService.call({\n+        taskId: taskIdentifier,\n+        environment: authenticatedEnvironment,\n+        body: {\n+          payload: { test: \"test\" },\n+          options: {\n+            idempotencyKey,\n+            parentRunId: parentRun2.friendlyId,\n+            resumeParentOnCompletion: true,\n+          },\n+        },\n+      });\n+\n+      await setTimeout(500);\n+\n+      // Now we can resolve the racepoint\n+      racepoint.resolve();\n+\n+      const result = await childTriggerPromise1;\n+      const result2 = await childTriggerPromise2;\n+\n+      expect(result).toBeDefined();\n+      expect(result?.run.friendlyId).toBeDefined();\n+      expect(result?.run.status).toBe(\"PENDING\");\n+\n+      const run = await prisma.taskRun.findUnique({\n+        where: {\n+          id: result?.run.id,\n+        },\n+      });\n+\n+      expect(run).toBeDefined();\n+      expect(run?.friendlyId).toBe(result?.run.friendlyId);\n+      expect(run?.engine).toBe(\"V2\");\n+      expect(run?.queuedAt).toBeDefined();\n+      expect(run?.queue).toBe(`task/${taskIdentifier}`);\n+\n+      expect(result2).toBeDefined();\n+      expect(result2?.run.friendlyId).toBe(result?.run.friendlyId);\n+\n+      const parent1ExecutionData = await engine.getRunExecutionData({ runId: parentRun1.id });\n+      assertNonNullable(parent1ExecutionData);\n+      expect(parent1ExecutionData.snapshot.executionStatus).toBe(\"EXECUTING_WITH_WAITPOINTS\");\n+\n+      const parent2ExecutionData = await engine.getRunExecutionData({ runId: parentRun2.id });\n+      assertNonNullable(parent2ExecutionData);\n+      expect(parent2ExecutionData.snapshot.executionStatus).toBe(\"EXECUTING_WITH_WAITPOINTS\");\n+\n+      const parent1RunWaitpoint = await prisma.taskRunWaitpoint.findFirst({\n+        where: {\n+          taskRunId: parentRun1.id,\n+        },\n+        include: {\n+          waitpoint: true,\n+        },\n+      });\n+\n+      assertNonNullable(parent1RunWaitpoint);\n+      expect(parent1RunWaitpoint.waitpoint.type).toBe(\"RUN\");\n+      expect(parent1RunWaitpoint.waitpoint.completedByTaskRunId).toBe(result?.run.id);\n+\n+      const parent2RunWaitpoint = await prisma.taskRunWaitpoint.findFirst({\n+        where: {\n+          taskRunId: parentRun2.id,\n+        },\n+        include: {\n+          waitpoint: true,\n+        },\n+      });\n+\n+      assertNonNullable(parent2RunWaitpoint);\n+      expect(parent2RunWaitpoint.waitpoint.type).toBe(\"RUN\");\n+      expect(parent2RunWaitpoint.waitpoint.completedByTaskRunId).toBe(result2?.run.id);\n+\n+      await engine.quit();\n+    }\n+  );\n+\n   containerTest(\n     \"should resolve queue names correctly when locked to version\",\n     async ({ prisma, redisOptions }) => {\ndiff --git a/internal-packages/run-engine/src/engine/index.ts b/internal-packages/run-engine/src/engine/index.ts\nindex 8f1aedbebe..f9b3061e91 100644\n--- a/internal-packages/run-engine/src/engine/index.ts\n+++ b/internal-packages/run-engine/src/engine/index.ts\n@@ -381,11 +381,15 @@ export class RunEngine {\n         const status = delayUntil ? \"DELAYED\" : \"PENDING\";\n \n         //create run\n-        let taskRun: TaskRun;\n+        let taskRun: TaskRun & { associatedWaitpoint: Waitpoint | null };\n+        const taskRunId = RunId.fromFriendlyId(friendlyId);\n         try {\n           taskRun = await prisma.taskRun.create({\n+            include: {\n+              associatedWaitpoint: true,\n+            },\n             data: {\n-              id: RunId.fromFriendlyId(friendlyId),\n+              id: taskRunId,\n               engine: \"V2\",\n               status,\n               number,\n@@ -459,6 +463,12 @@ export class RunEngine {\n                   runnerId,\n                 },\n               },\n+              associatedWaitpoint: {\n+                create: this.waitpointSystem.buildRunAssociatedWaitpoint({\n+                  projectId: environment.project.id,\n+                  environmentId: environment.id,\n+                }),\n+              },\n             },\n           });\n         } catch (error) {\n@@ -492,23 +502,13 @@ export class RunEngine {\n \n         span.setAttribute(\"runId\", taskRun.id);\n \n-        //create associated waitpoint (this completes when the run completes)\n-        const associatedWaitpoint = await this.waitpointSystem.createRunAssociatedWaitpoint(\n-          prisma,\n-          {\n-            projectId: environment.project.id,\n-            environmentId: environment.id,\n-            completedByTaskRunId: taskRun.id,\n-          }\n-        );\n-\n         //triggerAndWait or batchTriggerAndWait\n-        if (resumeParentOnCompletion && parentTaskRunId) {\n+        if (resumeParentOnCompletion && parentTaskRunId && taskRun.associatedWaitpoint) {\n           //this will block the parent run from continuing until this waitpoint is completed (and removed)\n           await this.waitpointSystem.blockRunWithWaitpoint({\n             runId: parentTaskRunId,\n-            waitpoints: associatedWaitpoint.id,\n-            projectId: associatedWaitpoint.projectId,\n+            waitpoints: taskRun.associatedWaitpoint.id,\n+            projectId: taskRun.associatedWaitpoint.projectId,\n             organizationId: environment.organization.id,\n             batch,\n             workerId,\ndiff --git a/internal-packages/run-engine/src/engine/systems/waitpointSystem.ts b/internal-packages/run-engine/src/engine/systems/waitpointSystem.ts\nindex 4e23934b73..74062ed17e 100644\n--- a/internal-packages/run-engine/src/engine/systems/waitpointSystem.ts\n+++ b/internal-packages/run-engine/src/engine/systems/waitpointSystem.ts\n@@ -738,25 +738,21 @@ export class WaitpointSystem {\n     }); // end of runlock\n   }\n \n-  public async createRunAssociatedWaitpoint(\n-    tx: PrismaClientOrTransaction,\n-    {\n+  public buildRunAssociatedWaitpoint({\n+    projectId,\n+    environmentId,\n+  }: {\n+    projectId: string;\n+    environmentId: string;\n+  }) {\n+    return {\n+      ...WaitpointId.generate(),\n+      type: \"RUN\" as const,\n+      status: \"PENDING\" as const,\n+      idempotencyKey: nanoid(24),\n+      userProvidedIdempotencyKey: false,\n       projectId,\n       environmentId,\n-      completedByTaskRunId,\n-    }: { projectId: string; environmentId: string; completedByTaskRunId: string }\n-  ) {\n-    return tx.waitpoint.create({\n-      data: {\n-        ...WaitpointId.generate(),\n-        type: \"RUN\",\n-        status: \"PENDING\",\n-        idempotencyKey: nanoid(24),\n-        userProvidedIdempotencyKey: false,\n-        projectId,\n-        environmentId,\n-        completedByTaskRunId,\n-      },\n-    });\n+    };\n   }\n }\ndiff --git a/internal-packages/run-engine/src/engine/tests/triggerAndWait.test.ts b/internal-packages/run-engine/src/engine/tests/triggerAndWait.test.ts\nindex 101314e86d..b874d3f4ca 100644\n--- a/internal-packages/run-engine/src/engine/tests/triggerAndWait.test.ts\n+++ b/internal-packages/run-engine/src/engine/tests/triggerAndWait.test.ts\n@@ -4,6 +4,7 @@ import { expect } from \"vitest\";\n import { RunEngine } from \"../index.js\";\n import { setTimeout } from \"node:timers/promises\";\n import { setupAuthenticatedEnvironment, setupBackgroundWorker } from \"./setup.js\";\n+import { RunDuplicateIdempotencyKeyError } from \"../errors.js\";\n \n vi.setConfig({ testTimeout: 60_000 });\n \n@@ -453,4 +454,164 @@ describe(\"RunEngine triggerAndWait\", () => {\n       }\n     }\n   );\n+  containerTest(\n+    \"triggerAndWait two parent runs triggering the same child run with the same idempotency key\",\n+    async ({ prisma, redisOptions }) => {\n+      //create environment\n+      const authenticatedEnvironment = await setupAuthenticatedEnvironment(prisma, \"PRODUCTION\");\n+\n+      const engine = new RunEngine({\n+        prisma,\n+        worker: {\n+          redis: redisOptions,\n+          workers: 1,\n+          tasksPerWorker: 10,\n+          pollIntervalMs: 100,\n+        },\n+        queue: {\n+          redis: redisOptions,\n+          masterQueueConsumersDisabled: true,\n+          processWorkerQueueDebounceMs: 50,\n+        },\n+        runLock: {\n+          redis: redisOptions,\n+        },\n+        machines: {\n+          defaultMachine: \"small-1x\",\n+          machines: {\n+            \"small-1x\": {\n+              name: \"small-1x\" as const,\n+              cpu: 0.5,\n+              memory: 0.5,\n+              centsPerMs: 0.0001,\n+            },\n+          },\n+          baseCostInCents: 0.0001,\n+        },\n+        tracer: trace.getTracer(\"test\", \"0.0.0\"),\n+      });\n+\n+      try {\n+        const parentTask = \"parent-task\";\n+        const childTask = \"child-task\";\n+        const idempotencyKey = \"a-key\";\n+\n+        //create background worker\n+        await setupBackgroundWorker(engine, authenticatedEnvironment, [parentTask, childTask]);\n+\n+        //trigger the run\n+        const parentRun1 = await engine.trigger(\n+          {\n+            number: 1,\n+            friendlyId: \"run_p1234\",\n+            environment: authenticatedEnvironment,\n+            taskIdentifier: parentTask,\n+            payload: \"{}\",\n+            payloadType: \"application/json\",\n+            context: {},\n+            traceContext: {},\n+            traceId: \"t12345\",\n+            spanId: \"s12345\",\n+            queue: `task/${parentTask}`,\n+            isTest: false,\n+            tags: [],\n+            workerQueue: \"main\",\n+          },\n+          prisma\n+        );\n+\n+        //dequeue parent and create the attempt\n+        await setTimeout(500);\n+        const dequeued = await engine.dequeueFromWorkerQueue({\n+          consumerId: \"test_12345\",\n+          workerQueue: \"main\",\n+        });\n+        await engine.startRunAttempt({\n+          runId: parentRun1.id,\n+          snapshotId: dequeued[0].snapshot.id,\n+        });\n+\n+        const parentRun2 = await engine.trigger(\n+          {\n+            number: 2,\n+            friendlyId: \"run_p12345\",\n+            environment: authenticatedEnvironment,\n+            taskIdentifier: parentTask,\n+            payload: \"{}\",\n+            payloadType: \"application/json\",\n+            context: {},\n+            traceContext: {},\n+            traceId: \"t12346\",\n+            spanId: \"s12346\",\n+            queue: `task/${parentTask}`,\n+            isTest: false,\n+            tags: [],\n+            workerQueue: \"main\",\n+          },\n+          prisma\n+        );\n+\n+        await setTimeout(500);\n+        const dequeued2 = await engine.dequeueFromWorkerQueue({\n+          consumerId: \"test_12345\",\n+          workerQueue: \"main\",\n+        });\n+        await engine.startRunAttempt({\n+          runId: parentRun2.id,\n+          snapshotId: dequeued2[0].snapshot.id,\n+        });\n+\n+        await engine.trigger(\n+          {\n+            number: 1,\n+            friendlyId: \"run_c1234\",\n+            environment: authenticatedEnvironment,\n+            taskIdentifier: childTask,\n+            payload: \"{}\",\n+            payloadType: \"application/json\",\n+            context: {},\n+            traceContext: {},\n+            traceId: \"t12345\",\n+            spanId: \"s12345\",\n+            queue: `task/${childTask}`,\n+            isTest: false,\n+            tags: [],\n+            resumeParentOnCompletion: true,\n+            parentTaskRunId: parentRun1.id,\n+            workerQueue: \"main\",\n+            idempotencyKey,\n+          },\n+          prisma\n+        );\n+\n+        // This should throw a RunDuplicateIdempotencyKeyError\n+        await expect(\n+          engine.trigger(\n+            {\n+              number: 2,\n+              friendlyId: \"run_c12345\",\n+              environment: authenticatedEnvironment,\n+              taskIdentifier: childTask,\n+              payload: \"{}\",\n+              payloadType: \"application/json\",\n+              context: {},\n+              traceContext: {},\n+              traceId: \"t123455\",\n+              spanId: \"s123455\",\n+              queue: `task/${childTask}`,\n+              isTest: false,\n+              tags: [],\n+              resumeParentOnCompletion: true,\n+              parentTaskRunId: parentRun2.id,\n+              workerQueue: \"main\",\n+              idempotencyKey,\n+            },\n+            prisma\n+          )\n+        ).rejects.toThrow(RunDuplicateIdempotencyKeyError);\n+      } finally {\n+        await engine.quit();\n+      }\n+    }\n+  );\n });\n", "test_patch": "", "problem_statement": "", "hints_text": ""}
{"instance_id": "triggerdotdev__trigger.dev.pr_mirror.2508", "repo": "triggerdotdev/trigger.dev", "base_commit": "7d333e5b3c0c698f95b8c90896bff3176ccb482b", "head_commit": "ff7be341a80ca382becb0e8695bef27fc4abfffa", "title": "fix(core): prettyPrintingPacket will now do a structuredClone on non-circular references instead of outputting [Circular]", "merged_at": "2025-09-15T16:43:46Z", "html_url": "https://github.com/triggerdotdev/trigger.dev/pull/2508", "test_files": ["apps/webapp/test/fairDequeuingStrategy.test.ts", "packages/core/test/ioSerialization.test.ts"], "code_files": ["apps/webapp/app/routes/resources.taskruns.$runParam.replay.ts", "packages/core/src/v3/utils/ioSerialization.ts", "references/hello-world/src/trigger/circularPayload.ts"], "total_changes": 431, "num_files": 5, "pull_number": 2508, "patch": "diff --git a/apps/webapp/app/routes/resources.taskruns.$runParam.replay.ts b/apps/webapp/app/routes/resources.taskruns.$runParam.replay.ts\nindex 0e87a3d1bd..57de7632a2 100644\n--- a/apps/webapp/app/routes/resources.taskruns.$runParam.replay.ts\n+++ b/apps/webapp/app/routes/resources.taskruns.$runParam.replay.ts\n@@ -108,6 +108,8 @@ export async function loader({ request, params }: LoaderFunctionArgs) {\n   const disableVersionSelection = environment.type === \"DEVELOPMENT\";\n   const allowArbitraryQueues = backgroundWorkers.at(0)?.engine === \"V1\";\n \n+  const payload = await prettyPrintPacket(run.payload, run.payloadType);\n+\n   return typedjson({\n     concurrencyKey: run.concurrencyKey,\n     maxAttempts: run.maxAttempts,\n@@ -116,7 +118,7 @@ export async function loader({ request, params }: LoaderFunctionArgs) {\n     ttlSeconds: run.ttl ? parseDuration(run.ttl, \"s\") ?? undefined : undefined,\n     idempotencyKey: run.idempotencyKey,\n     runTags: run.runTags,\n-    payload: await prettyPrintPacket(run.payload, run.payloadType),\n+    payload,\n     payloadType: run.payloadType,\n     queue: run.queue,\n     metadata: run.seedMetadata\ndiff --git a/apps/webapp/test/fairDequeuingStrategy.test.ts b/apps/webapp/test/fairDequeuingStrategy.test.ts\nindex 3b4a6a375b..0d8b708161 100644\n--- a/apps/webapp/test/fairDequeuingStrategy.test.ts\n+++ b/apps/webapp/test/fairDequeuingStrategy.test.ts\n@@ -270,8 +270,8 @@ describe(\"FairDequeuingStrategy\", () => {\n \n       console.log(\"Second distribution took\", distribute2Duration, \"ms\");\n \n-      // Make sure the second call is more than 2 times faster than the first\n-      expect(distribute2Duration).toBeLessThan(withTolerance(distribute1Duration / 2));\n+      // Make sure the second call is faster than the first\n+      expect(distribute2Duration).toBeLessThan(distribute1Duration);\n \n       const startDistribute3 = performance.now();\n \n@@ -284,8 +284,8 @@ describe(\"FairDequeuingStrategy\", () => {\n \n       console.log(\"Third distribution took\", distribute3Duration, \"ms\");\n \n-      // Make sure the third call is more than 4 times the second\n-      expect(withTolerance(distribute3Duration)).toBeGreaterThan(distribute2Duration * 4);\n+      // Make sure the third call is faster than the second\n+      expect(withTolerance(distribute3Duration)).toBeGreaterThan(distribute2Duration);\n     }\n   );\n \ndiff --git a/packages/core/src/v3/utils/ioSerialization.ts b/packages/core/src/v3/utils/ioSerialization.ts\nindex 103260b85c..9bacc41422 100644\n--- a/packages/core/src/v3/utils/ioSerialization.ts\n+++ b/packages/core/src/v3/utils/ioSerialization.ts\n@@ -1,3 +1,4 @@\n+import { JSONHeroPath } from \"@jsonhero/path\";\n import { Attributes, Span } from \"@opentelemetry/api\";\n import { z } from \"zod\";\n import { ApiClient } from \"../apiClient/index.js\";\n@@ -12,7 +13,6 @@ import { SemanticInternalAttributes } from \"../semanticInternalAttributes.js\";\n import { TriggerTracer } from \"../tracer.js\";\n import { zodfetch } from \"../zodfetch.js\";\n import { flattenAttributes } from \"./flattenAttributes.js\";\n-import { JSONHeroPath } from \"@jsonhero/path\";\n \n export type IOPacket = {\n   data?: string | undefined;\n@@ -389,16 +389,40 @@ export async function prettyPrintPacket(\n     if (typeof rawData === \"string\") {\n       rawData = safeJsonParse(rawData);\n     }\n+\n     const { deserialize } = await loadSuperJSON();\n \n-    return await prettyPrintPacket(deserialize(rawData), \"application/json\");\n+    const hasCircularReferences = rawData && rawData.meta && hasCircularReference(rawData.meta);\n+\n+    if (hasCircularReferences) {\n+      return await prettyPrintPacket(deserialize(rawData), \"application/json\", {\n+        ...options,\n+        cloneReferences: false,\n+      });\n+    }\n+\n+    return await prettyPrintPacket(deserialize(rawData), \"application/json\", {\n+      ...options,\n+      cloneReferences: true,\n+    });\n   }\n \n   if (dataType === \"application/json\") {\n     if (typeof rawData === \"string\") {\n       rawData = safeJsonParse(rawData);\n     }\n-    return JSON.stringify(rawData, makeSafeReplacer(options), 2);\n+\n+    try {\n+      return JSON.stringify(rawData, makeSafeReplacer(options), 2);\n+    } catch (error) {\n+      // If cloneReferences is true, it's possible if our hasCircularReference logic is incorrect that stringifying the data will fail with a circular reference error\n+      // So we will try to stringify the data with cloneReferences set to false\n+      if (options?.cloneReferences) {\n+        return JSON.stringify(rawData, makeSafeReplacer({ ...options, cloneReferences: false }), 2);\n+      }\n+\n+      throw error;\n+    }\n   }\n \n   if (typeof rawData === \"string\") {\n@@ -410,6 +434,7 @@ export async function prettyPrintPacket(\n \n interface ReplacerOptions {\n   filteredKeys?: string[];\n+  cloneReferences?: boolean;\n }\n \n function makeSafeReplacer(options?: ReplacerOptions) {\n@@ -418,6 +443,10 @@ function makeSafeReplacer(options?: ReplacerOptions) {\n   return function replacer(key: string, value: any) {\n     if (typeof value === \"object\" && value !== null) {\n       if (seen.has(value)) {\n+        if (options?.cloneReferences) {\n+          return structuredClone(value);\n+        }\n+\n         return \"[Circular]\";\n       }\n       seen.add(value);\n@@ -557,3 +586,80 @@ function getKeyFromObject(object: unknown, key: string) {\n \n   return jsonHeroPath.first(object);\n }\n+\n+/**\n+ * Detects if a superjson serialization contains circular references\n+ * by analyzing the meta.referentialEqualities structure.\n+ *\n+ * Based on superjson's ReferentialEqualityAnnotations type:\n+ * Record<string, string[]> | [string[]] | [string[], Record<string, string[]>]\n+ *\n+ * Circular references are represented as:\n+ * - [string[]] where strings are paths that reference back to root or ancestors\n+ * - The first element in [string[], Record<string, string[]>] format\n+ */\n+function hasCircularReference(meta: any): boolean {\n+  if (!meta?.referentialEqualities) {\n+    return false;\n+  }\n+\n+  const re = meta.referentialEqualities;\n+\n+  // Case 1: [string[]] - array containing only circular references\n+  if (Array.isArray(re) && re.length === 1 && Array.isArray(re[0])) {\n+    return re[0].length > 0; // Has circular references\n+  }\n+\n+  // Case 2: [string[], Record<string, string[]>] - mixed format\n+  if (Array.isArray(re) && re.length === 2 && Array.isArray(re[0])) {\n+    return re[0].length > 0; // First element contains circular references\n+  }\n+\n+  // Case 3: Record<string, string[]> - check for circular patterns in shared references\n+  if (!Array.isArray(re) && typeof re === \"object\") {\n+    // Check if any reference path points to an ancestor path\n+    for (const [targetPath, referencePaths] of Object.entries(re)) {\n+      for (const refPath of referencePaths as string[]) {\n+        if (isCircularPattern(targetPath, refPath)) {\n+          return true;\n+        }\n+      }\n+    }\n+    return false;\n+  }\n+\n+  return false;\n+}\n+\n+/**\n+ * Checks if a reference pattern represents a circular reference\n+ * by analyzing if the reference path points back to an ancestor of the target path\n+ */\n+function isCircularPattern(targetPath: string, referencePath: string): boolean {\n+  const targetParts = targetPath.split(\".\");\n+  const refParts = referencePath.split(\".\");\n+\n+  // For circular references, the reference path often contains the target path as a prefix\n+  // Example: targetPath=\"user\", referencePath=\"user.details.user\"\n+  // This means user.details.user points back to user (circular)\n+\n+  // Check if reference path starts with target path + additional segments that loop back\n+  if (refParts.length > targetParts.length) {\n+    // Check if reference path starts with target path\n+    let isPrefix = true;\n+    for (let i = 0; i < targetParts.length; i++) {\n+      if (targetParts[i] !== refParts[i]) {\n+        isPrefix = false;\n+        break;\n+      }\n+    }\n+\n+    // If reference path starts with target path and ends with target path,\n+    // it's likely a circular reference (e.g., \"user\" -> \"user.details.user\")\n+    if (isPrefix && refParts[refParts.length - 1] === targetParts[targetParts.length - 1]) {\n+      return true;\n+    }\n+  }\n+\n+  return false;\n+}\ndiff --git a/packages/core/test/ioSerialization.test.ts b/packages/core/test/ioSerialization.test.ts\nindex ffb9b30753..d7bd90add8 100644\n--- a/packages/core/test/ioSerialization.test.ts\n+++ b/packages/core/test/ioSerialization.test.ts\n@@ -1,4 +1,4 @@\n-import { replaceSuperJsonPayload } from \"../src/v3/utils/ioSerialization.js\";\n+import { replaceSuperJsonPayload, prettyPrintPacket } from \"../src/v3/utils/ioSerialization.js\";\n \n describe(\"ioSerialization\", () => {\n   describe(\"replaceSuperJsonPayload\", () => {\n@@ -188,4 +188,160 @@ describe(\"ioSerialization\", () => {\n       await expect(replaceSuperJsonPayload(originalSerialized, invalidPayload)).rejects.toThrow();\n     });\n   });\n+\n+  describe(\"prettyPrintPacket\", () => {\n+    it(\"should return empty string for undefined data\", async () => {\n+      const result = await prettyPrintPacket(undefined);\n+      expect(result).toBe(\"\");\n+    });\n+\n+    it(\"should return string data as-is\", async () => {\n+      const result = await prettyPrintPacket(\"Hello, World!\");\n+      expect(result).toBe(\"Hello, World!\");\n+    });\n+\n+    it(\"should pretty print JSON data with default options\", async () => {\n+      const data = { name: \"John\", age: 30, nested: { value: true } };\n+      const result = await prettyPrintPacket(data, \"application/json\");\n+\n+      expect(result).toBe(JSON.stringify(data, null, 2));\n+    });\n+\n+    it(\"should handle JSON data as string\", async () => {\n+      const data = { name: \"John\", age: 30 };\n+      const jsonString = JSON.stringify(data);\n+      const result = await prettyPrintPacket(jsonString, \"application/json\");\n+\n+      expect(result).toBe(JSON.stringify(data, null, 2));\n+    });\n+\n+    it(\"should pretty print SuperJSON data\", async () => {\n+      const data = {\n+        name: \"John\",\n+        date: new Date(\"2023-01-01\"),\n+        bigInt: BigInt(123),\n+        set: new Set([\"a\", \"b\"]),\n+        map: new Map([[\"key\", \"value\"]]),\n+      };\n+\n+      const superjson = await import(\"superjson\");\n+      const serialized = superjson.stringify(data);\n+\n+      const result = await prettyPrintPacket(serialized, \"application/super+json\");\n+\n+      // Should deserialize and pretty print the data\n+      expect(result).toContain('\"name\": \"John\"');\n+      expect(result).toContain('\"date\": \"2023-01-01T00:00:00.000Z\"');\n+      expect(result).toContain('\"bigInt\": \"123\"');\n+      expect(result).toContain('\"set\": [\\n    \"a\",\\n    \"b\"\\n  ]');\n+      expect(result).toContain('\"map\": {\\n    \"key\": \"value\"\\n  }');\n+    });\n+\n+    it(\"should handle circular references\", async () => {\n+      const data: any = { name: \"John\" };\n+      data.self = data; // Create circular reference\n+\n+      // Create a SuperJSON serialized version to test the circular reference detection\n+      const superjson = await import(\"superjson\");\n+      const serialized = superjson.stringify(data);\n+\n+      const result = await prettyPrintPacket(serialized, \"application/super+json\");\n+\n+      expect(result).toContain('\"name\": \"John\"');\n+      expect(result).toContain('\"self\": \"[Circular]\"');\n+    });\n+\n+    it(\"should handle regular non-circular references\", async () => {\n+      const person = { name: \"John\" };\n+\n+      const data: any = { person1: person, person2: person };\n+\n+      // Create a SuperJSON serialized version to test the circular reference detection\n+      const superjson = await import(\"superjson\");\n+      const serialized = superjson.stringify(data);\n+\n+      const result = await prettyPrintPacket(serialized, \"application/super+json\");\n+\n+      expect(result).toContain('\"person1\": {');\n+      expect(result).toContain('\"person2\": {');\n+    });\n+\n+    it(\"should filter out specified keys\", async () => {\n+      const data = { name: \"John\", password: \"secret\", age: 30 };\n+      const result = await prettyPrintPacket(data, \"application/json\", {\n+        filteredKeys: [\"password\"],\n+      });\n+\n+      expect(result).toContain('\"name\": \"John\"');\n+      expect(result).toContain('\"age\": 30');\n+      expect(result).not.toContain('\"password\"');\n+    });\n+\n+    it(\"should handle BigInt values\", async () => {\n+      const data = { id: BigInt(123456789), name: \"John\" };\n+      const result = await prettyPrintPacket(data, \"application/json\");\n+\n+      expect(result).toContain('\"id\": \"123456789\"');\n+      expect(result).toContain('\"name\": \"John\"');\n+    });\n+\n+    it(\"should handle RegExp values\", async () => {\n+      const data = { pattern: /test/gi, name: \"John\" };\n+      const result = await prettyPrintPacket(data, \"application/json\");\n+\n+      expect(result).toContain('\"pattern\": \"/test/gi\"');\n+      expect(result).toContain('\"name\": \"John\"');\n+    });\n+\n+    it(\"should handle Set values\", async () => {\n+      const data = { tags: new Set([\"tag1\", \"tag2\"]), name: \"John\" };\n+      const result = await prettyPrintPacket(data, \"application/json\");\n+\n+      expect(result).toContain('\"tags\": [\\n    \"tag1\",\\n    \"tag2\"\\n  ]');\n+      expect(result).toContain('\"name\": \"John\"');\n+    });\n+\n+    it(\"should handle Map values\", async () => {\n+      const data = { mapping: new Map([[\"key1\", \"value1\"]]), name: \"John\" };\n+      const result = await prettyPrintPacket(data, \"application/json\");\n+\n+      expect(result).toContain('\"mapping\": {\\n    \"key1\": \"value1\"\\n  }');\n+      expect(result).toContain('\"name\": \"John\"');\n+    });\n+\n+    it(\"should handle complex nested data\", async () => {\n+      const data = {\n+        user: {\n+          id: BigInt(123),\n+          createdAt: new Date(\"2023-01-01\"),\n+          settings: {\n+            theme: \"dark\",\n+            tags: new Set([\"admin\", \"user\"]),\n+            config: new Map([[\"timeout\", \"30s\"]]),\n+          },\n+        },\n+        metadata: {\n+          version: 1,\n+          pattern: /^test$/,\n+        },\n+      };\n+\n+      const result = await prettyPrintPacket(data, \"application/json\");\n+\n+      expect(result).toContain('\"id\": \"123\"');\n+      expect(result).toContain('\"createdAt\": \"2023-01-01T00:00:00.000Z\"');\n+      expect(result).toContain('\"theme\": \"dark\"');\n+      expect(result).toContain('\"tags\": [\\n        \"admin\",\\n        \"user\"\\n      ]');\n+      expect(result).toContain('\"config\": {\\n        \"timeout\": \"30s\"\\n      }');\n+      expect(result).toContain('\"version\": 1');\n+      expect(result).toContain('\"pattern\": \"/^test$/\"');\n+    });\n+\n+    it(\"should handle data without dataType parameter\", async () => {\n+      const data = { name: \"John\", age: 30 };\n+      const result = await prettyPrintPacket(data);\n+\n+      expect(result).toBe(JSON.stringify(data, null, 2));\n+    });\n+  });\n });\ndiff --git a/references/hello-world/src/trigger/circularPayload.ts b/references/hello-world/src/trigger/circularPayload.ts\nnew file mode 100644\nindex 0000000000..3e9d0a9545\n--- /dev/null\n+++ b/references/hello-world/src/trigger/circularPayload.ts\n@@ -0,0 +1,149 @@\n+import { logger, schemaTask, task, tasks } from \"@trigger.dev/sdk\";\n+import { z } from \"zod/v3\";\n+\n+export const referentialPayloadParentTask = task({\n+  id: \"referential-payload-parent\",\n+  run: async (payload: any) => {\n+    // Shared objects\n+    const workflowData = {\n+      id: \"workflow-123\",\n+      formName: \"Contact Form\",\n+    };\n+\n+    const response = [\n+      {\n+        id: \"q1_name\",\n+        answer: \"John Doe\",\n+      },\n+      {\n+        id: \"q2_consent\",\n+        answer: \"yes\",\n+        leadAttribute: undefined, // Will be marked in meta\n+      },\n+    ];\n+\n+    const personAttributes = {\n+      ip: \"192.168.1.1\",\n+      visitedForm: 1,\n+    };\n+\n+    // Main object with shared references\n+    const originalObject = {\n+      workflowData: workflowData, // Root reference\n+      workflowContext: {\n+        leadId: undefined, // Will be marked in meta\n+        workflowJob: {\n+          workflowData: workflowData, // Same reference as root\n+          createdAt: new Date(\"2025-08-19T12:13:42.260Z\"), // Date object\n+        },\n+        responseData: {\n+          personAttributes: personAttributes, // Same reference as root\n+        },\n+        response: response, // Same reference as root\n+      },\n+      personAttributes: personAttributes, // Root reference\n+      response: response, // Root reference\n+      jobArgs: {\n+        response: response, // Same reference as root\n+        args: workflowData, // Same reference as root\n+      },\n+    };\n+\n+    await tasks.triggerAndWait<typeof referentialPayloadChildTask>(\n+      \"referential-payload-child\",\n+      originalObject\n+    );\n+\n+    return {\n+      message: \"Hello, world!\",\n+    };\n+  },\n+});\n+\n+// Define the circular schema using z.lazy() for the recursive reference\n+const WorkflowDataSchema = z.object({\n+  id: z.string(),\n+  formName: z.string(),\n+});\n+\n+const ResponseItemSchema = z.object({\n+  id: z.string(),\n+  answer: z.string(),\n+  leadAttribute: z.undefined().optional(),\n+});\n+\n+const PersonAttributesSchema = z.object({\n+  ip: z.string(),\n+  visitedForm: z.number(),\n+});\n+\n+const OriginalObjectSchema = z.object({\n+  workflowData: WorkflowDataSchema,\n+  workflowContext: z.object({\n+    leadId: z.undefined(),\n+    workflowJob: z.object({\n+      workflowData: WorkflowDataSchema, // Same reference\n+      createdAt: z.date(),\n+    }),\n+    responseData: z.object({\n+      personAttributes: PersonAttributesSchema, // Same reference\n+    }),\n+    response: z.array(ResponseItemSchema), // Same reference\n+  }),\n+  personAttributes: PersonAttributesSchema, // Root reference\n+  response: z.array(ResponseItemSchema), // Root reference\n+  jobArgs: z.object({\n+    response: z.array(ResponseItemSchema), // Same reference\n+    args: WorkflowDataSchema, // Same reference\n+  }),\n+});\n+\n+export const referentialPayloadChildTask = schemaTask({\n+  id: \"referential-payload-child\",\n+  schema: OriginalObjectSchema,\n+  run: async (payload) => {\n+    logger.info(\"Received circular payload\", { payload });\n+\n+    return {\n+      message: \"Hello, world!\",\n+    };\n+  },\n+});\n+\n+export const circularReferenceParentTask = task({\n+  id: \"circular-reference-parent\",\n+  run: async (payload: any) => {\n+    const user = {\n+      name: \"Alice\",\n+      details: {\n+        age: 30,\n+        email: \"alice@example.com\",\n+      },\n+    };\n+    // @ts-expect-error - This is a circular reference\n+    user.details.user = user;\n+\n+    await tasks.triggerAndWait<typeof circularReferenceChildTask>(\"circular-reference-child\", {\n+      // @ts-expect-error - This is a circular reference\n+      user,\n+    });\n+  },\n+});\n+\n+type CircularReferencePayload = {\n+  user: {\n+    name: string;\n+    details: {\n+      age: number;\n+      email: string;\n+      user: CircularReferencePayload;\n+    };\n+  };\n+};\n+\n+export const circularReferenceChildTask = task({\n+  id: \"circular-reference-child\",\n+  run: async (payload: CircularReferencePayload) => {\n+    logger.info(\"Received circular payload\", { payload });\n+  },\n+});\n", "test_patch": "", "problem_statement": "", "hints_text": ""}
