{"repo": "directus/directus", "instance_id": "directus__directus.pr_mirror.25362", "base_commit": "68942ab8755f8d62ba508d9f22642d22bb311b84", "patch": "diff --git a/.changeset/fresh-rules-talk.md b/.changeset/fresh-rules-talk.md\nnew file mode 100644\nindex 0000000000000..ebeb0cafd7c9d\n--- /dev/null\n+++ b/.changeset/fresh-rules-talk.md\n@@ -0,0 +1,5 @@\n+---\n+'@directus/api': patch\n+---\n+\n+Removed implicit primaryKey permission for non relational meta queries\ndiff --git a/api/src/services/meta.test.ts b/api/src/services/meta.test.ts\nnew file mode 100644\nindex 0000000000000..7207238fc07a8\n--- /dev/null\n+++ b/api/src/services/meta.test.ts\n@@ -0,0 +1,499 @@\n+import { ForbiddenError } from '@directus/errors';\n+import { SchemaBuilder } from '@directus/schema-builder';\n+import type { Permission, Query } from '@directus/types';\n+import { knex } from 'knex';\n+import { MockClient } from 'knex-mock-client';\n+import { beforeEach, describe, expect, test, vi, type MockedFunction } from 'vitest';\n+import applyQuery from '../database/run-ast/lib/apply-query/index.js';\n+import { fetchPermissions } from '../permissions/lib/fetch-permissions.js';\n+import { fetchPolicies } from '../permissions/lib/fetch-policies.js';\n+import { getCases } from '../permissions/modules/process-ast/lib/get-cases.js';\n+import { validateAccess } from '../permissions/modules/validate-access/validate-access.js';\n+import { createDefaultAccountability } from '../permissions/utils/create-default-accountability.js';\n+import { MetaService } from './meta.js';\n+\n+vi.mock('../database/run-ast/lib/apply-query/index.js', () => ({ default: vi.fn() }));\n+\n+vi.mock('../permissions/lib/fetch-permissions.js', () => ({\n+\tfetchPermissions: vi.fn(),\n+}));\n+\n+vi.mock('../permissions/lib/fetch-policies.js', () => ({\n+\tfetchPolicies: vi.fn(),\n+}));\n+\n+vi.mock('../permissions/modules/process-ast/lib/get-cases.js', () => ({\n+\tgetCases: vi.fn(),\n+}));\n+\n+vi.mock('../permissions/modules/validate-access/validate-access.js', () => ({\n+\tvalidateAccess: vi.fn(),\n+}));\n+\n+describe('MetaService', () => {\n+\tlet db: MockedFunction<knex.Knex<any, unknown[]>>;\n+\n+\tconst mockSchema = new SchemaBuilder()\n+\t\t.collection('test_collection', (c) => {\n+\t\t\tc.field('id').id();\n+\t\t})\n+\t\t.build();\n+\n+\tbeforeEach(() => {\n+\t\tvi.clearAllMocks();\n+\n+\t\tdb = vi.mocked(knex.default({ client: MockClient }));\n+\t});\n+\n+\tdescribe('getMetaForQuery', () => {\n+\t\tlet service: MetaService;\n+\n+\t\tconst mockAccountability = createDefaultAccountability({\n+\t\t\tadmin: false,\n+\t\t});\n+\n+\t\tbeforeEach(() => {\n+\t\t\tvi.clearAllMocks();\n+\n+\t\t\tservice = new MetaService({\n+\t\t\t\tknex: db,\n+\t\t\t\taccountability: mockAccountability,\n+\t\t\t\tschema: mockSchema,\n+\t\t\t});\n+\t\t});\n+\n+\t\tdescribe('should return undefined when query is falsy', async () => {\n+\t\t\ttest.each([null, undefined])('%s', async () => {\n+\t\t\t\tconst result = await service.getMetaForQuery('test_collection', null);\n+\t\t\t\texpect(result).toBeUndefined();\n+\t\t\t});\n+\t\t});\n+\n+\t\ttest('should return undefined when query.meta is falsy', async () => {\n+\t\t\tconst query = { filter: { status: 'published' } };\n+\t\t\tconst result = await service.getMetaForQuery('test_collection', query);\n+\t\t\texpect(result).toBeUndefined();\n+\t\t});\n+\n+\t\ttest('should handle total_count meta value', async () => {\n+\t\t\tvi.spyOn(service, 'totalCount').mockResolvedValue(100);\n+\n+\t\t\tconst query = { meta: ['total_count'] };\n+\t\t\tconst result = await service.getMetaForQuery('test_collection', query);\n+\n+\t\t\texpect(service.totalCount).toHaveBeenCalledWith('test_collection');\n+\t\t\texpect(result).toEqual({ total_count: 100 });\n+\t\t});\n+\n+\t\ttest('should handle filter_count meta value', async () => {\n+\t\t\tvi.spyOn(service, 'filterCount').mockResolvedValue(50);\n+\n+\t\t\tconst query = { meta: ['filter_count'], filter: { status: 'published' } };\n+\t\t\tconst result = await service.getMetaForQuery('test_collection', query);\n+\n+\t\t\texpect(service.filterCount).toHaveBeenCalledWith('test_collection', query);\n+\t\t\texpect(result).toEqual({ filter_count: 50 });\n+\t\t});\n+\n+\t\ttest('should handle multiple meta values', async () => {\n+\t\t\tvi.spyOn(service, 'totalCount').mockResolvedValue(100);\n+\t\t\tvi.spyOn(service, 'filterCount').mockResolvedValue(50);\n+\n+\t\t\tconst query = { meta: ['total_count', 'filter_count'] };\n+\t\t\tconst result = await service.getMetaForQuery('test_collection', query);\n+\n+\t\t\texpect(result).toEqual({\n+\t\t\t\ttotal_count: 100,\n+\t\t\t\tfilter_count: 50,\n+\t\t\t});\n+\t\t});\n+\n+\t\ttest('should handle unknown meta values as undefined', async () => {\n+\t\t\tconst query = { meta: ['unknown_meta'] };\n+\t\t\tconst result = await service.getMetaForQuery('test_collection', query);\n+\n+\t\t\texpect(result).toEqual({ unknown_meta: undefined });\n+\t\t});\n+\n+\t\ttest('should handle mixed known and unknown meta values', async () => {\n+\t\t\tvi.spyOn(service, 'totalCount').mockResolvedValue(100);\n+\n+\t\t\tconst query = { meta: ['total_count', 'unknown_meta'] };\n+\t\t\tconst result = await service.getMetaForQuery('test_collection', query);\n+\n+\t\t\texpect(result).toEqual({\n+\t\t\t\ttotal_count: 100,\n+\t\t\t\tunknown_meta: undefined,\n+\t\t\t});\n+\t\t});\n+\t});\n+\n+\tdescribe('totalCount', () => {\n+\t\tlet service: MetaService;\n+\n+\t\tconst mockAccountability = createDefaultAccountability({\n+\t\t\tadmin: false,\n+\t\t});\n+\n+\t\tbeforeEach(() => {\n+\t\t\tvi.clearAllMocks();\n+\n+\t\t\tservice = new MetaService({\n+\t\t\t\tknex: db,\n+\t\t\t\taccountability: mockAccountability,\n+\t\t\t\tschema: mockSchema,\n+\t\t\t});\n+\t\t});\n+\n+\t\ttest('should call filterCount with empty query', async () => {\n+\t\t\tvi.spyOn(service, 'filterCount').mockResolvedValue(150);\n+\n+\t\t\tconst result = await service.totalCount('test_collection');\n+\n+\t\t\texpect(service.filterCount).toHaveBeenCalledWith('test_collection', {});\n+\t\t\texpect(result).toBe(150);\n+\t\t});\n+\t});\n+\n+\tdescribe('filterCount', () => {\n+\t\tconst createMockQueryBuilder = (\n+\t\t\tvalue: { count?: number | null } | { count: number | null }[] = [{ count: 10 }],\n+\t\t) => {\n+\t\t\tconst mockQueryBuilder = Promise.resolve(value) as any;\n+\t\t\tmockQueryBuilder.count = vi.fn().mockReturnValue(mockQueryBuilder);\n+\t\t\tmockQueryBuilder.countDistinct = vi.fn().mockReturnValue(mockQueryBuilder);\n+\n+\t\t\treturn mockQueryBuilder;\n+\t\t};\n+\n+\t\tbeforeEach(() => {\n+\t\t\tvi.clearAllMocks();\n+\t\t});\n+\n+\t\ttest('should handle admin user without permission checks', async () => {\n+\t\t\tconst mockAccountability = createDefaultAccountability({\n+\t\t\t\tadmin: true,\n+\t\t\t});\n+\n+\t\t\tconst service = new MetaService({\n+\t\t\t\tknex: db,\n+\t\t\t\taccountability: mockAccountability,\n+\t\t\t\tschema: mockSchema,\n+\t\t\t});\n+\n+\t\t\tvi.mocked(getCases).mockReturnValue({ cases: [], caseMap: {}, allowedFields: new Set() });\n+\n+\t\t\tvi.mocked(applyQuery).mockReturnValue({\n+\t\t\t\tquery: createMockQueryBuilder() as any,\n+\t\t\t\thasJoins: false,\n+\t\t\t\thasMultiRelationalFilter: false,\n+\t\t\t});\n+\n+\t\t\tconst result = await service.filterCount('test_collection', { filter: { status: { _eq: 'published' } } });\n+\n+\t\t\texpect(validateAccess).not.toHaveBeenCalled();\n+\t\t\texpect(fetchPolicies).not.toHaveBeenCalled();\n+\t\t\texpect(fetchPermissions).not.toHaveBeenCalled();\n+\t\t\texpect(result).toBe(10);\n+\t\t});\n+\n+\t\ttest('should handle null accountability without permission checks', async () => {\n+\t\t\tconst service = new MetaService({\n+\t\t\t\tknex: db,\n+\t\t\t\taccountability: null,\n+\t\t\t\tschema: mockSchema,\n+\t\t\t});\n+\n+\t\t\tvi.mocked(getCases).mockReturnValue({ cases: [], caseMap: {}, allowedFields: new Set() });\n+\n+\t\t\tvi.mocked(applyQuery).mockReturnValue({\n+\t\t\t\tquery: createMockQueryBuilder() as any,\n+\t\t\t\thasJoins: false,\n+\t\t\t\thasMultiRelationalFilter: false,\n+\t\t\t});\n+\n+\t\t\tconst result = await service.filterCount('test_collection', { filter: { status: { _eq: 'published' } } });\n+\n+\t\t\texpect(validateAccess).not.toHaveBeenCalled();\n+\t\t\texpect(fetchPolicies).not.toHaveBeenCalled();\n+\t\t\texpect(fetchPermissions).not.toHaveBeenCalled();\n+\t\t\texpect(result).toBe(10);\n+\t\t});\n+\n+\t\ttest('should perform permission checks for non-admin users', async () => {\n+\t\t\tconst mockPolicies = ['policy-1'];\n+\n+\t\t\tconst mockPermissions: Permission[] = [\n+\t\t\t\t{\n+\t\t\t\t\tid: 1,\n+\t\t\t\t\tcollection: 'test_collection',\n+\t\t\t\t\taction: 'read',\n+\t\t\t\t\tpermissions: {},\n+\t\t\t\t\tvalidation: {},\n+\t\t\t\t\tpresets: {},\n+\t\t\t\t\tfields: ['*'],\n+\t\t\t\t\tpolicy: 'policy-1',\n+\t\t\t\t},\n+\t\t\t];\n+\n+\t\t\tconst mockAccountability = createDefaultAccountability({\n+\t\t\t\tadmin: false,\n+\t\t\t});\n+\n+\t\t\tconst service = new MetaService({\n+\t\t\t\tknex: db,\n+\t\t\t\taccountability: mockAccountability,\n+\t\t\t\tschema: mockSchema,\n+\t\t\t});\n+\n+\t\t\tvi.mocked(validateAccess).mockResolvedValue(undefined);\n+\t\t\tvi.mocked(fetchPolicies).mockResolvedValue(mockPolicies);\n+\t\t\tvi.mocked(fetchPermissions).mockResolvedValue(mockPermissions);\n+\n+\t\t\tvi.mocked(getCases).mockReturnValue({ cases: [], caseMap: {}, allowedFields: new Set() });\n+\n+\t\t\tvi.mocked(applyQuery).mockReturnValue({\n+\t\t\t\tquery: createMockQueryBuilder() as any,\n+\t\t\t\thasJoins: false,\n+\t\t\t\thasMultiRelationalFilter: false,\n+\t\t\t});\n+\n+\t\t\tconst result = await service.filterCount('test_collection', { filter: { status: { _eq: 'published' } } });\n+\n+\t\t\texpect(validateAccess).toHaveBeenCalledWith(\n+\t\t\t\t{\n+\t\t\t\t\taccountability: mockAccountability,\n+\t\t\t\t\taction: 'read',\n+\t\t\t\t\tcollection: 'test_collection',\n+\t\t\t\t},\n+\t\t\t\t{ knex: db, schema: mockSchema },\n+\t\t\t);\n+\n+\t\t\texpect(fetchPolicies).toHaveBeenCalledWith(mockAccountability, { knex: db, schema: mockSchema });\n+\n+\t\t\texpect(fetchPermissions).toHaveBeenCalledWith(\n+\t\t\t\t{ action: 'read', accountability: mockAccountability, policies: mockPolicies },\n+\t\t\t\t{ knex: db, schema: mockSchema },\n+\t\t\t);\n+\n+\t\t\texpect(result).toBe(10);\n+\t\t});\n+\n+\t\ttest('should propagate validateAccess errors', async () => {\n+\t\t\tconst mockAccountability = createDefaultAccountability({ admin: false });\n+\n+\t\t\tconst service = new MetaService({\n+\t\t\t\tknex: db,\n+\t\t\t\taccountability: mockAccountability,\n+\t\t\t\tschema: mockSchema,\n+\t\t\t});\n+\n+\t\t\tconst mockError = new ForbiddenError({ reason: 'No access' });\n+\t\t\tvi.mocked(validateAccess).mockRejectedValue(mockError);\n+\n+\t\t\tawait expect(service.filterCount('test_collection', {})).rejects.toThrow(mockError);\n+\n+\t\t\texpect(fetchPolicies).not.toHaveBeenCalled();\n+\t\t\texpect(applyQuery).not.toHaveBeenCalled();\n+\t\t});\n+\n+\t\ttest('should use countDistinct when query has joins', async () => {\n+\t\t\tvi.mocked(getCases).mockReturnValue({ cases: [], caseMap: {}, allowedFields: new Set() });\n+\n+\t\t\tconst mockQueryBuilder = createMockQueryBuilder();\n+\n+\t\t\tvi.mocked(applyQuery).mockReturnValue({\n+\t\t\t\tquery: mockQueryBuilder,\n+\t\t\t\thasJoins: true,\n+\t\t\t\thasMultiRelationalFilter: false,\n+\t\t\t});\n+\n+\t\t\tconst service = new MetaService({\n+\t\t\t\tknex: db,\n+\t\t\t\tschema: mockSchema,\n+\t\t\t});\n+\n+\t\t\tconst result = await service.filterCount('test_collection', { filter: { status: { _eq: 'published' } } });\n+\n+\t\t\texpect(mockQueryBuilder.countDistinct).toHaveBeenCalledWith({\n+\t\t\t\tcount: ['test_collection.id'],\n+\t\t\t});\n+\n+\t\t\texpect(mockQueryBuilder.count).not.toHaveBeenCalled();\n+\t\t\texpect(result).toBe(10);\n+\t\t});\n+\n+\t\ttest('should use regular count when query has no joins', async () => {\n+\t\t\tvi.mocked(getCases).mockReturnValue({ cases: [], caseMap: {}, allowedFields: new Set() });\n+\n+\t\t\tconst mockQueryBuilder = createMockQueryBuilder();\n+\n+\t\t\tvi.mocked(applyQuery).mockReturnValue({\n+\t\t\t\tquery: mockQueryBuilder,\n+\t\t\t\thasJoins: false,\n+\t\t\t\thasMultiRelationalFilter: false,\n+\t\t\t});\n+\n+\t\t\tconst service = new MetaService({\n+\t\t\t\tknex: db,\n+\t\t\t\tschema: mockSchema,\n+\t\t\t});\n+\n+\t\t\tconst result = await service.filterCount('test_collection', { filter: { status: { _eq: 'published' } } });\n+\n+\t\t\texpect(mockQueryBuilder.count).toHaveBeenCalledWith('*', { as: 'count' });\n+\t\t\texpect(mockQueryBuilder.countDistinct).not.toHaveBeenCalled();\n+\t\t\texpect(result).toBe(10);\n+\t\t});\n+\n+\t\ttest('should handle array result from database', async () => {\n+\t\t\tvi.mocked(getCases).mockReturnValue({ cases: [], caseMap: {}, allowedFields: new Set() });\n+\n+\t\t\tconst mockQueryBuilder = createMockQueryBuilder([{ count: 15 }]);\n+\n+\t\t\tvi.mocked(applyQuery).mockReturnValue({\n+\t\t\t\tquery: mockQueryBuilder,\n+\t\t\t\thasJoins: true,\n+\t\t\t\thasMultiRelationalFilter: false,\n+\t\t\t});\n+\n+\t\t\tconst service = new MetaService({\n+\t\t\t\tknex: db,\n+\t\t\t\tschema: mockSchema,\n+\t\t\t});\n+\n+\t\t\tconst result = await service.filterCount('test_collection', { filter: { status: { _eq: 'published' } } });\n+\t\t\texpect(result).toBe(15);\n+\t\t});\n+\n+\t\ttest('should handle non-array result from database', async () => {\n+\t\t\tvi.mocked(getCases).mockReturnValue({ cases: [], caseMap: {}, allowedFields: new Set() });\n+\n+\t\t\tconst mockQueryBuilder = createMockQueryBuilder({ count: 30 });\n+\n+\t\t\tvi.mocked(applyQuery).mockReturnValue({\n+\t\t\t\tquery: mockQueryBuilder as any,\n+\t\t\t\thasJoins: false,\n+\t\t\t\thasMultiRelationalFilter: false,\n+\t\t\t});\n+\n+\t\t\tconst service = new MetaService({\n+\t\t\t\tknex: db,\n+\t\t\t\tschema: mockSchema,\n+\t\t\t});\n+\n+\t\t\tconst result = await service.filterCount('test_collection', { filter: { status: { _eq: 'published' } } });\n+\t\t\texpect(result).toBe(30);\n+\t\t});\n+\n+\t\tdescribe('should return 0 when count is null or undefined', () => {\n+\t\t\ttest.each([0, null])('%s', async (count) => {\n+\t\t\t\tvi.mocked(getCases).mockReturnValue({ cases: [], caseMap: {}, allowedFields: new Set() });\n+\n+\t\t\t\tconst mockQueryBuilder = createMockQueryBuilder({ count });\n+\n+\t\t\t\tvi.mocked(applyQuery).mockReturnValue({\n+\t\t\t\t\tquery: mockQueryBuilder as any,\n+\t\t\t\t\thasJoins: false,\n+\t\t\t\t\thasMultiRelationalFilter: false,\n+\t\t\t\t});\n+\n+\t\t\t\tconst service = new MetaService({\n+\t\t\t\t\tknex: db,\n+\t\t\t\t\tschema: mockSchema,\n+\t\t\t\t});\n+\n+\t\t\t\tconst result = await service.filterCount('test_collection', {});\n+\t\t\t\texpect(result).toBe(0);\n+\t\t\t});\n+\t\t});\n+\n+\t\ttest('should handle empty array result', async () => {\n+\t\t\tvi.mocked(getCases).mockReturnValue({ cases: [], caseMap: {}, allowedFields: new Set() });\n+\n+\t\t\tconst mockQueryBuilder = createMockQueryBuilder([]);\n+\n+\t\t\tvi.mocked(applyQuery).mockReturnValue({\n+\t\t\t\tquery: mockQueryBuilder as any,\n+\t\t\t\thasJoins: true,\n+\t\t\t\thasMultiRelationalFilter: false,\n+\t\t\t});\n+\n+\t\t\tconst service = new MetaService({\n+\t\t\t\tknex: db,\n+\t\t\t\tschema: mockSchema,\n+\t\t\t});\n+\n+\t\t\tconst result = await service.filterCount('test_collection', {});\n+\t\t\texpect(result).toBe(0);\n+\t\t});\n+\n+\t\ttest('should pass correct parameters to applyQuery', async () => {\n+\t\t\tconst mockCases = [{}];\n+\n+\t\t\tvi.mocked(getCases).mockReturnValue({ cases: mockCases, caseMap: {}, allowedFields: new Set() });\n+\n+\t\t\tconst mockQueryBuilder = createMockQueryBuilder();\n+\n+\t\t\tvi.mocked(applyQuery).mockReturnValue({\n+\t\t\t\tquery: mockQueryBuilder,\n+\t\t\t\thasJoins: false,\n+\t\t\t\thasMultiRelationalFilter: false,\n+\t\t\t});\n+\n+\t\t\tconst service = new MetaService({\n+\t\t\t\tknex: db,\n+\t\t\t\tschema: mockSchema,\n+\t\t\t});\n+\n+\t\t\tconst query: Query = {\n+\t\t\t\tfilter: { status: { _eq: 'published' } },\n+\t\t\t\tsearch: 'test search',\n+\t\t\t};\n+\n+\t\t\tawait service.filterCount('test_collection', query);\n+\n+\t\t\texpect(applyQuery).toHaveBeenCalledWith(\n+\t\t\t\tdb,\n+\t\t\t\t'test_collection',\n+\t\t\t\tdb('test_collection'),\n+\t\t\t\tquery,\n+\t\t\t\tmockSchema,\n+\t\t\t\tmockCases,\n+\t\t\t\t[],\n+\t\t\t);\n+\t\t});\n+\n+\t\ttest('should handle query with null filter and search', async () => {\n+\t\t\tvi.mocked(getCases).mockReturnValue({ cases: [], caseMap: {}, allowedFields: new Set() });\n+\n+\t\t\tconst mockQueryBuilder = createMockQueryBuilder();\n+\n+\t\t\tvi.mocked(applyQuery).mockReturnValue({\n+\t\t\t\tquery: mockQueryBuilder,\n+\t\t\t\thasJoins: false,\n+\t\t\t\thasMultiRelationalFilter: false,\n+\t\t\t});\n+\n+\t\t\tconst service = new MetaService({\n+\t\t\t\tknex: db,\n+\t\t\t\tschema: mockSchema,\n+\t\t\t});\n+\n+\t\t\tawait service.filterCount('test_collection', {});\n+\n+\t\t\texpect(applyQuery).toHaveBeenCalledWith(\n+\t\t\t\tdb,\n+\t\t\t\t'test_collection',\n+\t\t\t\tdb('test_collection'),\n+\t\t\t\t{\n+\t\t\t\t\tfilter: null,\n+\t\t\t\t\tsearch: null,\n+\t\t\t\t},\n+\t\t\t\tmockSchema,\n+\t\t\t\t[],\n+\t\t\t\t[],\n+\t\t\t);\n+\t\t});\n+\t});\n+});\ndiff --git a/api/src/services/meta.ts b/api/src/services/meta.ts\nindex 4be6ffa2ca2c3..fc06975a7cca0 100644\n--- a/api/src/services/meta.ts\n+++ b/api/src/services/meta.ts\n@@ -1,10 +1,12 @@\n-import type { AbstractServiceOptions, Accountability, Query, SchemaOverview } from '@directus/types';\n+import type { AbstractServiceOptions, Accountability, Permission, Query, SchemaOverview } from '@directus/types';\n import type { Knex } from 'knex';\n import { isArray } from 'lodash-es';\n-import { getAstFromQuery } from '../database/get-ast-from-query/get-ast-from-query.js';\n import getDatabase from '../database/index.js';\n-import { runAst } from '../database/run-ast/run-ast.js';\n-import { processAst } from '../permissions/modules/process-ast/process-ast.js';\n+import applyQuery from '../database/run-ast/lib/apply-query/index.js';\n+import { fetchPermissions } from '../permissions/lib/fetch-permissions.js';\n+import { fetchPolicies } from '../permissions/lib/fetch-policies.js';\n+import { getCases } from '../permissions/modules/process-ast/lib/get-cases.js';\n+import { validateAccess } from '../permissions/modules/validate-access/validate-access.js';\n \n export class MetaService {\n \tknex: Knex;\n@@ -41,40 +43,48 @@ export class MetaService {\n \t}\n \n \tasync filterCount(collection: string, query: Query): Promise<number> {\n-\t\tconst primaryKeyName = this.schema.collections[collection]!.primary;\n+\t\tlet permissions: Permission[] = [];\n \n-\t\tconst aggregateQuery: Query = {\n-\t\t\taggregate: {\n-\t\t\t\tcountDistinct: [primaryKeyName],\n-\t\t\t},\n-\t\t\tsearch: query.search ?? null,\n-\t\t\tfilter: query.filter ?? null,\n-\t\t};\n+\t\tif (this.accountability && this.accountability.admin !== true) {\n+\t\t\tconst context = { knex: this.knex, schema: this.schema };\n \n-\t\tlet ast = await getAstFromQuery(\n-\t\t\t{\n-\t\t\t\tcollection,\n-\t\t\t\tquery: aggregateQuery,\n-\t\t\t\taccountability: this.accountability,\n-\t\t\t},\n+\t\t\tawait validateAccess(\n+\t\t\t\t{\n+\t\t\t\t\taccountability: this.accountability,\n+\t\t\t\t\taction: 'read',\n+\t\t\t\t\tcollection,\n+\t\t\t\t},\n+\t\t\t\tcontext,\n+\t\t\t);\n+\n+\t\t\tconst policies = await fetchPolicies(this.accountability, context);\n+\n+\t\t\tpermissions = await fetchPermissions({ action: 'read', accountability: this.accountability, policies }, context);\n+\t\t}\n+\n+\t\tconst { cases } = getCases(collection, permissions, []);\n+\n+\t\tconst { query: dbQuery, hasJoins } = applyQuery(\n+\t\t\tthis.knex,\n+\t\t\tcollection,\n+\t\t\tthis.knex(collection),\n \t\t\t{\n-\t\t\t\tschema: this.schema,\n-\t\t\t\tknex: this.knex,\n+\t\t\t\tfilter: query.filter ?? null,\n+\t\t\t\tsearch: query.search ?? null,\n \t\t\t},\n+\t\t\tthis.schema,\n+\t\t\tcases,\n+\t\t\tpermissions,\n \t\t);\n \n-\t\tast = await processAst(\n-\t\t\t{ ast, action: 'read', accountability: this.accountability },\n-\t\t\t{ knex: this.knex, schema: this.schema },\n-\t\t);\n+\t\tif (hasJoins) {\n+\t\t\tdbQuery.countDistinct({ count: [`${collection}.${this.schema.collections[collection]!.primary}`] });\n+\t\t} else {\n+\t\t\tdbQuery.count('*', { as: 'count' });\n+\t\t}\n \n-\t\tconst records = await runAst(ast, this.schema, this.accountability, {\n-\t\t\tknex: this.knex,\n-\t\t});\n+\t\tconst records = await dbQuery;\n \n-\t\treturn Number(\n-\t\t\t(isArray(records) ? records[0]?.['countDistinct'][primaryKeyName] : records?.['countDistinct'][primaryKeyName]) ??\n-\t\t\t\t0,\n-\t\t);\n+\t\treturn Number((isArray(records) ? records[0]?.['count'] : records?.['count']) ?? 0);\n \t}\n }\n", "test_patch": "", "problem_statement": "<!--\r\n\r\nHeya! Thanks for opening a Pull Request! If your PR is implementing a new feature or fix for Directus, please make sure your PR adheres to the following requirements:\r\n\r\n- The PR closes an Issue (not Discussion)\r\n- Tests are added/updated and are passing locally if applicable\r\n- Documentation was added/updated if applicable\r\n\r\nPlease make sure to \"Link\" the issue you're closing. Without a Linked issue, this PR won't be accepted. See https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue for more information.\r\n\r\n-->\r\n\r\n## Scope\r\n\r\nWhat's changed:\r\n\r\n- Permissions to `read` on `primaryKey` is no longer required for non relational counts\r\n\r\n## Potential Risks / Drawbacks\r\n\r\n- None that I am aware of\r\n\r\n## Review Notes / Questions\r\n\r\n- I have tested all cases I could think of (listed below), please test any additional cases that may have been missed.\r\n- Do we want to check field permissions in filters as well and error if no access? Currently the no permission returns 0 results which is what we had previously.\r\n\r\n### Tests\r\n- db: `pg`\r\n#### Setup\r\n- Create an ingredient collection with a name field\r\n- Create a food collection with a name field and an ingredients field that is `m2m` to ingredient\r\n- Add 2 food records, one with 1 ingredient sub record and one with 2\r\n\r\n#### Setup Data\r\n\r\n##### Foods\r\n```csv\r\n\"id\",\"name\"\r\n1,\"Food 1\"\r\n2,\"Food 2\"\r\n```\r\n##### Ingredients\r\n```csv\r\n\"id\",\"name\"\r\n1,\"Ingredient 1\"\r\n2,\"Ingredient 2\"\r\n3,\"Ingredient 3\"\r\n```\r\n#### Cases\r\n- [x]  Expect `total_count` to return correctly with no filter\r\n   - `/items/food?meta=total_count`\r\n- [x]  Expect `filter_count` to return correctly with no filter\r\n   - `/items/food?meta=filter_count`\r\n- [x]  Expect `total_count` to return correctly for non relational filter\r\n   - `/items/food?filter[name][_contains]=2&meta=total_count`\r\n- [x]  Expect `filter_count` to return correctly for non relational filter\r\n   - `/items/food?filter[name][_contains]=2&meta=filter_count`\r\n- [x]  Expect `total_count` to return correctly for relational filter\r\n   - `/items/food?filter[ingredients][ingredient_id][name][_contains]=2&meta=total_count`\r\n- [x]  Expect `filter_count` to return correctly for relational filter\r\n   - `/items/food?filter[ingredients][ingredient_id][name][_contains]=2&meta=total_count`\r\n- [x] Expect `total_count` & `filter_count` to return correctly with no filter with `search`\r\n  - `/items/food?search=2&meta=total_count,filter_count`\r\n- [x] Expect `total_count` & `filter_count` to return correctly for non relational filter with `search`\r\n   - `/items/food?filter[name][_contains]=2&search=2&meta=total_count,filter_count`\r\n- [x] Expect `total_count` & `filter_count` to return correctly for relational filter with `search`\r\n   - `/items/food?filter[ingredients][ingredient_id][name][_contains]=2&search=2&meta=total_count,filter_count` \r\n- [x] Expect `search` to respect field permissions for `total_count` & `filter_count`\r\n   - Removed `read` for `food.name`\r\n   -  `/items/food?filter[id][_eq]=2&search=food&meta=total_count,filter_count`\r\n\r\n\r\n---\r\n\r\nFixes #25212\r\n", "hints_text": "", "created_at": "2025-06-26T12:50:42Z", "pull_number": 25362, "test_files": ["api/src/services/meta.test.ts"], "code_files": ["api/src/services/meta.ts"], "title": "Remove implicit primaryKey permission for non relational meta queries", "additions": 0, "deletions": 0}
{"repo": "directus/directus", "instance_id": "directus__directus.pr_mirror.26287", "base_commit": "b5b80b78b87f7f2dcfc38b495f7b966199c37b98", "patch": "diff --git a/.changeset/stale-onions-attend.md b/.changeset/stale-onions-attend.md\nnew file mode 100644\nindex 0000000000000..52af1e2e93ebc\n--- /dev/null\n+++ b/.changeset/stale-onions-attend.md\n@@ -0,0 +1,5 @@\n+---\n+'@directus/app': patch\n+---\n+\n+Added reactive primaryKey prop to useFlows composable\ndiff --git a/app/src/composables/use-flows.test.ts b/app/src/composables/use-flows.test.ts\nindex dea978def3f68..86531596b851e 100644\n--- a/app/src/composables/use-flows.test.ts\n+++ b/app/src/composables/use-flows.test.ts\n@@ -65,7 +65,7 @@ const mockOnRefresh = vi.fn();\n \n const useFlowsOptions = {\n \tcollection: ref('test_collection'),\n-\tprimaryKey: 'item_1',\n+\tprimaryKey: ref('item_1'),\n \tlocation: 'collection' as const,\n \thasEdits: ref(true),\n \tonRefreshCallback: mockOnRefresh,\n@@ -398,4 +398,39 @@ describe('runManualFlow', () => {\n \n \t\texpect(mockOnRefresh).toHaveBeenCalledOnce();\n \t});\n+\n+\ttest('calls runFlow with reactive primaryKey', async () => {\n+\t\tconst mockFlowsStore = {\n+\t\t\tgetManualFlowsForCollection: vi.fn().mockReturnValue(mockFlows),\n+\t\t};\n+\n+\t\tconst testOptions = {\n+\t\t\t...useFlowsOptions,\n+\t\t\tprimaryKey: ref('item_1'),\n+\t\t\thasEdits: ref(false),\n+\t\t\tlocation: 'item' as const,\n+\t\t};\n+\n+\t\tvi.mocked(useFlowsStore).mockReturnValue(mockFlowsStore as any);\n+\n+\t\tvi.mocked(api.post).mockResolvedValue({});\n+\n+\t\tconst { runManualFlow } = useFlows(testOptions);\n+\n+\t\tawait runManualFlow(mockFlows[1]!.id);\n+\n+\t\texpect(api.post).toHaveBeenCalledWith(`/flows/trigger/${mockFlows[1]!.id}`, {\n+\t\t\tcollection: 'test_collection',\n+\t\t\tkeys: ['item_1'],\n+\t\t});\n+\n+\t\ttestOptions.primaryKey.value = 'item_2';\n+\n+\t\tawait runManualFlow(mockFlows[1]!.id);\n+\n+\t\texpect(api.post).toHaveBeenCalledWith(`/flows/trigger/${mockFlows[1]!.id}`, {\n+\t\t\tcollection: 'test_collection',\n+\t\t\tkeys: ['item_2'],\n+\t\t});\n+\t});\n });\ndiff --git a/app/src/composables/use-flows.ts b/app/src/composables/use-flows.ts\nindex 5db04b47c5a25..09428d2fea657 100644\n--- a/app/src/composables/use-flows.ts\n+++ b/app/src/composables/use-flows.ts\n@@ -1,5 +1,5 @@\n import api from '@/api';\n-import { computed, ref, provide, inject, type Ref } from 'vue';\n+import { computed, ref, provide, inject, unref, type Ref } from 'vue';\n import { FlowRaw, Item, PrimaryKey } from '@directus/types';\n import { notify } from '@/utils/notify';\n import { translate } from '@/utils/translate-object-values';\n@@ -12,7 +12,7 @@ import formatTitle from '@directus/format-title';\n \n interface UseFlowsOptions {\n \tcollection: Ref<string>;\n-\tprimaryKey?: PrimaryKey | null;\n+\tprimaryKey?: Ref<PrimaryKey | null>;\n \tselection?: Ref<Item[]>;\n \tlocation: 'collection' | 'item';\n \thasEdits?: Ref<boolean>;\n@@ -150,7 +150,7 @@ export function useFlows(options: UseFlowsOptions) {\n \n \t\tfunction checkFlowDisabled(manualFlow: FlowRaw) {\n \t\t\tif (location === 'item' || manualFlow.options?.requireSelection === false) return false;\n-\t\t\treturn !primaryKey && selection.value.length === 0;\n+\t\t\treturn !unref(primaryKey) && selection.value.length === 0;\n \t\t}\n \n \t\treturn manualFlows;\n@@ -231,7 +231,8 @@ export function useFlows(options: UseFlowsOptions) {\n \t\t\t\t\tcollection: collection.value,\n \t\t\t\t});\n \t\t\t} else {\n-\t\t\t\tconst keys = primaryKey ? [primaryKey] : selection.value || [];\n+\t\t\t\tconst pk = unref(primaryKey);\n+\t\t\t\tconst keys = pk ? [pk] : selection.value || [];\n \n \t\t\t\tawait api.post(`/flows/trigger/${flowId}`, {\n \t\t\t\t\t...confirmValues.value,\ndiff --git a/app/src/modules/content/routes/item.vue b/app/src/modules/content/routes/item.vue\nindex e2805771de963..cbed86fcc16ae 100644\n--- a/app/src/modules/content/routes/item.vue\n+++ b/app/src/modules/content/routes/item.vue\n@@ -304,7 +304,7 @@ watch(\n \n const { flowDialogsContext, manualFlows, provideRunManualFlow } = useFlows({\n \tcollection,\n-\tprimaryKey: actualPrimaryKey.value,\n+\tprimaryKey: actualPrimaryKey,\n \tlocation: 'item',\n \thasEdits,\n \tonRefreshCallback: refresh,\ndiff --git a/app/src/views/private/components/overlay-item.vue b/app/src/views/private/components/overlay-item.vue\nindex 0f16dc55e6290..5afae6a4c3a4d 100644\n--- a/app/src/views/private/components/overlay-item.vue\n+++ b/app/src/views/private/components/overlay-item.vue\n@@ -244,7 +244,7 @@ const overlayItemContentProps = computed(() => {\n \n const { provideRunManualFlow } = useFlows({\n \tcollection,\n-\tprimaryKey: primaryKey.value,\n+\tprimaryKey: primaryKey,\n \tlocation: 'item',\n \thasEdits,\n \tonRefreshCallback: refresh,\n", "test_patch": "", "problem_statement": "## Scope\r\n\r\nWhat's changed:\r\n\r\n- Fixes issue where navigating from one item to another directly does not update the useFlows primaryKey because it was not reactive\r\n\r\n## Potential Risks / Drawbacks\r\n\r\n- Manually triggered flows stop working\r\n\r\n## Tested Scenarios\r\n\r\n- Tested running flow on item\r\n- Tested running flow on collection\r\n- Tested running flow on item in drawer\r\n- Tested running flow on item after direct navigation\r\n\r\n## Review Notes / Questions\r\n\r\n- Tests all still pass + added new test for this case\r\n\r\n## Checklist\r\n\r\n- [x] Added or updated tests\r\n- [x] Documentation PR created [here](https://github.com/directus/docs) or not required\r\n- [x] OpenAPI package PR created [here](https://github.com/directus/openapi) or not required\r\n\r\n---\r\n\r\nFixes CMS-1537\r\n", "hints_text": "", "created_at": "2025-12-01T22:17:39Z", "pull_number": 26287, "test_files": ["app/src/composables/use-flows.test.ts"], "code_files": ["app/src/composables/use-flows.ts"], "title": "Add reactive primaryKey prop to useFlows composable", "additions": 0, "deletions": 0}
{"repo": "directus/directus", "instance_id": "directus__directus.pr_mirror.25881", "base_commit": "e188b690fce5d01ef7ab0319be34536105bf00b2", "patch": "diff --git a/.changeset/chubby-papers-kiss.md b/.changeset/chubby-papers-kiss.md\nnew file mode 100644\nindex 0000000000000..4e5e517c0fe81\n--- /dev/null\n+++ b/.changeset/chubby-papers-kiss.md\n@@ -0,0 +1,5 @@\n+---\n+'@directus/api': patch\n+---\n+\n+Added support for MSSQL tables with triggers\ndiff --git a/api/src/services/items.test.ts b/api/src/services/items.test.ts\nindex 7fae6f0170f60..c7d9faf6126cc 100644\n--- a/api/src/services/items.test.ts\n+++ b/api/src/services/items.test.ts\n@@ -4,6 +4,7 @@ import knex, { type Knex } from 'knex';\n import { MockClient, Tracker, createTracker } from 'knex-mock-client';\n import { afterEach, beforeAll, beforeEach, describe, expect, it, vi, type MockedFunction } from 'vitest';\n import { validateUserCountIntegrity } from '../utils/validate-user-count-integrity.js';\n+import { getDatabaseClient } from '../database/index.js';\n import { ItemsService } from './index.js';\n \n vi.mock('../../src/database/index', () => ({\n@@ -56,6 +57,52 @@ describe('Integration Tests', () => {\n \n \t\t\t\texpect(validateUserCountIntegrity).toHaveBeenCalled();\n \t\t\t});\n+\n+\t\t\tit('should use includeTriggerModifications for MS SQL', async () => {\n+\t\t\t\tvi.mocked(getDatabaseClient).mockReturnValue('mssql');\n+\n+\t\t\t\tconst mockReturning = vi.fn().mockResolvedValue([{ id: 1 }]);\n+\n+\t\t\t\tconst mockQuery = {\n+\t\t\t\t\tinsert: vi.fn().mockReturnThis(),\n+\t\t\t\t\tinto: vi.fn().mockReturnThis(),\n+\t\t\t\t\treturning: mockReturning,\n+\t\t\t\t};\n+\n+\t\t\t\tconst transactionSpy = vi.spyOn(db, 'transaction').mockImplementation(async (callback) => {\n+\t\t\t\t\tconst trx = { ...db, ...mockQuery };\n+\t\t\t\t\treturn await callback(trx as any);\n+\t\t\t\t});\n+\n+\t\t\t\tawait service.createOne({ name: 'Test' });\n+\n+\t\t\t\texpect(mockReturning).toHaveBeenCalledWith('id', { includeTriggerModifications: true });\n+\n+\t\t\t\ttransactionSpy.mockRestore();\n+\t\t\t});\n+\n+\t\t\tit('should not use includeTriggerModifications for non-MS SQL', async () => {\n+\t\t\t\tvi.mocked(getDatabaseClient).mockReturnValue('postgres');\n+\n+\t\t\t\tconst mockReturning = vi.fn().mockResolvedValue([{ id: 1 }]);\n+\n+\t\t\t\tconst mockQuery = {\n+\t\t\t\t\tinsert: vi.fn().mockReturnThis(),\n+\t\t\t\t\tinto: vi.fn().mockReturnThis(),\n+\t\t\t\t\treturning: mockReturning,\n+\t\t\t\t};\n+\n+\t\t\t\tconst transactionSpy = vi.spyOn(db, 'transaction').mockImplementation(async (callback) => {\n+\t\t\t\t\tconst trx = { ...db, ...mockQuery };\n+\t\t\t\t\treturn await callback(trx as any);\n+\t\t\t\t});\n+\n+\t\t\t\tawait service.createOne({ name: 'Test' });\n+\n+\t\t\t\texpect(mockReturning).toHaveBeenCalledWith('id', undefined);\n+\n+\t\t\t\ttransactionSpy.mockRestore();\n+\t\t\t});\n \t\t});\n \n \t\tdescribe('createMany', () => {\ndiff --git a/api/src/services/items.ts b/api/src/services/items.ts\nindex 68abe56ebf58a..7147d1406d366 100644\n--- a/api/src/services/items.ts\n+++ b/api/src/services/items.ts\n@@ -23,7 +23,7 @@ import { getCache } from '../cache.js';\n import { translateDatabaseError } from '../database/errors/translate.js';\n import { getAstFromQuery } from '../database/get-ast-from-query/get-ast-from-query.js';\n import { getHelpers } from '../database/helpers/index.js';\n-import getDatabase from '../database/index.js';\n+import getDatabase, { getDatabaseClient } from '../database/index.js';\n import { runAst } from '../database/run-ast/run-ast.js';\n import emitter from '../emitter.js';\n import { processAst } from '../permissions/modules/process-ast/process-ast.js';\n@@ -243,10 +243,17 @@ export class ItemsService<Item extends AnyItem = AnyItem, Collection extends str\n \t\t\t}\n \n \t\t\ttry {\n+\t\t\t\tlet returningOptions = undefined;\n+\n+\t\t\t\t// Support MSSQL tables that have triggers.\n+\t\t\t\tif (getDatabaseClient(trx) === 'mssql') {\n+\t\t\t\t\treturningOptions = { includeTriggerModifications: true };\n+\t\t\t\t}\n+\n \t\t\t\tconst result = await trx\n \t\t\t\t\t.insert(payloadWithoutAliases)\n \t\t\t\t\t.into(this.collection)\n-\t\t\t\t\t.returning(primaryKeyField)\n+\t\t\t\t\t.returning(primaryKeyField, returningOptions)\n \t\t\t\t\t.then((result) => result[0]);\n \n \t\t\t\tconst returnedKey = typeof result === 'object' ? result[primaryKeyField] : result;\n", "test_patch": "", "problem_statement": "## Scope\r\n\r\nWhat's changed:\r\n\r\n- Added MS SQL trigger compatibility to `ItemsService.createOne()` method\r\n- Implemented conditional `includeTriggerModifications` flag for MS SQL database client\r\n- Added database client detection logic to handle MS SQL-specific requirements\r\n- Added comprehensive test coverage for MS SQL trigger scenarios\r\n\r\n## Potential Risks / Drawbacks\r\n\r\n- Very low risk as the change is conditional and only affects MS SQL databases\r\n- No impact on existing functionality for PostgreSQL, MySQL, SQLite, or other databases\r\n- The fix follows `Knex.js` best practices and official documentation\r\n\r\n## Tested Scenarios\r\n\r\n- MS SQL database client detection and `includeTriggerModifications` flag application\r\n- Non-MS SQL database clients continue to work without the flag (PostgreSQL, MySQL, etc.)\r\n- Existing `createOne()` functionality preserved across all database types\r\n\r\n## Review Notes / Questions\r\n\r\n- Special attention should be paid to the conditional logic that only applies the fix to MS SQL\r\n- The solution uses Knex's built-in `includeTriggerModifications` flag as recommended in their documentation\r\n\r\n## Checklist\r\n\r\n- [x] Added or updated tests\r\n- [ ] Documentation PR created [here](https://github.com/directus/docs) or not required\r\n\r\n---\r\nFixes: CMS-1352", "hints_text": "", "created_at": "2025-09-23T14:50:21Z", "pull_number": 25881, "test_files": ["api/src/services/items.test.ts"], "code_files": ["api/src/services/items.ts"], "title": "Add support for MSSQL tables with triggers", "additions": 0, "deletions": 0}
{"repo": "directus/directus", "instance_id": "directus__directus.pr_mirror.26268", "base_commit": "8f5775f4ae95dc7492b8ace93b6be51c52e777ab", "patch": "diff --git a/api/src/ai/chat/constants/system-prompt.ts b/api/src/ai/chat/constants/system-prompt.ts\nnew file mode 100644\nindex 0000000000000..0c2d965c31ee2\n--- /dev/null\n+++ b/api/src/ai/chat/constants/system-prompt.ts\n@@ -0,0 +1,51 @@\n+export const SYSTEM_PROMPT = `\n+<behavior_instructions>\n+You are **Directus Assistant**, a Directus CMS expert with access to a Directus instance through specialized tools\n+\n+## Communication Style\n+\n+- **Be concise**: Users prefer short, direct responses. One-line confirmations: \"Created collection 'products'\"\n+- **Match the audience**: Technical for developers, plain language for content editors\n+- **NEVER guess**: If not at least 99% about field values or user intent, ask for clarification\n+\n+## Tool Usage Patterns\n+\n+### Discovery First\n+\n+1. Understand the user's task and what they need to achieve.\n+2. Discover schema if needed for task - **schema()** with no params \u2192 lightweight collection list or **schema({ keys: [\"products\", \"categories\"] })** \u2192 full field/relation details\n+3. Use other tools as needed to achieve the user's task.\n+\n+### Content Items\n+\n+- Use \\`fields\\` whenever possible to fetch only the exact fields you need\n+- Use \\`filter\\` and \\`limit\\` to control the number of fetched items unless you absolutely need larger datasets\n+- When presenting repeated structured data with 4+ items, use markdown tables for better readability\n+\n+### Schema & Data Changes\n+\n+- **Confirm before modifying any schema**: Collections, fields, relations always need approval from the user.\n+- **Check namespace conflicts**: Collection folders and regular collections share namespace. Collection folders are\n+  distinct from file folders.\n+\n+### Safety Rules\n+\n+- **Deletions require confirmation**: ALWAYS ask before deleting anything\n+- **Warn on bulk operations**: Alert when affecting many items (\"This updates 500 items\")\n+- **Avoid duplicates**: Never create duplicates if you can't modify existing items\n+- **Use semantic HTML**: No classes, IDs, or inline styles in content fields (unless explicitly asked for by the user)\n+- **Permission errors**: Report immediately, don't retry\n+\n+### Behavior Rules\n+\n+- Call tools immediately without explanatory text\n+- Use parallel tool calls when possible\n+- If you don't have access to a certain tool, ask the user to grant you access to the tool from the chat settings.\n+- If there are unused tools in context but task is simple, suggest disabling unused tools (once per conversation)\n+\n+## Error Handling\n+\n+- Auto-retry once for clear errors (\"field X required\")\n+- Stop after 2 failures, consult user\n+- If tool unavailable, suggest enabling in chat settings\n+</behavior_instructions>`;\ndiff --git a/api/src/ai/chat/lib/create-ui-stream.test.ts b/api/src/ai/chat/lib/create-ui-stream.test.ts\nindex d3a807f5312d0..a368f2dd2e437 100644\n--- a/api/src/ai/chat/lib/create-ui-stream.test.ts\n+++ b/api/src/ai/chat/lib/create-ui-stream.test.ts\n@@ -1,6 +1,7 @@\n import { ServiceUnavailableError } from '@directus/errors';\n import type { UIMessage } from 'ai';\n-import { describe, expect, it, vi } from 'vitest';\n+import { streamText } from 'ai';\n+import { beforeEach, describe, expect, it, vi } from 'vitest';\n import { createUiStream } from './create-ui-stream.js';\n \n // Mocks\n@@ -12,6 +13,10 @@ vi.mock('@ai-sdk/anthropic', () => ({\n \tcreateAnthropic: vi.fn(() => (model: string) => ({ id: `anthropic:${model}` })),\n }));\n \n+vi.mock('../constants/system-prompt.js', () => ({\n+\tSYSTEM_PROMPT: 'DEFAULT_SYSTEM_PROMPT',\n+}));\n+\n const mockStreamTextResult = {\n \ttoDataStreamResponse: vi.fn(),\n \tpipeDataStreamToResponse: vi.fn(),\n@@ -26,6 +31,10 @@ vi.mock('ai', () => ({\n }));\n \n describe('createUiStream', () => {\n+\tbeforeEach(() => {\n+\t\tvi.clearAllMocks();\n+\t});\n+\n \tconst messages: UIMessage[] = [\n \t\t{ id: '1', role: 'user', parts: [{ type: 'text', text: 'Hello' }] },\n \t\t{ id: '2', role: 'assistant', parts: [{ type: 'text', text: 'Hi there!' }] },\n@@ -78,11 +87,52 @@ describe('createUiStream', () => {\n \tit('should throw Error for unknown provider', () => {\n \t\texpect(() =>\n \t\t\tcreateUiStream(messages, {\n-\t\t\t\tprovider: 'unknown',\n+\t\t\t\tprovider: 'unknown' as any,\n \t\t\t\tmodel: 'model',\n \t\t\t\ttools: {},\n \t\t\t\tapiKeys,\n \t\t\t}),\n \t\t).toThrow('Unexpected provider given: \"unknown\"');\n \t});\n+\n+\tit('uses default system prompt when none provided', () => {\n+\t\tcreateUiStream(messages, {\n+\t\t\tprovider: 'openai',\n+\t\t\tmodel: 'gpt-4',\n+\t\t\ttools: {},\n+\t\t\tapiKeys,\n+\t\t});\n+\n+\t\texpect(streamText).toHaveBeenCalledWith(\n+\t\t\texpect.objectContaining({ system: 'DEFAULT_SYSTEM_PROMPT' }),\n+\t\t);\n+\t});\n+\n+\tit('uses provided system prompt when given', () => {\n+\t\tcreateUiStream(messages, {\n+\t\t\tprovider: 'openai',\n+\t\t\tmodel: 'gpt-4o',\n+\t\t\ttools: {},\n+\t\t\tapiKeys,\n+\t\t\tsystemPrompt: 'CUSTOM_PROMPT',\n+\t\t});\n+\n+\t\texpect(streamText).toHaveBeenCalledWith(\n+\t\t\texpect.objectContaining({ system: 'CUSTOM_PROMPT' }),\n+\t\t);\n+\t});\n+\n+\tit('replaces empty string system prompt with default', () => {\n+\t\tcreateUiStream(messages, {\n+\t\t\tprovider: 'openai',\n+\t\t\tmodel: 'gpt-4o-mini',\n+\t\t\ttools: {},\n+\t\t\tapiKeys,\n+\t\t\tsystemPrompt: '',\n+\t\t});\n+\n+\t\texpect(streamText).toHaveBeenCalledWith(\n+\t\t\texpect.objectContaining({ system: 'DEFAULT_SYSTEM_PROMPT' }),\n+\t\t);\n+\t});\n });\ndiff --git a/api/src/ai/chat/lib/create-ui-stream.ts b/api/src/ai/chat/lib/create-ui-stream.ts\nindex babd8902e897b..ea71bd567c726 100644\n--- a/api/src/ai/chat/lib/create-ui-stream.ts\n+++ b/api/src/ai/chat/lib/create-ui-stream.ts\n@@ -9,6 +9,7 @@ import {\n \ttype Tool,\n \ttype UIMessage,\n } from 'ai';\n+import { SYSTEM_PROMPT } from '../constants/system-prompt.js';\n \n export interface CreateUiStreamOptions {\n \tprovider: 'openai' | 'anthropic';\n@@ -40,14 +41,10 @@ export const createUiStream = (\n \t\tthrow new Error(`Unexpected provider given: \"${provider}\"`);\n \t}\n \n-\tconst optionalStreamingParameters: { system?: string } = {};\n-\n-\tif (systemPrompt) {\n-\t\toptionalStreamingParameters.system = systemPrompt;\n-\t}\n+\tsystemPrompt ||= SYSTEM_PROMPT;\n \n \tconst stream = streamText({\n-\t\t...optionalStreamingParameters,\n+\t\tsystem: systemPrompt,\n \t\tmodel: modelProvider(model),\n \t\tmessages: convertToModelMessages(messages),\n \t\tstopWhen: [stepCountIs(10)],\n", "test_patch": "", "problem_statement": "## Scope\r\n\r\nWhat's changed:\r\n\r\n- Adds a \"soft\" default value for the system prompt\r\n- Use a modified version of the MCP system prompt as starting point\r\n\r\n## Potential Risks / Drawbacks\r\n\r\n- No existing work modified, this is a very low risk change\r\n\r\n## Tested Scenarios\r\n\r\n- It correctly defaults to the hardcoded system prompt\r\n- An empty string still uses the default system prompt\r\n\r\n## Review Notes / Questions\r\n\r\n- We don't utilize the actual database default value, as this system prompt default is something we expect to change a lot over the next couple of weeks\r\n\r\n## Checklist\r\n\r\n- [x] Added or updated tests\r\n- [ ] Documentation PR created [here](https://github.com/directus/docs) or not required\r\n- [ ] OpenAPI package PR created [here](https://github.com/directus/openapi) or not required\r\n", "hints_text": "", "created_at": "2025-11-26T19:30:29Z", "pull_number": 26268, "test_files": ["api/src/ai/chat/lib/create-ui-stream.test.ts"], "code_files": ["api/src/ai/chat/constants/system-prompt.ts", "api/src/ai/chat/lib/create-ui-stream.ts"], "title": "AI \u2192 Add soft-default for system prompt", "additions": 0, "deletions": 0}
{"repo": "directus/directus", "instance_id": "directus__directus.pr_mirror.25883", "base_commit": "453d2ba2b3cf193369c3a569fe800d29424e2bd3", "patch": "diff --git a/.changeset/khaki-falcons-search.md b/.changeset/khaki-falcons-search.md\nnew file mode 100644\nindex 0000000000000..b9618267a4150\n--- /dev/null\n+++ b/.changeset/khaki-falcons-search.md\n@@ -0,0 +1,5 @@\n+---\n+'@directus/storage-driver-supabase': patch\n+---\n+\n+Fixed Supabase storage driver file uploads and improved error handling\n\\ No newline at end of file\ndiff --git a/packages/storage-driver-supabase/src/index.test.ts b/packages/storage-driver-supabase/src/index.test.ts\nindex be18fef576e1e..a039cd0c6cfe6 100644\n--- a/packages/storage-driver-supabase/src/index.test.ts\n+++ b/packages/storage-driver-supabase/src/index.test.ts\n@@ -1,23 +1,23 @@\n-import { StorageClient } from '@supabase/storage-js';\n import {\n \trandAlphaNumeric,\n \trandGitBranch as randBucket,\n \trandDirectoryPath,\n \trandDomainName,\n+\trandFileName,\n \trandFilePath,\n \trandFileType,\n \trandNumber,\n \trandPastDate,\n \trandText,\n \trandGitShortSha as randUnique,\n-\trandFileName,\n } from '@ngneat/falso';\n-import { Response, fetch } from 'undici';\n+import { StorageClient } from '@supabase/storage-js';\n import { Readable } from 'node:stream';\n+import { ReadableStream } from 'node:stream/web';\n+import { Response, fetch } from 'undici';\n import { afterEach, beforeEach, describe, expect, test, vi } from 'vitest';\n import type { DriverSupabaseConfig } from './index.js';\n import { DriverSupabase } from './index.js';\n-import { ReadableStream } from 'node:stream/web';\n \n vi.mock('@supabase/storage-js');\n vi.mock('undici');\n@@ -52,6 +52,7 @@ beforeEach(() => {\n \t\t\tprojectId: randAlphaNumeric({ length: 10 }).join(''),\n \t\t\troot: randUnique() + randDirectoryPath(),\n \t\t\tendpoint: randDomainName(),\n+\t\t\ttus: { chunkSize: 1024 * 1024 },\n \t\t},\n \t\tpath: {\n \t\t\tinput: randUnique() + randFilePath(),\n@@ -448,7 +449,7 @@ describe('#copy', () => {\n describe('#write', () => {\n \tbeforeEach(() => {\n \t\tdriver['bucket'] = {\n-\t\t\tupload: vi.fn(),\n+\t\t\tupload: vi.fn().mockResolvedValue({ data: null, error: null }),\n \t\t} as any;\n \t});\n \n@@ -480,6 +481,18 @@ describe('#write', () => {\n \t\t\tupsert: true,\n \t\t});\n \t});\n+\n+\ttest('Throws error when upload fails', async () => {\n+\t\tconst uploadError = new Error('Upload failed');\n+\n+\t\tdriver['bucket'] = {\n+\t\t\tupload: vi.fn().mockResolvedValue({ data: null, error: uploadError }),\n+\t\t} as any;\n+\n+\t\tawait expect(driver.write(sample.path.input, sample.stream)).rejects.toThrow(\n+\t\t\tnew Error(`Error uploading file \"${sample.path.input}\"`, { cause: uploadError }),\n+\t\t);\n+\t});\n });\n \n describe('#delete', () => {\ndiff --git a/packages/storage-driver-supabase/src/index.ts b/packages/storage-driver-supabase/src/index.ts\nindex 1d62117dd510b..8698bd3605134 100644\n--- a/packages/storage-driver-supabase/src/index.ts\n+++ b/packages/storage-driver-supabase/src/index.ts\n@@ -139,12 +139,16 @@ export class DriverSupabase implements TusDriver {\n \t}\n \n \tasync write(filepath: string, content: Readable, type?: string) {\n-\t\tawait this.bucket.upload(this.fullPath(filepath), content, {\n+\t\tconst { error } = await this.bucket.upload(this.fullPath(filepath), content, {\n \t\t\tcontentType: type ?? '',\n \t\t\tcacheControl: '3600',\n \t\t\tupsert: true,\n \t\t\tduplex: 'half',\n \t\t});\n+\n+\t\tif (error) {\n+\t\t\tthrow new Error(`Error uploading file \"${filepath}\"`, { cause: error });\n+\t\t}\n \t}\n \n \tasync delete(filepath: string) {\ndiff --git a/pnpm-lock.yaml b/pnpm-lock.yaml\nindex 92305e08028a8..790194ef92b0b 100644\n--- a/pnpm-lock.yaml\n+++ b/pnpm-lock.yaml\n@@ -190,8 +190,8 @@ catalogs:\n       specifier: 4.1.0\n       version: 4.1.0\n     '@supabase/storage-js':\n-      specifier: 2.10.4\n-      version: 2.10.4\n+      specifier: 2.12.1\n+      version: 2.12.1\n     '@tinymce/tinymce-vue':\n       specifier: 6.3.0\n       version: 6.3.0\n@@ -2638,7 +2638,7 @@ importers:\n         version: link:../utils\n       '@supabase/storage-js':\n         specifier: 'catalog:'\n-        version: 2.10.4\n+        version: 2.12.1\n       tus-js-client:\n         specifier: 'catalog:'\n         version: 4.3.1\n@@ -3805,12 +3805,21 @@ packages:\n   '@emnapi/core@1.4.5':\n     resolution: {integrity: sha512-XsLw1dEOpkSX/WucdqUhPWP7hDxSvZiY+fsUC14h+FtQ2Ifni4znbBt8punRX+Uj2JG/uDb8nEHVKvrVlvdZ5Q==}\n \n+  '@emnapi/core@1.5.0':\n+    resolution: {integrity: sha512-sbP8GzB1WDzacS8fgNPpHlp6C9VZe+SJP3F90W9rLemaQj2PzIuTEl1qDOYQf58YIpyjViI24y9aPWCjEzY2cg==}\n+\n   '@emnapi/runtime@1.4.5':\n     resolution: {integrity: sha512-++LApOtY0pEEz1zrd9vy1/zXVaVJJ/EbAF3u0fXIzPJEDtnITsBGbbK0EkM72amhl/R5b+5xx0Y/QhcVOpuulg==}\n \n+  '@emnapi/runtime@1.5.0':\n+    resolution: {integrity: sha512-97/BJ3iXHww3djw6hYIfErCZFee7qCtrneuLa20UXFCOTCfBM2cvQHjWJ2EG0s0MtdNwInarqCTz35i4wWXHsQ==}\n+\n   '@emnapi/wasi-threads@1.0.4':\n     resolution: {integrity: sha512-PJR+bOmMOPH8AtcTGAyYNiuJ3/Fcoj2XN/gBEWzDIKh254XO+mM9XoXHk5GNEhodxeMznbg7BlRojVbKN+gC6g==}\n \n+  '@emnapi/wasi-threads@1.1.0':\n+    resolution: {integrity: sha512-WI0DdZ8xFSbgMjR1sFsKABJ/C5OnRrjT06JXbZKexJGrDuPTzZdDYfFlsgcCXCyf+suG5QU2e/y1Wo2V/OapLQ==}\n+\n   '@esbuild/aix-ppc64@0.21.5':\n     resolution: {integrity: sha512-1SDgH6ZSPTlggy1yI6+Dbkiz8xzpHJEVAlF/AM1tHPLsf5STom9rwtjE4hKAF20FfXXNTFqEYXyJNWh1GiZedQ==}\n     engines: {node: '>=12'}\n@@ -4822,6 +4831,9 @@ packages:\n   '@napi-rs/wasm-runtime@1.0.3':\n     resolution: {integrity: sha512-rZxtMsLwjdXkMUGC3WwsPwLNVqVqnTJT6MNIB6e+5fhMcSCPP0AOsNWuMQ5mdCq6HNjs/ZeWAEchpqeprqBD2Q==}\n \n+  '@napi-rs/wasm-runtime@1.0.5':\n+    resolution: {integrity: sha512-TBr9Cf9onSAS2LQ2+QHx6XcC6h9+RIzJgbqG3++9TUZSH204AwEy5jg3BTQ0VATsyoGj4ee49tN/y6rvaOOtcg==}\n+\n   '@ngneat/falso@8.0.2':\n     resolution: {integrity: sha512-vhPtuoHoxE5JGWPSPBqEyTXcjI4MAn8GllR+Vs8FfpAQu2sQRd4PJc3e8kc9vdbdhYHx1C9HmbECgtGLK30z4w==}\n \n@@ -4887,15 +4899,11 @@ packages:\n     resolution: {integrity: sha512-3rzy1bJAZ4s7zV9TKT60x119RwJDCDqEtCwK/Zc2qlm7wGhiIUxLLYUhE/mN91yB0u1kxm5sh4NjU12sPqQTpg==}\n     engines: {node: '>=6.9.0'}\n \n-  '@oxc-project/runtime@0.87.0':\n-    resolution: {integrity: sha512-ky2Hqi2q/uGX36UfY79zxMbUqiNIl1RyKKVJfFenG70lbn+/fcaKBVTbhmUwn8a2wPyv2gNtDQxuDytbKX9giQ==}\n-    engines: {node: '>=6.9.0'}\n-\n   '@oxc-project/types@0.80.0':\n     resolution: {integrity: sha512-xxHQm8wfCv2e8EmtaDwpMeAHOWqgQDAYg+BJouLXSQt5oTKu9TIXrgNMGSrM2fLvKmECsRd9uUFAAD+hPyootA==}\n \n-  '@oxc-project/types@0.87.0':\n-    resolution: {integrity: sha512-ipZFWVGE9fADBVXXWJWY/cxpysc41Gt5upKDeb32F6WMgFyO7XETUMVq8UuREKCih+Km5E6p2VhEvf6Fuhey6g==}\n+  '@oxc-project/types@0.90.0':\n+    resolution: {integrity: sha512-fWvaufWUcLtm/OBKcNmxUkR0kQW5ZKAF0t03BXPqdzpxmnVCmSKzvUDRCOKnSagSfNzG/3ZdKpComH3GMy881g==}\n \n   '@paralleldrive/cuid2@2.2.2':\n     resolution: {integrity: sha512-ZOBkgDwEdoYVlSeRbYYXs0S9MejQofiVYoTbKzy/6GQa39/q5tQU2IX46+shYnUkpEl3wc+J6wRlar7r2EK2xA==}\n@@ -5461,8 +5469,8 @@ packages:\n     cpu: [arm64]\n     os: [android]\n \n-  '@rolldown/binding-android-arm64@1.0.0-beta.37':\n-    resolution: {integrity: sha512-Pdr3USGBdoYzcygfJTSATHd7x476vVF3rnQ6SuUAh4YjhgGoNaI/ZycQ0RsonptwwU5NmQRWxfWv+aUPL6JlJg==}\n+  '@rolldown/binding-android-arm64@1.0.0-beta.39':\n+    resolution: {integrity: sha512-mjraAJQ3VRLPb3BUgVigHvmAYhiBpEeSM0dhvaO6XHtJ0k1o9Ng1Z6Qvlp4/1wDiUf7a10L5c3yleoGZ2r0Maw==}\n     engines: {node: ^20.19.0 || >=22.12.0}\n     cpu: [arm64]\n     os: [android]\n@@ -5472,8 +5480,8 @@ packages:\n     cpu: [arm64]\n     os: [darwin]\n \n-  '@rolldown/binding-darwin-arm64@1.0.0-beta.37':\n-    resolution: {integrity: sha512-iDdmatSgbWhTYOq51G2CkJXwFayiuQpv/ywG7Bv3wKqy31L7d0LltUhWqAdfCl7eBG3gybfUm/iEXiTldH3jYA==}\n+  '@rolldown/binding-darwin-arm64@1.0.0-beta.39':\n+    resolution: {integrity: sha512-tnuiLq9vd08KsZeFkFgzCXVKsTgSZGn+YBQjHSEiUvXJy5pfUf82X/YyLCG8P6I+WDd2cgrcLilMBQPZgaNwkg==}\n     engines: {node: ^20.19.0 || >=22.12.0}\n     cpu: [arm64]\n     os: [darwin]\n@@ -5483,8 +5491,8 @@ packages:\n     cpu: [x64]\n     os: [darwin]\n \n-  '@rolldown/binding-darwin-x64@1.0.0-beta.37':\n-    resolution: {integrity: sha512-LQPpi3YJDtIprj6mwMbVM1gLM4BV2m9oqe9h3Y1UwAd20xs+imnzWJqWFpm4Hw9SiFmefIf3q4EPx2k6Nj2K7A==}\n+  '@rolldown/binding-darwin-x64@1.0.0-beta.39':\n+    resolution: {integrity: sha512-wLFoB3ZM4AoeBlsP0eVbPzWfkEgvmnibMQEKUgWRfJnKhUWiSxl0kGdSw1fNYdX3KAqIeA5gPJNvSJmf6g5S3Q==}\n     engines: {node: ^20.19.0 || >=22.12.0}\n     cpu: [x64]\n     os: [darwin]\n@@ -5494,8 +5502,8 @@ packages:\n     cpu: [x64]\n     os: [freebsd]\n \n-  '@rolldown/binding-freebsd-x64@1.0.0-beta.37':\n-    resolution: {integrity: sha512-9JnfSWfYd/YrZOu4Sj3rb2THBrCj70nJB/2FOSdg0O9ZoRrdTeB8b7Futo6N7HLWZM5uqqnJBX6VTpA0RZD+ow==}\n+  '@rolldown/binding-freebsd-x64@1.0.0-beta.39':\n+    resolution: {integrity: sha512-wzFZlixF9VMbyi++rHCU4Cy72SH11aBNnkadmvwTAbokwjYHi8NqxQ3/Lx00c700N6kwwuiTsbcGt5DEA9aROw==}\n     engines: {node: ^20.19.0 || >=22.12.0}\n     cpu: [x64]\n     os: [freebsd]\n@@ -5505,8 +5513,8 @@ packages:\n     cpu: [arm]\n     os: [linux]\n \n-  '@rolldown/binding-linux-arm-gnueabihf@1.0.0-beta.37':\n-    resolution: {integrity: sha512-eEmQTpvefEtHxc0vg5sOnWCqBcGQB/SIDlPkkzKR9ESKq9BsjQfHxssJWuNMyQ+rpr9CYaogddyQtZ9GHkp8vA==}\n+  '@rolldown/binding-linux-arm-gnueabihf@1.0.0-beta.39':\n+    resolution: {integrity: sha512-eVnZcwGbje1uwdFjeQZQ6918RHgGIK7iTC+AoDsgetgAXQmQpnuWYQ9OWa5oTHNQyCkZbMfiHKgpkUPpceMecw==}\n     engines: {node: ^20.19.0 || >=22.12.0}\n     cpu: [arm]\n     os: [linux]\n@@ -5516,8 +5524,8 @@ packages:\n     cpu: [arm64]\n     os: [linux]\n \n-  '@rolldown/binding-linux-arm64-gnu@1.0.0-beta.37':\n-    resolution: {integrity: sha512-Ekv4OjDzQUl0X9kHM7M23N9hVRiYCYr89neLBNITCp7P4IHs1f6SNZiCIvvBVy6NIFzO1w9LZJGEeJYK5cQBVQ==}\n+  '@rolldown/binding-linux-arm64-gnu@1.0.0-beta.39':\n+    resolution: {integrity: sha512-Td96iRQA0nmRZM6kJ3+LDDKWLh4bl0zqeR+IYxXwPZBw4iXSREzXrcZ3QqgFHqnXPgryIJEW1U1Ebh2xf+b2UA==}\n     engines: {node: ^20.19.0 || >=22.12.0}\n     cpu: [arm64]\n     os: [linux]\n@@ -5527,8 +5535,8 @@ packages:\n     cpu: [arm64]\n     os: [linux]\n \n-  '@rolldown/binding-linux-arm64-musl@1.0.0-beta.37':\n-    resolution: {integrity: sha512-z8Aa5Kar5mhh0RVZEL+zKJwNz1cgcDISmwUMcTk0w986T8JZJOJCfJ/u9e8pqUTIJjxdM8SZq9/24nMgMlx5ng==}\n+  '@rolldown/binding-linux-arm64-musl@1.0.0-beta.39':\n+    resolution: {integrity: sha512-bcSIh1TFUoPcexJH+gO1sE6wpSR0j3UpWBnjAwyM1PRKfjtqN4R9Du90ofH5KsR/A35FT3eP4mdnhMDTd5Yt+A==}\n     engines: {node: ^20.19.0 || >=22.12.0}\n     cpu: [arm64]\n     os: [linux]\n@@ -5543,8 +5551,8 @@ packages:\n     cpu: [x64]\n     os: [linux]\n \n-  '@rolldown/binding-linux-x64-gnu@1.0.0-beta.37':\n-    resolution: {integrity: sha512-e+fNseKhfE/socjOw6VrQcXrbNKfi2V/KZ+ssuLnmeaYNGuJWqPhvML56oYhGb3IgROEEc61lzr3Riy5BIqoMA==}\n+  '@rolldown/binding-linux-x64-gnu@1.0.0-beta.39':\n+    resolution: {integrity: sha512-tYEcZdVGovEemh7ELr+VUoezGkuBgRZYvDHHW/HVIw9LQW5HKLtBIGLzFlOfu/Lq5b9FlDKl+lrY6weviaNnKw==}\n     engines: {node: ^20.19.0 || >=22.12.0}\n     cpu: [x64]\n     os: [linux]\n@@ -5554,14 +5562,14 @@ packages:\n     cpu: [x64]\n     os: [linux]\n \n-  '@rolldown/binding-linux-x64-musl@1.0.0-beta.37':\n-    resolution: {integrity: sha512-dPZfB396PMIasd19X0ikpdCvjK/7SaJFO8y5/TxnozJEy70vOf4GESe/oKcsJPav/MSTWBYsHjJSO6vX0oAW8g==}\n+  '@rolldown/binding-linux-x64-musl@1.0.0-beta.39':\n+    resolution: {integrity: sha512-xf9QdMC+qwQxtFAty/9RxgCLFdp9pFl09g86hxGPzlzCtHUjd+BmeUnUTXvVC8CHJLWECLQbFP6/233XHG0blA==}\n     engines: {node: ^20.19.0 || >=22.12.0}\n     cpu: [x64]\n     os: [linux]\n \n-  '@rolldown/binding-openharmony-arm64@1.0.0-beta.37':\n-    resolution: {integrity: sha512-rFjLXoHpRqxJqkSBXHuyt6bhyiIFnvLD9X2iPmCYlfpEkdTbrY1AXg4ZbF8UMO5LM7DAAZm/7vPYPO1TKTA7Sg==}\n+  '@rolldown/binding-openharmony-arm64@1.0.0-beta.39':\n+    resolution: {integrity: sha512-QCvN02VpE6zFYry0zAU+29D5+O9tJELNt+OjuCubilZdD/S8xFdho7qBJaa3YhFYyA9cReOMVH8Z8b3yWb4hcA==}\n     engines: {node: ^20.19.0 || >=22.12.0}\n     cpu: [arm64]\n     os: [openharmony]\n@@ -5571,8 +5579,8 @@ packages:\n     engines: {node: '>=14.0.0'}\n     cpu: [wasm32]\n \n-  '@rolldown/binding-wasm32-wasi@1.0.0-beta.37':\n-    resolution: {integrity: sha512-oQAe3lMaBGX6q0GSic0l3Obmd6/rX8R6eHLnRC8kyy/CvPLiCMV82MPGT8fxpPTo/ULFGrupSu2nV1zmOFBt/w==}\n+  '@rolldown/binding-wasm32-wasi@1.0.0-beta.39':\n+    resolution: {integrity: sha512-LFgshxApyBNiBHFVpun7tPrIQ4TvxW0f/endC5C4RzEHu7mxexBCQEkO5XrZ42Cr5DUY+ERNbkfNTUv+vVCaxQ==}\n     engines: {node: '>=14.0.0'}\n     cpu: [wasm32]\n \n@@ -5581,8 +5589,8 @@ packages:\n     cpu: [arm64]\n     os: [win32]\n \n-  '@rolldown/binding-win32-arm64-msvc@1.0.0-beta.37':\n-    resolution: {integrity: sha512-ucO6CiZhpkNRiVAk7ybvA9pZaMreCtfHej3BtJcBL5S3aYmp4h0g6TvaXLD5YRJx5sXobp/9A//xU4wPMul3Bg==}\n+  '@rolldown/binding-win32-arm64-msvc@1.0.0-beta.39':\n+    resolution: {integrity: sha512-Mykirawg+s1e0uzVSEFhUBTShvXrOghPnyuLYkCfw8gzy8bMYiJuxsAfcopzZIIAVOHeSblJoiA/e7gYFjg8HA==}\n     engines: {node: ^20.19.0 || >=22.12.0}\n     cpu: [arm64]\n     os: [win32]\n@@ -5592,8 +5600,8 @@ packages:\n     cpu: [ia32]\n     os: [win32]\n \n-  '@rolldown/binding-win32-ia32-msvc@1.0.0-beta.37':\n-    resolution: {integrity: sha512-Ya9DBWJe1EGHwil7ielI8CdE0ELCg6KyDvDQqIFllnTJEYJ1Rb74DK6mvlZo273qz6Mw8WrMm26urfDeZhCc3Q==}\n+  '@rolldown/binding-win32-ia32-msvc@1.0.0-beta.39':\n+    resolution: {integrity: sha512-4PQJfWx7mdzXbAa4y+3OSSo911BZyJ/Is4pJKiwcGUqtvY66MX7BqlNWMr9QAozArAGE2knDubLqCQwZpK631w==}\n     engines: {node: ^20.19.0 || >=22.12.0}\n     cpu: [ia32]\n     os: [win32]\n@@ -5603,8 +5611,8 @@ packages:\n     cpu: [x64]\n     os: [win32]\n \n-  '@rolldown/binding-win32-x64-msvc@1.0.0-beta.37':\n-    resolution: {integrity: sha512-r+RI+wMReoTIF/uXqQWJcD8xGWXzCzUyGdpLmQ8FC+MCyPHlkjEsFRv8OFIYI6HhiGAmbfWVYEGf+aeLJzkHGw==}\n+  '@rolldown/binding-win32-x64-msvc@1.0.0-beta.39':\n+    resolution: {integrity: sha512-0zmmPOWbFfp1g9ofieimHwhuclZMcib0HL52Q+JTRpOHChI2f83TtH3duKWtAaxqhLUndTr/Z5sxzb+G2FNL9g==}\n     engines: {node: ^20.19.0 || >=22.12.0}\n     cpu: [x64]\n     os: [win32]\n@@ -5615,8 +5623,8 @@ packages:\n   '@rolldown/pluginutils@1.0.0-beta.31':\n     resolution: {integrity: sha512-IaDZ9NhjOIOkYtm+hH0GX33h3iVZ2OeSUnFF0+7Z4+1GuKs4Kj5wK3+I2zNV9IPLfqV4XlwWif8SXrZNutxciQ==}\n \n-  '@rolldown/pluginutils@1.0.0-beta.37':\n-    resolution: {integrity: sha512-0taU1HpxFzrukvWIhLRI4YssJX2wOW5q1MxPXWztltsQ13TE51/larZIwhFdpyk7+K43TH7x6GJ8oEqAo+vDbA==}\n+  '@rolldown/pluginutils@1.0.0-beta.39':\n+    resolution: {integrity: sha512-GkTtNCV8ObWbq3LrJStPBv9jkRPct8WlwotVjx3aU0RwfH3LyheixWK9Zhaj22C4EQj/TJxYyetoX+uOn/MWKw==}\n \n   '@rollup/plugin-alias@5.1.1':\n     resolution: {integrity: sha512-PR9zDb+rOzkRb2VD+EuKB7UC41vU5DIwZ5qqCpk0KJudcWAyi8rvYOhS7+L5aZCspw1stTViLgN5v6FF1p5cgQ==}\n@@ -6092,8 +6100,8 @@ packages:\n     resolution: {integrity: sha512-1ibVeYUacxWYi9i0cf5efil6adJ9WRyZBLivgjs+AUpewx1F3xPi7gLgaASI2SmIQxPoCEjAsLAzKPgMJVgOUQ==}\n     engines: {node: 4.x || >=6.0.0}\n \n-  '@supabase/storage-js@2.10.4':\n-    resolution: {integrity: sha512-cvL02GarJVFcNoWe36VBybQqTVRq6wQSOCvTS64C+eyuxOruFIm1utZAY0xi2qKtHJO3EjKaj8iWJKySusDmAQ==}\n+  '@supabase/storage-js@2.12.1':\n+    resolution: {integrity: sha512-QWg3HV6Db2J81VQx0PqLq0JDBn4Q8B1FYn1kYcbla8+d5WDmTdwwMr+EJAxNOSs9W4mhKMv+EYCpCrTFlTj4VQ==}\n \n   '@svgdotjs/svg.draggable.js@3.0.6':\n     resolution: {integrity: sha512-7iJFm9lL3C40HQcqzEfezK2l+dW2CpoVY3b77KQGqc8GXWa6LhhmX5Ckv7alQfUXBuZbjpICZ+Dvq1czlGx7gA==}\n@@ -6161,6 +6169,9 @@ packages:\n   '@tybys/wasm-util@0.10.0':\n     resolution: {integrity: sha512-VyyPYFlOMNylG45GoAe0xDoLwWuowvf92F9kySqzYh8vmYm7D2u4iUJKa1tOUpS70Ku13ASrOkS4ScXFsTaCNQ==}\n \n+  '@tybys/wasm-util@0.10.1':\n+    resolution: {integrity: sha512-9tTaPJLSiejZKx+Bmog4uSubteqTvFrVrURwkmHixBo0G4seD0zUxp98E1DzUBJxLQ3NPwXrGKDiVjwx/DpPsg==}\n+\n   '@types/argparse@1.0.38':\n     resolution: {integrity: sha512-ebDJ9b0e702Yr7pWgB0jzm+CX4Srzz8RcXtLJDJB+BSccqMa36uyH/zUsSYao5+BD1ytv3k3rPYCq4mAE1hsXA==}\n \n@@ -11566,8 +11577,8 @@ packages:\n     resolution: {integrity: sha512-M2Q+RfG0FMJeSW3RSFTbvtjGVTcQpTQvN247D0EMSsPkpZFoinopR9oAnQiwgogQyzDuvKNnbyCbQQlmNAzSoQ==}\n     hasBin: true\n \n-  rolldown@1.0.0-beta.37:\n-    resolution: {integrity: sha512-KiTU6z1kHGaLvqaYjgsrv2LshHqNBn74waRZivlK8WbfN1obZeScVkQPKYunB66E/mxZWv/zyZlCv3xF2t0WOQ==}\n+  rolldown@1.0.0-beta.39:\n+    resolution: {integrity: sha512-05bTT0CJU9dvCRC0Uc4zwB79W5N9MV9OG/Inyx8KNE2pSrrApJoWxEEArW6rmjx113HIx5IreCoTjzLfgvXTdg==}\n     engines: {node: ^20.19.0 || >=22.12.0}\n     hasBin: true\n \n@@ -15011,16 +15022,32 @@ snapshots:\n       tslib: 2.8.1\n     optional: true\n \n+  '@emnapi/core@1.5.0':\n+    dependencies:\n+      '@emnapi/wasi-threads': 1.1.0\n+      tslib: 2.8.1\n+    optional: true\n+\n   '@emnapi/runtime@1.4.5':\n     dependencies:\n       tslib: 2.8.1\n     optional: true\n \n+  '@emnapi/runtime@1.5.0':\n+    dependencies:\n+      tslib: 2.8.1\n+    optional: true\n+\n   '@emnapi/wasi-threads@1.0.4':\n     dependencies:\n       tslib: 2.8.1\n     optional: true\n \n+  '@emnapi/wasi-threads@1.1.0':\n+    dependencies:\n+      tslib: 2.8.1\n+    optional: true\n+\n   '@esbuild/aix-ppc64@0.21.5':\n     optional: true\n \n@@ -16021,6 +16048,13 @@ snapshots:\n       '@tybys/wasm-util': 0.10.0\n     optional: true\n \n+  '@napi-rs/wasm-runtime@1.0.5':\n+    dependencies:\n+      '@emnapi/core': 1.5.0\n+      '@emnapi/runtime': 1.5.0\n+      '@tybys/wasm-util': 0.10.1\n+    optional: true\n+\n   '@ngneat/falso@8.0.2':\n     dependencies:\n       seedrandom: 3.0.5\n@@ -16097,11 +16131,9 @@ snapshots:\n \n   '@oxc-project/runtime@0.80.0': {}\n \n-  '@oxc-project/runtime@0.87.0': {}\n-\n   '@oxc-project/types@0.80.0': {}\n \n-  '@oxc-project/types@0.87.0': {}\n+  '@oxc-project/types@0.90.0': {}\n \n   '@paralleldrive/cuid2@2.2.2':\n     dependencies:\n@@ -17173,43 +17205,43 @@ snapshots:\n   '@rolldown/binding-android-arm64@1.0.0-beta.31':\n     optional: true\n \n-  '@rolldown/binding-android-arm64@1.0.0-beta.37':\n+  '@rolldown/binding-android-arm64@1.0.0-beta.39':\n     optional: true\n \n   '@rolldown/binding-darwin-arm64@1.0.0-beta.31':\n     optional: true\n \n-  '@rolldown/binding-darwin-arm64@1.0.0-beta.37':\n+  '@rolldown/binding-darwin-arm64@1.0.0-beta.39':\n     optional: true\n \n   '@rolldown/binding-darwin-x64@1.0.0-beta.31':\n     optional: true\n \n-  '@rolldown/binding-darwin-x64@1.0.0-beta.37':\n+  '@rolldown/binding-darwin-x64@1.0.0-beta.39':\n     optional: true\n \n   '@rolldown/binding-freebsd-x64@1.0.0-beta.31':\n     optional: true\n \n-  '@rolldown/binding-freebsd-x64@1.0.0-beta.37':\n+  '@rolldown/binding-freebsd-x64@1.0.0-beta.39':\n     optional: true\n \n   '@rolldown/binding-linux-arm-gnueabihf@1.0.0-beta.31':\n     optional: true\n \n-  '@rolldown/binding-linux-arm-gnueabihf@1.0.0-beta.37':\n+  '@rolldown/binding-linux-arm-gnueabihf@1.0.0-beta.39':\n     optional: true\n \n   '@rolldown/binding-linux-arm64-gnu@1.0.0-beta.31':\n     optional: true\n \n-  '@rolldown/binding-linux-arm64-gnu@1.0.0-beta.37':\n+  '@rolldown/binding-linux-arm64-gnu@1.0.0-beta.39':\n     optional: true\n \n   '@rolldown/binding-linux-arm64-musl@1.0.0-beta.31':\n     optional: true\n \n-  '@rolldown/binding-linux-arm64-musl@1.0.0-beta.37':\n+  '@rolldown/binding-linux-arm64-musl@1.0.0-beta.39':\n     optional: true\n \n   '@rolldown/binding-linux-arm64-ohos@1.0.0-beta.31':\n@@ -17218,16 +17250,16 @@ snapshots:\n   '@rolldown/binding-linux-x64-gnu@1.0.0-beta.31':\n     optional: true\n \n-  '@rolldown/binding-linux-x64-gnu@1.0.0-beta.37':\n+  '@rolldown/binding-linux-x64-gnu@1.0.0-beta.39':\n     optional: true\n \n   '@rolldown/binding-linux-x64-musl@1.0.0-beta.31':\n     optional: true\n \n-  '@rolldown/binding-linux-x64-musl@1.0.0-beta.37':\n+  '@rolldown/binding-linux-x64-musl@1.0.0-beta.39':\n     optional: true\n \n-  '@rolldown/binding-openharmony-arm64@1.0.0-beta.37':\n+  '@rolldown/binding-openharmony-arm64@1.0.0-beta.39':\n     optional: true\n \n   '@rolldown/binding-wasm32-wasi@1.0.0-beta.31':\n@@ -17235,34 +17267,34 @@ snapshots:\n       '@napi-rs/wasm-runtime': 1.0.3\n     optional: true\n \n-  '@rolldown/binding-wasm32-wasi@1.0.0-beta.37':\n+  '@rolldown/binding-wasm32-wasi@1.0.0-beta.39':\n     dependencies:\n-      '@napi-rs/wasm-runtime': 1.0.3\n+      '@napi-rs/wasm-runtime': 1.0.5\n     optional: true\n \n   '@rolldown/binding-win32-arm64-msvc@1.0.0-beta.31':\n     optional: true\n \n-  '@rolldown/binding-win32-arm64-msvc@1.0.0-beta.37':\n+  '@rolldown/binding-win32-arm64-msvc@1.0.0-beta.39':\n     optional: true\n \n   '@rolldown/binding-win32-ia32-msvc@1.0.0-beta.31':\n     optional: true\n \n-  '@rolldown/binding-win32-ia32-msvc@1.0.0-beta.37':\n+  '@rolldown/binding-win32-ia32-msvc@1.0.0-beta.39':\n     optional: true\n \n   '@rolldown/binding-win32-x64-msvc@1.0.0-beta.31':\n     optional: true\n \n-  '@rolldown/binding-win32-x64-msvc@1.0.0-beta.37':\n+  '@rolldown/binding-win32-x64-msvc@1.0.0-beta.39':\n     optional: true\n \n   '@rolldown/pluginutils@1.0.0-beta.29': {}\n \n   '@rolldown/pluginutils@1.0.0-beta.31': {}\n \n-  '@rolldown/pluginutils@1.0.0-beta.37': {}\n+  '@rolldown/pluginutils@1.0.0-beta.39': {}\n \n   '@rollup/plugin-alias@5.1.1(rollup@4.46.2)':\n     optionalDependencies:\n@@ -17806,7 +17838,7 @@ snapshots:\n     dependencies:\n       whatwg-url: 5.0.0\n \n-  '@supabase/storage-js@2.10.4':\n+  '@supabase/storage-js@2.12.1':\n     dependencies:\n       '@supabase/node-fetch': 2.6.15\n \n@@ -17874,6 +17906,11 @@ snapshots:\n       tslib: 2.8.1\n     optional: true\n \n+  '@tybys/wasm-util@0.10.1':\n+    dependencies:\n+      tslib: 2.8.1\n+    optional: true\n+\n   '@types/argparse@1.0.38': {}\n \n   '@types/async@3.2.24': {}\n@@ -23736,7 +23773,7 @@ snapshots:\n       glob: 11.0.3\n       package-json-from-dist: 1.0.1\n \n-  rolldown-plugin-dts@0.15.9(rolldown@1.0.0-beta.37)(typescript@5.8.3)(vue-tsc@3.0.5(typescript@5.8.3)):\n+  rolldown-plugin-dts@0.15.9(rolldown@1.0.0-beta.39)(typescript@5.8.3)(vue-tsc@3.0.5(typescript@5.8.3)):\n     dependencies:\n       '@babel/generator': 7.28.3\n       '@babel/parser': 7.28.3\n@@ -23746,7 +23783,7 @@ snapshots:\n       debug: 4.4.1(supports-color@5.5.0)\n       dts-resolver: 2.1.2\n       get-tsconfig: 4.10.1\n-      rolldown: 1.0.0-beta.37\n+      rolldown: 1.0.0-beta.39\n     optionalDependencies:\n       typescript: 5.8.3\n       vue-tsc: 3.0.5(typescript@5.8.3)\n@@ -23776,27 +23813,26 @@ snapshots:\n       '@rolldown/binding-win32-ia32-msvc': 1.0.0-beta.31\n       '@rolldown/binding-win32-x64-msvc': 1.0.0-beta.31\n \n-  rolldown@1.0.0-beta.37:\n+  rolldown@1.0.0-beta.39:\n     dependencies:\n-      '@oxc-project/runtime': 0.87.0\n-      '@oxc-project/types': 0.87.0\n-      '@rolldown/pluginutils': 1.0.0-beta.37\n+      '@oxc-project/types': 0.90.0\n+      '@rolldown/pluginutils': 1.0.0-beta.39\n       ansis: 4.1.0\n     optionalDependencies:\n-      '@rolldown/binding-android-arm64': 1.0.0-beta.37\n-      '@rolldown/binding-darwin-arm64': 1.0.0-beta.37\n-      '@rolldown/binding-darwin-x64': 1.0.0-beta.37\n-      '@rolldown/binding-freebsd-x64': 1.0.0-beta.37\n-      '@rolldown/binding-linux-arm-gnueabihf': 1.0.0-beta.37\n-      '@rolldown/binding-linux-arm64-gnu': 1.0.0-beta.37\n-      '@rolldown/binding-linux-arm64-musl': 1.0.0-beta.37\n-      '@rolldown/binding-linux-x64-gnu': 1.0.0-beta.37\n-      '@rolldown/binding-linux-x64-musl': 1.0.0-beta.37\n-      '@rolldown/binding-openharmony-arm64': 1.0.0-beta.37\n-      '@rolldown/binding-wasm32-wasi': 1.0.0-beta.37\n-      '@rolldown/binding-win32-arm64-msvc': 1.0.0-beta.37\n-      '@rolldown/binding-win32-ia32-msvc': 1.0.0-beta.37\n-      '@rolldown/binding-win32-x64-msvc': 1.0.0-beta.37\n+      '@rolldown/binding-android-arm64': 1.0.0-beta.39\n+      '@rolldown/binding-darwin-arm64': 1.0.0-beta.39\n+      '@rolldown/binding-darwin-x64': 1.0.0-beta.39\n+      '@rolldown/binding-freebsd-x64': 1.0.0-beta.39\n+      '@rolldown/binding-linux-arm-gnueabihf': 1.0.0-beta.39\n+      '@rolldown/binding-linux-arm64-gnu': 1.0.0-beta.39\n+      '@rolldown/binding-linux-arm64-musl': 1.0.0-beta.39\n+      '@rolldown/binding-linux-x64-gnu': 1.0.0-beta.39\n+      '@rolldown/binding-linux-x64-musl': 1.0.0-beta.39\n+      '@rolldown/binding-openharmony-arm64': 1.0.0-beta.39\n+      '@rolldown/binding-wasm32-wasi': 1.0.0-beta.39\n+      '@rolldown/binding-win32-arm64-msvc': 1.0.0-beta.39\n+      '@rolldown/binding-win32-ia32-msvc': 1.0.0-beta.39\n+      '@rolldown/binding-win32-x64-msvc': 1.0.0-beta.39\n \n   rollup-plugin-esbuild@6.2.1(esbuild@0.25.9)(rollup@4.46.2):\n     dependencies:\n@@ -25012,8 +25048,8 @@ snapshots:\n       diff: 8.0.2\n       empathic: 2.0.0\n       hookable: 5.5.3\n-      rolldown: 1.0.0-beta.37\n-      rolldown-plugin-dts: 0.15.9(rolldown@1.0.0-beta.37)(typescript@5.8.3)(vue-tsc@3.0.5(typescript@5.8.3))\n+      rolldown: 1.0.0-beta.39\n+      rolldown-plugin-dts: 0.15.9(rolldown@1.0.0-beta.39)(typescript@5.8.3)(vue-tsc@3.0.5(typescript@5.8.3))\n       semver: 7.7.2\n       tinyexec: 1.0.1\n       tinyglobby: 0.2.14\ndiff --git a/pnpm-workspace.yaml b/pnpm-workspace.yaml\nindex d05e4bd7af234..8aadb08a24e75 100644\n--- a/pnpm-workspace.yaml\n+++ b/pnpm-workspace.yaml\n@@ -70,7 +70,7 @@ catalog:\n   '@sinclair/typebox': 0.34.38\n   '@sindresorhus/slugify': 2.2.1\n   '@smithy/node-http-handler': 4.1.0\n-  '@supabase/storage-js': 2.10.4\n+  '@supabase/storage-js': 2.12.1\n   '@tinymce/tinymce-vue': 6.3.0\n   '@turf/meta': 7.2.0\n   '@tus/server': 1.10.2\n", "test_patch": "", "problem_statement": "## Scope\r\n\r\nWhat's changed:\r\n\r\n- Upgraded @supabase/storage-js from 2.10.4 to 2.12.1 to fix Node.js duplex option compatibility issues\r\n- Added proper error handling in DriverSupabase.write() method to catch and throw upload failures\r\n\r\n## Potential Risks / Drawbacks\r\n\r\n- Upload errors that were previously silent will now throw exceptions\r\n- New Supabase storage library version may introduce unforeseen compatibility issues\r\n\r\n## Tested Scenarios\r\n\r\n- File upload with valid Supabase configuration - uploads succeed and filename_disk is properly populated\r\n- File upload without duplex: 'half' throws an error during upload and has been caught before the stat call function.\r\n\r\n## Review Notes / Questions\r\n\r\n- I would like to verify that the new Supabase library version doesn't break any existing functionality in production environments\r\n- Special attention should be paid to dolor sit amet\r\n\r\n## Checklist\r\n\r\n- [x] Added or updated tests\r\n- [ ] Documentation PR created [here](https://github.com/directus/docs) or not required\r\n\r\n---\r\n\r\nFixes #25871 \r\n", "hints_text": "", "created_at": "2025-09-23T19:41:30Z", "pull_number": 25883, "test_files": ["packages/storage-driver-supabase/src/index.test.ts"], "code_files": ["packages/storage-driver-supabase/src/index.ts"], "title": "Fix Supabase storage driver file uploads and improve error handling", "additions": 0, "deletions": 0}
{"repo": "directus/directus", "instance_id": "directus__directus.pr_mirror.26234", "base_commit": "5b9c5809c77ad154774057d63857aa34afa8de6a", "patch": "diff --git a/.changeset/petite-beds-rhyme.md b/.changeset/petite-beds-rhyme.md\nnew file mode 100644\nindex 0000000000000..7a8d2d0dbb3c5\n--- /dev/null\n+++ b/.changeset/petite-beds-rhyme.md\n@@ -0,0 +1,5 @@\n+---\n+'@directus/utils': patch\n+---\n+\n+Preserved Error when passed to run-script operation\ndiff --git a/packages/utils/shared/sieve-functions.test.ts b/packages/utils/shared/sieve-functions.test.ts\nindex a07e33d126886..b753cc335c36d 100644\n--- a/packages/utils/shared/sieve-functions.test.ts\n+++ b/packages/utils/shared/sieve-functions.test.ts\n@@ -57,3 +57,26 @@ test('sieve nested array', () => {\n test('sieve date', () => {\n \texpect(sieveFunctions(new Date())).toEqual({});\n });\n+\n+test('sieve error', () => {\n+\tconst error = new Error('Test error message');\n+\tconst sieved = sieveFunctions(error);\n+\n+\texpect(sieved).toBe(error);\n+});\n+\n+test('sieve nested error in object', () => {\n+\tconst error = new Error('Nested error');\n+\n+\tconst obj = {\n+\t\tstatus: 'failed',\n+\t\terror: error,\n+\t\tfn: () => {},\n+\t};\n+\n+\tconst sieved = sieveFunctions(obj) as any;\n+\n+\texpect(sieved).toHaveProperty('status', obj.status);\n+\texpect(sieved.error).toBe(error);\n+\texpect(sieved.fn).toBe(undefined);\n+});\ndiff --git a/packages/utils/shared/sieve-functions.ts b/packages/utils/shared/sieve-functions.ts\nindex 995acab5039ca..bbfee79155bf9 100644\n--- a/packages/utils/shared/sieve-functions.ts\n+++ b/packages/utils/shared/sieve-functions.ts\n@@ -3,6 +3,8 @@ export function sieveFunctions(data: unknown): unknown {\n \t\treturn undefined;\n \t} else if (Array.isArray(data)) {\n \t\treturn data.map(sieveFunctions);\n+\t} else if (data instanceof Error) {\n+\t\treturn data;\n \t} else if (typeof data === 'object' && data !== null) {\n \t\treturn Object.fromEntries(Object.entries(data).map(([key, value]) => [key, sieveFunctions(value)]));\n \t}\n", "test_patch": "", "problem_statement": "## Scope\r\n\r\nWhat's changed:\r\n\r\n- Fixed `sieveFunctions` to preserve non-enumerable Error object properties (name, message, stack)\r\n- Error objects in run-script operations now retain all standard and custom properties\r\n\r\n## Potential Risks / Drawbacks:\r\n\r\n- None expected - this is a bug fix restoring the behavior before #25106\r\n\r\n## Tested Scenarios\r\n\r\n- Standard Error objects with name, message, stack properties\r\n- Error objects with custom properties (code, status, extensions)\r\n- Nested Error objects within data structures\r\n- Functions are still properly removed from data\r\n\r\n## Checklist\r\n\r\n- [X] Added or updated tests\r\n- [ ] Documentation PR created [here](https://github.com/directus/docs) or not required\r\n- [ ] OpenAPI package PR created [here](https://github.com/directus/openapi) or not required\r\n\r\n---\r\n\r\nFixes #26207 \r\n", "hints_text": "", "created_at": "2025-11-20T19:07:25Z", "pull_number": 26234, "test_files": ["packages/utils/shared/sieve-functions.test.ts"], "code_files": ["packages/utils/shared/sieve-functions.ts"], "title": "Preserve Error when passed to run-script operation", "additions": 0, "deletions": 0}
{"repo": "directus/directus", "instance_id": "directus__directus.pr_mirror.26247", "base_commit": "f74b2c1f76e595ce073870a076755bf62b6825ce", "patch": "diff --git a/.changeset/tall-sheep-write.md b/.changeset/tall-sheep-write.md\nnew file mode 100644\nindex 0000000000000..b6f9c707bc0c5\n--- /dev/null\n+++ b/.changeset/tall-sheep-write.md\n@@ -0,0 +1,5 @@\n+---\n+'@directus/api': patch\n+---\n+\n+Fixed missing accountability for `files.upload` when TUS is enabled\ndiff --git a/api/src/services/tus/server.test.ts b/api/src/services/tus/server.test.ts\nnew file mode 100644\nindex 0000000000000..12b2da13cd5b1\n--- /dev/null\n+++ b/api/src/services/tus/server.test.ts\n@@ -0,0 +1,198 @@\n+import type { Accountability, File, SchemaOverview } from '@directus/types';\n+import { afterEach, beforeEach, describe, expect, test, vi } from 'vitest';\n+import { createTusServer } from './server.js';\n+import emitter from '../../emitter.js';\n+import { ItemsService } from '../index.js';\n+import { extractMetadata } from '../files/lib/extract-metadata.js';\n+import getDatabase from '../../database/index.js';\n+import { getSchema } from '../../utils/get-schema.js';\n+\n+vi.mock('../../emitter.js', () => ({\n+\tdefault: {\n+\t\temitAction: vi.fn(),\n+\t},\n+}));\n+\n+vi.mock('../index.js', () => ({\n+\tItemsService: vi.fn(),\n+}));\n+\n+vi.mock('../files/lib/extract-metadata.js', () => ({\n+\textractMetadata: vi.fn(),\n+}));\n+\n+vi.mock('../../database/index.js', () => ({\n+\tdefault: vi.fn(),\n+}));\n+\n+vi.mock('../../utils/get-schema.js', () => ({\n+\tgetSchema: vi.fn(),\n+}));\n+\n+vi.mock('../../storage/index.js', () => ({\n+\tgetStorage: vi.fn().mockResolvedValue({\n+\t\tlocation: vi.fn().mockReturnValue({\n+\t\t\tread: vi.fn(),\n+\t\t\twrite: vi.fn(),\n+\t\t\tdelete: vi.fn(),\n+\t\t\tstat: vi.fn(),\n+\t\t\tcopy: vi.fn(),\n+\t\t\tmove: vi.fn(),\n+\t\t\tlist: vi.fn(),\n+\t\t\t$createMultipartUpload: vi.fn(),\n+\t\t\t$uploadPart: vi.fn(),\n+\t\t\t$completeMultipartUpload: vi.fn(),\n+\t\t\t$abortMultipartUpload: vi.fn(),\n+\t\t\t$listParts: vi.fn(),\n+\t\t}),\n+\t}),\n+}));\n+\n+vi.mock('@directus/storage', () => ({\n+\tsupportsTus: vi.fn().mockReturnValue(true),\n+}));\n+\n+vi.mock('@directus/env', () => ({\n+\tuseEnv: vi.fn().mockReturnValue({\n+\t\tSTORAGE_LOCATIONS: 'local',\n+\t\tPUBLIC_URL: 'http://localhost:8055',\n+\t\tCORS_ALLOWED_HEADERS: ['*'],\n+\t\tCORS_EXPOSED_HEADERS: ['*'],\n+\t}),\n+}));\n+\n+describe('createTusServer', () => {\n+\tlet mockSchema: SchemaOverview;\n+\tlet mockAccountability: Accountability;\n+\tlet mockDatabase: any;\n+\tlet mockItemsService: any;\n+\n+\tbeforeEach(() => {\n+\t\tmockSchema = {\n+\t\t\tcollections: {},\n+\t\t\trelations: [],\n+\t\t};\n+\n+\t\tmockAccountability = {\n+\t\t\trole: 'test-role',\n+\t\t\tuser: 'test-user-id',\n+\t\t} as Accountability;\n+\n+\t\tmockDatabase = {};\n+\n+\t\tmockItemsService = {\n+\t\t\treadByQuery: vi.fn(),\n+\t\t\treadOne: vi.fn(),\n+\t\t\tupdateOne: vi.fn(),\n+\t\t\tdeleteOne: vi.fn(),\n+\t\t};\n+\n+\t\tvi.mocked(getDatabase).mockReturnValue(mockDatabase);\n+\t\tvi.mocked(getSchema).mockResolvedValue(mockSchema);\n+\t\tvi.mocked(ItemsService).mockImplementation(() => mockItemsService);\n+\t\tvi.mocked(extractMetadata).mockResolvedValue({});\n+\t});\n+\n+\tafterEach(() => {\n+\t\tvi.clearAllMocks();\n+\t});\n+\n+\tdescribe('onUploadFinish', () => {\n+\t\ttest('should pass accountability to emitter.emitAction when accountability is provided (issue #26242)', async () => {\n+\t\t\tconst mockFile: Partial<File> = {\n+\t\t\t\tid: 'test-file-id',\n+\t\t\t\tstorage: 'local',\n+\t\t\t\tfilename_download: 'test.txt',\n+\t\t\t\ttus_id: 'upload-123',\n+\t\t\t\ttus_data: null,\n+\t\t\t};\n+\n+\t\t\tmockItemsService.readByQuery.mockResolvedValue([mockFile]);\n+\n+\t\t\tconst [server, _cleanup] = await createTusServer({\n+\t\t\t\tschema: mockSchema,\n+\t\t\t\taccountability: mockAccountability,\n+\t\t\t});\n+\n+\t\t\tconst onUploadFinish = (server as any).options.onUploadFinish;\n+\t\t\texpect(onUploadFinish).toBeDefined();\n+\n+\t\t\tawait onUploadFinish(\n+\t\t\t\t{},\n+\t\t\t\t{\n+\t\t\t\t\tid: 'upload-123',\n+\t\t\t\t\tmetadata: { id: 'test-file-id' },\n+\t\t\t\t},\n+\t\t\t);\n+\n+\t\t\texpect(emitter.emitAction).toHaveBeenCalledWith(\n+\t\t\t\t'files.upload',\n+\t\t\t\t{\n+\t\t\t\t\tpayload: {\n+\t\t\t\t\t\tid: 'test-file-id',\n+\t\t\t\t\t\tstorage: 'local',\n+\t\t\t\t\t\tfilename_download: 'test.txt',\n+\t\t\t\t\t\ttus_id: null,\n+\t\t\t\t\t\ttus_data: null,\n+\t\t\t\t\t},\n+\t\t\t\t\tkey: 'test-file-id',\n+\t\t\t\t\tcollection: 'directus_files',\n+\t\t\t\t},\n+\t\t\t\t{\n+\t\t\t\t\tschema: mockSchema,\n+\t\t\t\t\tdatabase: mockDatabase,\n+\t\t\t\t\taccountability: mockAccountability,\n+\t\t\t\t},\n+\t\t\t);\n+\t\t});\n+\n+\t\ttest('should pass null accountability to emitter.emitAction when accountability is not provided', async () => {\n+\t\t\tconst mockFile: Partial<File> = {\n+\t\t\t\tid: 'test-file-id',\n+\t\t\t\tstorage: 'local',\n+\t\t\t\tfilename_download: 'test.txt',\n+\t\t\t\ttus_id: 'upload-123',\n+\t\t\t\ttus_data: null,\n+\t\t\t};\n+\n+\t\t\tmockItemsService.readByQuery.mockResolvedValue([mockFile]);\n+\n+\t\t\tconst [server, _cleanup] = await createTusServer({\n+\t\t\t\tschema: mockSchema,\n+\t\t\t\taccountability: undefined,\n+\t\t\t});\n+\n+\t\t\tconst tusServer = server as any;\n+\t\t\tconst onUploadFinish = tusServer.options.onUploadFinish;\n+\n+\t\t\texpect(onUploadFinish).toBeDefined();\n+\n+\t\t\tconst mockUpload = {\n+\t\t\t\tid: 'upload-123',\n+\t\t\t\tmetadata: { id: 'test-file-id' },\n+\t\t\t};\n+\n+\t\t\tawait onUploadFinish({}, mockUpload);\n+\n+\t\t\texpect(emitter.emitAction).toHaveBeenCalledWith(\n+\t\t\t\t'files.upload',\n+\t\t\t\t{\n+\t\t\t\t\tpayload: {\n+\t\t\t\t\t\tid: 'test-file-id',\n+\t\t\t\t\t\tstorage: 'local',\n+\t\t\t\t\t\tfilename_download: 'test.txt',\n+\t\t\t\t\t\ttus_id: null,\n+\t\t\t\t\t\ttus_data: null,\n+\t\t\t\t\t},\n+\t\t\t\t\tkey: 'test-file-id',\n+\t\t\t\t\tcollection: 'directus_files',\n+\t\t\t\t},\n+\t\t\t\t{\n+\t\t\t\t\tschema: mockSchema,\n+\t\t\t\t\tdatabase: mockDatabase,\n+\t\t\t\t\taccountability: null,\n+\t\t\t\t},\n+\t\t\t);\n+\t\t});\n+\t});\n+});\ndiff --git a/api/src/services/tus/server.ts b/api/src/services/tus/server.ts\nindex 657bb26878934..5d921b738b263 100644\n--- a/api/src/services/tus/server.ts\n+++ b/api/src/services/tus/server.ts\n@@ -53,7 +53,7 @@ export async function createTusServer(context: Context): Promise<[Server, () =>\n \t\tdatastore: store,\n \t\tlocker: getTusLocker(),\n \t\t...(RESUMABLE_UPLOADS.MAX_SIZE !== null && { maxSize: RESUMABLE_UPLOADS.MAX_SIZE }),\n-\t\tasync onUploadFinish(req: any, upload) {\n+\t\tasync onUploadFinish(_req: any, upload) {\n \t\t\tconst schema = await getSchema();\n \n \t\t\tconst service = new ItemsService<File>('directus_files', {\n@@ -119,9 +119,9 @@ export async function createTusServer(context: Context): Promise<[Server, () =>\n \t\t\t\t\tcollection: 'directus_files',\n \t\t\t\t},\n \t\t\t\t{\n-\t\t\t\t\tdatabase: getDatabase(),\n \t\t\t\t\tschema,\n-\t\t\t\t\taccountability: req.accountability,\n+\t\t\t\t\tdatabase: getDatabase(),\n+\t\t\t\t\taccountability: context.accountability ?? null,\n \t\t\t\t},\n \t\t\t);\n \n", "test_patch": "", "problem_statement": "## Scope\r\n\r\nWhat's changed:\r\n\r\nAfter the `@tus/server` dependency update it looks like the Directus request object no longer gets properly propagated to its callback functions.\r\n\r\n- The `createTusServer` receives the proper request object containing `accountability`, `schema` and `token` from our middleware\r\n- But the `onUploadFinish` callback however seems to be lacking our custom properties listed above\r\n\r\nTo fix this issue I am using the `context` object provided to the `createTusServer` function as the data for emitting the event instead of relying on the `req` parameter of the callback.\r\n\r\n## Potential Risks / Drawbacks\r\n\r\n- Small fix i dont see many risks\r\n\r\n## Tested Scenarios\r\n\r\n- Lorem ipsum dolor sit amet\r\n- Consectetur adipiscing elit\r\n\r\n## Review Notes / Questions\r\n\r\n- I would like to lorem ipsum\r\n- Special attention should be paid to dolor sit amet\r\n\r\n## Checklist\r\n\r\n- [x] Added or updated tests\r\n\r\n---\r\n\r\nFixes #26242\r\n", "hints_text": "", "created_at": "2025-11-24T15:00:56Z", "pull_number": 26247, "test_files": ["api/src/services/tus/server.test.ts"], "code_files": ["api/src/services/tus/server.ts"], "title": "Fixed missing accountability for `files.upload` when TUS is enabled", "additions": 0, "deletions": 0}
{"repo": "directus/directus", "instance_id": "directus__directus.pr_mirror.26190", "base_commit": "f74b2c1f76e595ce073870a076755bf62b6825ce", "patch": "diff --git a/.changeset/mighty-facts-study.md b/.changeset/mighty-facts-study.md\nnew file mode 100644\nindex 0000000000000..587d0b24f2b72\n--- /dev/null\n+++ b/.changeset/mighty-facts-study.md\n@@ -0,0 +1,5 @@\n+---\n+'@directus/app': minor\n+---\n+\n+Added support for float intervals and min/max warnings for number inputs\n\\ No newline at end of file\ndiff --git a/app/src/components/__snapshots__/v-input.test.ts.snap b/app/src/components/__snapshots__/v-input.test.ts.snap\nindex 75084478e58ca..1163c8ad3a68b 100644\n--- a/app/src/components/__snapshots__/v-input.test.ts.snap\n+++ b/app/src/components/__snapshots__/v-input.test.ts.snap\n@@ -1,27 +1,12 @@\n // Vitest Snapshot v1, https://vitest.dev/guide/snapshot.html\n \n-exports[`Mount component 1`] = `\n-\"<div data-v-418390f4=\"\" class=\"v-input full-width\">\n-  <!--v-if-->\n-  <div data-v-418390f4=\"\" class=\"input\">\n-    <!--v-if-->\n-    <!--v-if--><input data-v-418390f4=\"\" autocomplete=\"off\" type=\"text\" step=\"1\" value=\"\">\n-    <!--v-if-->\n-    <!--v-if-->\n-    <!--v-if-->\n-    <!--v-if-->\n-  </div>\n-  <!--v-if-->\n-</div>\"\n-`;\n-\n-exports[`invalid warning > should appear for invalid input 1`] = `\n+exports[`inline warning > should appear for invalid input 1`] = `\n \"<div data-v-418390f4=\"\" class=\"v-input full-width invalid\">\n   <!--v-if-->\n   <div data-v-418390f4=\"\" class=\"input\">\n     <!--v-if-->\n     <!--v-if--><input data-v-418390f4=\"\" autocomplete=\"off\" type=\"number\" step=\"1\" value=\"\">\n-    <v-icon-stub data-v-418390f4=\"\" name=\"warning\" class=\"warning-invalid\"></v-icon-stub>\n+    <v-icon-stub data-v-418390f4=\"\" name=\"warning\" class=\"inline-warning\"></v-icon-stub>\n     <!--v-if--><span data-v-418390f4=\"\"><v-icon-stub data-v-418390f4=\"\" class=\"step-up\" name=\"keyboard_arrow_up\" tabindex=\"-1\" clickable=\"\" disabled=\"false\"></v-icon-stub><v-icon-stub data-v-418390f4=\"\" class=\"step-down\" name=\"keyboard_arrow_down\" tabindex=\"-1\" clickable=\"\" disabled=\"false\"></v-icon-stub></span>\n     <!--v-if-->\n   </div>\n@@ -29,7 +14,7 @@ exports[`invalid warning > should appear for invalid input 1`] = `\n </div>\"\n `;\n \n-exports[`invalid warning > should not appear for valid input 1`] = `\n+exports[`inline warning > should not appear for valid input 1`] = `\n \"<div data-v-418390f4=\"\" class=\"v-input full-width\">\n   <!--v-if-->\n   <div data-v-418390f4=\"\" class=\"input\">\ndiff --git a/app/src/components/v-input.test.ts b/app/src/components/v-input.test.ts\nindex 4734520815185..463291b6a1ba6 100644\n--- a/app/src/components/v-input.test.ts\n+++ b/app/src/components/v-input.test.ts\n@@ -1,28 +1,20 @@\n import { Focus } from '@/__utils__/focus';\n+import { Tooltip } from '@/__utils__/tooltip';\n import type { GlobalMountOptions } from '@/__utils__/types';\n-import { i18n } from '@/lang';\n import { mount } from '@vue/test-utils';\n import { afterEach, describe, expect, test, vi } from 'vitest';\n import VInput from './v-input.vue';\n+import { i18n } from '@/lang';\n \n const global: GlobalMountOptions = {\n \tstubs: ['v-icon'],\n \tplugins: [i18n],\n \tdirectives: {\n \t\tfocus: Focus,\n+\t\ttooltip: Tooltip,\n \t},\n };\n \n-test('Mount component', () => {\n-\texpect(VInput).toBeTruthy();\n-\n-\tconst wrapper = mount(VInput, {\n-\t\tglobal,\n-\t});\n-\n-\texpect(wrapper.html()).toMatchSnapshot();\n-});\n-\n test('modelValue prop', async () => {\n \tconst wrapper = mount(VInput, {\n \t\tprops: {\n@@ -262,7 +254,7 @@ describe('emitValue', () => {\n \t});\n });\n \n-describe('invalid warning', () => {\n+describe('inline warning', () => {\n \tafterEach(() => {\n \t\tvi.restoreAllMocks();\n \t});\n@@ -295,16 +287,18 @@ describe('invalid warning', () => {\n \t\tconst validitySpy = vi.spyOn(inputEl, 'validity', 'get').mockReturnValue({ ...validityMock, badInput: true });\n \n \t\texpect(inputEl.validity.badInput).toBe(true);\n-\t\texpect((wrapper.vm as any).isInvalidInput).toBe(false);\n+\t\texpect((wrapper.vm as any).isBadInput).toBe(false);\n \n \t\tawait input.trigger('input');\n \t\tawait wrapper.vm.$nextTick();\n \n-\t\texpect((wrapper.vm as any).isInvalidInput).toBe(true);\n+\t\texpect((wrapper.vm as any).isBadInput).toBe(true);\n \t\texpect(wrapper.find('.v-input.invalid').exists()).toBe(true);\n-\t\texpect(wrapper.find('v-icon-stub.warning-invalid').exists()).toBe(true);\n+\t\texpect(wrapper.find('v-icon-stub.inline-warning').exists()).toBe(true);\n \t\texpect(validitySpy).toHaveBeenCalledTimes(2);\n \n+\t\texpect((wrapper.vm as any).inlineWarning).toBe(i18n.global.t('not_a_number'));\n+\n \t\texpect(wrapper.html()).toMatchSnapshot();\n \t});\n \n@@ -322,16 +316,295 @@ describe('invalid warning', () => {\n \t\tconst validitySpy = vi.spyOn(inputEl, 'validity', 'get').mockReturnValue(validityMock);\n \n \t\texpect(inputEl.validity.badInput).toBe(false);\n-\t\texpect((wrapper.vm as any).isInvalidInput).toBe(false);\n+\t\texpect((wrapper.vm as any).isBadInput).toBe(false);\n \n \t\tawait input.trigger('input');\n \t\tawait wrapper.vm.$nextTick();\n \n-\t\texpect((wrapper.vm as any).isInvalidInput).toBe(false);\n+\t\texpect((wrapper.vm as any).isBadInput).toBe(false);\n \t\texpect(wrapper.find('.v-input.invalid').exists()).toBe(false);\n-\t\texpect(wrapper.find('v-icon-stub.warning-invalid').exists()).toBe(false);\n+\t\texpect(wrapper.find('v-icon-stub.inline-warning').exists()).toBe(false);\n \t\texpect(validitySpy).toHaveBeenCalledTimes(2);\n \n \t\texpect(wrapper.html()).toMatchSnapshot();\n \t});\n+\n+\ttest('should appear when value exceeds maximum', async () => {\n+\t\tconst wrapper = mount(VInput, {\n+\t\t\tprops: {\n+\t\t\t\ttype: 'number',\n+\t\t\t\tmodelValue: 15,\n+\t\t\t\tmin: 0,\n+\t\t\t\tmax: 10,\n+\t\t\t\tinteger: true,\n+\t\t\t},\n+\t\t\tglobal,\n+\t\t});\n+\n+\t\tawait wrapper.vm.$nextTick();\n+\n+\t\texpect((wrapper.vm as any).inlineWarning).toBeDefined();\n+\t\texpect(wrapper.find('v-icon-stub.inline-warning').exists()).toBe(true);\n+\t\texpect((wrapper.vm as any).inlineWarning).toBe(i18n.global.t('invalid_range_max', { value: 10 }));\n+\t});\n+\n+\ttest('should appear when value is below minimum', async () => {\n+\t\tconst wrapper = mount(VInput, {\n+\t\t\tprops: {\n+\t\t\t\ttype: 'number',\n+\t\t\t\tmodelValue: -5,\n+\t\t\t\tmin: 0,\n+\t\t\t\tmax: 10,\n+\t\t\t\tinteger: true,\n+\t\t\t},\n+\t\t\tglobal,\n+\t\t});\n+\n+\t\tawait wrapper.vm.$nextTick();\n+\n+\t\texpect((wrapper.vm as any).inlineWarning).toBeDefined();\n+\t\texpect(wrapper.find('v-icon-stub.inline-warning').exists()).toBe(true);\n+\t\texpect((wrapper.vm as any).inlineWarning).toBe(i18n.global.t('invalid_range_min', { value: 0 }));\n+\t});\n+\n+\ttest('should not appear when value is within range', async () => {\n+\t\tconst wrapper = mount(VInput, {\n+\t\t\tprops: {\n+\t\t\t\ttype: 'number',\n+\t\t\t\tmodelValue: 5,\n+\t\t\t\tmin: 0,\n+\t\t\t\tmax: 10,\n+\t\t\t\tinteger: true,\n+\t\t\t},\n+\t\t\tglobal,\n+\t\t});\n+\n+\t\tawait wrapper.vm.$nextTick();\n+\n+\t\texpect((wrapper.vm as any).inlineWarning).toBeUndefined();\n+\t\texpect(wrapper.find('v-icon-stub.inline-warning').exists()).toBe(false);\n+\t});\n+\n+\ttest('should work with decimal values for float type', async () => {\n+\t\tconst wrapper = mount(VInput, {\n+\t\t\tprops: {\n+\t\t\t\ttype: 'number',\n+\t\t\t\tmodelValue: 10.5,\n+\t\t\t\tmin: 0.5,\n+\t\t\t\tmax: 10,\n+\t\t\t\tfloat: true,\n+\t\t\t},\n+\t\t\tglobal,\n+\t\t});\n+\n+\t\tawait wrapper.vm.$nextTick();\n+\n+\t\texpect((wrapper.vm as any).inlineWarning).toBeDefined();\n+\t\texpect(wrapper.find('v-icon-stub.inline-warning').exists()).toBe(true);\n+\t\texpect((wrapper.vm as any).inlineWarning).toBe(i18n.global.t('invalid_range_max', { value: 10 }));\n+\t});\n+\n+\ttest('should show invalid_input key for non-number type', async () => {\n+\t\tconst wrapper = mount(VInput, {\n+\t\t\tprops: {\n+\t\t\t\ttype: 'text',\n+\t\t\t},\n+\t\t\tglobal,\n+\t\t});\n+\n+\t\tconst input = wrapper.find('input');\n+\t\tconst inputEl = input.element as HTMLInputElement;\n+\n+\t\tvi.spyOn(inputEl, 'validity', 'get').mockReturnValue({\n+\t\t\tbadInput: true,\n+\t\t} as ValidityState);\n+\n+\t\tawait input.trigger('input');\n+\t\tawait wrapper.vm.$nextTick();\n+\n+\t\texpect((wrapper.vm as any).inlineWarning).toBe(i18n.global.t('invalid_input'));\n+\t});\n+\n+\ttest('useInvalidInput takes priority over useInvalidRange', async () => {\n+\t\tconst wrapper = mount(VInput, {\n+\t\t\tprops: {\n+\t\t\t\ttype: 'number',\n+\t\t\t\tmodelValue: 15,\n+\t\t\t\tmin: 0,\n+\t\t\t\tmax: 10,\n+\t\t\t\tinteger: true,\n+\t\t\t},\n+\t\t\tglobal,\n+\t\t});\n+\n+\t\tconst input = wrapper.find('input');\n+\t\tconst inputEl = input.element as HTMLInputElement;\n+\n+\t\tvi.spyOn(inputEl, 'validity', 'get').mockReturnValue({\n+\t\t\tbadInput: true,\n+\t\t} as ValidityState);\n+\n+\t\tawait input.trigger('input');\n+\t\tawait wrapper.vm.$nextTick();\n+\n+\t\texpect((wrapper.vm as any).isBadInput).toBe(true);\n+\t\texpect(wrapper.find('.v-input.invalid').exists()).toBe(true);\n+\t});\n+});\n+\n+describe('step controls', () => {\n+\ttest('isStepUpAllowed should work with integer values', async () => {\n+\t\tconst wrapper = mount(VInput, {\n+\t\t\tprops: {\n+\t\t\t\ttype: 'number',\n+\t\t\t\tmodelValue: 5,\n+\t\t\t\tmax: 10,\n+\t\t\t\tinteger: true,\n+\t\t\t},\n+\t\t\tglobal,\n+\t\t});\n+\n+\t\texpect((wrapper.vm as any).isStepUpAllowed).toBe(true);\n+\t});\n+\n+\ttest('isStepUpAllowed should work with float values', async () => {\n+\t\tconst wrapper = mount(VInput, {\n+\t\t\tprops: {\n+\t\t\t\ttype: 'number',\n+\t\t\t\tmodelValue: 5.5,\n+\t\t\t\tmax: 10,\n+\t\t\t\tfloat: true,\n+\t\t\t},\n+\t\t\tglobal,\n+\t\t});\n+\n+\t\texpect((wrapper.vm as any).isStepUpAllowed).toBe(true);\n+\t});\n+\n+\ttest('isStepUpAllowed should be false when at max', async () => {\n+\t\tconst wrapper = mount(VInput, {\n+\t\t\tprops: {\n+\t\t\t\ttype: 'number',\n+\t\t\t\tmodelValue: 10,\n+\t\t\t\tmax: 10,\n+\t\t\t\tinteger: true,\n+\t\t\t},\n+\t\t\tglobal,\n+\t\t});\n+\n+\t\texpect((wrapper.vm as any).isStepUpAllowed).toBe(false);\n+\t});\n+\n+\ttest('isStepUpAllowed should be false when exceeding max', async () => {\n+\t\tconst wrapper = mount(VInput, {\n+\t\t\tprops: {\n+\t\t\t\ttype: 'number',\n+\t\t\t\tmodelValue: 10.5,\n+\t\t\t\tmax: 10,\n+\t\t\t\tfloat: true,\n+\t\t\t},\n+\t\t\tglobal,\n+\t\t});\n+\n+\t\texpect((wrapper.vm as any).isStepUpAllowed).toBe(false);\n+\t});\n+\n+\ttest('isStepDownAllowed should work with integer values', async () => {\n+\t\tconst wrapper = mount(VInput, {\n+\t\t\tprops: {\n+\t\t\t\ttype: 'number',\n+\t\t\t\tmodelValue: 5,\n+\t\t\t\tmin: 0,\n+\t\t\t\tinteger: true,\n+\t\t\t},\n+\t\t\tglobal,\n+\t\t});\n+\n+\t\texpect((wrapper.vm as any).isStepDownAllowed).toBe(true);\n+\t});\n+\n+\ttest('isStepDownAllowed should work with float values', async () => {\n+\t\tconst wrapper = mount(VInput, {\n+\t\t\tprops: {\n+\t\t\t\ttype: 'number',\n+\t\t\t\tmodelValue: 5.5,\n+\t\t\t\tmin: 0,\n+\t\t\t\tfloat: true,\n+\t\t\t},\n+\t\t\tglobal,\n+\t\t});\n+\n+\t\texpect((wrapper.vm as any).isStepDownAllowed).toBe(true);\n+\t});\n+\n+\ttest('isStepDownAllowed should be false when at min', async () => {\n+\t\tconst wrapper = mount(VInput, {\n+\t\t\tprops: {\n+\t\t\t\ttype: 'number',\n+\t\t\t\tmodelValue: 0,\n+\t\t\t\tmin: 0,\n+\t\t\t\tinteger: true,\n+\t\t\t},\n+\t\t\tglobal,\n+\t\t});\n+\n+\t\texpect((wrapper.vm as any).isStepDownAllowed).toBe(false);\n+\t});\n+\n+\ttest('isStepDownAllowed should be false when below min', async () => {\n+\t\tconst wrapper = mount(VInput, {\n+\t\t\tprops: {\n+\t\t\t\ttype: 'number',\n+\t\t\t\tmodelValue: -0.5,\n+\t\t\t\tmin: 0,\n+\t\t\t\tfloat: true,\n+\t\t\t},\n+\t\t\tglobal,\n+\t\t});\n+\n+\t\texpect((wrapper.vm as any).isStepDownAllowed).toBe(false);\n+\t});\n+\n+\ttest('isStepUpAllowed should be true when no max is set', async () => {\n+\t\tconst wrapper = mount(VInput, {\n+\t\t\tprops: {\n+\t\t\t\ttype: 'number',\n+\t\t\t\tmodelValue: 100,\n+\t\t\t\tinteger: true,\n+\t\t\t},\n+\t\t\tglobal,\n+\t\t});\n+\n+\t\texpect((wrapper.vm as any).isStepUpAllowed).toBe(true);\n+\t});\n+\n+\ttest('isStepDownAllowed should be true when no min is set', async () => {\n+\t\tconst wrapper = mount(VInput, {\n+\t\t\tprops: {\n+\t\t\t\ttype: 'number',\n+\t\t\t\tmodelValue: -100,\n+\t\t\t\tinteger: true,\n+\t\t\t},\n+\t\t\tglobal,\n+\t\t});\n+\n+\t\texpect((wrapper.vm as any).isStepDownAllowed).toBe(true);\n+\t});\n+\n+\ttest('step controls should be disabled when input is disabled', async () => {\n+\t\tconst wrapper = mount(VInput, {\n+\t\t\tprops: {\n+\t\t\t\ttype: 'number',\n+\t\t\t\tmodelValue: 5,\n+\t\t\t\tmin: 0,\n+\t\t\t\tmax: 10,\n+\t\t\t\tdisabled: true,\n+\t\t\t\tinteger: true,\n+\t\t\t},\n+\t\t\tglobal,\n+\t\t});\n+\n+\t\texpect((wrapper.vm as any).isStepUpAllowed).toBe(false);\n+\t\texpect((wrapper.vm as any).isStepDownAllowed).toBe(false);\n+\t});\n });\ndiff --git a/app/src/components/v-input.vue b/app/src/components/v-input.vue\nindex e5d21d5fd2a9d..b9bbd6a1ca4db 100644\n--- a/app/src/components/v-input.vue\n+++ b/app/src/components/v-input.vue\n@@ -1,7 +1,7 @@\n <script setup lang=\"ts\">\n import { keyMap, systemKeys } from '@/composables/use-shortcut';\n import slugify from '@sindresorhus/slugify';\n-import { omit } from 'lodash';\n+import { isNil, omit } from 'lodash';\n import { computed, ref, useAttrs } from 'vue';\n import { useI18n } from 'vue-i18n';\n \n@@ -114,20 +114,20 @@ const classes = computed(() => [\n \t\t'has-click': props.clickable,\n \t\tdisabled: props.disabled,\n \t\tsmall: props.small,\n-\t\tinvalid: isInvalidInput.value,\n+\t\tinvalid: isBadInput.value,\n \t},\n \t...((attrs.class || '') as string).split(' '),\n ]);\n \n const isStepUpAllowed = computed(() => {\n-\treturn props.disabled === false && (props.max === undefined || parseInt(String(props.modelValue), 10) < props.max);\n+\treturn props.disabled === false && (props.max === undefined || Number(props.modelValue) < props.max);\n });\n \n const isStepDownAllowed = computed(() => {\n-\treturn props.disabled === false && (props.min === undefined || parseInt(String(props.modelValue), 10) > props.min);\n+\treturn props.disabled === false && (props.min === undefined || Number(props.modelValue) > props.min);\n });\n \n-const { isInvalidInput, tooltipInvalid, setInvalidInput } = useInvalidInput();\n+const { isBadInput, setInvalidInput, inlineWarning } = useInlineWarning();\n \n function onInput(event: InputEvent) {\n \tconst target = event.target as HTMLInputElement;\n@@ -291,15 +291,37 @@ function stepDown() {\n \t}\n }\n \n-function useInvalidInput() {\n-\tconst isInvalidInput = ref(false);\n-\tconst tooltipInvalid = computed(() => t(props.type === 'number' ? 'not_a_number' : 'invalid_input'));\n+function useInlineWarning() {\n+\tconst isBadInput = ref(false);\n \n-\treturn { isInvalidInput, tooltipInvalid, setInvalidInput };\n+\tconst badInputWarning = computed(() => {\n+\t\tif (!isBadInput.value) return undefined;\n+\t\treturn t(props.type === 'number' ? 'not_a_number' : 'invalid_input');\n+\t});\n+\n+\tconst invalidRangeWarning = computed(() => {\n+\t\tif (isNil(props.modelValue)) return undefined;\n+\n+\t\tconst modelValue = Number(props.modelValue);\n+\n+\t\tif (props.min !== undefined && modelValue < props.min) {\n+\t\t\treturn t('invalid_range_min', { value: props.min });\n+\t\t}\n+\n+\t\tif (props.max !== undefined && modelValue > props.max) {\n+\t\t\treturn t('invalid_range_max', { value: props.max });\n+\t\t}\n+\n+\t\treturn undefined;\n+\t});\n+\n+\tconst inlineWarning = computed(() => badInputWarning.value ?? invalidRangeWarning.value);\n+\n+\treturn { isBadInput, setInvalidInput, inlineWarning };\n \n \tfunction setInvalidInput(target: HTMLInputElement) {\n \t\t// When the input\u2019s validity.badInput property is true (e.g., due to invalid user input like non-numeric characters in a number field), the input event\u2019s target.value will be empty even if we see a value in the input field. This means we can\u2019t sanitize the input value in the input event handler.\n-\t\tisInvalidInput.value = target.validity.badInput;\n+\t\tisBadInput.value = target.validity.badInput;\n \t}\n }\n </script>\n@@ -333,7 +355,7 @@ function useInvalidInput() {\n \t\t\t\t\t@keydown.enter=\"$emit('keydown:enter', $event)\"\n \t\t\t\t/>\n \t\t\t</slot>\n-\t\t\t<v-icon v-if=\"isInvalidInput\" v-tooltip=\"tooltipInvalid\" name=\"warning\" class=\"warning-invalid\" />\n+\t\t\t<v-icon v-if=\"inlineWarning\" v-tooltip=\"inlineWarning\" name=\"warning\" class=\"inline-warning\" />\n \t\t\t<span v-if=\"suffix\" class=\"suffix\">{{ suffix }}</span>\n \t\t\t<span v-if=\"type === 'number' && !hideArrows && !nonEditable\">\n \t\t\t\t<v-icon\n@@ -560,7 +582,7 @@ function useInvalidInput() {\n \t\tcolor: var(--theme--foreground-subdued);\n \t}\n \n-\t.warning-invalid {\n+\t.inline-warning {\n \t\t--v-icon-color: var(--theme--warning);\n \n \t\tmargin-inline-end: 8px;\ndiff --git a/app/src/interfaces/input/index.test.ts b/app/src/interfaces/input/index.test.ts\nnew file mode 100644\nindex 0000000000000..87807857c09b5\n--- /dev/null\n+++ b/app/src/interfaces/input/index.test.ts\n@@ -0,0 +1,153 @@\n+import { describe, expect, test } from 'vitest';\n+import type { ExtensionOptionsContext } from '@directus/extensions';\n+import config from './index';\n+\n+type OptionsFunction = (context: Partial<ExtensionOptionsContext>) => unknown;\n+\n+describe('input interface options', () => {\n+\tdescribe('numeric field types', () => {\n+\t\ttest('returns float type for min/max/step when field is float', () => {\n+\t\t\tconst field = {\n+\t\t\t\ttype: 'float' as const,\n+\t\t\t};\n+\n+\t\t\texpect(typeof config.options).toBe('function');\n+\t\t\tconst options = (config.options as OptionsFunction)({ field });\n+\n+\t\t\texpect(options).toBeDefined();\n+\t\t\texpect(Array.isArray(options)).toBe(true);\n+\n+\t\t\tconst stepOption = (options as any[]).find((opt) => opt.field === 'step');\n+\t\t\texpect(stepOption).toBeDefined();\n+\t\t\texpect(stepOption.type).toBe('float');\n+\n+\t\t\tconst minOption = (options as any[]).find((opt) => opt.field === 'min');\n+\t\t\texpect(minOption).toBeDefined();\n+\t\t\texpect(minOption.type).toBe('float');\n+\n+\t\t\tconst maxOption = (options as any[]).find((opt) => opt.field === 'max');\n+\t\t\texpect(maxOption).toBeDefined();\n+\t\t\texpect(maxOption.type).toBe('float');\n+\t\t});\n+\n+\t\ttest('returns integer type for min/max/step when field is integer', () => {\n+\t\t\tconst field = {\n+\t\t\t\ttype: 'integer' as const,\n+\t\t\t};\n+\n+\t\t\texpect(typeof config.options).toBe('function');\n+\t\t\tconst options = (config.options as OptionsFunction)({ field });\n+\n+\t\t\texpect(options).toBeDefined();\n+\t\t\texpect(Array.isArray(options)).toBe(true);\n+\n+\t\t\tconst stepOption = (options as any[]).find((opt) => opt.field === 'step');\n+\t\t\texpect(stepOption).toBeDefined();\n+\t\t\texpect(stepOption.type).toBe('integer');\n+\n+\t\t\tconst minOption = (options as any[]).find((opt) => opt.field === 'min');\n+\t\t\texpect(minOption).toBeDefined();\n+\t\t\texpect(minOption.type).toBe('integer');\n+\n+\t\t\tconst maxOption = (options as any[]).find((opt) => opt.field === 'max');\n+\t\t\texpect(maxOption).toBeDefined();\n+\t\t\texpect(maxOption.type).toBe('integer');\n+\t\t});\n+\n+\t\ttest('has default step value of 1 for numeric types', () => {\n+\t\t\tconst floatField = {\n+\t\t\t\ttype: 'float' as const,\n+\t\t\t};\n+\n+\t\t\tconst integerField = {\n+\t\t\t\ttype: 'integer' as const,\n+\t\t\t\tfield: 'test',\n+\t\t\t};\n+\n+\t\t\texpect(typeof config.options).toBe('function');\n+\t\t\tconst floatOptions = (config.options as OptionsFunction)({ field: floatField });\n+\t\t\tconst integerOptions = (config.options as OptionsFunction)({ field: integerField });\n+\n+\t\t\texpect(floatOptions).toBeDefined();\n+\t\t\texpect(integerOptions).toBeDefined();\n+\n+\t\t\tconst floatStepOption = (floatOptions as any[]).find((opt) => opt.field === 'step');\n+\t\t\tconst integerStepOption = (integerOptions as any[]).find((opt) => opt.field === 'step');\n+\n+\t\t\texpect(floatStepOption.schema.default_value).toBe(1);\n+\t\t\texpect(integerStepOption.schema.default_value).toBe(1);\n+\t\t});\n+\t});\n+\n+\tdescribe('text field types', () => {\n+\t\ttest('returns textOptions for string field', () => {\n+\t\t\tconst field = {\n+\t\t\t\ttype: 'string' as const,\n+\t\t\t\tfield: 'test',\n+\t\t\t};\n+\n+\t\t\texpect(typeof config.options).toBe('function');\n+\t\t\tconst options = (config.options as OptionsFunction)({ field });\n+\n+\t\t\texpect(options).toBeDefined();\n+\t\t\texpect(options).toHaveProperty('standard');\n+\t\t\texpect(options).toHaveProperty('advanced');\n+\t\t});\n+\n+\t\ttest('returns textOptions for text field', () => {\n+\t\t\tconst field = {\n+\t\t\t\ttype: 'text' as const,\n+\t\t\t\tfield: 'test',\n+\t\t\t};\n+\n+\t\t\texpect(typeof config.options).toBe('function');\n+\t\t\tconst options = (config.options as OptionsFunction)({ field });\n+\n+\t\t\texpect(options).toBeDefined();\n+\t\t\texpect(options).toHaveProperty('standard');\n+\t\t\texpect(options).toHaveProperty('advanced');\n+\t\t});\n+\n+\t\ttest('returns textOptions for uuid field', () => {\n+\t\t\tconst field = {\n+\t\t\t\ttype: 'uuid' as const,\n+\t\t\t\tfield: 'test',\n+\t\t\t};\n+\n+\t\t\texpect(typeof config.options).toBe('function');\n+\t\t\tconst options = (config.options as OptionsFunction)({ field });\n+\n+\t\t\texpect(options).toBeDefined();\n+\t\t\texpect(options).toHaveProperty('standard');\n+\t\t\texpect(options).toHaveProperty('advanced');\n+\t\t});\n+\n+\t\ttest('returns textOptions for decimal field', () => {\n+\t\t\tconst field = {\n+\t\t\t\ttype: 'decimal' as const,\n+\t\t\t\tfield: 'test',\n+\t\t\t};\n+\n+\t\t\texpect(typeof config.options).toBe('function');\n+\t\t\tconst options = (config.options as OptionsFunction)({ field });\n+\n+\t\t\texpect(options).toBeDefined();\n+\t\t\texpect(options).toHaveProperty('standard');\n+\t\t\texpect(options).toHaveProperty('advanced');\n+\t\t});\n+\n+\t\ttest('returns textOptions for bigInteger field', () => {\n+\t\t\tconst field = {\n+\t\t\t\ttype: 'bigInteger' as const,\n+\t\t\t\tfield: 'test',\n+\t\t\t};\n+\n+\t\t\texpect(typeof config.options).toBe('function');\n+\t\t\tconst options = (config.options as OptionsFunction)({ field });\n+\n+\t\t\texpect(options).toBeDefined();\n+\t\t\texpect(options).toHaveProperty('standard');\n+\t\t\texpect(options).toHaveProperty('advanced');\n+\t\t});\n+\t});\n+});\ndiff --git a/app/src/interfaces/input/index.ts b/app/src/interfaces/input/index.ts\nindex d4330a9776468..a89463d5a6da2 100644\n--- a/app/src/interfaces/input/index.ts\n+++ b/app/src/interfaces/input/index.ts\n@@ -146,7 +146,7 @@ export default defineInterface({\n \t\t\t{\n \t\t\t\tfield: 'min',\n \t\t\t\tname: '$t:interfaces.input.minimum_value',\n-\t\t\t\ttype: 'integer',\n+\t\t\t\ttype: field.type,\n \t\t\t\tmeta: {\n \t\t\t\t\twidth: 'half',\n \t\t\t\t\tinterface: 'input',\n@@ -155,7 +155,7 @@ export default defineInterface({\n \t\t\t{\n \t\t\t\tfield: 'max',\n \t\t\t\tname: '$t:interfaces.input.maximum_value',\n-\t\t\t\ttype: 'integer',\n+\t\t\t\ttype: field.type,\n \t\t\t\tmeta: {\n \t\t\t\t\twidth: 'half',\n \t\t\t\t\tinterface: 'input',\n@@ -164,7 +164,7 @@ export default defineInterface({\n \t\t\t{\n \t\t\t\tfield: 'step',\n \t\t\t\tname: '$t:interfaces.input.step_interval',\n-\t\t\t\ttype: 'integer',\n+\t\t\t\ttype: field.type,\n \t\t\t\tmeta: {\n \t\t\t\t\twidth: 'half',\n \t\t\t\t\tinterface: 'input',\ndiff --git a/app/src/interfaces/input/input.test.ts b/app/src/interfaces/input/input.test.ts\nnew file mode 100644\nindex 0000000000000..2973a8d2155e4\n--- /dev/null\n+++ b/app/src/interfaces/input/input.test.ts\n@@ -0,0 +1,293 @@\n+import { mount } from '@vue/test-utils';\n+import { beforeEach, describe, expect, test, vi } from 'vitest';\n+import InputInterface from './input.vue';\n+\n+const mountOptions = {\n+\tglobal: {\n+\t\tstubs: {\n+\t\t\t'v-input': {\n+\t\t\t\tname: 'v-input',\n+\t\t\t\tprops: ['modelValue', 'type', 'min', 'max', 'step', 'placeholder', 'disabled', 'trim', 'integer', 'float'],\n+\t\t\t\ttemplate: '<input />',\n+\t\t\t\temits: ['update:model-value'],\n+\t\t\t},\n+\t\t\t'v-icon': {\n+\t\t\t\ttemplate: '<span><slot /></span>',\n+\t\t\t},\n+\t\t},\n+\t},\n+};\n+\n+describe('input interface', () => {\n+\tlet wrapper: any;\n+\n+\tbeforeEach(() => {\n+\t\tvi.clearAllMocks();\n+\t});\n+\n+\ttest('interface mounts', () => {\n+\t\texpect(() => {\n+\t\t\twrapper = mount(InputInterface, {\n+\t\t\t\t...mountOptions,\n+\t\t\t\tprops: {\n+\t\t\t\t\tvalue: 'test',\n+\t\t\t\t\ttype: 'string',\n+\t\t\t\t},\n+\t\t\t});\n+\t\t}).not.toThrow();\n+\n+\t\texpect(wrapper.exists()).toBe(true);\n+\t});\n+\n+\tdescribe('type handling', () => {\n+\t\ttest('sets inputType to \"number\" for integer type', () => {\n+\t\t\twrapper = mount(InputInterface, {\n+\t\t\t\t...mountOptions,\n+\t\t\t\tprops: {\n+\t\t\t\t\tvalue: 42,\n+\t\t\t\t\ttype: 'integer',\n+\t\t\t\t},\n+\t\t\t});\n+\n+\t\t\tconst input = wrapper.findComponent({ name: 'v-input' });\n+\t\t\texpect(input.props('type')).toBe('number');\n+\t\t});\n+\n+\t\ttest('sets inputType to \"number\" for float type', () => {\n+\t\t\twrapper = mount(InputInterface, {\n+\t\t\t\t...mountOptions,\n+\t\t\t\tprops: {\n+\t\t\t\t\tvalue: 3.14,\n+\t\t\t\t\ttype: 'float',\n+\t\t\t\t},\n+\t\t\t});\n+\n+\t\t\tconst input = wrapper.findComponent({ name: 'v-input' });\n+\t\t\texpect(input.props('type')).toBe('number');\n+\t\t});\n+\n+\t\ttest('sets inputType to \"text\" for string type', () => {\n+\t\t\twrapper = mount(InputInterface, {\n+\t\t\t\t...mountOptions,\n+\t\t\t\tprops: {\n+\t\t\t\t\tvalue: 'test',\n+\t\t\t\t\ttype: 'string',\n+\t\t\t\t},\n+\t\t\t});\n+\n+\t\t\tconst input = wrapper.findComponent({ name: 'v-input' });\n+\t\t\texpect(input.props('type')).toBe('text');\n+\t\t});\n+\n+\t\ttest('sets inputType to \"password\" when masked is true', () => {\n+\t\t\twrapper = mount(InputInterface, {\n+\t\t\t\t...mountOptions,\n+\t\t\t\tprops: {\n+\t\t\t\t\tvalue: 'secret',\n+\t\t\t\t\ttype: 'string',\n+\t\t\t\t\tmasked: true,\n+\t\t\t\t},\n+\t\t\t});\n+\n+\t\t\tconst input = wrapper.findComponent({ name: 'v-input' });\n+\t\t\texpect(input.props('type')).toBe('password');\n+\t\t});\n+\t});\n+\n+\tdescribe('integer and float props', () => {\n+\t\ttest('sets integer prop to true for integer type', () => {\n+\t\t\twrapper = mount(InputInterface, {\n+\t\t\t\t...mountOptions,\n+\t\t\t\tprops: {\n+\t\t\t\t\tvalue: 42,\n+\t\t\t\t\ttype: 'integer',\n+\t\t\t\t},\n+\t\t\t});\n+\n+\t\t\tconst input = wrapper.findComponent({ name: 'v-input' });\n+\t\t\texpect(input.props('integer')).toBe(true);\n+\t\t\texpect(input.props('float')).toBe(false);\n+\t\t});\n+\n+\t\ttest('sets integer prop to true for bigInteger type', () => {\n+\t\t\twrapper = mount(InputInterface, {\n+\t\t\t\t...mountOptions,\n+\t\t\t\tprops: {\n+\t\t\t\t\tvalue: 42,\n+\t\t\t\t\ttype: 'bigInteger',\n+\t\t\t\t},\n+\t\t\t});\n+\n+\t\t\tconst input = wrapper.findComponent({ name: 'v-input' });\n+\t\t\texpect(input.props('integer')).toBe(true);\n+\t\t\texpect(input.props('float')).toBe(false);\n+\t\t});\n+\n+\t\ttest('sets float prop to true for float type', () => {\n+\t\t\twrapper = mount(InputInterface, {\n+\t\t\t\t...mountOptions,\n+\t\t\t\tprops: {\n+\t\t\t\t\tvalue: 3.14,\n+\t\t\t\t\ttype: 'float',\n+\t\t\t\t},\n+\t\t\t});\n+\n+\t\t\tconst input = wrapper.findComponent({ name: 'v-input' });\n+\t\t\texpect(input.props('float')).toBe(true);\n+\t\t\texpect(input.props('integer')).toBe(false);\n+\t\t});\n+\n+\t\ttest('sets float prop to true for decimal type', () => {\n+\t\t\twrapper = mount(InputInterface, {\n+\t\t\t\t...mountOptions,\n+\t\t\t\tprops: {\n+\t\t\t\t\tvalue: 19.99,\n+\t\t\t\t\ttype: 'decimal',\n+\t\t\t\t},\n+\t\t\t});\n+\n+\t\t\tconst input = wrapper.findComponent({ name: 'v-input' });\n+\t\t\texpect(input.props('float')).toBe(true);\n+\t\t\texpect(input.props('integer')).toBe(false);\n+\t\t});\n+\t});\n+\n+\tdescribe('numeric options', () => {\n+\t\ttest('passes min and max props correctly', () => {\n+\t\t\twrapper = mount(InputInterface, {\n+\t\t\t\t...mountOptions,\n+\t\t\t\tprops: {\n+\t\t\t\t\tvalue: 5,\n+\t\t\t\t\ttype: 'integer',\n+\t\t\t\t\tmin: 0,\n+\t\t\t\t\tmax: 10,\n+\t\t\t\t},\n+\t\t\t});\n+\n+\t\t\tconst input = wrapper.findComponent({ name: 'v-input' });\n+\t\t\texpect(input.props('min')).toBe(0);\n+\t\t\texpect(input.props('max')).toBe(10);\n+\t\t});\n+\n+\t\ttest('passes step prop correctly', () => {\n+\t\t\twrapper = mount(InputInterface, {\n+\t\t\t\t...mountOptions,\n+\t\t\t\tprops: {\n+\t\t\t\t\tvalue: 5,\n+\t\t\t\t\ttype: 'integer',\n+\t\t\t\t\tstep: 2,\n+\t\t\t\t},\n+\t\t\t});\n+\n+\t\t\tconst input = wrapper.findComponent({ name: 'v-input' });\n+\t\t\texpect(input.props('step')).toBe(2);\n+\t\t});\n+\n+\t\ttest('defaults step to 1', () => {\n+\t\t\twrapper = mount(InputInterface, {\n+\t\t\t\t...mountOptions,\n+\t\t\t\tprops: {\n+\t\t\t\t\tvalue: 5,\n+\t\t\t\t\ttype: 'integer',\n+\t\t\t\t},\n+\t\t\t});\n+\n+\t\t\tconst input = wrapper.findComponent({ name: 'v-input' });\n+\t\t\texpect(input.props('step')).toBe(1);\n+\t\t});\n+\n+\t\ttest('supports decimal step for float types', () => {\n+\t\t\twrapper = mount(InputInterface, {\n+\t\t\t\t...mountOptions,\n+\t\t\t\tprops: {\n+\t\t\t\t\tvalue: 5.5,\n+\t\t\t\t\ttype: 'float',\n+\t\t\t\t\tstep: 0.2,\n+\t\t\t\t},\n+\t\t\t});\n+\n+\t\t\tconst input = wrapper.findComponent({ name: 'v-input' });\n+\t\t\texpect(input.props('step')).toBe(0.2);\n+\t\t});\n+\n+\t\ttest('supports decimal min and max for float types', () => {\n+\t\t\twrapper = mount(InputInterface, {\n+\t\t\t\t...mountOptions,\n+\t\t\t\tprops: {\n+\t\t\t\t\tvalue: 5.5,\n+\t\t\t\t\ttype: 'float',\n+\t\t\t\t\tmin: 0.5,\n+\t\t\t\t\tmax: 10.5,\n+\t\t\t\t},\n+\t\t\t});\n+\n+\t\t\tconst input = wrapper.findComponent({ name: 'v-input' });\n+\t\t\texpect(input.props('min')).toBe(0.5);\n+\t\t\texpect(input.props('max')).toBe(10.5);\n+\t\t});\n+\t});\n+\n+\tdescribe('events', () => {\n+\t\ttest('emits input event when value changes', async () => {\n+\t\t\twrapper = mount(InputInterface, {\n+\t\t\t\t...mountOptions,\n+\t\t\t\tprops: {\n+\t\t\t\t\tvalue: 'test',\n+\t\t\t\t\ttype: 'string',\n+\t\t\t\t},\n+\t\t\t});\n+\n+\t\t\tconst input = wrapper.findComponent({ name: 'v-input' });\n+\t\t\tawait input.vm.$emit('update:model-value', 'new value');\n+\n+\t\t\texpect(wrapper.emitted('input')).toBeTruthy();\n+\t\t\texpect(wrapper.emitted('input')?.[0]).toEqual(['new value']);\n+\t\t});\n+\t});\n+\n+\tdescribe('text field options', () => {\n+\t\ttest('renders with placeholder', () => {\n+\t\t\twrapper = mount(InputInterface, {\n+\t\t\t\t...mountOptions,\n+\t\t\t\tprops: {\n+\t\t\t\t\tvalue: '',\n+\t\t\t\t\ttype: 'string',\n+\t\t\t\t\tplaceholder: 'Enter text...',\n+\t\t\t\t},\n+\t\t\t});\n+\n+\t\t\tconst input = wrapper.findComponent({ name: 'v-input' });\n+\t\t\texpect(input.props('placeholder')).toBe('Enter text...');\n+\t\t});\n+\n+\t\ttest('passes trim prop for text trimming', () => {\n+\t\t\twrapper = mount(InputInterface, {\n+\t\t\t\t...mountOptions,\n+\t\t\t\tprops: {\n+\t\t\t\t\tvalue: 'test',\n+\t\t\t\t\ttype: 'string',\n+\t\t\t\t\ttrim: true,\n+\t\t\t\t},\n+\t\t\t});\n+\n+\t\t\tconst input = wrapper.findComponent({ name: 'v-input' });\n+\t\t\texpect(input.props('trim')).toBe(true);\n+\t\t});\n+\t});\n+\n+\tdescribe('state management', () => {\n+\t\ttest('handles disabled state', () => {\n+\t\t\twrapper = mount(InputInterface, {\n+\t\t\t\t...mountOptions,\n+\t\t\t\tprops: {\n+\t\t\t\t\tvalue: 'test',\n+\t\t\t\t\ttype: 'string',\n+\t\t\t\t\tdisabled: true,\n+\t\t\t\t},\n+\t\t\t});\n+\n+\t\t\tconst input = wrapper.findComponent({ name: 'v-input' });\n+\t\t\texpect(input.props('disabled')).toBe(true);\n+\t\t});\n+\t});\n+});\ndiff --git a/app/src/lang/translations/en-US.yaml b/app/src/lang/translations/en-US.yaml\nindex 2f1f00cbd08cd..0c8c786e388d4 100644\n--- a/app/src/lang/translations/en-US.yaml\n+++ b/app/src/lang/translations/en-US.yaml\n@@ -75,6 +75,8 @@ condition_rules: Condition Rules\n input: Input\n invalid_input: Invalid Input\n not_a_number: Not a Number\n+invalid_range_min: Value is below minimum of {value}\n+invalid_range_max: Value exceeds maximum of {value}\n maps: Maps\n switch_user: Switch User\n item_creation: Item Creation\n", "test_patch": "", "problem_statement": "## Scope\r\n\r\nWhat's changed:\r\n\r\n- Step, min, and max options now accept decimal values for float/decimal fields\r\n - Input validation warnings now detect and display min/max range violations\r\n - Step up/down controls now properly handle float values\r\n\r\n## Tested Scenarios\r\n\r\n- Configured float field with decimal step interval (0.2)\r\n- Entered value exceeding configured maximum, warning icon displayed\r\n- Entered value below configured minimum, warning icon displayed\r\n- Step up/down controls with integer values\r\n- Step up/down controls with float/decimal values\r\n- Step controls respect min/max boundaries\r\n- Invalid input validation takes priority over range validation\r\n\r\n## Checklist\r\n\r\n- [X] Added or updated tests\r\n- [x] Documentation PR created [here](https://github.com/directus/docs) or not required\r\n- [x] OpenAPI package PR created [here](https://github.com/directus/openapi) or not required\r\n\r\n---\r\n\r\nFixes #25682 \r\n", "hints_text": "", "created_at": "2025-11-14T15:02:29Z", "pull_number": 26190, "test_files": ["app/src/components/v-input.test.ts", "app/src/interfaces/input/index.test.ts", "app/src/interfaces/input/input.test.ts"], "code_files": ["app/src/interfaces/input/index.ts"], "title": "Add support for float intervals and min/max warnings for number inputs", "additions": 0, "deletions": 0}
{"repo": "directus/directus", "instance_id": "directus__directus.pr_mirror.26228", "base_commit": "d5bc1f5834f6ff8bce26becfba1fe3cb4a3c799d", "patch": "diff --git a/.changeset/shy-cougars-matter.md b/.changeset/shy-cougars-matter.md\nnew file mode 100644\nindex 0000000000000..c221b1e20bbe9\n--- /dev/null\n+++ b/.changeset/shy-cougars-matter.md\n@@ -0,0 +1,5 @@\n+---\n+'@directus/api': patch\n+---\n+\n+Fixed telemetry reporting when visual editor urls are set\ndiff --git a/api/src/telemetry/utils/get-settings.test.ts b/api/src/telemetry/utils/get-settings.test.ts\nindex 414757dbfcfed..f5281fa7f03ae 100644\n--- a/api/src/telemetry/utils/get-settings.test.ts\n+++ b/api/src/telemetry/utils/get-settings.test.ts\n@@ -1,20 +1,22 @@\n import type { Knex } from 'knex';\n import { describe, expect, it, vi } from 'vitest';\n import { getSettings } from './get-settings.js';\n+import { SettingsService } from '../../services/settings.js';\n+\n+vi.mock('../../utils/get-schema.js');\n+vi.mock('../../services/settings.js');\n+\n+const mockDb: Knex = {} as Knex;\n \n describe('getSettings', () => {\n \tit('should return settings when they exist in the database', async () => {\n-\t\tconst mockDb = {\n-\t\t\tselect: vi.fn().mockReturnThis(),\n-\t\t\tfrom: vi.fn().mockReturnThis(),\n-\t\t\tfirst: vi.fn().mockResolvedValue({\n-\t\t\t\tproject_id: 'test-project-id',\n-\t\t\t\tmcp_enabled: true,\n-\t\t\t\tmcp_allow_deletes: false,\n-\t\t\t\tmcp_system_prompt_enabled: true,\n-\t\t\t\tvisual_editor_urls: '[\"https://example.com\",\"https://example.org\"]',\n-\t\t\t}),\n-\t\t} as unknown as Knex;\n+\t\tvi.mocked(SettingsService.prototype.readSingleton).mockResolvedValue({\n+\t\t\tproject_id: 'test-project-id',\n+\t\t\tmcp_enabled: true,\n+\t\t\tmcp_allow_deletes: false,\n+\t\t\tmcp_system_prompt_enabled: true,\n+\t\t\tvisual_editor_urls: ['https://example.com', 'https://example.org'],\n+\t\t} as any);\n \n \t\tconst result = await getSettings(mockDb);\n \n@@ -28,15 +30,11 @@ describe('getSettings', () => {\n \t});\n \n \tit('should coerce missing values to defaults when they are not set', async () => {\n-\t\tconst mockDb = {\n-\t\t\tselect: vi.fn().mockReturnThis(),\n-\t\t\tfrom: vi.fn().mockReturnThis(),\n-\t\t\tfirst: vi.fn().mockResolvedValue({\n-\t\t\t\tproject_id: 'test-project-id',\n-\t\t\t\t// booleans omitted on purpose to ensure toBoolean handles undefined\n-\t\t\t\tvisual_editor_urls: null,\n-\t\t\t}),\n-\t\t} as unknown as Knex;\n+\t\tvi.mocked(SettingsService.prototype.readSingleton).mockResolvedValue({\n+\t\t\tproject_id: 'test-project-id',\n+\t\t\t// booleans omitted on purpose to ensure handles undefined\n+\t\t\tvisual_editor_urls: null,\n+\t\t} as any);\n \n \t\tconst result = await getSettings(mockDb);\n \n@@ -48,14 +46,4 @@ describe('getSettings', () => {\n \t\t\tvisual_editor_urls: 0,\n \t\t});\n \t});\n-\n-\tit('should handle unexpected database errors gracefully', async () => {\n-\t\tconst mockDb = {\n-\t\t\tselect: vi.fn().mockReturnThis(),\n-\t\t\tfrom: vi.fn().mockReturnThis(),\n-\t\t\tfirst: vi.fn().mockRejectedValue(new Error('Database error')),\n-\t\t} as unknown as Knex;\n-\n-\t\tawait expect(getSettings(mockDb)).rejects.toThrow('Database error');\n-\t});\n });\ndiff --git a/api/src/telemetry/utils/get-settings.ts b/api/src/telemetry/utils/get-settings.ts\nindex cc103805054b9..3cc9cb9dbb589 100644\n--- a/api/src/telemetry/utils/get-settings.ts\n+++ b/api/src/telemetry/utils/get-settings.ts\n@@ -1,4 +1,5 @@\n-import { toBoolean } from '@directus/utils';\n+import { SettingsService } from '../../services/settings.js';\n+import { getSchema } from '../../utils/get-schema.js';\n import type { Knex } from 'knex';\n \n export type TelemetrySettings = {\n@@ -9,17 +10,29 @@ export type TelemetrySettings = {\n \tvisual_editor_urls: number;\n };\n \n+type DatabaseSettings = {\n+\tproject_id: string;\n+\tmcp_enabled?: boolean;\n+\tmcp_allow_deletes?: boolean;\n+\tmcp_system_prompt_enabled?: boolean;\n+\tvisual_editor_urls?: { url: string }[];\n+};\n+\n export const getSettings = async (db: Knex): Promise<TelemetrySettings> => {\n-\tconst settings = await db\n-\t\t.select('project_id', 'mcp_enabled', 'mcp_allow_deletes', 'mcp_system_prompt_enabled', 'visual_editor_urls')\n-\t\t.from('directus_settings')\n-\t\t.first();\n+\tconst settingsService = new SettingsService({\n+\t\tknex: db,\n+\t\tschema: await getSchema({ database: db }),\n+\t});\n+\n+\tconst settings = (await settingsService.readSingleton({\n+\t\tfields: ['project_id', 'mcp_enabled', 'mcp_allow_deletes', 'mcp_system_prompt_enabled', 'visual_editor_urls'],\n+\t})) as DatabaseSettings;\n \n \treturn {\n \t\tproject_id: settings.project_id,\n-\t\tmcp_enabled: toBoolean(settings?.mcp_enabled),\n-\t\tmcp_allow_deletes: toBoolean(settings?.mcp_allow_deletes),\n-\t\tmcp_system_prompt_enabled: toBoolean(settings?.mcp_system_prompt_enabled),\n-\t\tvisual_editor_urls: settings.visual_editor_urls ? JSON.parse(settings.visual_editor_urls).length : 0,\n+\t\tmcp_enabled: settings?.mcp_enabled || false,\n+\t\tmcp_allow_deletes: settings?.mcp_allow_deletes || false,\n+\t\tmcp_system_prompt_enabled: settings?.mcp_system_prompt_enabled || false,\n+\t\tvisual_editor_urls: settings.visual_editor_urls?.length || 0,\n \t};\n };\n", "test_patch": "", "problem_statement": "## Scope\r\n\r\nWhat's changed:\r\n\r\n- Not all database vendors return JSON as a string, we should use the SettingsService instead of Raw KNEX to get instance settings.\r\n\r\n## Potential Risks / Drawbacks\r\n\r\n- SettingsService isn't typed so this isn't fully typesafe.\r\n\r\n## Tested Scenarios\r\n\r\n- Getting Full Settings\r\n- Getting Settings with Missing Values\r\n\r\n## Review Notes / Questions\r\n\r\n- Test with multiple different database vendors.\r\n\r\n## Checklist\r\n\r\n- [X] Added or updated tests\r\n", "hints_text": "", "created_at": "2025-11-19T21:07:24Z", "pull_number": 26228, "test_files": ["api/src/telemetry/utils/get-settings.test.ts"], "code_files": ["api/src/telemetry/utils/get-settings.ts"], "title": "Fix telemetry reporting for visual editor URLs and update tests", "additions": 0, "deletions": 0}
{"repo": "directus/directus", "instance_id": "directus__directus.pr_mirror.26233", "base_commit": "d5bc1f5834f6ff8bce26becfba1fe3cb4a3c799d", "patch": "diff --git a/.changeset/forty-wombats-wash.md b/.changeset/forty-wombats-wash.md\nnew file mode 100644\nindex 0000000000000..3245ad1d428e6\n--- /dev/null\n+++ b/.changeset/forty-wombats-wash.md\n@@ -0,0 +1,5 @@\n+---\n+'@directus/api': patch\n+---\n+\n+Fixed `_by_id` querying with M2A filters in GraphQL\ndiff --git a/api/src/services/graphql/resolvers/query.test.ts b/api/src/services/graphql/resolvers/query.test.ts\nnew file mode 100644\nindex 0000000000000..828daaacf1ca8\n--- /dev/null\n+++ b/api/src/services/graphql/resolvers/query.test.ts\n@@ -0,0 +1,243 @@\n+import { afterEach, beforeEach, describe, expect, test, vi } from 'vitest';\n+import { parseArgs } from '../schema/parse-args.js';\n+import { getQuery } from '../schema/parse-query.js';\n+import { getAggregateQuery } from '../utils/aggregate-query.js';\n+import { replaceFragmentsInSelections } from '../utils/replace-fragments.js';\n+import { resolveQuery } from './query.js';\n+\n+vi.mock('../utils/replace-fragments.js');\n+vi.mock('../schema/parse-args.js');\n+vi.mock('../utils/aggregate-query.js');\n+vi.mock('../schema/parse-query.js');\n+\n+describe('resolveQuery', () => {\n+\tconst mockReplaceFragments = vi.fn();\n+\tconst mockParseArgs = vi.fn();\n+\tconst mockGetAggregateQuery = vi.fn();\n+\tconst mockGetQuery = vi.fn();\n+\n+\tbeforeEach(() => {\n+\t\tvi.mocked(replaceFragmentsInSelections).mockImplementation(mockReplaceFragments);\n+\t\tvi.mocked(parseArgs).mockImplementation(mockParseArgs);\n+\t\tvi.mocked(getAggregateQuery).mockImplementation(mockGetAggregateQuery);\n+\t\tvi.mocked(getQuery).mockImplementation(mockGetQuery);\n+\t});\n+\n+\tafterEach(() => {\n+\t\tvi.clearAllMocks();\n+\t\tvi.resetAllMocks();\n+\t\tvi.restoreAllMocks();\n+\t});\n+\n+\ttest('system scope prefixes collection with directus_', async () => {\n+\t\tmockReplaceFragments.mockReturnValue([{}]);\n+\t\tmockParseArgs.mockReturnValue({});\n+\n+\t\tmockGetQuery.mockResolvedValue({\n+\t\t\tfields: [],\n+\t\t});\n+\n+\t\tconst gql: any = {\n+\t\t\tscope: 'system',\n+\t\t\tschema: { collections: {} },\n+\t\t\taccountability: {},\n+\t\t\tread: vi.fn(() => []),\n+\t\t};\n+\n+\t\tconst info: any = {\n+\t\t\tfieldName: 'users',\n+\t\t\tfieldNodes: [{ selectionSet: { selections: [{}] }, arguments: [] }],\n+\t\t\tfragments: {},\n+\t\t\tvariableValues: {},\n+\t\t};\n+\n+\t\tawait resolveQuery(gql, info);\n+\n+\t\texpect(mockGetQuery).toHaveBeenCalled();\n+\t\tconst lastCallArgs = mockGetQuery.mock.calls[mockGetQuery.mock.calls.length - 1];\n+\t\tconst collectionArg = lastCallArgs?.[lastCallArgs.length - 1];\n+\t\texpect(collectionArg).toBe('directus_users');\n+\t});\n+\n+\ttest('returns null when selections are missing', async () => {\n+\t\tmockReplaceFragments.mockReturnValue(null);\n+\n+\t\tconst gql: any = {\n+\t\t\tscope: 'app',\n+\t\t\tschema: { collections: {} },\n+\t\t\taccountability: {},\n+\t\t\tread: vi.fn(),\n+\t\t};\n+\n+\t\tconst info: any = {\n+\t\t\tfieldName: 'posts',\n+\t\t\tfieldNodes: [{ selectionSet: undefined }],\n+\t\t\tfragments: {},\n+\t\t\tvariableValues: {},\n+\t\t};\n+\n+\t\tconst res = await resolveQuery(gql, info);\n+\n+\t\texpect(res).toBeNull();\n+\t\texpect(mockParseArgs).not.toHaveBeenCalled();\n+\t});\n+\n+\ttest('aggregate branch calls getAggregateQuery with correct collection name', async () => {\n+\t\tmockReplaceFragments.mockReturnValue([{}]);\n+\t\tmockParseArgs.mockReturnValue({ id: 'id' });\n+\n+\t\tmockGetAggregateQuery.mockReturnValue({\n+\t\t\tfields: [],\n+\t\t});\n+\n+\t\tconst gql: any = {\n+\t\t\tscope: 'app',\n+\t\t\tschema: {\n+\t\t\t\tcollections: {},\n+\t\t\t},\n+\t\t\taccountability: {},\n+\t\t\tread: vi.fn(),\n+\t\t};\n+\n+\t\tconst info: any = {\n+\t\t\tfieldName: 'posts_aggregated',\n+\t\t\tfieldNodes: [{ selectionSet: { selections: [{}] }, arguments: [] }],\n+\t\t\tfragments: {},\n+\t\t\tvariableValues: {},\n+\t\t};\n+\n+\t\tawait resolveQuery(gql, info);\n+\n+\t\tconst lastCallArgs = mockGetAggregateQuery.mock.calls[mockGetAggregateQuery.mock.calls.length - 1];\n+\t\tconst collectionArg = lastCallArgs?.[lastCallArgs.length - 1];\n+\t\texpect(collectionArg).toBe('posts');\n+\t});\n+\n+\ttest('query by id calls getQuery with correct collection name', async () => {\n+\t\tmockReplaceFragments.mockReturnValue([{}]);\n+\t\tmockParseArgs.mockReturnValue({ id: 'abc' });\n+\n+\t\tmockGetQuery.mockReturnValue({\n+\t\t\tfields: [],\n+\t\t});\n+\n+\t\tconst gql: any = {\n+\t\t\tscope: 'app',\n+\t\t\tschema: {\n+\t\t\t\tcollections: {},\n+\t\t\t},\n+\t\t\taccountability: {},\n+\t\t\tread: vi.fn(),\n+\t\t};\n+\n+\t\tconst info: any = {\n+\t\t\tfieldName: 'posts_by_id',\n+\t\t\tfieldNodes: [{ selectionSet: { selections: [{}] }, arguments: [] }],\n+\t\t\tfragments: {},\n+\t\t\tvariableValues: {},\n+\t\t};\n+\n+\t\tawait resolveQuery(gql, info);\n+\n+\t\texpect(mockGetQuery).toHaveBeenCalled();\n+\t\tconst lastCallArgs = mockGetQuery.mock.calls[mockGetQuery.mock.calls.length - 1];\n+\t\tconst collectionArg = lastCallArgs?.[lastCallArgs.length - 1];\n+\t\texpect(collectionArg).toBe('posts');\n+\t});\n+\n+\ttest('query by version injects versionRaw to query', async () => {\n+\t\tmockReplaceFragments.mockReturnValue([{}]);\n+\t\tmockParseArgs.mockReturnValue({ id: 'abc' });\n+\n+\t\tmockGetQuery.mockReturnValue({\n+\t\t\tfields: [],\n+\t\t});\n+\n+\t\tconst gql: any = {\n+\t\t\tscope: 'app',\n+\t\t\tschema: {\n+\t\t\t\tcollections: {},\n+\t\t\t},\n+\t\t\taccountability: {},\n+\t\t\tread: vi.fn(),\n+\t\t};\n+\n+\t\tconst info: any = {\n+\t\t\tfieldName: 'posts_by_version',\n+\t\t\tfieldNodes: [{ selectionSet: { selections: [{}] }, arguments: [] }],\n+\t\t\tfragments: {},\n+\t\t\tvariableValues: {},\n+\t\t};\n+\n+\t\tawait resolveQuery(gql, info);\n+\n+\t\texpect(gql.read).toHaveBeenCalled();\n+\t\tconst lastCallArgs = gql.read.mock.calls[gql.read.mock.calls.length - 1];\n+\t\tconst queryArg = lastCallArgs?.[1];\n+\t\texpect(queryArg).toEqual(expect.objectContaining({ versionRaw: true }));\n+\t});\n+\n+\ttest('properly resolves fields to correct path for each nested function field', async () => {\n+\t\tmockReplaceFragments.mockReturnValue([{}]);\n+\t\tmockParseArgs.mockReturnValue({ id: 'abc' });\n+\n+\t\tmockGetAggregateQuery.mockResolvedValue({\n+\t\t\tfields: ['count(a)', 'sum(b.c)', 'max(c.d.e)'],\n+\t\t});\n+\n+\t\tconst gql: any = {\n+\t\t\tscope: 'app',\n+\t\t\tschema: { collections: {} },\n+\t\t\taccountability: {},\n+\t\t\tread: vi.fn(() => []),\n+\t\t};\n+\n+\t\tconst info: any = {\n+\t\t\tfieldName: 'col_aggregated',\n+\t\t\tfieldNodes: [{ selectionSet: { selections: [{}] }, arguments: [] }],\n+\t\t\tfragments: {},\n+\t\t\tvariableValues: {},\n+\t\t};\n+\n+\t\tawait resolveQuery(gql, info);\n+\n+\t\texpect(gql.read).toHaveBeenCalled();\n+\t\tconst lastCallArgs = gql.read.mock.calls[gql.read.mock.calls.length - 1];\n+\t\tconst queryArg = lastCallArgs?.[1];\n+\t\texpect(queryArg).toEqual(expect.objectContaining({ fields: ['count(a)', 'b.sum(c)', 'c.d.max(e)'] }));\n+\t});\n+\n+\ttest('inject group field for each item when grouping', async () => {\n+\t\tmockReplaceFragments.mockReturnValue([{}]);\n+\t\tmockParseArgs.mockReturnValue({});\n+\n+\t\tmockGetAggregateQuery.mockResolvedValue({\n+\t\t\tgroup: ['category'],\n+\t\t\taggregate: { count: ['id'] },\n+\t\t});\n+\n+\t\tconst gql: any = {\n+\t\t\tscope: 'app',\n+\t\t\tschema: { collections: {} },\n+\t\t\taccountability: {},\n+\t\t\tread: vi.fn(() => [\n+\t\t\t\t{ category: 'A', count: { id: 5 } },\n+\t\t\t\t{ category: 'B', count: { id: 10 } },\n+\t\t\t]),\n+\t\t};\n+\n+\t\tconst info: any = {\n+\t\t\tfieldName: 'items_aggregated',\n+\t\t\tfieldNodes: [{ selectionSet: { selections: [{}] }, arguments: [] }],\n+\t\t\tfragments: {},\n+\t\t\tvariableValues: {},\n+\t\t};\n+\n+\t\tconst res = await resolveQuery(gql, info);\n+\n+\t\texpect(res).toEqual([\n+\t\t\t{ category: 'A', count: { id: 5 }, group: { category: 'A' } },\n+\t\t\t{ category: 'B', count: { id: 10 }, group: { category: 'B' } },\n+\t\t]);\n+\t});\n+});\ndiff --git a/api/src/services/graphql/resolvers/query.ts b/api/src/services/graphql/resolvers/query.ts\nindex b014b12d67253..dafadf2e820f6 100644\n--- a/api/src/services/graphql/resolvers/query.ts\n+++ b/api/src/services/graphql/resolvers/query.ts\n@@ -28,12 +28,12 @@ export async function resolveQuery(gql: GraphQLService, info: GraphQLResolveInfo\n \t\tcollection = collection.slice(0, -11);\n \t\tquery = await getAggregateQuery(args, selections, gql.schema, gql.accountability, collection);\n \t} else {\n-\t\tquery = await getQuery(args, gql.schema, selections, info.variableValues, gql.accountability, collection);\n-\n \t\tif (collection.endsWith('_by_id') && collection in gql.schema.collections === false) {\n \t\t\tcollection = collection.slice(0, -6);\n \t\t}\n \n+\t\tquery = await getQuery(args, gql.schema, selections, info.variableValues, gql.accountability, collection);\n+\n \t\tif (collection.endsWith('_by_version') && collection in gql.schema.collections === false) {\n \t\t\tcollection = collection.slice(0, -11);\n \t\t\tquery.versionRaw = true;\ndiff --git a/api/src/services/graphql/schema/parse-query.test.ts b/api/src/services/graphql/schema/parse-query.test.ts\nindex d806a4dbeea0c..aeb33eb2a9951 100644\n--- a/api/src/services/graphql/schema/parse-query.test.ts\n+++ b/api/src/services/graphql/schema/parse-query.test.ts\n@@ -1,11 +1,8 @@\n import type { FieldNode, SelectionNode } from 'graphql';\n import { afterEach, describe, expect, test, vi } from 'vitest';\n import { sanitizeQuery } from '../../../utils/sanitize-query.js';\n-import { parseArgs } from './parse-args.js';\n import { getQuery } from './parse-query.js';\n \n-vi.mock('/parse-args.js');\n-\n vi.mock('../../../utils/sanitize-query.js', () => ({\n \tsanitizeQuery: vi.fn(async (q) => q),\n }));\n@@ -23,8 +20,6 @@ vi.mock('../utils/replace-funcs.js', () => ({\n \treplaceFuncs: vi.fn((v) => v),\n }));\n \n-vi.mock('./parse-args.js');\n-\n const mockSchema = {} as any;\n const mockAccountability = null;\n const mockVariableValues = {};\n@@ -103,7 +98,6 @@ describe('parseFields', () => {\n \n \t\tconst query = await getQuery({}, mockSchema, selections, mockVariableValues, mockAccountability);\n \t\texpect(query.fields).toEqual(['posts']);\n-\t\texpect(parseArgs).toHaveBeenCalledWith(selections[0]!.arguments, mockVariableValues);\n \t});\n \n \ttest('should parse InlineFragment with arguments', async () => {\n", "test_patch": "", "problem_statement": "## Scope\r\n\r\nWhat's changed:\r\n\r\n- The correct collection name is now passed down for filtering m2a fields\r\n\r\n## Potential Risks / Drawbacks\r\n\r\n- Should be none\r\n\r\n## Tested Scenarios\r\n\r\n-  [x] Expect M2A filtering with `_by_id` to succeed\r\n\r\n## Review Notes / Questions\r\n\r\n- I would like to lorem ipsum\r\n- Special attention should be paid to dolor sit amet\r\n\r\n## Checklist\r\n\r\n- [x] Added or updated tests\r\n- [ ] Documentation PR created [here](https://github.com/directus/docs) or not required\r\n- [ ] OpenAPI package PR created [here](https://github.com/directus/openapi) or not required\r\n\r\n---\r\n\r\nFixes #26232", "hints_text": "", "created_at": "2025-11-20T17:45:50Z", "pull_number": 26233, "test_files": ["api/src/services/graphql/resolvers/query.test.ts", "api/src/services/graphql/schema/parse-query.test.ts"], "code_files": ["api/src/services/graphql/resolvers/query.ts"], "title": "Fixed `_by_id` querying with M2A filters in GraphQL", "additions": 0, "deletions": 0}
{"repo": "directus/directus", "instance_id": "directus__directus.pr_mirror.26213", "base_commit": "b5aff1a1bdab458049fc2972008b4bf785b21257", "patch": "diff --git a/.changeset/eighty-bats-deny.md b/.changeset/eighty-bats-deny.md\nnew file mode 100644\nindex 0000000000000..1414b884d83dc\n--- /dev/null\n+++ b/.changeset/eighty-bats-deny.md\n@@ -0,0 +1,5 @@\n+---\n+'@directus/api': patch\n+---\n+\n+Fixed notification emails failing due to transaction race condition\ndiff --git a/api/src/services/mail/index.ts b/api/src/services/mail/index.ts\nindex 5542d51fb3497..2cfc45b3b5f93 100644\n--- a/api/src/services/mail/index.ts\n+++ b/api/src/services/mail/index.ts\n@@ -32,6 +32,13 @@ export type EmailOptions = SendMailOptions & {\n \t};\n };\n \n+export type DefaultTemplateData = {\n+\tprojectName: string;\n+\tprojectColor: string;\n+\tprojectLogo: string;\n+\tprojectUrl: string;\n+};\n+\n export class MailService {\n \tschema: SchemaOverview;\n \taccountability: Accountability | null;\n@@ -54,18 +61,19 @@ export class MailService {\n \t\t}\n \t}\n \n-\tasync send<T>(options: EmailOptions): Promise<T | null> {\n+\tasync send<T>(data: EmailOptions, options?: { defaultTemplateData: DefaultTemplateData }): Promise<T | null> {\n \t\tawait useEmailRateLimiterQueue();\n \n-\t\tconst payload = await emitter.emitFilter(`email.send`, options, {});\n+\t\tconst payload = await emitter.emitFilter(`email.send`, data, {});\n \n \t\tif (!payload) return null;\n \n \t\tconst { template, ...emailOptions } = payload;\n \n-\t\tlet { html } = options;\n+\t\tlet { html } = data;\n \n-\t\tconst defaultTemplateData = await this.getDefaultTemplateData();\n+\t\t// option for providing tempalate data was added to prevent transaction race conditions with preceding promises\n+\t\tconst defaultTemplateData = options?.defaultTemplateData ?? (await this.getDefaultTemplateData());\n \n \t\tif (isObject(emailOptions.from) && (!emailOptions.from.name || !emailOptions.from.address)) {\n \t\t\tthrow new InvalidPayloadError({ reason: 'A name and address property are required in the \"from\" object' });\n@@ -117,7 +125,7 @@ export class MailService {\n \t\treturn html;\n \t}\n \n-\tprivate async getDefaultTemplateData() {\n+\tasync getDefaultTemplateData() {\n \t\tconst projectInfo = await this.knex\n \t\t\t.select(['project_name', 'project_logo', 'project_color', 'project_url'])\n \t\t\t.from('directus_settings')\ndiff --git a/api/src/services/notifications.ts b/api/src/services/notifications.ts\nindex 3e8a2214d1bd4..b773185c66a64 100644\n--- a/api/src/services/notifications.ts\n+++ b/api/src/services/notifications.ts\n@@ -57,14 +57,19 @@ export class NotificationsService extends ItemsService {\n \t\t\t\t});\n \n \t\t\t\tmailService\n-\t\t\t\t\t.send({\n-\t\t\t\t\t\ttemplate: {\n-\t\t\t\t\t\t\tname: 'base',\n-\t\t\t\t\t\t\tdata: app_access ? { url: manageUserAccountUrl, html } : { html },\n+\t\t\t\t\t.send(\n+\t\t\t\t\t\t{\n+\t\t\t\t\t\t\ttemplate: {\n+\t\t\t\t\t\t\t\tname: 'base',\n+\t\t\t\t\t\t\t\tdata: app_access ? { url: manageUserAccountUrl, html } : { html },\n+\t\t\t\t\t\t\t},\n+\t\t\t\t\t\t\tto: user['email'],\n+\t\t\t\t\t\t\tsubject: data.subject,\n \t\t\t\t\t\t},\n-\t\t\t\t\t\tto: user['email'],\n-\t\t\t\t\t\tsubject: data.subject,\n-\t\t\t\t\t})\n+\t\t\t\t\t\t{\n+\t\t\t\t\t\t\tdefaultTemplateData: await mailService.getDefaultTemplateData(),\n+\t\t\t\t\t\t},\n+\t\t\t\t\t)\n \t\t\t\t\t.catch((error) => {\n \t\t\t\t\t\tlogger.error(error, `Could not send notification via mail`);\n \t\t\t\t\t});\ndiff --git a/pnpm-lock.yaml b/pnpm-lock.yaml\nindex 9f2f53de4c964..5afd3a6c6d939 100644\n--- a/pnpm-lock.yaml\n+++ b/pnpm-lock.yaml\n@@ -3025,9 +3025,15 @@ importers:\n       '@types/lodash-es':\n         specifier: 'catalog:'\n         version: 4.17.12\n+      '@types/mailparser':\n+        specifier: 3.4.6\n+        version: 3.4.6\n       '@types/seedrandom':\n         specifier: 3.0.8\n         version: 3.0.8\n+      '@types/smtp-server':\n+        specifier: 3.5.12\n+        version: 3.5.12\n       '@types/supertest':\n         specifier: 6.0.2\n         version: 6.0.2\n@@ -3067,9 +3073,15 @@ importers:\n       lodash-es:\n         specifier: 'catalog:'\n         version: 4.17.21\n+      mailparser:\n+        specifier: 3.9.0\n+        version: 3.9.0\n       seedrandom:\n         specifier: 3.0.5\n         version: 3.0.5\n+      smtp-server:\n+        specifier: 3.16.1\n+        version: 3.16.1\n       supertest:\n         specifier: 7.1.4\n         version: 7.1.4\n@@ -6142,6 +6154,9 @@ packages:\n   '@sec-ant/readable-stream@0.4.1':\n     resolution: {integrity: sha512-831qok9r2t8AlxLko40y2ebgSDhenenCatLVeW/uBtnHPyhHOvG0C7TvfgecV+wHzIm5KUICgzmVpWS+IMEAeg==}\n \n+  '@selderee/plugin-htmlparser2@0.11.0':\n+    resolution: {integrity: sha512-P33hHGdldxGabLFjPPpaTxVolMrzrcegejx+0GxjrIb9Zv48D8yAIA/QTDR2dFl7Uz7urX8aX6+5bCZslr+gWQ==}\n+\n   '@shopify/semaphore@3.1.0':\n     resolution: {integrity: sha512-LxonkiWEu12FbZhuOMhsdocpxCqm7By8C/2U9QgNuEoXUx2iMrlXjJv3p93RwfNC6TrdlNRo17gRer1z1309VQ==}\n     engines: {node: '>=18.12.0'}\n@@ -6612,6 +6627,9 @@ packages:\n   '@types/luxon@3.7.1':\n     resolution: {integrity: sha512-H3iskjFIAn5SlJU7OuxUmTEpebK6TKB8rxZShDslBMZJ5u9S//KM1sbdAisiSrqwLQncVjnpi2OK2J51h+4lsg==}\n \n+  '@types/mailparser@3.4.6':\n+    resolution: {integrity: sha512-wVV3cnIKzxTffaPH8iRnddX1zahbYB1ZEoAxyhoBo3TBCBuK6nZ8M8JYO/RhsCuuBVOw/DEN/t/ENbruwlxn6Q==}\n+\n   '@types/mapbox-gl@3.4.1':\n     resolution: {integrity: sha512-NsGKKtgW93B+UaLPti6B7NwlxYlES5DpV5Gzj9F75rK5ALKsqSk15CiEHbOnTr09RGbr6ZYiCdI+59NNNcAImg==}\n \n@@ -6708,6 +6726,9 @@ packages:\n   '@types/serve-static@1.15.9':\n     resolution: {integrity: sha512-dOTIuqpWLyl3BBXU3maNQsS4A3zuuoYRNIvYSxxhebPfXg2mzWQEPne/nlJ37yOse6uGgR386uTpdsx4D0QZWA==}\n \n+  '@types/smtp-server@3.5.12':\n+    resolution: {integrity: sha512-IBemrqI6nzvbgwE41Lnd4v4Yf1Kc7F1UHjk1GFBLNhLcI/Zop1ggHQ8g7Y8QYc6jGVgzWQcsa0MBNcGnDY9UGw==}\n+\n   '@types/ssri@7.1.5':\n     resolution: {integrity: sha512-odD/56S3B51liILSk5aXJlnYt99S6Rt9EFDDqGtJM26rKHApHcwyU/UoYHrzKkdkHMAIquGWCuHtQTbes+FRQw==}\n \n@@ -7089,6 +7110,9 @@ packages:\n     engines: {node: '>= 8'}\n     hasBin: true\n \n+  '@zone-eu/mailsplit@5.4.7':\n+    resolution: {integrity: sha512-jApX86aDgolMz08pP20/J2zcns02NSK3zSiYouf01QQg4250L+GUAWSWicmS7eRvs+Z7wP7QfXrnkaTBGrIpwQ==}\n+\n   JSV@4.0.2:\n     resolution: {integrity: sha512-ZJ6wx9xaKJ3yFUhq5/sk82PJMuUyLk277I8mQeyDgCTjGdjWJIvPfaU5LIXaMuaN2UO1X3kZH4+lgphublZUHw==}\n \n@@ -7390,6 +7414,10 @@ packages:\n   base-64@1.0.0:\n     resolution: {integrity: sha512-kwDPIFCGx0NZHog36dj+tHiwP4QMzsZ3AgMViUBKI0+V5n4U0ufTCUMhnQ04diaRI8EX/QcPfql7zlhZ7j4zgg==}\n \n+  base32.js@0.1.0:\n+    resolution: {integrity: sha512-n3TkB02ixgBOhTvANakDb4xaMXnYUVkNoRFJjQflcqMQhyEKxEHdj3E6N8t8sUQ0mjH/3/JxzlXuz3ul/J90pQ==}\n+    engines: {node: '>=0.12.0'}\n+\n   base64-js@1.5.1:\n     resolution: {integrity: sha512-AKpaYlHn8t4SVbOHCy+b5+KKgvR4vrsD8vbvrbiQJps7fKDTkjkDry6ji0rUJjC0kzbNePLwzxq8iypo41qeWA==}\n \n@@ -8530,6 +8558,10 @@ packages:\n     resolution: {integrity: sha512-Q0n9HRi4m6JuGIV1eFlmvJB7ZEVxu93IrMyiMsGC0lrMJMWzRgx6WGquyfQgZVb31vhGgXnfmPNNXmxnOkRBrg==}\n     engines: {node: '>= 0.8'}\n \n+  encoding-japanese@2.2.0:\n+    resolution: {integrity: sha512-EuJWwlHPZ1LbADuKTClvHtwbaFn4rOD+dRAbWysqEOXRc2Uui0hJInNJrsdH0c+OhJA4nrCBdSkW4DD5YxAo6A==}\n+    engines: {node: '>=8.10.0'}\n+\n   encoding@0.1.13:\n     resolution: {integrity: sha512-ETBauow1T35Y/WZMkio9jiM0Z5xjHHmJ4XmjZOq1l/dXz3lr2sRn87nJy20RupqSh1F2m3HHPSp8ShIPQJrJ3A==}\n \n@@ -9400,6 +9432,10 @@ packages:\n     resolution: {integrity: sha512-ztqyC3kLto0e9WbNp0aeP+M3kTt+nbaIveGmUxAtZa+8iFgKLUOD4YKM5j+f3QD89bra7UeumolZHKuOXnTmeQ==}\n     engines: {node: '>=8'}\n \n+  html-to-text@9.0.5:\n+    resolution: {integrity: sha512-qY60FjREgVZL03vJU6IfMV4GDjGBIoOyvuFdpBDIX9yTlDw0TjxVBQp+P8NvpdIXNJvfWBTNul7fsAQJq2FNpg==}\n+    engines: {node: '>=14'}\n+\n   htmlparser2@8.0.2:\n     resolution: {integrity: sha512-GYdjWKDkbRLkZ5geuHs5NY1puJ+PXwP7+fHPRz06Eirsb9ugf6d8kkXav6ADhcODhFFPMIXyxkxSuMf3D6NCFA==}\n \n@@ -9569,6 +9605,9 @@ packages:\n     resolution: {integrity: sha512-0KI/607xoxSToH7GjN1FfSbLoU0+btTicjsQSWQlh/hZykN8KpmMf7uYwPW3R+akZ6R/w18ZlXSHBYXiYUPO3g==}\n     engines: {node: '>= 0.10'}\n \n+  ipv6-normalize@1.0.1:\n+    resolution: {integrity: sha512-Bm6H79i01DjgGTCWjUuCjJ6QDo1HB96PT/xCYuyJUP9WFbVDrLSbG4EZCvOCun2rNswZb0c3e4Jt/ws795esHA==}\n+\n   is-arrayish@0.2.1:\n     resolution: {integrity: sha512-zz06S8t0ozoDXMG+ube26zeCTNXcKIPJZJi8hBrF4idCLms4CG9QtK7qBl1boi5ODzFpjswb5JPmHCbMpjaYzg==}\n \n@@ -9970,6 +10009,9 @@ packages:\n     engines: {node: '>=10.13.0'}\n     deprecated: This package has been decomissioned. See https://github.com/ldapjs/node-ldapjs/blob/8ffd0bc9c149088a10ec4c1ec6a18450f76ad05d/README.md\n \n+  leac@0.6.0:\n+    resolution: {integrity: sha512-y+SqErxb8h7nE/fiEX07jsbuhrpO9lL8eca7/Y1nuWV2moNlXhyd59iDGcRf6moVyDMbmTNzL40SUyrFU/yDpg==}\n+\n   leven@2.1.0:\n     resolution: {integrity: sha512-nvVPLpIHUxCUoRLrFqTgSxXJ614d8AgQoWl7zPe/2VadE8+1dpU3LBhowRuBAcuwruWtOdD8oYC9jDNJjXDPyA==}\n     engines: {node: '>=0.10.0'}\n@@ -9978,6 +10020,15 @@ packages:\n     resolution: {integrity: sha512-+bT2uH4E5LGE7h/n3evcS/sQlJXCpIp6ym8OWJ5eV6+67Dsql/LaaT7qJBAt2rzfoa/5QBGBhxDix1dMt2kQKQ==}\n     engines: {node: '>= 0.8.0'}\n \n+  libbase64@1.3.0:\n+    resolution: {integrity: sha512-GgOXd0Eo6phYgh0DJtjQ2tO8dc0IVINtZJeARPeiIJqge+HdsWSuaDTe8ztQ7j/cONByDZ3zeB325AHiv5O0dg==}\n+\n+  libmime@5.3.7:\n+    resolution: {integrity: sha512-FlDb3Wtha8P01kTL3P9M+ZDNDWPKPmKHWaU/cG/lg5pfuAwdflVpZE+wm9m7pKmC5ww6s+zTxBKS1p6yl3KpSw==}\n+\n+  libqp@2.1.1:\n+    resolution: {integrity: sha512-0Wd+GPz1O134cP62YU2GTOPNA7Qgl09XwCqM5zpBv87ERCXdfDtyKXvV7c9U22yWJh44QZqBocFnXN11K96qow==}\n+\n   lilconfig@3.1.3:\n     resolution: {integrity: sha512-/vlFKAoH5Cgt3Ie+JLhRbwOsCQePABiU3tJ1egGvyQ+33R/vcwM2Zl2QR/LzjsBeItPt3oSVXapn+m4nQDvpzw==}\n     engines: {node: '>=14'}\n@@ -9988,6 +10039,9 @@ packages:\n   linkify-it@3.0.3:\n     resolution: {integrity: sha512-ynTsyrFSdE5oZ/O9GEf00kPngmOfVwazR5GKDq6EYfhlpFug3J2zybX56a2PRRpc9P+FuSoGNAwjlbDs9jJBPQ==}\n \n+  linkify-it@5.0.0:\n+    resolution: {integrity: sha512-5aHCbzQRADcdP+ATqnDuhhJ/MRIqDkZX5pyjFHRRysS8vZ5AbqGEoFIb6pYHPZ+L/OC2Lc+xT8uHVVR5CAK/wQ==}\n+\n   liquidjs@10.24.0:\n     resolution: {integrity: sha512-TAUNAdgwaAXjjcUFuYVJm9kOVH7zc0mTKxsG9t9Lu4qdWjB2BEblyVIYpjWcmJLMGgiYqnGNJjpNMHx0gp/46A==}\n     engines: {node: '>=16'}\n@@ -10185,6 +10239,9 @@ packages:\n   mailgun.js@8.2.2:\n     resolution: {integrity: sha512-po/KtofzrTuKhHLenbmliDsVVOFANwcfDFUGnggwnyZJmZz7JgBlV6nzK9o2Fk+OK2SiBmJTK25RbkAj57Hd+Q==}\n \n+  mailparser@3.9.0:\n+    resolution: {integrity: sha512-jpaNLhDjwy0w2f8sySOSRiWREjPqssSc0C2czV98btCXCRX3EyNloQ2IWirmMDj1Ies8Fkm0l96bZBZpDG7qkg==}\n+\n   make-dir@4.0.0:\n     resolution: {integrity: sha512-hXdUTZYIVOt1Ex//jAQi+wTZZpUpwBj/0QsOzqegb3rGMMeJiSEu5xLHnYfBrRV4RH2+OCSOO95Is/7x1WJ4bw==}\n     engines: {node: '>=10'}\n@@ -10981,6 +11038,9 @@ packages:\n   parse5@7.3.0:\n     resolution: {integrity: sha512-IInvU7fabl34qmi9gY8XOVxhYyMyuH2xUNpb2q8/Y+7552KlejkRvqvD19nMoUW/uQGGbqNpA6Tufu5FL5BZgw==}\n \n+  parseley@0.12.1:\n+    resolution: {integrity: sha512-e6qHKe3a9HWr0oMRVDTRhKce+bRO8VGQR3NyVwcjwrbhMmFCX9KszEV35+rn4AdilFAq9VPxP/Fe1wC9Qjd2lw==}\n+\n   parseurl@1.3.3:\n     resolution: {integrity: sha512-CiyeOxFT/JZyN5m0z9PfXw4SCBJ6Sygz1Dpl0wqjlhDEGGBP1GnsUVEL0p63hoG1fcj3fHynXi9NYO4nWOL+qQ==}\n     engines: {node: '>= 0.8'}\n@@ -11073,6 +11133,9 @@ packages:\n     resolution: {integrity: sha512-XDF38WCH3z5OV/OVa8GKUNtLAyneuzbCisx7QUCF8Q6Nutx0WnJrQe5O+kOtBlLfRNUws98Y58Lblp+NJG5T4Q==}\n     hasBin: true\n \n+  peberminta@0.9.0:\n+    resolution: {integrity: sha512-XIxfHpEuSJbITd1H3EeQwpcZbTLHc+VVr8ANI9t5sit565tsI4/xK3KWTUFE2e6QiangUkh3B0jihzmGnNrRsQ==}\n+\n   perfect-debounce@1.0.0:\n     resolution: {integrity: sha512-xCy9V055GLEqoFaHoC1SoLIaLmWctgCUaBaWxDZ7/Zx4CTyX7cJQLJOok/orfjZAh9kEYpjJa4d0KcJmCbctZA==}\n \n@@ -11594,6 +11657,10 @@ packages:\n   pump@3.0.3:\n     resolution: {integrity: sha512-todwxLMY7/heScKmntwQG8CXVkWUOdYxIvY2s0VWAAMh/nd8SoYiRaKjlr7+iCs984f2P8zvrfWcDDYVb73NfA==}\n \n+  punycode.js@2.3.1:\n+    resolution: {integrity: sha512-uxFIHU0YlHYhDQtV4R9J6a52SLx28BCjT+4ieh7IGbgwVJWO+km431c4yRlREUAsAmt/uMjQUyQHNEPf0M39CA==}\n+    engines: {node: '>=6'}\n+\n   punycode@2.3.1:\n     resolution: {integrity: sha512-vYt7UD1U9Wg6138shLtLOvdAu+8DsC/ilFtEVHcH+wydcSpNE20AfSOduf6MkRFahL5FY7X1oU7nKVZFtfq8Fg==}\n     engines: {node: '>=6'}\n@@ -12093,6 +12160,9 @@ packages:\n   seedrandom@3.0.5:\n     resolution: {integrity: sha512-8OwmbklUNzwezjGInmZ+2clQmExQPvomqjL7LFqOYqtmuxRgQYqOD3mHaU+MvZn5FLUeVxVfQjwLZW/n/JFuqg==}\n \n+  selderee@0.11.0:\n+    resolution: {integrity: sha512-5TF+l7p4+OsnP8BCCvSyZiSPc4x4//p5uPwK8TCnVPJYRmU2aYKMpOXvw8zM5a5JvuuCGN1jmsMwuU2W02ukfA==}\n+\n   semver-utils@1.1.4:\n     resolution: {integrity: sha512-EjnoLE5OGmDAVV/8YDoN5KiajNadjzIp9BAHOhYeQHt7j0UWxjmgsx4YD48wp4Ue1Qogq38F1GNUJNqF1kKKxA==}\n \n@@ -12257,6 +12327,10 @@ packages:\n   smob@1.5.0:\n     resolution: {integrity: sha512-g6T+p7QO8npa+/hNx9ohv1E5pVCmWrVCUzUXJyLdMmftX6ER0oiWY/w9knEonLpnOp6b6FenKnMfR8gqwWdwig==}\n \n+  smtp-server@3.16.1:\n+    resolution: {integrity: sha512-7oUsW8+7eXOW85lV8/kMCFGGzqxI+JtNJYptR8XDgjgTNL8Bcnj3toAfDZiqg4o3XpJRQhDwKZNbKcPdxEFsTw==}\n+    engines: {node: '>=18.18.0'}\n+\n   snake-case@3.0.4:\n     resolution: {integrity: sha512-LAOh4z89bGQvl9pFfNF8V146i7o7/CqFPbqzYgP+yYzDIDeS9HaNFtXABamRW+AQzEVODcvE79ljJ+8a9YSdMg==}\n \n@@ -12838,6 +12912,10 @@ packages:\n     resolution: {integrity: sha512-azl+t0z7pw/z958Gy9svOTuzqIk6xq+NSheJzn5MMWtWTFywIacg2wUlzKFGtt3cthx0r2SxMK0yzJOR0IES7Q==}\n     engines: {node: '>=14.0.0'}\n \n+  tlds@1.261.0:\n+    resolution: {integrity: sha512-QXqwfEl9ddlGBaRFXIvNKK6OhipSiLXuRuLJX5DErz0o0Q0rYxulWLdFryTkV5PkdZct5iMInwYEGe/eR++1AA==}\n+    hasBin: true\n+\n   tmp@0.2.5:\n     resolution: {integrity: sha512-voyz6MApa1rQGUxT3E+BK7/ROe8itEx7vD8/HEvt4xwXucvQ5G5oeEiHkmHZJuBO21RpOf+YYm9MOivj709jow==}\n     engines: {node: '>=14.14'}\n@@ -13023,6 +13101,9 @@ packages:\n   uc.micro@1.0.6:\n     resolution: {integrity: sha512-8Y75pvTYkLJW2hWQHXxoqRgV7qb9B+9vFEtidML+7koHUFapnVJAZ6cKs+Qjz5Aw3aZWHMC6u0wJE3At+nSGwA==}\n \n+  uc.micro@2.1.0:\n+    resolution: {integrity: sha512-ARDJmphmdvUk6Glw7y9DQ2bFkKBHwQHLi2lsaH6PPmz/Ka9sFOBsBluozhDltWmnv9u/cF6Rt87znRTPV+yp/A==}\n+\n   ufo@1.6.1:\n     resolution: {integrity: sha512-9a4/uxlTWJ4+a5i0ooc1rU7C7YOw3wT+UGqdeNNHWnOF9qcMBgLRS+4IYUqbczewFx4mLEig6gawh7X6mFlEkA==}\n \n@@ -17742,6 +17823,11 @@ snapshots:\n \n   '@sec-ant/readable-stream@0.4.1': {}\n \n+  '@selderee/plugin-htmlparser2@0.11.0':\n+    dependencies:\n+      domhandler: 5.0.3\n+      selderee: 0.11.0\n+\n   '@shopify/semaphore@3.1.0': {}\n \n   '@sinclair/typebox@0.27.8': {}\n@@ -18337,6 +18423,11 @@ snapshots:\n \n   '@types/luxon@3.7.1': {}\n \n+  '@types/mailparser@3.4.6':\n+    dependencies:\n+      '@types/node': 24.9.1\n+      iconv-lite: 0.6.3\n+\n   '@types/mapbox-gl@3.4.1':\n     dependencies:\n       '@types/geojson': 7946.0.16\n@@ -18450,6 +18541,13 @@ snapshots:\n       '@types/node': 24.9.1\n       '@types/send': 0.17.5\n \n+  '@types/smtp-server@3.5.12':\n+    dependencies:\n+      '@types/node': 24.9.1\n+      '@types/nodemailer': 7.0.3\n+    transitivePeerDependencies:\n+      - aws-crt\n+\n   '@types/ssri@7.1.5':\n     dependencies:\n       '@types/node': 24.9.1\n@@ -19007,6 +19105,12 @@ snapshots:\n     dependencies:\n       isexe: 2.0.0\n \n+  '@zone-eu/mailsplit@5.4.7':\n+    dependencies:\n+      libbase64: 1.3.0\n+      libmime: 5.3.7\n+      libqp: 2.1.1\n+\n   JSV@4.0.2: {}\n \n   abab@2.0.6: {}\n@@ -19327,6 +19431,8 @@ snapshots:\n \n   base-64@1.0.0: {}\n \n+  base32.js@0.1.0: {}\n+\n   base64-js@1.5.1: {}\n \n   base64id@2.0.0: {}\n@@ -20317,6 +20423,8 @@ snapshots:\n \n   encodeurl@2.0.0: {}\n \n+  encoding-japanese@2.2.0: {}\n+\n   encoding@0.1.13:\n     dependencies:\n       iconv-lite: 0.6.3\n@@ -21417,6 +21525,14 @@ snapshots:\n \n   html-tags@3.3.1: {}\n \n+  html-to-text@9.0.5:\n+    dependencies:\n+      '@selderee/plugin-htmlparser2': 0.11.0\n+      deepmerge: 4.3.1\n+      dom-serializer: 2.0.0\n+      htmlparser2: 8.0.2\n+      selderee: 0.11.0\n+\n   htmlparser2@8.0.2:\n     dependencies:\n       domelementtype: 2.3.0\n@@ -21604,6 +21720,8 @@ snapshots:\n \n   ipaddr.js@1.9.1: {}\n \n+  ipv6-normalize@1.0.1: {}\n+\n   is-arrayish@0.2.1: {}\n \n   is-binary-path@2.1.0:\n@@ -22004,6 +22122,8 @@ snapshots:\n       vasync: 2.2.1\n       verror: 1.10.1\n \n+  leac@0.6.0: {}\n+\n   leven@2.1.0: {}\n \n   levn@0.4.1:\n@@ -22011,6 +22131,17 @@ snapshots:\n       prelude-ls: 1.2.1\n       type-check: 0.4.0\n \n+  libbase64@1.3.0: {}\n+\n+  libmime@5.3.7:\n+    dependencies:\n+      encoding-japanese: 2.2.0\n+      iconv-lite: 0.6.3\n+      libbase64: 1.3.0\n+      libqp: 2.1.1\n+\n+  libqp@2.1.1: {}\n+\n   lilconfig@3.1.3: {}\n \n   lines-and-columns@1.2.4: {}\n@@ -22019,6 +22150,10 @@ snapshots:\n     dependencies:\n       uc.micro: 1.0.6\n \n+  linkify-it@5.0.0:\n+    dependencies:\n+      uc.micro: 2.1.0\n+\n   liquidjs@10.24.0:\n     dependencies:\n       commander: 10.0.1\n@@ -22218,6 +22353,19 @@ snapshots:\n       - debug\n     optional: true\n \n+  mailparser@3.9.0:\n+    dependencies:\n+      '@zone-eu/mailsplit': 5.4.7\n+      encoding-japanese: 2.2.0\n+      he: 1.2.0\n+      html-to-text: 9.0.5\n+      iconv-lite: 0.7.0\n+      libmime: 5.3.7\n+      linkify-it: 5.0.0\n+      nodemailer: 7.0.10\n+      punycode.js: 2.3.1\n+      tlds: 1.261.0\n+\n   make-dir@4.0.0:\n     dependencies:\n       semver: 7.7.3\n@@ -23118,6 +23266,11 @@ snapshots:\n     dependencies:\n       entities: 6.0.1\n \n+  parseley@0.12.1:\n+    dependencies:\n+      leac: 0.6.0\n+      peberminta: 0.9.0\n+\n   parseurl@1.3.3: {}\n \n   pascal-case@3.1.2:\n@@ -23197,6 +23350,8 @@ snapshots:\n       ieee754: 1.2.1\n       resolve-protobuf-schema: 2.1.0\n \n+  peberminta@0.9.0: {}\n+\n   perfect-debounce@1.0.0: {}\n \n   pg-cloudflare@1.2.7:\n@@ -23799,6 +23954,8 @@ snapshots:\n       end-of-stream: 1.4.5\n       once: 1.4.0\n \n+  punycode.js@2.3.1: {}\n+\n   punycode@2.3.1: {}\n \n   qified@0.5.1:\n@@ -24390,6 +24547,10 @@ snapshots:\n \n   seedrandom@3.0.5: {}\n \n+  selderee@0.11.0:\n+    dependencies:\n+      parseley: 0.12.1\n+\n   semver-utils@1.1.4: {}\n \n   semver@5.7.2: {}\n@@ -24607,6 +24768,13 @@ snapshots:\n \n   smob@1.5.0: {}\n \n+  smtp-server@3.16.1:\n+    dependencies:\n+      base32.js: 0.1.0\n+      ipv6-normalize: 1.0.1\n+      nodemailer: 7.0.10\n+      punycode.js: 2.3.1\n+\n   snake-case@3.0.4:\n     dependencies:\n       dot-case: 3.0.4\n@@ -25307,6 +25475,8 @@ snapshots:\n \n   tinyspy@4.0.4: {}\n \n+  tlds@1.261.0: {}\n+\n   tmp@0.2.5: {}\n \n   to-regex-range@5.0.1:\n@@ -25471,6 +25641,8 @@ snapshots:\n \n   uc.micro@1.0.6: {}\n \n+  uc.micro@2.1.0: {}\n+\n   ufo@1.6.1: {}\n \n   uid-number@0.0.6: {}\ndiff --git a/tests/blackbox/common/config.ts b/tests/blackbox/common/config.ts\nindex 4c3652ef7c538..3d3c2e7859b84 100644\n--- a/tests/blackbox/common/config.ts\n+++ b/tests/blackbox/common/config.ts\n@@ -92,6 +92,9 @@ const directusConfig = {\n \tACCESS_TOKEN_TTL: '25d', // should be larger than 24.86 days to test Expires value larger than 32-bit signed integer\n \tWEBSOCKETS_ENABLED: 'true',\n \tTUS_ENABLED: 'true',\n+\tEMAIL_TRANSPORT: 'smtp',\n+\tEMAIL_SMTP_HOST: '127.0.0.1',\n+\tEMAIL_SMTP_PORT: '1025',\n \t...directusAuthConfig,\n \t...directusStorageConfig,\n };\ndiff --git a/tests/blackbox/package.json b/tests/blackbox/package.json\nindex 48a0f0a0b33d5..6889b938169bf 100644\n--- a/tests/blackbox/package.json\n+++ b/tests/blackbox/package.json\n@@ -14,11 +14,15 @@\n \t\t\"tus-js-client\": \"catalog:\",\n \t\t\"@types/js-yaml\": \"catalog:\",\n \t\t\"@types/lodash-es\": \"catalog:\",\n+\t\t\"@types/mailparser\": \"3.4.6\",\n \t\t\"@types/seedrandom\": \"3.0.8\",\n+\t\t\"@types/smtp-server\": \"3.5.12\",\n \t\t\"@types/supertest\": \"6.0.2\",\n \t\t\"@types/ws\": \"catalog:\",\n \t\t\"argon2\": \"catalog:\",\n \t\t\"autocannon\": \"8.0.0\",\n+\t\t\"smtp-server\": \"3.16.1\",\n+\t\t\"mailparser\": \"3.9.0\",\n \t\t\"axios\": \"catalog:\",\n \t\t\"get-port\": \"catalog:\",\n \t\t\"globby\": \"14.1.0\",\ndiff --git a/tests/blackbox/setup/sequential-tests.ts b/tests/blackbox/setup/sequential-tests.ts\nindex 7409c03d23bf2..e43f25d28f88a 100644\n--- a/tests/blackbox/setup/sequential-tests.ts\n+++ b/tests/blackbox/setup/sequential-tests.ts\n@@ -16,6 +16,7 @@ export const sequentialTestsList: Record<'db' | 'common', SequentialTestsList> =\n \t\t\t'/tests/db/routes/collections/crud.test.ts',\n \t\t\t'/tests/db/routes/fields/change-fields.test.ts',\n \t\t\t'/tests/db/routes/fields/crud.test.ts',\n+\t\t\t'/tests/db/routes/items/version.test.ts',\n \t\t],\n \t\tafter: [\n \t\t\t'/tests/db/schema/timezone/timezone.test.ts',\ndiff --git a/tests/blackbox/tests/db/mail/mail.test.ts b/tests/blackbox/tests/db/mail/mail.test.ts\nnew file mode 100644\nindex 0000000000000..6f99b344d5a07\n--- /dev/null\n+++ b/tests/blackbox/tests/db/mail/mail.test.ts\n@@ -0,0 +1,80 @@\n+import { getUrl } from '@common/config';\n+import vendors from '@common/get-dbs-to-test';\n+import { USER } from '@common/variables';\n+import { sleep } from '@utils/sleep';\n+import { simpleParser, type ParsedMail } from 'mailparser';\n+import { SMTPServer } from 'smtp-server';\n+import request from 'supertest';\n+import { afterAll, beforeAll, beforeEach, describe, expect, it } from 'vitest';\n+\n+describe('Mail', async () => {\n+\tlet fakeSMTPServer: SMTPServer;\n+\tlet messages: ParsedMail[] = [];\n+\n+\tbeforeAll(async () => {\n+\t\tfakeSMTPServer = new SMTPServer({\n+\t\t\tauthOptional: true,\n+\t\t\thideSTARTTLS: true,\n+\t\t\tonData(stream, _, cb) {\n+\t\t\t\tsimpleParser(stream, (err, message) => {\n+\t\t\t\t\tif (err) {\n+\t\t\t\t\t\treturn cb();\n+\t\t\t\t\t}\n+\n+\t\t\t\t\tmessages.push(message);\n+\t\t\t\t\tcb();\n+\t\t\t\t});\n+\t\t\t},\n+\t\t});\n+\n+\t\tawait new Promise<void>((resolve) =>\n+\t\t\tfakeSMTPServer.listen(1025, '127.0.0.1', () => {\n+\t\t\t\tresolve();\n+\t\t\t}),\n+\t\t);\n+\t}, 180_000);\n+\n+\tafterAll(async () => {\n+\t\tawait new Promise<void>((resolve) =>\n+\t\t\tfakeSMTPServer.close(() => {\n+\t\t\t\tresolve();\n+\t\t\t}),\n+\t\t);\n+\t});\n+\n+\tbeforeEach(() => {\n+\t\tmessages = [];\n+\t});\n+\n+\tdescribe('POST /notifications', () => {\n+\t\tit.each(vendors)('%s', async (vendor) => {\n+\t\t\t// Setup\n+\t\t\tconst notifications = [\n+\t\t\t\t{\n+\t\t\t\t\trecipient: USER.TESTS_FLOW.ID,\n+\t\t\t\t\tsubject: 'inbox',\n+\t\t\t\t\tmessage: 'Lorem Ipsum',\n+\t\t\t\t},\n+\t\t\t\t{\n+\t\t\t\t\trecipient: USER.TESTS_FLOW.ID,\n+\t\t\t\t\tsubject: 'inbox',\n+\t\t\t\t\tmessage: 'Dolor Sat',\n+\t\t\t\t},\n+\t\t\t];\n+\n+\t\t\t// action\n+\t\t\tconst response = await request(getUrl(vendor))\n+\t\t\t\t.post('/notifications')\n+\t\t\t\t.set('Authorization', `Bearer ${USER.ADMIN.TOKEN}`)\n+\t\t\t\t.send(notifications);\n+\n+\t\t\t// Checks\n+\t\t\texpect(response.status).toEqual(200);\n+\n+\t\t\t// wait for mail to arrive\n+\t\t\tawait sleep(5000);\n+\n+\t\t\texpect(messages).toHaveLength(2);\n+\t\t});\n+\t});\n+});\ndiff --git a/tests/blackbox/tests/db/routes/server/health.test.ts b/tests/blackbox/tests/db/routes/server/health.test.ts\nindex d7bf255bb1f82..1c2488ffbee08 100644\n--- a/tests/blackbox/tests/db/routes/server/health.test.ts\n+++ b/tests/blackbox/tests/db/routes/server/health.test.ts\n@@ -2,11 +2,38 @@ import { getUrl } from '@common/config';\n import vendors from '@common/get-dbs-to-test';\n import { requestGraphQL } from '@common/transport';\n import { TEST_USERS, USER } from '@common/variables';\n+import { SMTPServer } from 'smtp-server';\n import request from 'supertest';\n-import { describe, expect, it } from 'vitest';\n+import { afterAll, beforeAll, describe, expect, it } from 'vitest';\n \n describe('/server', () => {\n \tdescribe('GET /health', () => {\n+\t\tlet fakeSMTPServer: SMTPServer;\n+\n+\t\tbeforeAll(async () => {\n+\t\t\tfakeSMTPServer = new SMTPServer({\n+\t\t\t\tauthOptional: true,\n+\t\t\t\thideSTARTTLS: true,\n+\t\t\t\tonData(_stream, _, cb) {\n+\t\t\t\t\tcb();\n+\t\t\t\t},\n+\t\t\t});\n+\n+\t\t\tawait new Promise<void>((resolve) =>\n+\t\t\t\tfakeSMTPServer.listen(1025, '127.0.0.1', () => {\n+\t\t\t\t\tresolve();\n+\t\t\t\t}),\n+\t\t\t);\n+\t\t}, 180_000);\n+\n+\t\tafterAll(async () => {\n+\t\t\tawait new Promise<void>((resolve) =>\n+\t\t\t\tfakeSMTPServer.close(() => {\n+\t\t\t\t\tresolve();\n+\t\t\t\t}),\n+\t\t\t);\n+\t\t});\n+\n \t\tTEST_USERS.forEach((userKey) => {\n \t\t\tdescribe(USER[userKey].NAME, () => {\n \t\t\t\tit.each(vendors)('%s', async (vendor) => {\n", "test_patch": "", "problem_statement": "## Scope\r\n\r\nWhat's changed:\r\n\r\n- Added an option to passing the defaultTemplateData removing the race condition while providing backwards compatiblity\r\n\r\n## Potential Risks / Drawbacks\r\n\r\n- Should be none as we default to default behaviour\r\n\r\n## Tested Scenarios\r\n\r\n- [x] Expect send operation to send email with no error\r\n- [x] Expect notification operation to send email with no error\r\n\r\n## Review Notes / Questions\r\n\r\n- The issue here is due to the additional await from the emailQueue the transaction sometimes completes before the query is triggered resulting in the reported error being logged.\r\n- Open to alternative suggestions in regards to solution.\r\n\r\n## Checklist\r\n\r\n- [x] Added or updated tests \r\n- [ ] Documentation PR created [here](https://github.com/directus/docs) or not required\r\n- [ ] OpenAPI package PR created [here](https://github.com/directus/openapi) or not required\r\n\r\n---\r\n\r\nFixes #26210\r\n", "hints_text": "", "created_at": "2025-11-17T20:26:35Z", "pull_number": 26213, "test_files": ["tests/blackbox/tests/db/mail/mail.test.ts", "tests/blackbox/tests/db/routes/server/health.test.ts"], "code_files": ["api/src/services/mail/index.ts", "api/src/services/notifications.ts", "tests/blackbox/common/config.ts", "tests/blackbox/setup/sequential-tests.ts"], "title": "Fix notification emails failing due to transaction race condition", "additions": 0, "deletions": 0}
{"repo": "directus/directus", "instance_id": "directus__directus.pr_mirror.26179", "base_commit": "4ed1ba707c075e555106f1289cd1b7c24198142c", "patch": "diff --git a/api/src/ai/chat/controllers/chat.post.test.ts b/api/src/ai/chat/controllers/chat.post.test.ts\nindex 99f3af48cd20c..af14c8e107f9c 100644\n--- a/api/src/ai/chat/controllers/chat.post.test.ts\n+++ b/api/src/ai/chat/controllers/chat.post.test.ts\n@@ -195,14 +195,13 @@ describe('aiChatPostHandler', () => {\n \t\t\t\ttools: [],\n \t\t\t};\n \n-\t\t\tawait expect(aiChatPostHandler(mockReq as Request, mockRes as Response, vi.fn())).rejects.toThrow(\n-\t\t\t\tInvalidPayloadError,\n-\t\t\t);\n+\t\tawait expect(aiChatPostHandler(mockReq as Request, mockRes as Response, vi.fn())).rejects.toThrow(\n+\t\t\tInvalidPayloadError,\n+\t\t);\n \n-\t\t\texpect(vi.mocked(safeValidateUIMessages)).toHaveBeenCalledWith({\n-\t\t\t\tmessages: [{ role: 'invalid', content: 'test' }],\n-\t\t\t\ttools: {},\n-\t\t\t});\n+\t\texpect(vi.mocked(safeValidateUIMessages)).toHaveBeenCalledWith({\n+\t\t\tmessages: [{ role: 'invalid', content: 'test' }],\n+\t\t});\n \t\t});\n \n \t\tit('should call safeValidateUIMessages with correct messages', async () => {\n@@ -218,10 +217,10 @@ describe('aiChatPostHandler', () => {\n \t\t\t\ttools: [],\n \t\t\t};\n \n-\t\t\tawait aiChatPostHandler(mockReq as Request, mockRes as Response, vi.fn());\n+\t\tawait aiChatPostHandler(mockReq as Request, mockRes as Response, vi.fn());\n \n-\t\t\texpect(vi.mocked(safeValidateUIMessages)).toHaveBeenCalledWith({ messages, tools: {} });\n-\t\t});\n+\t\texpect(vi.mocked(safeValidateUIMessages)).toHaveBeenCalledWith({ messages });\n+\t});\n \t});\n \n \tdescribe('api keys handling', () => {\n@@ -287,10 +286,9 @@ describe('aiChatPostHandler', () => {\n \t\t\t\tcustom: { name: 'custom', mocked: true },\n \t\t\t};\n \n-\t\t\texpect(vi.mocked(safeValidateUIMessages)).toHaveBeenCalledWith({\n-\t\t\t\tmessages: [{ role: 'user', content: 'Hello' }],\n-\t\t\t\ttools: expectedTools,\n-\t\t\t});\n+\t\texpect(vi.mocked(safeValidateUIMessages)).toHaveBeenCalledWith({\n+\t\t\tmessages: [{ role: 'user', content: 'Hello' }],\n+\t\t});\n \n \t\t\texpect(vi.mocked(createUiStream)).toHaveBeenCalledWith(expect.any(Array), {\n \t\t\t\tprovider: 'openai',\ndiff --git a/api/src/ai/chat/controllers/chat.post.ts b/api/src/ai/chat/controllers/chat.post.ts\nindex a8ad1efca47b9..75596b7c93665 100644\n--- a/api/src/ai/chat/controllers/chat.post.ts\n+++ b/api/src/ai/chat/controllers/chat.post.ts\n@@ -5,6 +5,7 @@ import { fromZodError } from 'zod-validation-error';\n import { createUiStream } from '../lib/create-ui-stream.js';\n import { ChatRequest } from '../models/chat-request.js';\n import { chatRequestToolToAiSdkTool } from '../utils/chat-request-tool-to-ai-sdk-tool.js';\n+import { fixErrorToolCalls } from '../utils/fix-error-tool-calls.js';\n \n export const aiChatPostHandler: RequestHandler = async (req, res) => {\n \tif (!req.accountability) {\n@@ -30,7 +31,8 @@ export const aiChatPostHandler: RequestHandler = async (req, res) => {\n \t\treturn acc;\n \t}, {});\n \n-\tconst validationResult = await safeValidateUIMessages({ messages: rawMessages, tools: tools });\n+\tconst fixedMessages = fixErrorToolCalls(rawMessages);\n+\tconst validationResult = await safeValidateUIMessages({ messages: fixedMessages });\n \n \tif (validationResult.success === false) {\n \t\tthrow new InvalidPayloadError({ reason: validationResult.error.message });\ndiff --git a/api/src/ai/chat/lib/create-ui-stream.ts b/api/src/ai/chat/lib/create-ui-stream.ts\nindex c89c140a8e6b1..d6e032305769f 100644\n--- a/api/src/ai/chat/lib/create-ui-stream.ts\n+++ b/api/src/ai/chat/lib/create-ui-stream.ts\n@@ -45,7 +45,9 @@ export const createUiStream = (\n \t\tstopWhen: [stepCountIs(10)],\n \t\tproviderOptions: {\n \t\t\topenai: {\n-\t\t\t\treasoningSummary: 'detailed',\n+\t\t\t\treasoningSummary: 'auto',\n+\t\t\t\tstore: false,\n+\t\t\t\tinclude: ['reasoning.encrypted_content'],\n \t\t\t},\n \t\t},\n \t\ttools,\ndiff --git a/api/src/ai/chat/utils/fix-error-tool-calls.test.ts b/api/src/ai/chat/utils/fix-error-tool-calls.test.ts\nnew file mode 100644\nindex 0000000000000..a885c7f1a4b09\n--- /dev/null\n+++ b/api/src/ai/chat/utils/fix-error-tool-calls.test.ts\n@@ -0,0 +1,454 @@\n+import { describe, expect, it } from 'vitest';\n+import { fixErrorToolCalls } from './fix-error-tool-calls.js';\n+\n+describe('fixErrorToolCalls', () => {\n+\tit('copies rawInput to input for error tool call without input', () => {\n+\t\tconst messages = [\n+\t\t\t{\n+\t\t\t\trole: 'assistant',\n+\t\t\t\tparts: [\n+\t\t\t\t\t{\n+\t\t\t\t\t\ttype: 'tool-input-available',\n+\t\t\t\t\t\tstate: 'output-error',\n+\t\t\t\t\t\ttoolCallId: 'call_123',\n+\t\t\t\t\t\ttoolName: 'test-tool',\n+\t\t\t\t\t\trawInput: { foo: 'bar' },\n+\t\t\t\t\t\terrorText: 'Something went wrong',\n+\t\t\t\t\t},\n+\t\t\t\t],\n+\t\t\t},\n+\t\t] as const;\n+\n+\t\tconst result = fixErrorToolCalls(messages as any);\n+\n+\t\texpect(result).toEqual([\n+\t\t\t{\n+\t\t\t\trole: 'assistant',\n+\t\t\t\tparts: [\n+\t\t\t\t\t{\n+\t\t\t\t\t\ttype: 'tool-input-available',\n+\t\t\t\t\t\tstate: 'output-error',\n+\t\t\t\t\t\ttoolCallId: 'call_123',\n+\t\t\t\t\t\ttoolName: 'test-tool',\n+\t\t\t\t\t\trawInput: { foo: 'bar' },\n+\t\t\t\t\t\tinput: { foo: 'bar' },\n+\t\t\t\t\t\terrorText: 'Something went wrong',\n+\t\t\t\t\t},\n+\t\t\t\t],\n+\t\t\t},\n+\t\t]);\n+\t});\n+\n+\tit('does not modify error tool call that already has input', () => {\n+\t\tconst messages = [\n+\t\t\t{\n+\t\t\t\trole: 'assistant',\n+\t\t\t\tparts: [\n+\t\t\t\t\t{\n+\t\t\t\t\t\ttype: 'tool-input-available',\n+\t\t\t\t\t\tstate: 'output-error',\n+\t\t\t\t\t\ttoolCallId: 'call_456',\n+\t\t\t\t\t\ttoolName: 'test-tool',\n+\t\t\t\t\t\trawInput: { raw: 'data' },\n+\t\t\t\t\t\tinput: { existing: 'input' },\n+\t\t\t\t\t\terrorText: 'Error occurred',\n+\t\t\t\t\t},\n+\t\t\t\t],\n+\t\t\t},\n+\t\t] as const;\n+\n+\t\tconst result = fixErrorToolCalls(messages as any);\n+\n+\t\texpect(result).toEqual(messages);\n+\t});\n+\n+\tit('does not modify error tool call with only input (no rawInput)', () => {\n+\t\tconst messages = [\n+\t\t\t{\n+\t\t\t\trole: 'assistant',\n+\t\t\t\tparts: [\n+\t\t\t\t\t{\n+\t\t\t\t\t\ttype: 'tool-input-available',\n+\t\t\t\t\t\tstate: 'output-error',\n+\t\t\t\t\t\ttoolCallId: 'call_789',\n+\t\t\t\t\t\ttoolName: 'test-tool',\n+\t\t\t\t\t\tinput: { only: 'input' },\n+\t\t\t\t\t\terrorText: 'Error message',\n+\t\t\t\t\t},\n+\t\t\t\t],\n+\t\t\t},\n+\t\t] as const;\n+\n+\t\tconst result = fixErrorToolCalls(messages as any);\n+\n+\t\texpect(result).toEqual(messages);\n+\t});\n+\n+\tit('does not modify successful tool call', () => {\n+\t\tconst messages = [\n+\t\t\t{\n+\t\t\t\trole: 'assistant',\n+\t\t\t\tparts: [\n+\t\t\t\t\t{\n+\t\t\t\t\t\ttype: 'tool-output',\n+\t\t\t\t\t\tstate: 'output-available',\n+\t\t\t\t\t\ttoolCallId: 'call_success',\n+\t\t\t\t\t\ttoolName: 'test-tool',\n+\t\t\t\t\t\toutput: { result: 'success' },\n+\t\t\t\t\t},\n+\t\t\t\t],\n+\t\t\t},\n+\t\t] as const;\n+\n+\t\tconst result = fixErrorToolCalls(messages as any);\n+\n+\t\texpect(result).toEqual(messages);\n+\t});\n+\n+\tit('does not modify tool call without state field', () => {\n+\t\tconst messages = [\n+\t\t\t{\n+\t\t\t\trole: 'assistant',\n+\t\t\t\tparts: [\n+\t\t\t\t\t{\n+\t\t\t\t\t\ttype: 'tool-input-available',\n+\t\t\t\t\t\ttoolCallId: 'call_in_progress',\n+\t\t\t\t\t\ttoolName: 'test-tool',\n+\t\t\t\t\t\tinput: { pending: 'data' },\n+\t\t\t\t\t},\n+\t\t\t\t],\n+\t\t\t},\n+\t\t] as const;\n+\n+\t\tconst result = fixErrorToolCalls(messages as any);\n+\n+\t\texpect(result).toEqual(messages);\n+\t});\n+\n+\tit('fixes multiple error tool calls in single assistant message', () => {\n+\t\tconst messages = [\n+\t\t\t{\n+\t\t\t\trole: 'assistant',\n+\t\t\t\tparts: [\n+\t\t\t\t\t{\n+\t\t\t\t\t\ttype: 'tool-input-available',\n+\t\t\t\t\t\tstate: 'output-error',\n+\t\t\t\t\t\ttoolCallId: 'call_1',\n+\t\t\t\t\t\ttoolName: 'tool-1',\n+\t\t\t\t\t\trawInput: { data: 1 },\n+\t\t\t\t\t\terrorText: 'Error 1',\n+\t\t\t\t\t},\n+\t\t\t\t\t{\n+\t\t\t\t\t\ttype: 'tool-input-available',\n+\t\t\t\t\t\tstate: 'output-error',\n+\t\t\t\t\t\ttoolCallId: 'call_2',\n+\t\t\t\t\t\ttoolName: 'tool-2',\n+\t\t\t\t\t\trawInput: { data: 2 },\n+\t\t\t\t\t\terrorText: 'Error 2',\n+\t\t\t\t\t},\n+\t\t\t\t],\n+\t\t\t},\n+\t\t] as const;\n+\n+\t\tconst result = fixErrorToolCalls(messages as any);\n+\n+\t\texpect(result).toEqual([\n+\t\t\t{\n+\t\t\t\trole: 'assistant',\n+\t\t\t\tparts: [\n+\t\t\t\t\t{\n+\t\t\t\t\t\ttype: 'tool-input-available',\n+\t\t\t\t\t\tstate: 'output-error',\n+\t\t\t\t\t\ttoolCallId: 'call_1',\n+\t\t\t\t\t\ttoolName: 'tool-1',\n+\t\t\t\t\t\trawInput: { data: 1 },\n+\t\t\t\t\t\tinput: { data: 1 },\n+\t\t\t\t\t\terrorText: 'Error 1',\n+\t\t\t\t\t},\n+\t\t\t\t\t{\n+\t\t\t\t\t\ttype: 'tool-input-available',\n+\t\t\t\t\t\tstate: 'output-error',\n+\t\t\t\t\t\ttoolCallId: 'call_2',\n+\t\t\t\t\t\ttoolName: 'tool-2',\n+\t\t\t\t\t\trawInput: { data: 2 },\n+\t\t\t\t\t\tinput: { data: 2 },\n+\t\t\t\t\t\terrorText: 'Error 2',\n+\t\t\t\t\t},\n+\t\t\t\t],\n+\t\t\t},\n+\t\t]);\n+\t});\n+\n+\tit('handles assistant message with mixed parts', () => {\n+\t\tconst messages = [\n+\t\t\t{\n+\t\t\t\trole: 'assistant',\n+\t\t\t\tparts: [\n+\t\t\t\t\t{\n+\t\t\t\t\t\ttype: 'text',\n+\t\t\t\t\t\ttext: 'Let me help you with that',\n+\t\t\t\t\t},\n+\t\t\t\t\t{\n+\t\t\t\t\t\ttype: 'reasoning',\n+\t\t\t\t\t\treasoning: 'I need to call a tool',\n+\t\t\t\t\t},\n+\t\t\t\t\t{\n+\t\t\t\t\t\ttype: 'tool-input-available',\n+\t\t\t\t\t\tstate: 'output-error',\n+\t\t\t\t\t\ttoolCallId: 'call_error',\n+\t\t\t\t\t\ttoolName: 'error-tool',\n+\t\t\t\t\t\trawInput: { x: 1 },\n+\t\t\t\t\t\terrorText: 'Failed',\n+\t\t\t\t\t},\n+\t\t\t\t\t{\n+\t\t\t\t\t\ttype: 'tool-output',\n+\t\t\t\t\t\tstate: 'output-available',\n+\t\t\t\t\t\ttoolCallId: 'call_success',\n+\t\t\t\t\t\ttoolName: 'success-tool',\n+\t\t\t\t\t\toutput: { y: 2 },\n+\t\t\t\t\t},\n+\t\t\t\t],\n+\t\t\t},\n+\t\t] as const;\n+\n+\t\tconst result = fixErrorToolCalls(messages as any);\n+\n+\t\texpect(result).toEqual([\n+\t\t\t{\n+\t\t\t\trole: 'assistant',\n+\t\t\t\tparts: [\n+\t\t\t\t\t{\n+\t\t\t\t\t\ttype: 'text',\n+\t\t\t\t\t\ttext: 'Let me help you with that',\n+\t\t\t\t\t},\n+\t\t\t\t\t{\n+\t\t\t\t\t\ttype: 'reasoning',\n+\t\t\t\t\t\treasoning: 'I need to call a tool',\n+\t\t\t\t\t},\n+\t\t\t\t\t{\n+\t\t\t\t\t\ttype: 'tool-input-available',\n+\t\t\t\t\t\tstate: 'output-error',\n+\t\t\t\t\t\ttoolCallId: 'call_error',\n+\t\t\t\t\t\ttoolName: 'error-tool',\n+\t\t\t\t\t\trawInput: { x: 1 },\n+\t\t\t\t\t\tinput: { x: 1 },\n+\t\t\t\t\t\terrorText: 'Failed',\n+\t\t\t\t\t},\n+\t\t\t\t\t{\n+\t\t\t\t\t\ttype: 'tool-output',\n+\t\t\t\t\t\tstate: 'output-available',\n+\t\t\t\t\t\ttoolCallId: 'call_success',\n+\t\t\t\t\t\ttoolName: 'success-tool',\n+\t\t\t\t\t\toutput: { y: 2 },\n+\t\t\t\t\t},\n+\t\t\t\t],\n+\t\t\t},\n+\t\t]);\n+\t});\n+\n+\tit('does not modify user message', () => {\n+\t\tconst messages = [\n+\t\t\t{\n+\t\t\t\trole: 'user',\n+\t\t\t\tcontent: 'Hello, how are you?',\n+\t\t\t},\n+\t\t] as const;\n+\n+\t\tconst result = fixErrorToolCalls(messages as any);\n+\n+\t\texpect(result).toEqual(messages);\n+\t});\n+\n+\tit('returns empty array for empty messages array', () => {\n+\t\tconst messages = [] as const;\n+\n+\t\tconst result = fixErrorToolCalls(messages as any);\n+\n+\t\texpect(result).toEqual([]);\n+\t});\n+\n+\tit('does not modify message without parts field', () => {\n+\t\tconst messages = [\n+\t\t\t{\n+\t\t\t\trole: 'assistant',\n+\t\t\t\tcontent: 'This is a simple response',\n+\t\t\t},\n+\t\t] as const;\n+\n+\t\tconst result = fixErrorToolCalls(messages as any);\n+\n+\t\texpect(result).toEqual(messages);\n+\t});\n+\n+\tit('handles error tool call with input set to undefined explicitly', () => {\n+\t\tconst messages = [\n+\t\t\t{\n+\t\t\t\trole: 'assistant',\n+\t\t\t\tparts: [\n+\t\t\t\t\t{\n+\t\t\t\t\t\ttype: 'tool-input-available',\n+\t\t\t\t\t\tstate: 'output-error',\n+\t\t\t\t\t\ttoolCallId: 'call_undefined',\n+\t\t\t\t\t\ttoolName: 'test-tool',\n+\t\t\t\t\t\trawInput: { should: 'copy' },\n+\t\t\t\t\t\tinput: undefined,\n+\t\t\t\t\t\terrorText: 'Error',\n+\t\t\t\t\t},\n+\t\t\t\t],\n+\t\t\t},\n+\t\t] as const;\n+\n+\t\tconst result = fixErrorToolCalls(messages as any);\n+\n+\t\texpect(result).toEqual([\n+\t\t\t{\n+\t\t\t\trole: 'assistant',\n+\t\t\t\tparts: [\n+\t\t\t\t\t{\n+\t\t\t\t\t\ttype: 'tool-input-available',\n+\t\t\t\t\t\tstate: 'output-error',\n+\t\t\t\t\t\ttoolCallId: 'call_undefined',\n+\t\t\t\t\t\ttoolName: 'test-tool',\n+\t\t\t\t\t\trawInput: { should: 'copy' },\n+\t\t\t\t\t\tinput: { should: 'copy' },\n+\t\t\t\t\t\terrorText: 'Error',\n+\t\t\t\t\t},\n+\t\t\t\t],\n+\t\t\t},\n+\t\t]);\n+\t});\n+\n+\tit('handles error tool call with input set to null explicitly', () => {\n+\t\tconst messages = [\n+\t\t\t{\n+\t\t\t\trole: 'assistant',\n+\t\t\t\tparts: [\n+\t\t\t\t\t{\n+\t\t\t\t\t\ttype: 'tool-input-available',\n+\t\t\t\t\t\tstate: 'output-error',\n+\t\t\t\t\t\ttoolCallId: 'call_null',\n+\t\t\t\t\t\ttoolName: 'test-tool',\n+\t\t\t\t\t\trawInput: { should: 'copy' },\n+\t\t\t\t\t\tinput: null,\n+\t\t\t\t\t\terrorText: 'Error',\n+\t\t\t\t\t},\n+\t\t\t\t],\n+\t\t\t},\n+\t\t] as const;\n+\n+\t\tconst result = fixErrorToolCalls(messages as any);\n+\n+\t\texpect(result).toEqual([\n+\t\t\t{\n+\t\t\t\trole: 'assistant',\n+\t\t\t\tparts: [\n+\t\t\t\t\t{\n+\t\t\t\t\t\ttype: 'tool-input-available',\n+\t\t\t\t\t\tstate: 'output-error',\n+\t\t\t\t\t\ttoolCallId: 'call_null',\n+\t\t\t\t\t\ttoolName: 'test-tool',\n+\t\t\t\t\t\trawInput: { should: 'copy' },\n+\t\t\t\t\t\tinput: { should: 'copy' },\n+\t\t\t\t\t\terrorText: 'Error',\n+\t\t\t\t\t},\n+\t\t\t\t],\n+\t\t\t},\n+\t\t]);\n+\t});\n+\n+\tit('handles complex nested rawInput objects', () => {\n+\t\tconst messages = [\n+\t\t\t{\n+\t\t\t\trole: 'assistant',\n+\t\t\t\tparts: [\n+\t\t\t\t\t{\n+\t\t\t\t\t\ttype: 'tool-input-available',\n+\t\t\t\t\t\tstate: 'output-error',\n+\t\t\t\t\t\ttoolCallId: 'call_complex',\n+\t\t\t\t\t\ttoolName: 'complex-tool',\n+\t\t\t\t\t\trawInput: {\n+\t\t\t\t\t\t\tnested: {\n+\t\t\t\t\t\t\t\tdata: [1, 2, 3],\n+\t\t\t\t\t\t\t\tobj: { key: 'value' },\n+\t\t\t\t\t\t\t},\n+\t\t\t\t\t\t\tarray: ['a', 'b', 'c'],\n+\t\t\t\t\t\t},\n+\t\t\t\t\t\terrorText: 'Complex error',\n+\t\t\t\t\t},\n+\t\t\t\t],\n+\t\t\t},\n+\t\t] as const;\n+\n+\t\tconst result = fixErrorToolCalls(messages as any);\n+\n+\t\texpect(result[0]?.parts?.[0]).toHaveProperty('input', {\n+\t\t\tnested: {\n+\t\t\t\tdata: [1, 2, 3],\n+\t\t\t\tobj: { key: 'value' },\n+\t\t\t},\n+\t\t\tarray: ['a', 'b', 'c'],\n+\t\t});\n+\t});\n+\n+\tit('does not modify non-tool part types', () => {\n+\t\tconst messages = [\n+\t\t\t{\n+\t\t\t\trole: 'assistant',\n+\t\t\t\tparts: [\n+\t\t\t\t\t{\n+\t\t\t\t\t\ttype: 'text',\n+\t\t\t\t\t\ttext: 'Some text',\n+\t\t\t\t\t},\n+\t\t\t\t\t{\n+\t\t\t\t\t\ttype: 'image',\n+\t\t\t\t\t\turl: 'https://example.com/image.png',\n+\t\t\t\t\t},\n+\t\t\t\t],\n+\t\t\t},\n+\t\t] as const;\n+\n+\t\tconst result = fixErrorToolCalls(messages as any);\n+\n+\t\texpect(result).toEqual(messages);\n+\t});\n+\n+\tit('handles multiple messages with mixed scenarios', () => {\n+\t\tconst messages = [\n+\t\t\t{\n+\t\t\t\trole: 'user',\n+\t\t\t\tcontent: 'User message',\n+\t\t\t},\n+\t\t\t{\n+\t\t\t\trole: 'assistant',\n+\t\t\t\tparts: [\n+\t\t\t\t\t{\n+\t\t\t\t\t\ttype: 'tool-input-available',\n+\t\t\t\t\t\tstate: 'output-error',\n+\t\t\t\t\t\ttoolCallId: 'call_1',\n+\t\t\t\t\t\ttoolName: 'tool-1',\n+\t\t\t\t\t\trawInput: { fix: 'me' },\n+\t\t\t\t\t\terrorText: 'Error 1',\n+\t\t\t\t\t},\n+\t\t\t\t],\n+\t\t\t},\n+\t\t\t{\n+\t\t\t\trole: 'assistant',\n+\t\t\t\tparts: [\n+\t\t\t\t\t{\n+\t\t\t\t\t\ttype: 'tool-output',\n+\t\t\t\t\t\tstate: 'output-available',\n+\t\t\t\t\t\ttoolCallId: 'call_2',\n+\t\t\t\t\t\ttoolName: 'tool-2',\n+\t\t\t\t\t\toutput: { success: true },\n+\t\t\t\t\t},\n+\t\t\t\t],\n+\t\t\t},\n+\t\t] as const;\n+\n+\t\tconst result = fixErrorToolCalls(messages as any);\n+\n+\t\texpect(result[0]).toEqual(messages[0]);\n+\t\texpect(result[1]?.parts?.[0]).toHaveProperty('input', { fix: 'me' });\n+\t\texpect(result[2]).toEqual(messages[2]);\n+\t});\n+});\ndiff --git a/api/src/ai/chat/utils/fix-error-tool-calls.ts b/api/src/ai/chat/utils/fix-error-tool-calls.ts\nnew file mode 100644\nindex 0000000000000..44069d7f5413c\n--- /dev/null\n+++ b/api/src/ai/chat/utils/fix-error-tool-calls.ts\n@@ -0,0 +1,37 @@\n+import type { UIMessage } from 'ai';\n+\n+/**\n+ * Fixes tool calls with error states by copying rawInput to input field.\n+ * This is required because error tool calls from the frontend use rawInput\n+ * but the AI SDK's convertToModelMessages expects input to generate arguments\n+ * for the OpenAI API.\n+ * @param messages - Array of message objects from the chat request\n+ * @returns Messages with error tool calls fixed, typed as UIMessage[]\n+ */\n+export const fixErrorToolCalls = (messages: { [x: string]: unknown }[]): UIMessage[] => {\n+\treturn messages.map((msg) => {\n+\t\tif (msg['role'] === 'assistant' && msg['parts'] && Array.isArray(msg['parts'])) {\n+\t\t\tconst fixedParts = (msg['parts'] as unknown[]).map((part) => {\n+\t\t\t\tif (\n+\t\t\t\t\ttypeof part === 'object' &&\n+\t\t\t\t\tpart !== null &&\n+\t\t\t\t\t'type' in part &&\n+\t\t\t\t\ttypeof part.type === 'string' &&\n+\t\t\t\t\tpart.type.startsWith('tool-') &&\n+\t\t\t\t\t'state' in part &&\n+\t\t\t\t\tpart.state === 'output-error' &&\n+\t\t\t\t\t'rawInput' in part &&\n+\t\t\t\t\t(!('input' in part) || part.input == null)\n+\t\t\t\t) {\n+\t\t\t\t\treturn { ...part, input: part.rawInput };\n+\t\t\t\t}\n+\n+\t\t\t\treturn part;\n+\t\t\t});\n+\n+\t\t\treturn { ...msg, parts: fixedParts };\n+\t\t}\n+\n+\t\treturn msg;\n+\t}) as unknown as UIMessage[];\n+};\n", "test_patch": "", "problem_statement": "This pull request improves the handling of tool call errors in chat messages and updates provider options for OpenAI requests. The main changes include introducing a utility to fix error tool calls before validation and refining the configuration for OpenAI chat streams.\r\n\r\n**Error handling improvements:**\r\n\r\n* Added a new utility function `fixErrorToolCalls` in `fix-error-tool-calls.ts` to automatically copy `rawInput` to the `input` field for tool calls with error states, ensuring compatibility with the AI SDK's message conversion.\r\n* Updated `aiChatPostHandler` in `chat.post.ts` to preprocess incoming messages with `fixErrorToolCalls` before validation, improving robustness when handling error tool calls from the frontend. [[1]](diffhunk://#diff-ad3058ca5cba1112d57bc8b535cf793f8f211a9aa92ad96299ada6546830c99bR8) [[2]](diffhunk://#diff-ad3058ca5cba1112d57bc8b535cf793f8f211a9aa92ad96299ada6546830c99bL33-R35)\r\n\r\n**OpenAI provider configuration:**\r\n\r\n* Modified `createUiStream` in `create-ui-stream.ts` to set `reasoningSummary` to `'auto'`, disable storing, and include only `reasoning.encrypted_content` in the OpenAI provider options, optimizing the data sent and received.", "hints_text": "", "created_at": "2025-11-13T22:33:01Z", "pull_number": 26179, "test_files": ["api/src/ai/chat/controllers/chat.post.test.ts", "api/src/ai/chat/utils/fix-error-tool-calls.test.ts"], "code_files": ["api/src/ai/chat/controllers/chat.post.ts", "api/src/ai/chat/lib/create-ui-stream.ts", "api/src/ai/chat/utils/fix-error-tool-calls.ts"], "title": "AI -> Fix failed tool calls", "additions": 0, "deletions": 0}
{"repo": "directus/directus", "instance_id": "directus__directus.pr_mirror.26148", "base_commit": "b98cca06b80860e6aa75d08668fb8a89c609c4a7", "patch": "diff --git a/.changeset/funny-months-wonder.md b/.changeset/funny-months-wonder.md\nnew file mode 100644\nindex 0000000000000..9e6f4194bb249\n--- /dev/null\n+++ b/.changeset/funny-months-wonder.md\n@@ -0,0 +1,6 @@\n+---\n+'@directus/types': patch\n+'@directus/api': patch\n+---\n+\n+Fixed aliases on GQL M2A filters\ndiff --git a/api/src/services/graphql/schema/parse-query.ts b/api/src/services/graphql/schema/parse-query.ts\nindex a31198738c7f2..86ac294030a5b 100644\n--- a/api/src/services/graphql/schema/parse-query.ts\n+++ b/api/src/services/graphql/schema/parse-query.ts\n@@ -138,10 +138,10 @@ export async function getQuery(\n \n \tif (collection) {\n \t\tif (query.filter) {\n-\t\t\tquery.filter = filterReplaceM2A(query.filter, collection, schema);\n+\t\t\tquery.filter = filterReplaceM2A(query.filter, collection, schema, { aliasMap: query.alias });\n \t\t}\n \n-\t\tquery.deep = filterReplaceM2ADeep(query.deep, collection, schema);\n+\t\tquery.deep = filterReplaceM2ADeep(query.deep, collection, schema, { aliasMap: query.alias });\n \t}\n \n \tvalidateQuery(query);\ndiff --git a/api/src/services/graphql/utils/filter-replace-m2a.test.ts b/api/src/services/graphql/utils/filter-replace-m2a.test.ts\nindex ecfb982c5ab20..57a6ef03afd16 100644\n--- a/api/src/services/graphql/utils/filter-replace-m2a.test.ts\n+++ b/api/src/services/graphql/utils/filter-replace-m2a.test.ts\n@@ -1,5 +1,5 @@\n import { RelationBuilder, SchemaBuilder } from '@directus/schema-builder';\n-import { expect, test } from 'vitest';\n+import { describe, expect, test } from 'vitest';\n import { filterReplaceM2A, filterReplaceM2ADeep } from './filter-replace-m2a.js';\n \n const schema = new SchemaBuilder()\n@@ -22,87 +22,128 @@ const schema = new SchemaBuilder()\n \t})\n \t.build();\n \n-test('empty filter', () => {\n-\tconst result = filterReplaceM2A({}, 'article', { collections: {}, relations: [] });\n+describe('filterReplaceM2A', () => {\n+\ttest('empty filter', () => {\n+\t\tconst result = filterReplaceM2A({}, 'article', { collections: {}, relations: [] });\n \n-\texpect(result).toEqual({});\n-});\n+\t\texpect(result).toEqual({});\n+\t});\n+\n+\ttest('filter with aliases field', () => {\n+\t\tconst result = filterReplaceM2A(\n+\t\t\t{\n+\t\t\t\tid: { _eq: 1 },\n+\t\t\t\taliased_blocks: {\n+\t\t\t\t\tanyitem__text: {\n+\t\t\t\t\t\tid: { _eq: 1 },\n+\t\t\t\t\t\tcontent: { _eq: 'Hello World' },\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t\t'article',\n+\t\t\tschema,\n+\t\t\t{ aliasMap: { aliased_blocks: 'blocks' } },\n+\t\t);\n \n-test('filter with no relations', () => {\n-\tconst result = filterReplaceM2A(\n-\t\t{\n+\t\texpect(result).toEqual({\n+\t\t\tid: { _eq: 1 },\n+\t\t\taliased_blocks: {\n+\t\t\t\t'anyitem:text': {\n+\t\t\t\t\tid: { _eq: 1 },\n+\t\t\t\t\tcontent: { _eq: 'Hello World' },\n+\t\t\t\t},\n+\t\t\t},\n+\t\t});\n+\t});\n+\n+\ttest('filter with no relations', () => {\n+\t\tconst result = filterReplaceM2A(\n+\t\t\t{\n+\t\t\t\tid: {\n+\t\t\t\t\t_eq: 1,\n+\t\t\t\t},\n+\t\t\t\tsome: {\n+\t\t\t\t\t_eq: 'value',\n+\t\t\t\t},\n+\t\t\t},\n+\t\t\t'article',\n+\t\t\t{ collections: {}, relations: [] },\n+\t\t);\n+\n+\t\texpect(result).toEqual({\n \t\t\tid: {\n \t\t\t\t_eq: 1,\n \t\t\t},\n \t\t\tsome: {\n \t\t\t\t_eq: 'value',\n \t\t\t},\n-\t\t},\n-\t\t'article',\n-\t\t{ collections: {}, relations: [] },\n-\t);\n-\n-\texpect(result).toEqual({\n-\t\tid: {\n-\t\t\t_eq: 1,\n-\t\t},\n-\t\tsome: {\n-\t\t\t_eq: 'value',\n-\t\t},\n+\t\t});\n \t});\n-});\n \n-test('filter with a m2o relation', () => {\n-\tconst result = filterReplaceM2A(\n-\t\t{\n+\ttest('filter with a m2o relation', () => {\n+\t\tconst result = filterReplaceM2A(\n+\t\t\t{\n+\t\t\t\tid: { _eq: 1 },\n+\t\t\t\tauthor: {\n+\t\t\t\t\tid: { _eq: 1 },\n+\t\t\t\t\tname: { _eq: 'John Doe' },\n+\t\t\t\t},\n+\t\t\t},\n+\t\t\t'article',\n+\t\t\tschema,\n+\t\t);\n+\n+\t\texpect(result).toEqual({\n \t\t\tid: { _eq: 1 },\n \t\t\tauthor: {\n \t\t\t\tid: { _eq: 1 },\n \t\t\t\tname: { _eq: 'John Doe' },\n \t\t\t},\n-\t\t},\n-\t\t'article',\n-\t\tschema,\n-\t);\n-\n-\texpect(result).toEqual({\n-\t\tid: { _eq: 1 },\n-\t\tauthor: {\n-\t\t\tid: { _eq: 1 },\n-\t\t\tname: { _eq: 'John Doe' },\n-\t\t},\n+\t\t});\n \t});\n-});\n \n-test('filter with a a2o relation', () => {\n-\tconst result = filterReplaceM2A(\n-\t\t{\n+\ttest('filter with a a2o relation', () => {\n+\t\tconst result = filterReplaceM2A(\n+\t\t\t{\n+\t\t\t\tid: { _eq: 1 },\n+\t\t\t\tblocks: {\n+\t\t\t\t\tanyitem__text: {\n+\t\t\t\t\t\tid: { _eq: 1 },\n+\t\t\t\t\t\tcontent: { _eq: 'Hello World' },\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t\t'article',\n+\t\t\tschema,\n+\t\t);\n+\n+\t\texpect(result).toEqual({\n \t\t\tid: { _eq: 1 },\n \t\t\tblocks: {\n-\t\t\t\tanyitem__text: {\n+\t\t\t\t'anyitem:text': {\n \t\t\t\t\tid: { _eq: 1 },\n \t\t\t\t\tcontent: { _eq: 'Hello World' },\n \t\t\t\t},\n \t\t\t},\n-\t\t},\n-\t\t'article',\n-\t\tschema,\n-\t);\n-\n-\texpect(result).toEqual({\n-\t\tid: { _eq: 1 },\n-\t\tblocks: {\n-\t\t\t'anyitem:text': {\n+\t\t});\n+\t});\n+\n+\ttest('filter with a fake a2o relation', () => {\n+\t\tconst result = filterReplaceM2A(\n+\t\t\t{\n \t\t\t\tid: { _eq: 1 },\n-\t\t\t\tcontent: { _eq: 'Hello World' },\n+\t\t\t\tblocks: {\n+\t\t\t\t\titem__text: {\n+\t\t\t\t\t\tid: { _eq: 1 },\n+\t\t\t\t\t\tcontent: { _eq: 'Hello World' },\n+\t\t\t\t\t},\n+\t\t\t\t},\n \t\t\t},\n-\t\t},\n-\t});\n-});\n+\t\t\t'article',\n+\t\t\tschema,\n+\t\t);\n \n-test('filter with a fake a2o relation', () => {\n-\tconst result = filterReplaceM2A(\n-\t\t{\n+\t\texpect(result).toEqual({\n \t\t\tid: { _eq: 1 },\n \t\t\tblocks: {\n \t\t\t\titem__text: {\n@@ -110,57 +151,57 @@ test('filter with a fake a2o relation', () => {\n \t\t\t\t\tcontent: { _eq: 'Hello World' },\n \t\t\t\t},\n \t\t\t},\n-\t\t},\n-\t\t'article',\n-\t\tschema,\n-\t);\n-\n-\texpect(result).toEqual({\n-\t\tid: { _eq: 1 },\n-\t\tblocks: {\n-\t\t\titem__text: {\n-\t\t\t\tid: { _eq: 1 },\n-\t\t\t\tcontent: { _eq: 'Hello World' },\n-\t\t\t},\n-\t\t},\n+\t\t});\n \t});\n-});\n \n-test('filter with a a2o relation inside _and', () => {\n-\tconst result = filterReplaceM2A(\n-\t\t{\n+\ttest('filter with a a2o relation inside _and', () => {\n+\t\tconst result = filterReplaceM2A(\n+\t\t\t{\n+\t\t\t\t_and: [\n+\t\t\t\t\t{\n+\t\t\t\t\t\tblocks: {\n+\t\t\t\t\t\t\tanyitem__text: {\n+\t\t\t\t\t\t\t\tid: { _eq: 1 },\n+\t\t\t\t\t\t\t\tcontent: { _eq: 'Hello World' },\n+\t\t\t\t\t\t\t},\n+\t\t\t\t\t\t},\n+\t\t\t\t\t},\n+\t\t\t\t],\n+\t\t\t},\n+\t\t\t'article',\n+\t\t\tschema,\n+\t\t);\n+\n+\t\texpect(result).toEqual({\n \t\t\t_and: [\n \t\t\t\t{\n \t\t\t\t\tblocks: {\n-\t\t\t\t\t\tanyitem__text: {\n+\t\t\t\t\t\t'anyitem:text': {\n \t\t\t\t\t\t\tid: { _eq: 1 },\n \t\t\t\t\t\t\tcontent: { _eq: 'Hello World' },\n \t\t\t\t\t\t},\n \t\t\t\t\t},\n \t\t\t\t},\n \t\t\t],\n-\t\t},\n-\t\t'article',\n-\t\tschema,\n-\t);\n+\t\t});\n+\t});\n \n-\texpect(result).toEqual({\n-\t\t_and: [\n+\ttest('filter with a a2o relation and wrong target collection', () => {\n+\t\tconst result = filterReplaceM2A(\n \t\t\t{\n+\t\t\t\tid: { _eq: 1 },\n \t\t\t\tblocks: {\n-\t\t\t\t\t'anyitem:text': {\n+\t\t\t\t\tanyitem__wrong: {\n \t\t\t\t\t\tid: { _eq: 1 },\n \t\t\t\t\t\tcontent: { _eq: 'Hello World' },\n \t\t\t\t\t},\n \t\t\t\t},\n \t\t\t},\n-\t\t],\n-\t});\n-});\n+\t\t\t'article',\n+\t\t\tschema,\n+\t\t);\n \n-test('filter with a a2o relation and wrong target collection', () => {\n-\tconst result = filterReplaceM2A(\n-\t\t{\n+\t\texpect(result).toEqual({\n \t\t\tid: { _eq: 1 },\n \t\t\tblocks: {\n \t\t\t\tanyitem__wrong: {\n@@ -168,79 +209,171 @@ test('filter with a a2o relation and wrong target collection', () => {\n \t\t\t\t\tcontent: { _eq: 'Hello World' },\n \t\t\t\t},\n \t\t\t},\n-\t\t},\n-\t\t'article',\n-\t\tschema,\n-\t);\n-\n-\texpect(result).toEqual({\n-\t\tid: { _eq: 1 },\n-\t\tblocks: {\n-\t\t\tanyitem__wrong: {\n-\t\t\t\tid: { _eq: 1 },\n-\t\t\t\tcontent: { _eq: 'Hello World' },\n-\t\t\t},\n-\t\t},\n+\t\t});\n \t});\n });\n \n-test('deep with filter', () => {\n-\tconst result = filterReplaceM2ADeep(\n-\t\t{\n+describe('filterReplaceM2aDeep', () => {\n+\ttest('empty filter', () => {\n+\t\tconst result = filterReplaceM2ADeep({}, 'article', { collections: {}, relations: [] });\n+\n+\t\texpect(result).toEqual({});\n+\t});\n+\n+\ttest('deep with filter', () => {\n+\t\tconst result = filterReplaceM2ADeep(\n+\t\t\t{\n+\t\t\t\tblocks: {\n+\t\t\t\t\t_filter: {\n+\t\t\t\t\t\tid: { _eq: 1 },\n+\t\t\t\t\t\tcontent: { _eq: 'Hello World' },\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t\t'article',\n+\t\t\tschema,\n+\t\t);\n+\n+\t\texpect(result).toEqual({\n \t\t\tblocks: {\n \t\t\t\t_filter: {\n \t\t\t\t\tid: { _eq: 1 },\n \t\t\t\t\tcontent: { _eq: 'Hello World' },\n \t\t\t\t},\n \t\t\t},\n-\t\t},\n-\t\t'article',\n-\t\tschema,\n-\t);\n-\n-\texpect(result).toEqual({\n-\t\tblocks: {\n-\t\t\t_filter: {\n-\t\t\t\tid: { _eq: 1 },\n-\t\t\t\tcontent: { _eq: 'Hello World' },\n+\t\t});\n+\t});\n+\n+\ttest('filter with aliased relation', () => {\n+\t\tconst result = filterReplaceM2ADeep(\n+\t\t\t{\n+\t\t\t\taliased_blocks: {\n+\t\t\t\t\t_filter: {\n+\t\t\t\t\t\tanyitem__text: {\n+\t\t\t\t\t\t\tid: { _eq: 1 },\n+\t\t\t\t\t\t\tcontent: { _eq: 'Hello World' },\n+\t\t\t\t\t\t},\n+\t\t\t\t\t},\n+\t\t\t\t},\n \t\t\t},\n-\t\t},\n+\t\t\t'article',\n+\t\t\tschema,\n+\t\t\t{ aliasMap: { aliased_blocks: 'blocks' } },\n+\t\t);\n+\n+\t\texpect(result).toEqual({\n+\t\t\taliased_blocks: {\n+\t\t\t\t_filter: {\n+\t\t\t\t\t'anyitem:text': {\n+\t\t\t\t\t\tid: { _eq: 1 },\n+\t\t\t\t\t\tcontent: { _eq: 'Hello World' },\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t});\n \t});\n-});\n \n-test('deep with filter having a2o', () => {\n-\tconst result = filterReplaceM2ADeep(\n-\t\t{\n-\t\t\tblocks: {\n+\ttest('filter with nested aliased relation', () => {\n+\t\tconst result = filterReplaceM2ADeep(\n+\t\t\t{\n+\t\t\t\taliased_blocks: {\n+\t\t\t\t\tarticle_id: {\n+\t\t\t\t\t\t_alias: { aliased_blocks: 'blocks' },\n+\t\t\t\t\t\taliased_blocks: {\n+\t\t\t\t\t\t\t_filter: {\n+\t\t\t\t\t\t\t\tanyitem__text: {\n+\t\t\t\t\t\t\t\t\tid: { _eq: 1 },\n+\t\t\t\t\t\t\t\t\tcontent: { _eq: 'Hello World' },\n+\t\t\t\t\t\t\t\t},\n+\t\t\t\t\t\t\t},\n+\t\t\t\t\t\t},\n+\t\t\t\t\t},\n+\t\t\t\t\t_filter: {\n+\t\t\t\t\t\tanyitem__text: {\n+\t\t\t\t\t\t\tid: { _eq: 1 },\n+\t\t\t\t\t\t\tcontent: { _eq: 'Hello World' },\n+\t\t\t\t\t\t},\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t\t'article',\n+\t\t\tschema,\n+\t\t\t{ aliasMap: { aliased_blocks: 'blocks' } },\n+\t\t);\n+\n+\t\texpect(result).toEqual({\n+\t\t\taliased_blocks: {\n+\t\t\t\tarticle_id: {\n+\t\t\t\t\t_alias: {\n+\t\t\t\t\t\taliased_blocks: 'blocks',\n+\t\t\t\t\t},\n+\t\t\t\t\taliased_blocks: {\n+\t\t\t\t\t\t_filter: {\n+\t\t\t\t\t\t\t'anyitem:text': {\n+\t\t\t\t\t\t\t\tid: { _eq: 1 },\n+\t\t\t\t\t\t\t\tcontent: { _eq: 'Hello World' },\n+\t\t\t\t\t\t\t},\n+\t\t\t\t\t\t},\n+\t\t\t\t\t},\n+\t\t\t\t},\n \t\t\t\t_filter: {\n-\t\t\t\t\tanyitem__text: {\n+\t\t\t\t\t'anyitem:text': {\n \t\t\t\t\t\tid: { _eq: 1 },\n \t\t\t\t\t\tcontent: { _eq: 'Hello World' },\n \t\t\t\t\t},\n \t\t\t\t},\n \t\t\t},\n-\t\t},\n-\t\t'article',\n-\t\tschema,\n-\t);\n-\n-\texpect(result).toEqual({\n-\t\tblocks: {\n-\t\t\t_filter: {\n-\t\t\t\t'anyitem:text': {\n-\t\t\t\t\tid: { _eq: 1 },\n-\t\t\t\t\tcontent: { _eq: 'Hello World' },\n+\t\t});\n+\t});\n+\n+\ttest('deep with filter having a2o', () => {\n+\t\tconst result = filterReplaceM2ADeep(\n+\t\t\t{\n+\t\t\t\tblocks: {\n+\t\t\t\t\t_filter: {\n+\t\t\t\t\t\tanyitem__text: {\n+\t\t\t\t\t\t\tid: { _eq: 1 },\n+\t\t\t\t\t\t\tcontent: { _eq: 'Hello World' },\n+\t\t\t\t\t\t},\n+\t\t\t\t\t},\n \t\t\t\t},\n \t\t\t},\n-\t\t},\n+\t\t\t'article',\n+\t\t\tschema,\n+\t\t);\n+\n+\t\texpect(result).toEqual({\n+\t\t\tblocks: {\n+\t\t\t\t_filter: {\n+\t\t\t\t\t'anyitem:text': {\n+\t\t\t\t\t\tid: { _eq: 1 },\n+\t\t\t\t\t\tcontent: { _eq: 'Hello World' },\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t});\n \t});\n-});\n \n-test('deep with nested filter having a2o', () => {\n-\tconst result = filterReplaceM2ADeep(\n-\t\t{\n+\ttest('deep with nested filter having a2o', () => {\n+\t\tconst result = filterReplaceM2ADeep(\n+\t\t\t{\n+\t\t\t\tblocks: {\n+\t\t\t\t\tanyitem__text: {\n+\t\t\t\t\t\tblocks: {\n+\t\t\t\t\t\t\t_filter: {\n+\t\t\t\t\t\t\t\tid: { _eq: 1 },\n+\t\t\t\t\t\t\t},\n+\t\t\t\t\t\t},\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t\t'article',\n+\t\t\tschema,\n+\t\t);\n+\n+\t\texpect(result).toEqual({\n \t\t\tblocks: {\n-\t\t\t\tanyitem__text: {\n+\t\t\t\t'anyitem:text': {\n \t\t\t\t\tblocks: {\n \t\t\t\t\t\t_filter: {\n \t\t\t\t\t\t\tid: { _eq: 1 },\n@@ -248,27 +381,26 @@ test('deep with nested filter having a2o', () => {\n \t\t\t\t\t},\n \t\t\t\t},\n \t\t\t},\n-\t\t},\n-\t\t'article',\n-\t\tschema,\n-\t);\n-\n-\texpect(result).toEqual({\n-\t\tblocks: {\n-\t\t\t'anyitem:text': {\n-\t\t\t\tblocks: {\n+\t\t});\n+\t});\n+\n+\ttest('deep with filter having a2o on wrong deep', () => {\n+\t\tconst result = filterReplaceM2ADeep(\n+\t\t\t{\n+\t\t\t\twrong: {\n \t\t\t\t\t_filter: {\n-\t\t\t\t\t\tid: { _eq: 1 },\n+\t\t\t\t\t\tanyitem__text: {\n+\t\t\t\t\t\t\tid: { _eq: 1 },\n+\t\t\t\t\t\t\tcontent: { _eq: 'Hello World' },\n+\t\t\t\t\t\t},\n \t\t\t\t\t},\n \t\t\t\t},\n \t\t\t},\n-\t\t},\n-\t});\n-});\n+\t\t\t'article',\n+\t\t\tschema,\n+\t\t);\n \n-test('deep with filter having a2o on wrong deep', () => {\n-\tconst result = filterReplaceM2ADeep(\n-\t\t{\n+\t\texpect(result).toEqual({\n \t\t\twrong: {\n \t\t\t\t_filter: {\n \t\t\t\t\tanyitem__text: {\n@@ -277,19 +409,6 @@ test('deep with filter having a2o on wrong deep', () => {\n \t\t\t\t\t},\n \t\t\t\t},\n \t\t\t},\n-\t\t},\n-\t\t'article',\n-\t\tschema,\n-\t);\n-\n-\texpect(result).toEqual({\n-\t\twrong: {\n-\t\t\t_filter: {\n-\t\t\t\tanyitem__text: {\n-\t\t\t\t\tid: { _eq: 1 },\n-\t\t\t\t\tcontent: { _eq: 'Hello World' },\n-\t\t\t\t},\n-\t\t\t},\n-\t\t},\n+\t\t});\n \t});\n });\ndiff --git a/api/src/services/graphql/utils/filter-replace-m2a.ts b/api/src/services/graphql/utils/filter-replace-m2a.ts\nindex 3b264402a4e40..a14ce0d7f2266 100644\n--- a/api/src/services/graphql/utils/filter-replace-m2a.ts\n+++ b/api/src/services/graphql/utils/filter-replace-m2a.ts\n@@ -1,34 +1,43 @@\n-import type { Filter, NestedDeepQuery, SchemaOverview } from '@directus/types';\n+import type { DeepQuery, Filter, NestedDeepQuery, Query, SchemaOverview } from '@directus/types';\n import { getRelation } from '@directus/utils';\n import { getRelationType } from '../../../utils/get-relation-type.js';\n \n-export function filterReplaceM2A(filter_arg: Filter, collection: string, schema: SchemaOverview): any {\n+export function filterReplaceM2A(\n+\tfilter_arg: Filter,\n+\tcollection: string,\n+\tschema: SchemaOverview,\n+\toptions?: { aliasMap?: Query['alias'] },\n+): any {\n \tconst filter: any = filter_arg;\n \n \tfor (const key in filter) {\n-\t\tconst [field, any_collection] = key.split('__');\n+\t\tconst parts = key.split('__');\n+\t\tlet field = parts[0];\n+\t\tconst any_collection = parts[1];\n \n \t\tif (!field) continue;\n \n+\t\tfield = options?.aliasMap?.[field] ?? field;\n+\n \t\tconst relation = getRelation(schema.relations, collection, field);\n \t\tconst type = relation ? getRelationType({ relation, collection, field }) : null;\n \n \t\tif (type === 'o2m' && relation) {\n-\t\t\tfilter[key] = filterReplaceM2A(filter[key], relation.collection, schema);\n+\t\t\tfilter[key] = filterReplaceM2A(filter[key], relation.collection, schema, options);\n \t\t} else if (type === 'm2o' && relation) {\n-\t\t\tfilter[key] = filterReplaceM2A(filter[key], relation.related_collection!, schema);\n+\t\t\tfilter[key] = filterReplaceM2A(filter[key], relation.related_collection!, schema, options);\n \t\t} else if (\n \t\t\ttype === 'a2o' &&\n \t\t\trelation &&\n \t\t\tany_collection &&\n \t\t\trelation.meta?.one_allowed_collections?.includes(any_collection)\n \t\t) {\n-\t\t\tfilter[`${field}:${any_collection}`] = filterReplaceM2A(filter[key], any_collection, schema);\n+\t\t\tfilter[`${field}:${any_collection}`] = filterReplaceM2A(filter[key], any_collection, schema, options);\n \t\t\tdelete filter[key];\n \t\t} else if (Array.isArray(filter[key])) {\n-\t\t\tfilter[key] = filter[key].map((item) => filterReplaceM2A(item, collection, schema));\n+\t\t\tfilter[key] = filter[key].map((item) => filterReplaceM2A(item, collection, schema, options));\n \t\t} else if (typeof filter[key] === 'object') {\n-\t\t\tfilter[key] = filterReplaceM2A(filter[key], collection, schema);\n+\t\t\tfilter[key] = filterReplaceM2A(filter[key], collection, schema, options);\n \t\t}\n \t}\n \n@@ -39,15 +48,20 @@ export function filterReplaceM2ADeep(\n \tdeep_arg: NestedDeepQuery | null | undefined,\n \tcollection: string,\n \tschema: SchemaOverview,\n+\toptions?: { aliasMap?: Query['alias'] },\n ) {\n \tconst deep: any = deep_arg;\n \n \tfor (const key in deep) {\n \t\tif (key.startsWith('_') === false) {\n-\t\t\tconst [field, any_collection] = key.split('__');\n+\t\t\tconst parts = key.split('__');\n+\t\t\tlet field = parts[0];\n+\t\t\tconst any_collection = parts[1];\n \n \t\t\tif (!field) continue;\n \n+\t\t\tfield = options?.aliasMap?.[field] || (deep as DeepQuery)._alias?.[field] || field;\n+\n \t\t\tconst relation = getRelation(schema.relations, collection, field);\n \n \t\t\tif (!relation) continue;\ndiff --git a/packages/types/src/query.ts b/packages/types/src/query.ts\nindex 36f5fcf250b2b..f7955e005abe5 100644\n--- a/packages/types/src/query.ts\n+++ b/packages/types/src/query.ts\n@@ -19,6 +19,7 @@ export type Query = {\n };\n \n export type DeepQuery = {\n+\t_alias?: Record<string, string> | null;\n \t_fields?: string[] | null;\n \t_sort?: string[] | null;\n \t_filter?: Filter | null;\n", "test_patch": "", "problem_statement": "## Scope\r\n\r\nWhat's changed:\r\n\r\n- Aliases are now accounted for when building m2a filters\r\n- Added missing `_alias` property in type `DeepQuery`\r\n\r\n## Potential Risks / Drawbacks\r\n\r\n- Some filter breaks\r\n\r\n## Tested Scenarios\r\n\r\n- [x] Expect m2a filter to support aliases\r\n- [x] Expect m2a deep filter to support aliases\r\n\r\n## Review Notes / Questions\r\n\r\n- N/A\r\n\r\n## Checklist\r\n\r\n- [x] Added or updated tests\r\n- [ ] Documentation PR created [here](https://github.com/directus/docs) or not required\r\n\r\n---\r\n\r\nFixes #26133\r\n", "hints_text": "", "created_at": "2025-11-07T20:34:44Z", "pull_number": 26148, "test_files": ["api/src/services/graphql/utils/filter-replace-m2a.test.ts"], "code_files": ["api/src/services/graphql/schema/parse-query.ts", "api/src/services/graphql/utils/filter-replace-m2a.ts", "packages/types/src/query.ts"], "title": "Fix aliases on GQL M2A filters", "additions": 0, "deletions": 0}
{"repo": "directus/directus", "instance_id": "directus__directus.pr_mirror.25965", "base_commit": "f636050870ad3ed1cff05aa2513c16c0384f36a0", "patch": "diff --git a/.changeset/eager-tables-invite.md b/.changeset/eager-tables-invite.md\nnew file mode 100644\nindex 0000000000000..147b9b53adc5e\n--- /dev/null\n+++ b/.changeset/eager-tables-invite.md\n@@ -0,0 +1,5 @@\n+---\n+'@directus/app': patch\n+---\n+\n+Fixed merge behavior during validation for nested drawer forms\ndiff --git a/app/src/composables/use-item/index.ts b/app/src/composables/use-item/index.ts\nindex 75a55f23d8414..ad7c48391f6ff 100644\n--- a/app/src/composables/use-item/index.ts\n+++ b/app/src/composables/use-item/index.ts\n@@ -5,24 +5,25 @@ import { i18n } from '@/lang';\n import { useFieldsStore } from '@/stores/fields';\n import { useRelationsStore } from '@/stores/relations';\n import { APIError } from '@/types/error';\n+import { applyConditions } from '@/utils/apply-conditions';\n import { getDefaultValuesFromFields } from '@/utils/get-default-values-from-fields';\n+import { getFieldsInGroup } from '@/utils/get-fields-in-group';\n+import { mergeItemData } from '@/utils/merge-item-data';\n import { notify } from '@/utils/notify';\n import { pushGroupOptionsDown } from '@/utils/push-group-options-down';\n import { translate } from '@/utils/translate-object-values';\n import { unexpectedError } from '@/utils/unexpected-error';\n import { validateItem } from '@/utils/validate-item';\n-import { getFieldsInGroup } from '@/utils/get-fields-in-group';\n import { useCollection } from '@directus/composables';\n import { isSystemCollection } from '@directus/system-data';\n import { Alterations, Field, Item, PrimaryKey, Query, Relation } from '@directus/types';\n import { getEndpoint, isObject } from '@directus/utils';\n import { AxiosResponse } from 'axios';\n import { jsonToGraphQLQuery } from 'json-to-graphql-query';\n-import { mergeWith, cloneDeep } from 'lodash';\n+import { cloneDeep, mergeWith } from 'lodash';\n import { ComputedRef, MaybeRef, Ref, computed, isRef, ref, unref, watch } from 'vue';\n import { UsablePermissions, usePermissions } from '../use-permissions';\n import { getGraphqlQueryFields } from './lib/get-graphql-query-fields';\n-import { applyConditions } from '@/utils/apply-conditions';\n \n type UsableItem<T extends Item> = {\n \tedits: Ref<Item>;\n@@ -183,7 +184,7 @@ export function useItem<T extends Item>(\n \n \t\tconst editsWithClearedValues = clearHiddenFieldsByCondition(edits.value, fields, defaultValues.value, item.value);\n \n-\t\tconst payloadToValidate = mergeItemData(defaultValues.value, item.value, editsWithClearedValues);\n+\t\tconst payloadToValidate = mergeItemData(defaultValues.value, item.value ?? {}, editsWithClearedValues);\n \n \t\tconst errors = validateItem(payloadToValidate, fields, isNew.value);\n \t\tif (nestedValidationErrors.value?.length) errors.push(...nestedValidationErrors.value);\n@@ -221,14 +222,6 @@ export function useItem<T extends Item>(\n \t\t}\n \t}\n \n-\tfunction mergeItemData(defaultValues: any, item: any, edits: any) {\n-\t\treturn mergeWith({}, defaultValues, item, edits, function (_from: any, to: any) {\n-\t\t\tif (typeof to !== 'undefined') {\n-\t\t\t\treturn to;\n-\t\t\t}\n-\t\t});\n-\t}\n-\n \tasync function saveAsCopy() {\n \t\tsaving.value = true;\n \t\tvalidationErrors.value = [];\ndiff --git a/app/src/composables/use-versions.ts b/app/src/composables/use-versions.ts\nindex a342263e900e3..1b3648a437975 100644\n--- a/app/src/composables/use-versions.ts\n+++ b/app/src/composables/use-versions.ts\n@@ -1,16 +1,16 @@\n import api from '@/api';\n+import { useNestedValidation } from '@/composables/use-nested-validation';\n+import { VALIDATION_TYPES } from '@/constants';\n+import { APIError } from '@/types/error';\n+import { getDefaultValuesFromFields } from '@/utils/get-default-values-from-fields';\n+import { mergeItemData } from '@/utils/merge-item-data';\n+import { pushGroupOptionsDown } from '@/utils/push-group-options-down';\n import { unexpectedError } from '@/utils/unexpected-error';\n-import { ContentVersion, Filter, Query, Item } from '@directus/types';\n+import { validateItem } from '@/utils/validate-item';\n+import { ContentVersion, Filter, Item, Query } from '@directus/types';\n import { useRouteQuery } from '@vueuse/router';\n import { Ref, computed, ref, unref, watch } from 'vue';\n import { useCollectionPermissions, usePermissions } from './use-permissions';\n-import { mergeWith } from 'lodash';\n-import { pushGroupOptionsDown } from '@/utils/push-group-options-down';\n-import { validateItem } from '@/utils/validate-item';\n-import { useNestedValidation } from '@/composables/use-nested-validation';\n-import { getDefaultValuesFromFields } from '@/utils/get-default-values-from-fields';\n-import { APIError } from '@/types/error';\n-import { VALIDATION_TYPES } from '@/constants';\n \n export function useVersions(collection: Ref<string>, isSingleton: Ref<boolean>, primaryKey: Ref<string | null>) {\n \tconst currentVersion = ref<ContentVersion | null>(null);\n@@ -191,17 +191,7 @@ export function useVersions(collection: Ref<string>, isSingleton: Ref<boolean>,\n \t\tsaveVersionLoading.value = true;\n \t\tvalidationErrors.value = [];\n \n-\t\tconst payloadToValidate = mergeWith(\n-\t\t\t{},\n-\t\t\tdefaultValues.value,\n-\t\t\titem.value,\n-\t\t\tedits.value,\n-\t\t\tfunction (_from: any, to: any) {\n-\t\t\t\tif (typeof to !== 'undefined') {\n-\t\t\t\t\treturn to;\n-\t\t\t\t}\n-\t\t\t},\n-\t\t);\n+\t\tconst payloadToValidate = mergeItemData(defaultValues.value, item.value, edits.value);\n \n \t\tconst fields = pushGroupOptionsDown(fieldsWithPermissions.value);\n \ndiff --git a/app/src/utils/merge-item-data.test.ts b/app/src/utils/merge-item-data.test.ts\nnew file mode 100644\nindex 0000000000000..072f16f80d656\n--- /dev/null\n+++ b/app/src/utils/merge-item-data.test.ts\n@@ -0,0 +1,85 @@\n+import { describe, it, expect } from 'vitest';\n+import { mergeItemData } from './merge-item-data';\n+\n+describe('mergeItemData', () => {\n+\tit('should use existing if field is undefined in edits', () => {\n+\t\tconst defaults = { x: 'default' };\n+\t\tconst existing = { x: 'existing' };\n+\t\tconst edits = {};\n+\t\tconst result = mergeItemData(defaults, existing, edits);\n+\t\texpect(result.x).toMatchInlineSnapshot(`\"existing\"`);\n+\t});\n+\n+\tit('should use default if field is undefined in both existing and edits', () => {\n+\t\tconst defaults = { x: 'default' };\n+\t\tconst existing = {};\n+\t\tconst edits = {};\n+\t\tconst result = mergeItemData(defaults, existing, edits);\n+\t\texpect(result.x).toMatchInlineSnapshot(`\"default\"`);\n+\t});\n+\n+\tit('should use edits over existing and default', () => {\n+\t\tconst defaults = { x: 'default' };\n+\t\tconst existing = { x: 'existing' };\n+\t\tconst edits = { x: 'edited' };\n+\t\tconst result = mergeItemData(defaults, existing, edits);\n+\t\texpect(result.x).toMatchInlineSnapshot(`\"edited\"`);\n+\t});\n+\n+\tit('should merge default, existing, and edits with correct precedence', () => {\n+\t\tconst defaults = { b: 'default b', c: 'default c' };\n+\t\tconst existing = { a: 'existing a', b: 'existing b', d: 'existing d' };\n+\t\tconst edits = { b: 'edit b', e: 'edit e' };\n+\t\tconst result = mergeItemData(defaults, existing, edits);\n+\n+\t\texpect(result).toMatchInlineSnapshot(`\n+\t\t\t{\n+\t\t\t  \"a\": \"existing a\",\n+\t\t\t  \"b\": \"edit b\",\n+\t\t\t  \"c\": \"default c\",\n+\t\t\t  \"d\": \"existing d\",\n+\t\t\t  \"e\": \"edit e\",\n+\t\t\t}\n+\t\t`);\n+\t});\n+\n+\tit('should not merge nested objects', () => {\n+\t\tconst defaults = { obj: { a: 1, b: 2 } };\n+\t\tconst existing = { obj: { b: 3 } };\n+\t\tconst edits = { obj: { c: 4 } };\n+\t\tconst result = mergeItemData(defaults, existing, edits);\n+\n+\t\texpect(result.obj).toMatchInlineSnapshot(`\n+\t\t\t{\n+\t\t\t  \"c\": 4,\n+\t\t\t}\n+\t\t`);\n+\t});\n+\n+\tit('should not merge nested arrays', () => {\n+\t\tconst defaults = { arr: [1, 2, 3] };\n+\t\tconst existing = { arr: [4, 5] };\n+\t\tconst edits = { arr: [6] };\n+\t\tconst result = mergeItemData(defaults, existing, edits);\n+\n+\t\texpect(result.arr).toMatchInlineSnapshot(`\n+\t\t\t[\n+\t\t\t  6,\n+\t\t\t]\n+\t\t`);\n+\t});\n+\n+\tit('should handle null and undefined values correctly', () => {\n+\t\tconst defaults = { a: 'default a', b: 'default b' };\n+\t\tconst existing = { a: null };\n+\t\tconst edits = { b: undefined };\n+\t\tconst result = mergeItemData(defaults, existing, edits);\n+\n+\t\texpect(result).toMatchInlineSnapshot(`\n+\t\t\t{\n+\t\t\t  \"a\": null,\n+\t\t\t  \"b\": \"default b\",\n+\t\t\t}\n+\t\t`);\n+\t});\n+});\ndiff --git a/app/src/utils/merge-item-data.ts b/app/src/utils/merge-item-data.ts\nnew file mode 100644\nindex 0000000000000..a30d1907426e9\n--- /dev/null\n+++ b/app/src/utils/merge-item-data.ts\n@@ -0,0 +1,13 @@\n+import { mergeWith } from 'lodash';\n+\n+export function mergeItemData(\n+\tdefaultValues: Record<string, any>,\n+\texistingValues: Record<string, any>,\n+\tedits: Record<string, any>,\n+) {\n+\treturn mergeWith({}, defaultValues, existingValues, edits, customizer);\n+\n+\tfunction customizer(_from: unknown, to: unknown): any {\n+\t\tif (typeof to !== 'undefined') return to;\n+\t}\n+}\ndiff --git a/app/src/views/private/components/overlay-item.vue b/app/src/views/private/components/overlay-item.vue\nindex 99f165cd7c2de..772373a2b4214 100644\n--- a/app/src/views/private/components/overlay-item.vue\n+++ b/app/src/views/private/components/overlay-item.vue\n@@ -2,13 +2,15 @@\n import api from '@/api';\n import { type ApplyShortcut } from '@/components/v-dialog.vue';\n import { useEditsGuard } from '@/composables/use-edits-guard';\n+import { useFlows } from '@/composables/use-flows';\n+import { useNestedValidation } from '@/composables/use-nested-validation';\n import { usePermissions } from '@/composables/use-permissions';\n import { useShortcut } from '@/composables/use-shortcut';\n import { useTemplateData } from '@/composables/use-template-data';\n-import { useNestedValidation } from '@/composables/use-nested-validation';\n import { useFieldsStore } from '@/stores/fields';\n import { useRelationsStore } from '@/stores/relations';\n import { getDefaultValuesFromFields } from '@/utils/get-default-values-from-fields';\n+import { mergeItemData } from '@/utils/merge-item-data';\n import { translateShortcut } from '@/utils/translate-shortcut';\n import { unexpectedError } from '@/utils/unexpected-error';\n import { validateItem } from '@/utils/validate-item';\n@@ -16,12 +18,11 @@ import { useCollection } from '@directus/composables';\n import { isSystemCollection } from '@directus/system-data';\n import { Field, PrimaryKey, Relation } from '@directus/types';\n import { getEndpoint } from '@directus/utils';\n-import { isEmpty, merge, set } from 'lodash';\n-import { computed, ref, toRefs, watch, unref, type Ref } from 'vue';\n+import { isEmpty, set } from 'lodash';\n+import { computed, ref, toRefs, unref, watch, type Ref } from 'vue';\n import { useI18n } from 'vue-i18n';\n import { useRouter } from 'vue-router';\n import OverlayItemContent from './overlay-item-content.vue';\n-import { useFlows } from '@/composables/use-flows';\n \n export interface OverlayItemProps {\n \toverlay?: 'drawer' | 'modal' | 'popover';\n@@ -435,7 +436,12 @@ function useActions() {\n \t}\n \n \tfunction validateForm({ defaultValues, existingValues, editsToValidate, fieldsToValidate }: Record<string, any>) {\n-\t\treturn validateItem(merge({}, defaultValues, existingValues, editsToValidate), fieldsToValidate, isNew.value, true);\n+\t\treturn validateItem(\n+\t\t\tmergeItemData(defaultValues, existingValues, editsToValidate),\n+\t\t\tfieldsToValidate,\n+\t\t\tisNew.value,\n+\t\t\ttrue,\n+\t\t);\n \t}\n \n \tfunction save() {\n", "test_patch": "", "problem_statement": "## Scope\r\n\r\nWhat's changed:\r\n\r\n- Fixed an issue where saving nested many-to-many relationships triggered a validation error due to incorrect merging behavior\r\n- Moved the redundant logic from the useItem() and useVersions() composables into a new mergeItemData utility, and also applied it to the overlay-item component\r\n\r\n\r\n## Potential Risks / Drawbacks\r\n\r\n\u2014\r\n\r\n## Tested Scenarios\r\n\r\n- Reproduction steps\r\n\r\n## Review Notes / Questions\r\n\r\n\u2014\r\n\r\n## Checklist\r\n\r\n- [x] Added or updated tests\r\n- [x] Documentation PR created [here](https://github.com/directus/docs) or not required\r\n\r\n---\r\n\r\nFixes #25919\r\n", "hints_text": "", "created_at": "2025-10-10T12:59:51Z", "pull_number": 25965, "test_files": ["app/src/utils/merge-item-data.test.ts"], "code_files": ["app/src/composables/use-item/index.ts", "app/src/composables/use-versions.ts", "app/src/utils/merge-item-data.ts"], "title": "Fix merge behavior during validation for nested drawer forms", "additions": 0, "deletions": 0}
{"repo": "directus/directus", "instance_id": "directus__directus.pr_mirror.26193", "base_commit": "bbd4802f0e163906855a68724927ee4d944d4416", "patch": "diff --git a/.changeset/wet-cities-start.md b/.changeset/wet-cities-start.md\nnew file mode 100644\nindex 0000000000000..c6135cae6c4cc\n--- /dev/null\n+++ b/.changeset/wet-cities-start.md\n@@ -0,0 +1,5 @@\n+---\n+'@directus/api': patch\n+---\n+\n+Improved extension install error messages\ndiff --git a/api/src/extensions/lib/installation/manager.test.ts b/api/src/extensions/lib/installation/manager.test.ts\nnew file mode 100644\nindex 0000000000000..0597a4f8dcf31\n--- /dev/null\n+++ b/api/src/extensions/lib/installation/manager.test.ts\n@@ -0,0 +1,115 @@\n+import { download } from '@directus/extensions-registry';\n+import { mkdir, readFile, rm } from 'node:fs/promises';\n+import { beforeEach, describe, expect, test, vi } from 'vitest';\n+import { useLogger } from '../../../logger/index.js';\n+import { InstallationManager } from './manager.js';\n+\n+vi.mock('@directus/env', () => ({\n+\tuseEnv: vi.fn(() => ({\n+\t\tTEMP_PATH: '/tmp',\n+\t\tEXTENSIONS_PATH: '/extensions',\n+\t})),\n+}));\n+\n+vi.mock('@directus/extensions-registry', () => ({\n+\tdownload: vi.fn(),\n+}));\n+\n+vi.mock('@directus/storage-driver-local');\n+\n+vi.mock('fs-extra', () => ({\n+\tmove: vi.fn(),\n+\tremove: vi.fn(),\n+}));\n+\n+vi.mock('node:fs/promises', () => ({\n+\tmkdir: vi.fn(),\n+\treadFile: vi.fn(),\n+\trm: vi.fn(),\n+}));\n+\n+vi.mock('tar', () => ({\n+\textract: vi.fn(),\n+}));\n+\n+vi.mock('../../../logger/index.js', () => ({\n+\tuseLogger: vi.fn(() => ({ warn: vi.fn() })),\n+}));\n+\n+vi.mock('../../../storage/index.js', () => ({\n+\tgetStorage: vi.fn(),\n+}));\n+\n+vi.mock('../get-extensions-path.js', () => ({\n+\tgetExtensionsPath: vi.fn(() => '/extensions'),\n+}));\n+\n+describe('InstallationManager', () => {\n+\tlet manager: InstallationManager;\n+\tlet mockLogger: any;\n+\n+\tbeforeEach(async () => {\n+\t\tvi.clearAllMocks();\n+\n+\t\tmockLogger = {\n+\t\t\twarn: vi.fn(),\n+\t\t};\n+\n+\t\tvi.mocked(useLogger).mockReturnValue(mockLogger);\n+\t\tvi.mocked(mkdir).mockResolvedValue(undefined);\n+\n+\t\t// Setup successful mocks by default\n+\t\tconst mockReadableStream = {\n+\t\t\tgetReader: () => ({\n+\t\t\t\tread: vi.fn().mockResolvedValue({ done: true, value: undefined }),\n+\t\t\t}),\n+\t\t};\n+\n+\t\tvi.mocked(download).mockResolvedValue(mockReadableStream as any);\n+\n+\t\tvi.mocked(readFile).mockResolvedValue(\n+\t\t\tJSON.stringify({\n+\t\t\t\tname: 'test-extension',\n+\t\t\t\tdirectus: {\n+\t\t\t\t\ttype: 'interface',\n+\t\t\t\t},\n+\t\t\t}),\n+\t\t);\n+\n+\t\tmanager = new InstallationManager();\n+\t});\n+\n+\tdescribe('Errors', () => {\n+\t\ttest('should throw marketplace ServiceUnavailableError when download fails', async () => {\n+\t\t\tvi.mocked(download).mockRejectedValue(new Error('Network error'));\n+\n+\t\t\tawait expect(manager.install('test-version')).rejects.toThrowError(\n+\t\t\t\t'Service \"marketplace\" is unavailable. Could not download the extension.',\n+\t\t\t);\n+\t\t});\n+\n+\t\ttest('should throw extension ServiceUnavailableError for any non marketplace error', async () => {\n+\t\t\tvi.mocked(mkdir).mockRejectedValue(new Error());\n+\n+\t\t\tawait expect(manager.install('test-version')).rejects.toThrowError(\n+\t\t\t\t'Service \"extensions\" is unavailable. Failed to extract the extension or write it to storage.',\n+\t\t\t);\n+\t\t});\n+\n+\t\ttest('should always clean up temporary directory even when error occurs', async () => {\n+\t\t\tvi.mocked(mkdir).mockRejectedValue(new Error());\n+\n+\t\t\tawait expect(manager.install('test-version')).rejects.toThrow();\n+\n+\t\t\texpect(rm).toHaveBeenCalledWith('/tmp/marketplace/test-version', { recursive: true });\n+\t\t});\n+\n+\t\ttest('should log warning when error occurs', async () => {\n+\t\t\tvi.mocked(download).mockRejectedValue(new Error('Test error'));\n+\n+\t\t\tawait expect(manager.install('test-version')).rejects.toThrow();\n+\n+\t\t\texpect(mockLogger.warn).toHaveBeenCalled();\n+\t\t});\n+\t});\n+});\ndiff --git a/api/src/extensions/lib/installation/manager.ts b/api/src/extensions/lib/installation/manager.ts\nindex 227afd39243b4..689c6c0679ca0 100644\n--- a/api/src/extensions/lib/installation/manager.ts\n+++ b/api/src/extensions/lib/installation/manager.ts\n@@ -1,5 +1,5 @@\n import { useEnv } from '@directus/env';\n-import { ServiceUnavailableError } from '@directus/errors';\n+import { ErrorCode, isDirectusError, ServiceUnavailableError } from '@directus/errors';\n import { EXTENSION_PKG_KEY, ExtensionManifest } from '@directus/extensions';\n import { download, type DownloadOptions } from '@directus/extensions-registry';\n import DriverLocal from '@directus/storage-driver-local';\n@@ -33,7 +33,16 @@ export class InstallationManager {\n \t\t\t\toptions.registry = env['MARKETPLACE_REGISTRY'];\n \t\t\t}\n \n-\t\t\tconst tarReadableStream = await download(versionId, env['MARKETPLACE_TRUST'] === 'sandbox', options);\n+\t\t\tlet tarReadableStream;\n+\n+\t\t\ttry {\n+\t\t\t\ttarReadableStream = await download(versionId, env['MARKETPLACE_TRUST'] === 'sandbox', options);\n+\t\t\t} catch (error) {\n+\t\t\t\tthrow new ServiceUnavailableError(\n+\t\t\t\t\t{ service: 'marketplace', reason: 'Could not download the extension' },\n+\t\t\t\t\t{ cause: error },\n+\t\t\t\t);\n+\t\t\t}\n \n \t\t\tif (!tarReadableStream) {\n \t\t\t\tthrow new Error(`No readable stream returned from download`);\n@@ -92,8 +101,13 @@ export class InstallationManager {\n \t\t} catch (err) {\n \t\t\tlogger.warn(err);\n \n+\t\t\t// rethrow marketplace servic unavailable\n+\t\t\tif (isDirectusError(err, ErrorCode.ServiceUnavailable)) {\n+\t\t\t\tthrow err;\n+\t\t\t}\n+\n \t\t\tthrow new ServiceUnavailableError(\n-\t\t\t\t{ service: 'marketplace', reason: 'Could not download and extract the extension' },\n+\t\t\t\t{ service: 'extensions', reason: 'Failed to extract the extension or write it to storage' },\n \t\t\t\t{ cause: err },\n \t\t\t);\n \t\t} finally {\ndiff --git a/api/src/services/extensions.test.ts b/api/src/services/extensions.test.ts\nnew file mode 100644\nindex 0000000000000..7f88bc2917a91\n--- /dev/null\n+++ b/api/src/services/extensions.test.ts\n@@ -0,0 +1,92 @@\n+import { ServiceUnavailableError } from '@directus/errors';\n+import { describe as registryDescribe } from '@directus/extensions-registry';\n+import { beforeEach, describe, expect, test, vi } from 'vitest';\n+import { getExtensionManager } from '../extensions/index.js';\n+import { ExtensionsService } from './extensions.js';\n+import { ItemsService } from './items.js';\n+\n+// Mock dependencies at the top level\n+vi.mock('@directus/env', () => ({\n+\tuseEnv: vi.fn(() => ({})),\n+}));\n+\n+vi.mock('@directus/extensions-registry', () => ({\n+\tdescribe: vi.fn(),\n+}));\n+\n+vi.mock('../extensions/index.js', () => ({\n+\tgetExtensionManager: vi.fn(),\n+}));\n+\n+vi.mock('./items.js', () => ({\n+\tItemsService: vi.fn(),\n+}));\n+\n+vi.mock('../database/index.js', () => ({\n+\tdefault: vi.fn(),\n+}));\n+\n+describe('ExtensionsService', () => {\n+\tlet mockExtensionManager: any;\n+\tlet mockExtensionsItemService: any;\n+\n+\tbeforeEach(async () => {\n+\t\tvi.clearAllMocks();\n+\n+\t\tmockExtensionsItemService = {\n+\t\t\tcreateOne: vi.fn(),\n+\t\t\tcreateMany: vi.fn(),\n+\t\t\treadOne: vi.fn(),\n+\t\t\tupdateOne: vi.fn(),\n+\t\t\tdeleteOne: vi.fn(),\n+\t\t\tdeleteByQuery: vi.fn(),\n+\t\t\treadByQuery: vi.fn(),\n+\t\t};\n+\n+\t\tmockExtensionManager = {\n+\t\t\tinstall: vi.fn(),\n+\t\t\tuninstall: vi.fn(),\n+\t\t\textensions: [],\n+\t\t\tgetExtension: vi.fn(),\n+\t\t\treload: vi.fn(),\n+\t\t\tbroadcastReloadNotification: vi.fn(),\n+\t\t};\n+\n+\t\tvi.mocked(getExtensionManager).mockReturnValue(mockExtensionManager);\n+\n+\t\tvi.mocked(ItemsService).mockImplementation(() => mockExtensionsItemService);\n+\n+\t\tvi.mocked(registryDescribe).mockResolvedValue({\n+\t\t\tdata: {\n+\t\t\t\ttype: 'interface',\n+\t\t\t\tversions: [\n+\t\t\t\t\t{\n+\t\t\t\t\t\tid: 'test-version',\n+\t\t\t\t\t\tbundled: [],\n+\t\t\t\t\t},\n+\t\t\t\t],\n+\t\t\t},\n+\t\t} as any);\n+\t});\n+\n+\tdescribe('install', () => {\n+\t\ttest('should propagate extension manager install error', async () => {\n+\t\t\tmockExtensionManager.install.mockRejectedValue(\n+\t\t\t\tnew ServiceUnavailableError({\n+\t\t\t\t\tservice: 'marketplace',\n+\t\t\t\t\treason: 'Could not download the extension',\n+\t\t\t\t}),\n+\t\t\t);\n+\n+\t\t\tconst service = new ExtensionsService({\n+\t\t\t\tknex: {} as any,\n+\t\t\t\tschema: {} as any,\n+\t\t\t\taccountability: null,\n+\t\t\t});\n+\n+\t\t\tawait expect(service.install('test-extension', 'test-version')).rejects.toThrow(\n+\t\t\t\t'Could not download the extension',\n+\t\t\t);\n+\t\t});\n+\t});\n+});\n", "test_patch": "", "problem_statement": "## Scope\r\n\r\nBuilds upon #25810\r\n\r\nWhat's changed:\r\n\r\n- Splits the generic service error message into two independent messages\r\n- Improves clarity by being more explicit as to what stage the process failed\r\n\r\n### Extract/Save error\r\nhttps://github.com/user-attachments/assets/69e41532-8d4d-413a-ac37-ca5e8ecc7657\r\n### Fetch/Download error\r\nhttps://github.com/user-attachments/assets/34d56ae9-724a-4df0-a4f1-de2a3fdddb2f\r\n\r\n\r\n## Potential Risks / Drawbacks\r\n\r\n- Should be none\r\n\r\n## Tested Scenarios\r\n\r\n- [x] Expect registry failure to show registry unavailable\r\n- [x] Expect any other errors to result in extension service unavailable \r\n\r\n## Review Notes / Questions\r\n\r\n- I would like to lorem ipsum\r\n- Special attention should be paid to dolor sit amet\r\n\r\n## Checklist\r\n\r\n- [x] Added or updated tests\r\n- [ ] Documentation PR created [here](https://github.com/directus/docs) or not required\r\n- [ ] OpenAPI package PR created [here](https://github.com/directus/openapi) or not required\r\n\r\n---\r\n\r\nFixes #25807\r\nAlternate of: https://github.com/directus/directus/pull/25810\r\n", "hints_text": "", "created_at": "2025-11-14T19:33:59Z", "pull_number": 26193, "test_files": ["api/src/extensions/lib/installation/manager.test.ts", "api/src/services/extensions.test.ts"], "code_files": ["api/src/extensions/lib/installation/manager.ts"], "title": "Improve extension install error messages", "additions": 0, "deletions": 0}
{"repo": "directus/directus", "instance_id": "directus__directus.pr_mirror.26126", "base_commit": "91ab160aa6d711f371a11e28101d44710f67d9bf", "patch": "diff --git a/.changeset/slick-eagles-dance.md b/.changeset/slick-eagles-dance.md\nnew file mode 100644\nindex 0000000000000..a0495f5261641\n--- /dev/null\n+++ b/.changeset/slick-eagles-dance.md\n@@ -0,0 +1,5 @@\n+---\n+'@directus/api': patch\n+---\n+\n+Fixed file replacement with tus enabled\ndiff --git a/api/src/services/tus/data-store.ts b/api/src/services/tus/data-store.ts\nindex 236d5b654c4eb..9531ff9afe5ad 100644\n--- a/api/src/services/tus/data-store.ts\n+++ b/api/src/services/tus/data-store.ts\n@@ -1,14 +1,14 @@\n import formatTitle from '@directus/format-title';\n import type { TusDriver } from '@directus/storage';\n import type { Accountability, ChunkedUploadContext, File, SchemaOverview } from '@directus/types';\n+import { DataStore, ERRORS, Upload } from '@tus/utils';\n+import { omit } from 'lodash-es';\n import { extension } from 'mime-types';\n import { extname } from 'node:path';\n import stream from 'node:stream';\n-import { DataStore, ERRORS, Upload } from '@tus/utils';\n-import { ItemsService } from '../items.js';\n-import { useLogger } from '../../logger/index.js';\n import getDatabase from '../../database/index.js';\n-import { omit } from 'lodash-es';\n+import { useLogger } from '../../logger/index.js';\n+import { ItemsService } from '../items.js';\n \n export type TusDataStoreConfig = {\n \tconstants: {\n@@ -97,7 +97,7 @@ export class TusDataStore extends DataStore {\n \t\t}\n \n \t\tconst fileData: Partial<File> = {\n-\t\t\t...omit(upload.metadata, ['id']),\n+\t\t\t...omit(upload.metadata, ['id', 'replace_id']),\n \t\t\ttus_id: upload.id,\n \t\t\ttus_data: upload,\n \t\t\tfilesize: upload.size,\ndiff --git a/pnpm-lock.yaml b/pnpm-lock.yaml\nindex 714d84c1546ff..6f03db0fc564a 100644\n--- a/pnpm-lock.yaml\n+++ b/pnpm-lock.yaml\n@@ -3073,6 +3073,9 @@ importers:\n       supertest:\n         specifier: 7.1.4\n         version: 7.1.4\n+      tus-js-client:\n+        specifier: 'catalog:'\n+        version: 4.3.1\n       typescript:\n         specifier: 'catalog:'\n         version: 5.9.3\n@@ -3739,9 +3742,6 @@ packages:\n   '@emnapi/core@1.6.0':\n     resolution: {integrity: sha512-zq/ay+9fNIJJtJiZxdTnXS20PllcYMX3OE23ESc4HK/bdYu3cOWYVhsOhVnXALfU/uqJIxn5NBPd9z4v+SfoSg==}\n \n-  '@emnapi/runtime@1.6.0':\n-    resolution: {integrity: sha512-obtUmAHTMjll499P+D9A3axeJFlhdjOWdKUNs/U6QIGT7V5RjcUW1xToAzjvmgTSQhDbYn/NwfTRoJcQ2rNBxA==}\n-\n   '@emnapi/runtime@1.7.0':\n     resolution: {integrity: sha512-oAYoQnCYaQZKVS53Fq23ceWMRxq5EhQsE0x0RdQ55jT7wagMu5k+fS39v1fiSLrtrLQlXwVINenqhLMtTrV/1Q==}\n \n@@ -4402,15 +4402,6 @@ packages:\n       '@types/node':\n         optional: true\n \n-  '@inquirer/external-editor@1.0.2':\n-    resolution: {integrity: sha512-yy9cOoBnx58TlsPrIxauKIFQTiyH+0MK4e97y4sV9ERbI+zDxw7i2hxHLCIEGIE/8PPvDxGhgzIOTSOWcs6/MQ==}\n-    engines: {node: '>=18'}\n-    peerDependencies:\n-      '@types/node': '>=18'\n-    peerDependenciesMeta:\n-      '@types/node':\n-        optional: true\n-\n   '@inquirer/external-editor@1.0.3':\n     resolution: {integrity: sha512-RWbSrDiYmO4LbejWY7ttpxczuwQyZLBUyygsA9Nsv95hpzUWwnNTVQmAq3xuh7vNwCp07UTmE5i11XAEExx4RA==}\n     engines: {node: '>=18'}\n@@ -6768,27 +6759,15 @@ packages:\n     peerDependencies:\n       '@babel/core': ^7.0.0-0\n \n-  '@vue/compiler-core@3.5.22':\n-    resolution: {integrity: sha512-jQ0pFPmZwTEiRNSb+i9Ow/I/cHv2tXYqsnHKKyCQ08irI2kdF5qmYedmF8si8mA7zepUFmJ2hqzS8CQmNOWOkQ==}\n-\n   '@vue/compiler-core@3.5.24':\n     resolution: {integrity: sha512-eDl5H57AOpNakGNAkFDH+y7kTqrQpJkZFXhWZQGyx/5Wh7B1uQYvcWkvZi11BDhscPgj8N7XV3oRwiPnx1Vrig==}\n \n-  '@vue/compiler-dom@3.5.22':\n-    resolution: {integrity: sha512-W8RknzUM1BLkypvdz10OVsGxnMAuSIZs9Wdx1vzA3mL5fNMN15rhrSCLiTm6blWeACwUwizzPVqGJgOGBEN/hA==}\n-\n   '@vue/compiler-dom@3.5.24':\n     resolution: {integrity: sha512-1QHGAvs53gXkWdd3ZMGYuvQFXHW4ksKWPG8HP8/2BscrbZ0brw183q2oNWjMrSWImYLHxHrx1ItBQr50I/q2zw==}\n \n-  '@vue/compiler-sfc@3.5.22':\n-    resolution: {integrity: sha512-tbTR1zKGce4Lj+JLzFXDq36K4vcSZbJ1RBu8FxcDv1IGRz//Dh2EBqksyGVypz3kXpshIfWKGOCcqpSbyGWRJQ==}\n-\n   '@vue/compiler-sfc@3.5.24':\n     resolution: {integrity: sha512-8EG5YPRgmTB+YxYBM3VXy8zHD9SWHUJLIGPhDovo3Z8VOgvP+O7UP5vl0J4BBPWYD9vxtBabzW1EuEZ+Cqs14g==}\n \n-  '@vue/compiler-ssr@3.5.22':\n-    resolution: {integrity: sha512-GdgyLvg4R+7T8Nk2Mlighx7XGxq/fJf9jaVofc3IL0EPesTE86cP/8DD1lT3h1JeZr2ySBvyqKQJgbS54IX1Ww==}\n-\n   '@vue/compiler-ssr@3.5.24':\n     resolution: {integrity: sha512-trOvMWNBMQ/odMRHW7Ae1CdfYx+7MuiQu62Jtu36gMLXcaoqKvAyh+P73sYG9ll+6jLB6QPovqoKGGZROzkFFg==}\n \n@@ -6839,9 +6818,6 @@ packages:\n     peerDependencies:\n       vue: 3.5.24\n \n-  '@vue/shared@3.5.22':\n-    resolution: {integrity: sha512-F4yc6palwq3TT0u+FYf0Ns4Tfl9GRFURDN2gWG7L1ecIaS/4fCIuFOjMTnCyjsu/OK6vaDKLCrGAa+KvvH+h4w==}\n-\n   '@vue/shared@3.5.24':\n     resolution: {integrity: sha512-9cwHL2EsJBdi8NY22pngYYWzkTDhld6fAD6jlaeloNGciNSJL6bLpbxVgXl96X00Jtc6YWQv96YA/0sxex/k1A==}\n \n@@ -7499,9 +7475,6 @@ packages:\n   char-spinner@1.0.1:\n     resolution: {integrity: sha512-acv43vqJ0+N0rD+Uw3pDHSxP30FHrywu2NO6/wBaHChJIizpDeBUd6NjqhNhy9LGaEAhZAXn46QzmlAvIWd16g==}\n \n-  chardet@2.1.0:\n-    resolution: {integrity: sha512-bNFETTG/pM5ryzQ9Ad0lJOTa6HWD/YsScAR3EnCPZRPlQh77JocYktSHOUHelyhm8IARL+o4c4F1bP5KVOjiRA==}\n-\n   chardet@2.1.1:\n     resolution: {integrity: sha512-PsezH1rqdV9VvyNhxxOW32/d75r01NY7TQCmOqomRo15ZSOKbpTFVsfjghxo6JloQUCGnH4k1LGu0R4yCLlWQQ==}\n \n@@ -12597,10 +12570,6 @@ packages:\n     resolution: {integrity: sha512-DZ4yORTwrbTj/7MZYq2w+/ZFdI6OZ/f9SFHR+71gIVUZhOQPHzVCLpvRnPgyaMpfWxxk/4ONva3GQSyNIKRv6A==}\n     engines: {node: '>=10'}\n \n-  tar@7.5.1:\n-    resolution: {integrity: sha512-nlGpxf+hv0v7GkWBK2V9spgactGOp0qvfWRxUMjqHyzrt3SgwE48DIv/FhqPHJYLHpgW1opq3nERbz5Anq7n1g==}\n-    engines: {node: '>=18'}\n-\n   tar@7.5.2:\n     resolution: {integrity: sha512-7NyxrTE4Anh8km8iEy7o0QYPs+0JKBTj5ZaqHg6B39erLg0qYXN3BijtShwbsNSvQ+LN75+KV+C4QR/f6Gwnpg==}\n     engines: {node: '>=18'}\n@@ -14650,7 +14619,7 @@ snapshots:\n       '@changesets/should-skip-package': 0.1.2\n       '@changesets/types': 6.1.0\n       '@changesets/write': 0.4.0\n-      '@inquirer/external-editor': 1.0.2(@types/node@24.9.1)\n+      '@inquirer/external-editor': 1.0.3(@types/node@24.9.1)\n       '@manypkg/get-packages': 1.1.3\n       ansi-colors: 4.1.3\n       ci-info: 3.9.0\n@@ -14922,11 +14891,6 @@ snapshots:\n       tslib: 2.8.1\n     optional: true\n \n-  '@emnapi/runtime@1.6.0':\n-    dependencies:\n-      tslib: 2.8.1\n-    optional: true\n-\n   '@emnapi/runtime@1.7.0':\n     dependencies:\n       tslib: 2.8.1\n@@ -15484,13 +15448,6 @@ snapshots:\n     optionalDependencies:\n       '@types/node': 24.9.1\n \n-  '@inquirer/external-editor@1.0.2(@types/node@24.9.1)':\n-    dependencies:\n-      chardet: 2.1.0\n-      iconv-lite: 0.7.0\n-    optionalDependencies:\n-      '@types/node': 24.9.1\n-\n   '@inquirer/external-editor@1.0.3(@types/node@22.13.14)':\n     dependencies:\n       chardet: 2.1.1\n@@ -15973,7 +15930,7 @@ snapshots:\n   '@napi-rs/wasm-runtime@1.0.7':\n     dependencies:\n       '@emnapi/core': 1.6.0\n-      '@emnapi/runtime': 1.6.0\n+      '@emnapi/runtime': 1.7.0\n       '@tybys/wasm-util': 0.10.1\n     optional: true\n \n@@ -18585,7 +18542,7 @@ snapshots:\n       '@babel/types': 7.28.5\n       '@vue/babel-helper-vue-transform-on': 1.5.0\n       '@vue/babel-plugin-resolve-type': 1.5.0(@babel/core@7.28.4)\n-      '@vue/shared': 3.5.22\n+      '@vue/shared': 3.5.24\n     optionalDependencies:\n       '@babel/core': 7.28.4\n     transitivePeerDependencies:\n@@ -18598,18 +18555,10 @@ snapshots:\n       '@babel/helper-module-imports': 7.27.1\n       '@babel/helper-plugin-utils': 7.27.1\n       '@babel/parser': 7.28.5\n-      '@vue/compiler-sfc': 3.5.22\n+      '@vue/compiler-sfc': 3.5.24\n     transitivePeerDependencies:\n       - supports-color\n \n-  '@vue/compiler-core@3.5.22':\n-    dependencies:\n-      '@babel/parser': 7.28.5\n-      '@vue/shared': 3.5.22\n-      entities: 4.5.0\n-      estree-walker: 2.0.2\n-      source-map-js: 1.2.1\n-\n   '@vue/compiler-core@3.5.24':\n     dependencies:\n       '@babel/parser': 7.28.5\n@@ -18618,28 +18567,11 @@ snapshots:\n       estree-walker: 2.0.2\n       source-map-js: 1.2.1\n \n-  '@vue/compiler-dom@3.5.22':\n-    dependencies:\n-      '@vue/compiler-core': 3.5.22\n-      '@vue/shared': 3.5.22\n-\n   '@vue/compiler-dom@3.5.24':\n     dependencies:\n       '@vue/compiler-core': 3.5.24\n       '@vue/shared': 3.5.24\n \n-  '@vue/compiler-sfc@3.5.22':\n-    dependencies:\n-      '@babel/parser': 7.28.5\n-      '@vue/compiler-core': 3.5.22\n-      '@vue/compiler-dom': 3.5.22\n-      '@vue/compiler-ssr': 3.5.22\n-      '@vue/shared': 3.5.22\n-      estree-walker: 2.0.2\n-      magic-string: 0.30.21\n-      postcss: 8.5.6\n-      source-map-js: 1.2.1\n-\n   '@vue/compiler-sfc@3.5.24':\n     dependencies:\n       '@babel/parser': 7.28.5\n@@ -18652,11 +18584,6 @@ snapshots:\n       postcss: 8.5.6\n       source-map-js: 1.2.1\n \n-  '@vue/compiler-ssr@3.5.22':\n-    dependencies:\n-      '@vue/compiler-dom': 3.5.22\n-      '@vue/shared': 3.5.22\n-\n   '@vue/compiler-ssr@3.5.24':\n     dependencies:\n       '@vue/compiler-dom': 3.5.24\n@@ -18698,9 +18625,9 @@ snapshots:\n   '@vue/language-core@2.2.0(typescript@5.9.3)':\n     dependencies:\n       '@volar/language-core': 2.4.23\n-      '@vue/compiler-dom': 3.5.22\n+      '@vue/compiler-dom': 3.5.24\n       '@vue/compiler-vue2': 2.7.16\n-      '@vue/shared': 3.5.22\n+      '@vue/shared': 3.5.24\n       alien-signals: 0.4.14\n       minimatch: 9.0.5\n       muggle-string: 0.4.1\n@@ -18711,8 +18638,8 @@ snapshots:\n   '@vue/language-core@3.1.3(typescript@5.9.3)':\n     dependencies:\n       '@volar/language-core': 2.4.23\n-      '@vue/compiler-dom': 3.5.22\n-      '@vue/shared': 3.5.22\n+      '@vue/compiler-dom': 3.5.24\n+      '@vue/shared': 3.5.24\n       alien-signals: 3.0.3\n       muggle-string: 0.4.1\n       path-browserify: 1.0.1\n@@ -18742,8 +18669,6 @@ snapshots:\n       '@vue/shared': 3.5.24\n       vue: 3.5.24(typescript@5.9.3)\n \n-  '@vue/shared@3.5.22': {}\n-\n   '@vue/shared@3.5.24': {}\n \n   '@vue/test-utils@2.4.6':\n@@ -19358,7 +19283,7 @@ snapshots:\n       minipass-pipeline: 1.2.4\n       p-map: 7.0.3\n       ssri: 12.0.0\n-      tar: 7.5.1\n+      tar: 7.5.2\n       unique-filename: 4.0.0\n \n   cache-parser@1.2.5: {}\n@@ -19495,8 +19420,6 @@ snapshots:\n \n   char-spinner@1.0.1: {}\n \n-  chardet@2.1.0: {}\n-\n   chardet@2.1.1: {}\n \n   charm@0.1.2: {}\n@@ -22469,7 +22392,7 @@ snapshots:\n       nopt: 8.1.0\n       proc-log: 5.0.0\n       semver: 7.7.3\n-      tar: 7.5.1\n+      tar: 7.5.2\n       tinyglobby: 0.2.15\n       which: 5.0.0\n     transitivePeerDependencies:\n@@ -24996,14 +24919,6 @@ snapshots:\n       yallist: 4.0.0\n     optional: true\n \n-  tar@7.5.1:\n-    dependencies:\n-      '@isaacs/fs-minipass': 4.0.1\n-      chownr: 3.0.0\n-      minipass: 7.1.2\n-      minizlib: 3.1.0\n-      yallist: 5.0.0\n-\n   tar@7.5.2:\n     dependencies:\n       '@isaacs/fs-minipass': 4.0.1\n@@ -25615,7 +25530,7 @@ snapshots:\n       '@babel/plugin-syntax-import-meta': 7.10.4(@babel/core@7.28.4)\n       '@babel/plugin-transform-typescript': 7.28.0(@babel/core@7.28.4)\n       '@vue/babel-plugin-jsx': 1.5.0(@babel/core@7.28.4)\n-      '@vue/compiler-dom': 3.5.22\n+      '@vue/compiler-dom': 3.5.24\n       kolorist: 1.8.0\n       magic-string: 0.30.21\n       vite: 7.1.12(@types/node@24.9.1)(jiti@2.6.1)(sass-embedded@1.93.3)(sass@1.93.3)(terser@5.44.0)(tsx@4.20.6)(yaml@2.8.1)\ndiff --git a/tests/blackbox/common/config.ts b/tests/blackbox/common/config.ts\nindex 352581cfdbe53..4c3652ef7c538 100644\n--- a/tests/blackbox/common/config.ts\n+++ b/tests/blackbox/common/config.ts\n@@ -91,6 +91,7 @@ const directusConfig = {\n \tQUERY_LIMIT_DEFAULT: '90', // Must be less than MAX_BATCH_MUTATION by at least 3\n \tACCESS_TOKEN_TTL: '25d', // should be larger than 24.86 days to test Expires value larger than 32-bit signed integer\n \tWEBSOCKETS_ENABLED: 'true',\n+\tTUS_ENABLED: 'true',\n \t...directusAuthConfig,\n \t...directusStorageConfig,\n };\ndiff --git a/tests/blackbox/common/functions.ts b/tests/blackbox/common/functions.ts\nindex fe18d525fca50..2c2f2c20d81ab 100644\n--- a/tests/blackbox/common/functions.ts\n+++ b/tests/blackbox/common/functions.ts\n@@ -786,7 +786,7 @@ export async function CreatePolicy(vendor: Vendor, options: OptionsCreatePolicy)\n \n export type OptionsCreatePermission = {\n \trole: keyof typeof ROLE;\n-\tpermission: Omit<Partial<Permission>, 'id' | 'role' | 'system'>;\n+\tpermissions: Omit<Partial<Permission>, 'id' | 'role' | 'system' | 'policy'>[];\n \tpolicy?: string;\n \tpolicyName?: string;\n };\n@@ -799,7 +799,7 @@ export async function CreatePermission(vendor: Vendor, options: OptionsCreatePer\n \t\tconst role = await request(getUrl(vendor))\n \t\t\t.get('/roles')\n \t\t\t.query({ filter: { name: { _eq: ROLE[roleId].NAME } } })\n-\t\t\t.set('Authorization', `Bearer ${USER.APP_ACCESS.TOKEN}`);\n+\t\t\t.set('Authorization', `Bearer ${USER.ADMIN.TOKEN}`);\n \n \t\troleId = role.body.data[0].id;\n \t}\n@@ -817,12 +817,29 @@ export async function CreatePermission(vendor: Vendor, options: OptionsCreatePer\n \n \tconst response = await request(getUrl(vendor))\n \t\t.patch(`/policies/${policyId}`)\n-\t\t.set('Authorization', `Bearer ${USER.TESTS_FLOW.TOKEN}`)\n-\t\t.send({ permissions: { create: [{ ...options.permission, policy: options.policy }], update: [], delete: [] } });\n+\t\t.set('Authorization', `Bearer ${USER.ADMIN.TOKEN}`)\n+\t\t.send({\n+\t\t\tpermissions: {\n+\t\t\t\tcreate: options.permissions.map((p) => ({ ...p, policy: policyId })),\n+\t\t\t\tupdate: [],\n+\t\t\t\tdelete: [],\n+\t\t\t},\n+\t\t});\n \n \treturn response.body.data;\n }\n \n+export type OptionsDeletePermission = {\n+\tpolicyId: string;\n+};\n+\n+export async function DeletePermission(vendor: Vendor, { policyId }: OptionsDeletePermission) {\n+\tconst response = await request(getUrl(vendor))\n+\t\t.delete(`/policies/${policyId}`)\n+\t\t.set('Authorization', `Bearer ${USER.ADMIN.TOKEN}`);\n+\n+\treturn response.body;\n+}\n+\n // TODO\n // export async function UpdatePermission() {}\n-// export async function DeletePermission() {}\ndiff --git a/tests/blackbox/package.json b/tests/blackbox/package.json\nindex 1074dafcf7dd6..48a0f0a0b33d5 100644\n--- a/tests/blackbox/package.json\n+++ b/tests/blackbox/package.json\n@@ -11,6 +11,7 @@\n \t\t\"@directus/tsconfig\": \"catalog:\",\n \t\t\"@directus/types\": \"workspace:*\",\n \t\t\"@directus/utils\": \"workspace:*\",\n+\t\t\"tus-js-client\": \"catalog:\",\n \t\t\"@types/js-yaml\": \"catalog:\",\n \t\t\"@types/lodash-es\": \"catalog:\",\n \t\t\"@types/seedrandom\": \"3.0.8\",\ndiff --git a/tests/blackbox/tests/db/routes/files/tus.test.ts b/tests/blackbox/tests/db/routes/files/tus.test.ts\nnew file mode 100644\nindex 0000000000000..da329b9f6bc16\n--- /dev/null\n+++ b/tests/blackbox/tests/db/routes/files/tus.test.ts\n@@ -0,0 +1,145 @@\n+import { getUrl } from '@common/config';\n+import { CreatePermission, DeletePermission } from '@common/functions';\n+import vendors, { type Vendor } from '@common/get-dbs-to-test';\n+import { USER } from '@common/variables';\n+import type { Query } from '@directus/types';\n+import request, { type Response } from 'supertest';\n+import { Upload } from 'tus-js-client';\n+import { afterAll, beforeAll, describe, expect, it } from 'vitest';\n+\n+const file = {\n+\tname: 'tus.text',\n+\ttype: 'text/plain',\n+\tcontent: 'tus',\n+};\n+\n+const policies = new Map();\n+\n+function createUpload(vendor: Vendor, payload: { filename_download: string; type: string; id?: string }) {\n+\treturn new Promise<Response>((resolve, reject) => {\n+\t\tconst upload = new Upload(Buffer.from(file.content), {\n+\t\t\theaders: {\n+\t\t\t\tAuthorization: `Bearer ${USER.APP_ACCESS.TOKEN}`,\n+\t\t\t},\n+\t\t\tendpoint: getUrl(vendor) + `/files/tus`,\n+\t\t\tchunkSize: Buffer.from(file.content).byteLength,\n+\t\t\tmetadata: payload,\n+\t\t\tremoveFingerprintOnSuccess: true,\n+\t\t\tonError(error: unknown) {\n+\t\t\t\treject(error);\n+\t\t\t},\n+\t\t\tasync onSuccess() {\n+\t\t\t\tconst query: Query = {\n+\t\t\t\t\tfilter: { filename_download: { _eq: payload.filename_download } },\n+\t\t\t\t\tfields: ['id'],\n+\t\t\t\t\tlimit: 1,\n+\t\t\t\t};\n+\n+\t\t\t\tif (payload.id) {\n+\t\t\t\t\tquery.filter = {\n+\t\t\t\t\t\t...query.filter,\n+\t\t\t\t\t\tid: { _eq: payload.id },\n+\t\t\t\t\t};\n+\t\t\t\t}\n+\n+\t\t\t\tconst response = await request(getUrl(vendor))\n+\t\t\t\t\t.get('/files')\n+\t\t\t\t\t.query(query)\n+\t\t\t\t\t.set('Authorization', `Bearer ${USER.APP_ACCESS.TOKEN}`);\n+\n+\t\t\t\tresolve(response);\n+\t\t\t},\n+\t\t\tonShouldRetry() {\n+\t\t\t\treturn false;\n+\t\t\t},\n+\t\t});\n+\n+\t\tupload.start();\n+\t});\n+}\n+\n+beforeAll(async () => {\n+\tfor (const vendor of vendors) {\n+\t\tconst response = await CreatePermission(vendor, {\n+\t\t\trole: USER.APP_ACCESS.KEY,\n+\t\t\tpermissions: [\n+\t\t\t\t{\n+\t\t\t\t\tcollection: 'directus_files',\n+\t\t\t\t\taction: 'create',\n+\t\t\t\t\tpermissions: {},\n+\t\t\t\t\tfields: ['*'],\n+\t\t\t\t},\n+\t\t\t\t{\n+\t\t\t\t\tcollection: 'directus_files',\n+\t\t\t\t\taction: 'read',\n+\t\t\t\t\tpermissions: {},\n+\t\t\t\t\tfields: ['*'],\n+\t\t\t\t},\n+\t\t\t\t{\n+\t\t\t\t\tcollection: 'directus_files',\n+\t\t\t\t\taction: 'update',\n+\t\t\t\t\tpermissions: {},\n+\t\t\t\t\tfields: ['*'],\n+\t\t\t\t},\n+\t\t\t\t{\n+\t\t\t\t\tcollection: 'directus_files',\n+\t\t\t\t\taction: 'delete',\n+\t\t\t\t\tpermissions: {},\n+\t\t\t\t\tfields: ['*'],\n+\t\t\t\t},\n+\t\t\t],\n+\t\t\tpolicyName: 'TUS',\n+\t\t});\n+\n+\t\tpolicies.set(vendor, response.id);\n+\t}\n+});\n+\n+afterAll(async () => {\n+\tfor (const vendor of vendors) {\n+\t\tif (!policies.has(vendor)) continue;\n+\n+\t\tawait DeletePermission(vendor, {\n+\t\t\tpolicyId: policies.get(vendor),\n+\t\t});\n+\t}\n+});\n+\n+describe('/files/tus', () => {\n+\tdescribe('POST /files/tus', () => {\n+\t\tit.each(vendors)('%s', async (vendor) => {\n+\t\t\t// Action\n+\t\t\tconst response = await createUpload(vendor, { filename_download: file.name, type: file.type });\n+\n+\t\t\t// Assert\n+\t\t\texpect(response.statusCode).toBe(200);\n+\t\t\texpect(response.body.data?.[0]?.id).toBeDefined();\n+\t\t});\n+\t});\n+\n+\tdescribe('PATCH /files/tus/:id', () => {\n+\t\tit.each(vendors)('%s', async (vendor) => {\n+\t\t\tconst fileResponse = await request(getUrl(vendor))\n+\t\t\t\t.get('/files')\n+\t\t\t\t.query({\n+\t\t\t\t\tfilter: { filename_download: { _eq: file.name } },\n+\t\t\t\t\tfields: ['id'],\n+\t\t\t\t\tlimit: 1,\n+\t\t\t\t})\n+\t\t\t\t.set('Authorization', `Bearer ${USER.APP_ACCESS.TOKEN}`);\n+\n+\t\t\tfile.name = `changed_${file.name}`;\n+\n+\t\t\t// Action\n+\t\t\tconst response = await createUpload(vendor, {\n+\t\t\t\tfilename_download: file.name,\n+\t\t\t\ttype: file.type,\n+\t\t\t\tid: fileResponse.body.data?.[0]?.id,\n+\t\t\t});\n+\n+\t\t\t// Assert\n+\t\t\texpect(response.statusCode).toBe(200);\n+\t\t\texpect(response.body.data?.[0]?.id).toBeDefined();\n+\t\t});\n+\t});\n+});\ndiff --git a/tests/blackbox/tests/db/routes/permissions/check-item-permissions.test.ts b/tests/blackbox/tests/db/routes/permissions/check-item-permissions.test.ts\nindex bb777478c0dd7..65fb2a42164ba 100644\n--- a/tests/blackbox/tests/db/routes/permissions/check-item-permissions.test.ts\n+++ b/tests/blackbox/tests/db/routes/permissions/check-item-permissions.test.ts\n@@ -61,13 +61,15 @@ describe('/permissions/me/:collection/:id?', () => {\n \n \t\t\t\t\tawait CreatePermission(vendor, {\n \t\t\t\t\t\trole: USER.APP_ACCESS.KEY,\n-\t\t\t\t\t\tpermission: {\n-\t\t\t\t\t\t\tcollection,\n-\t\t\t\t\t\t\taction: 'update',\n-\t\t\t\t\t\t\tpermissions: { _and: [{ name: { _eq: collectionItemName } }] },\n-\t\t\t\t\t\t\tpresets: {},\n-\t\t\t\t\t\t\tfields: ['name'],\n-\t\t\t\t\t\t},\n+\t\t\t\t\t\tpermissions: [\n+\t\t\t\t\t\t\t{\n+\t\t\t\t\t\t\t\tcollection,\n+\t\t\t\t\t\t\t\taction: 'update',\n+\t\t\t\t\t\t\t\tpermissions: { _and: [{ name: { _eq: collectionItemName } }] },\n+\t\t\t\t\t\t\t\tpresets: {},\n+\t\t\t\t\t\t\t\tfields: ['name'],\n+\t\t\t\t\t\t\t},\n+\t\t\t\t\t\t],\n \t\t\t\t\t\tpolicyName: 'Check Update Collection',\n \t\t\t\t\t});\n \n@@ -105,13 +107,15 @@ describe('/permissions/me/:collection/:id?', () => {\n \n \t\t\t\t\tawait CreatePermission(vendor, {\n \t\t\t\t\t\trole: USER.APP_ACCESS.KEY,\n-\t\t\t\t\t\tpermission: {\n-\t\t\t\t\t\t\tcollection: singleton,\n-\t\t\t\t\t\t\taction: 'update',\n-\t\t\t\t\t\t\tpermissions: { _and: [{ name: { _eq: singletonItemName } }] },\n-\t\t\t\t\t\t\tpresets: {},\n-\t\t\t\t\t\t\tfields: ['name'],\n-\t\t\t\t\t\t},\n+\t\t\t\t\t\tpermissions: [\n+\t\t\t\t\t\t\t{\n+\t\t\t\t\t\t\t\tcollection: singleton,\n+\t\t\t\t\t\t\t\taction: 'update',\n+\t\t\t\t\t\t\t\tpermissions: { _and: [{ name: { _eq: singletonItemName } }] },\n+\t\t\t\t\t\t\t\tpresets: {},\n+\t\t\t\t\t\t\t\tfields: ['name'],\n+\t\t\t\t\t\t\t},\n+\t\t\t\t\t\t],\n \t\t\t\t\t\tpolicyName: 'Check Update Singleton',\n \t\t\t\t\t});\n \n", "test_patch": "", "problem_statement": "## Scope\r\n\r\nWhat's changed:\r\n\r\n- No longer attempt to save metadata only field `replace_id`. This resulted in permission errors for all but admin\r\n\r\n## Potential Risks / Drawbacks\r\n\r\n- Should be none as the expectation is for `replace_id` to be tracked under `tus_data`\r\n\r\n## Tested Scenarios\r\n\r\n- [x] Expect upload to succeed\r\n- [x] Expect replace to succeed\r\n- [x] Expect delete to succeed\r\n\r\n## Review Notes / Questions\r\n\r\n- I would like to lorem ipsum\r\n- Special attention should be paid to dolor sit amet\r\n\r\n## Checklist\r\n\r\n- [x] Added or updated tests\r\n- [ ] Documentation PR created [here](https://github.com/directus/docs) or not required\r\n\r\n---\r\n\r\nFixes #26118\r\n", "hints_text": "", "created_at": "2025-11-06T00:56:06Z", "pull_number": 26126, "test_files": ["tests/blackbox/tests/db/routes/files/tus.test.ts", "tests/blackbox/tests/db/routes/permissions/check-item-permissions.test.ts"], "code_files": ["api/src/services/tus/data-store.ts", "tests/blackbox/common/config.ts", "tests/blackbox/common/functions.ts"], "title": "Fix file replacement with tus enabled", "additions": 0, "deletions": 0}
