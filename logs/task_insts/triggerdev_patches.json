[
  {
    "instance_id": "triggerdotdev__trigger.dev.d1c3bfb9.2508",
    "repo": "triggerdotdev__trigger.dev.d1c3bfb9",
    "base_commit": "7d333e5b3c0c698f95b8c90896bff3176ccb482b",
    "head_commit": "ff7be341a80ca382becb0e8695bef27fc4abfffa",
    "title": "fix(core): prettyPrintingPacket will now do a structuredClone on non-circular references instead of outputting [Circular]",
    "merged_at": "2025-09-15T16:43:46Z",
    "html_url": "https://github.com/triggerdotdev/trigger.dev/pull/2508",
    "test_files": [
      "apps/webapp/test/fairDequeuingStrategy.test.ts",
      "packages/core/test/ioSerialization.test.ts"
    ],
    "code_files": [
      "apps/webapp/app/routes/resources.taskruns.$runParam.replay.ts",
      "packages/core/src/v3/utils/ioSerialization.ts",
      "references/hello-world/src/trigger/circularPayload.ts"
    ],
    "total_changes": 431,
    "num_files": 5,
    "pull_number": 2508,
    "patch": "diff --git a/apps/webapp/app/routes/resources.taskruns.$runParam.replay.ts b/apps/webapp/app/routes/resources.taskruns.$runParam.replay.ts\nindex 0e87a3d1bd..57de7632a2 100644\n--- a/apps/webapp/app/routes/resources.taskruns.$runParam.replay.ts\n+++ b/apps/webapp/app/routes/resources.taskruns.$runParam.replay.ts\n@@ -108,6 +108,8 @@ export async function loader({ request, params }: LoaderFunctionArgs) {\n   const disableVersionSelection = environment.type === \"DEVELOPMENT\";\n   const allowArbitraryQueues = backgroundWorkers.at(0)?.engine === \"V1\";\n \n+  const payload = await prettyPrintPacket(run.payload, run.payloadType);\n+\n   return typedjson({\n     concurrencyKey: run.concurrencyKey,\n     maxAttempts: run.maxAttempts,\n@@ -116,7 +118,7 @@ export async function loader({ request, params }: LoaderFunctionArgs) {\n     ttlSeconds: run.ttl ? parseDuration(run.ttl, \"s\") ?? undefined : undefined,\n     idempotencyKey: run.idempotencyKey,\n     runTags: run.runTags,\n-    payload: await prettyPrintPacket(run.payload, run.payloadType),\n+    payload,\n     payloadType: run.payloadType,\n     queue: run.queue,\n     metadata: run.seedMetadata\ndiff --git a/apps/webapp/test/fairDequeuingStrategy.test.ts b/apps/webapp/test/fairDequeuingStrategy.test.ts\nindex 3b4a6a375b..0d8b708161 100644\n--- a/apps/webapp/test/fairDequeuingStrategy.test.ts\n+++ b/apps/webapp/test/fairDequeuingStrategy.test.ts\n@@ -270,8 +270,8 @@ describe(\"FairDequeuingStrategy\", () => {\n \n       console.log(\"Second distribution took\", distribute2Duration, \"ms\");\n \n-      // Make sure the second call is more than 2 times faster than the first\n-      expect(distribute2Duration).toBeLessThan(withTolerance(distribute1Duration / 2));\n+      // Make sure the second call is faster than the first\n+      expect(distribute2Duration).toBeLessThan(distribute1Duration);\n \n       const startDistribute3 = performance.now();\n \n@@ -284,8 +284,8 @@ describe(\"FairDequeuingStrategy\", () => {\n \n       console.log(\"Third distribution took\", distribute3Duration, \"ms\");\n \n-      // Make sure the third call is more than 4 times the second\n-      expect(withTolerance(distribute3Duration)).toBeGreaterThan(distribute2Duration * 4);\n+      // Make sure the third call is faster than the second\n+      expect(withTolerance(distribute3Duration)).toBeGreaterThan(distribute2Duration);\n     }\n   );\n \ndiff --git a/packages/core/src/v3/utils/ioSerialization.ts b/packages/core/src/v3/utils/ioSerialization.ts\nindex 103260b85c..9bacc41422 100644\n--- a/packages/core/src/v3/utils/ioSerialization.ts\n+++ b/packages/core/src/v3/utils/ioSerialization.ts\n@@ -1,3 +1,4 @@\n+import { JSONHeroPath } from \"@jsonhero/path\";\n import { Attributes, Span } from \"@opentelemetry/api\";\n import { z } from \"zod\";\n import { ApiClient } from \"../apiClient/index.js\";\n@@ -12,7 +13,6 @@ import { SemanticInternalAttributes } from \"../semanticInternalAttributes.js\";\n import { TriggerTracer } from \"../tracer.js\";\n import { zodfetch } from \"../zodfetch.js\";\n import { flattenAttributes } from \"./flattenAttributes.js\";\n-import { JSONHeroPath } from \"@jsonhero/path\";\n \n export type IOPacket = {\n   data?: string | undefined;\n@@ -389,16 +389,40 @@ export async function prettyPrintPacket(\n     if (typeof rawData === \"string\") {\n       rawData = safeJsonParse(rawData);\n     }\n+\n     const { deserialize } = await loadSuperJSON();\n \n-    return await prettyPrintPacket(deserialize(rawData), \"application/json\");\n+    const hasCircularReferences = rawData && rawData.meta && hasCircularReference(rawData.meta);\n+\n+    if (hasCircularReferences) {\n+      return await prettyPrintPacket(deserialize(rawData), \"application/json\", {\n+        ...options,\n+        cloneReferences: false,\n+      });\n+    }\n+\n+    return await prettyPrintPacket(deserialize(rawData), \"application/json\", {\n+      ...options,\n+      cloneReferences: true,\n+    });\n   }\n \n   if (dataType === \"application/json\") {\n     if (typeof rawData === \"string\") {\n       rawData = safeJsonParse(rawData);\n     }\n-    return JSON.stringify(rawData, makeSafeReplacer(options), 2);\n+\n+    try {\n+      return JSON.stringify(rawData, makeSafeReplacer(options), 2);\n+    } catch (error) {\n+      // If cloneReferences is true, it's possible if our hasCircularReference logic is incorrect that stringifying the data will fail with a circular reference error\n+      // So we will try to stringify the data with cloneReferences set to false\n+      if (options?.cloneReferences) {\n+        return JSON.stringify(rawData, makeSafeReplacer({ ...options, cloneReferences: false }), 2);\n+      }\n+\n+      throw error;\n+    }\n   }\n \n   if (typeof rawData === \"string\") {\n@@ -410,6 +434,7 @@ export async function prettyPrintPacket(\n \n interface ReplacerOptions {\n   filteredKeys?: string[];\n+  cloneReferences?: boolean;\n }\n \n function makeSafeReplacer(options?: ReplacerOptions) {\n@@ -418,6 +443,10 @@ function makeSafeReplacer(options?: ReplacerOptions) {\n   return function replacer(key: string, value: any) {\n     if (typeof value === \"object\" && value !== null) {\n       if (seen.has(value)) {\n+        if (options?.cloneReferences) {\n+          return structuredClone(value);\n+        }\n+\n         return \"[Circular]\";\n       }\n       seen.add(value);\n@@ -557,3 +586,80 @@ function getKeyFromObject(object: unknown, key: string) {\n \n   return jsonHeroPath.first(object);\n }\n+\n+/**\n+ * Detects if a superjson serialization contains circular references\n+ * by analyzing the meta.referentialEqualities structure.\n+ *\n+ * Based on superjson's ReferentialEqualityAnnotations type:\n+ * Record<string, string[]> | [string[]] | [string[], Record<string, string[]>]\n+ *\n+ * Circular references are represented as:\n+ * - [string[]] where strings are paths that reference back to root or ancestors\n+ * - The first element in [string[], Record<string, string[]>] format\n+ */\n+function hasCircularReference(meta: any): boolean {\n+  if (!meta?.referentialEqualities) {\n+    return false;\n+  }\n+\n+  const re = meta.referentialEqualities;\n+\n+  // Case 1: [string[]] - array containing only circular references\n+  if (Array.isArray(re) && re.length === 1 && Array.isArray(re[0])) {\n+    return re[0].length > 0; // Has circular references\n+  }\n+\n+  // Case 2: [string[], Record<string, string[]>] - mixed format\n+  if (Array.isArray(re) && re.length === 2 && Array.isArray(re[0])) {\n+    return re[0].length > 0; // First element contains circular references\n+  }\n+\n+  // Case 3: Record<string, string[]> - check for circular patterns in shared references\n+  if (!Array.isArray(re) && typeof re === \"object\") {\n+    // Check if any reference path points to an ancestor path\n+    for (const [targetPath, referencePaths] of Object.entries(re)) {\n+      for (const refPath of referencePaths as string[]) {\n+        if (isCircularPattern(targetPath, refPath)) {\n+          return true;\n+        }\n+      }\n+    }\n+    return false;\n+  }\n+\n+  return false;\n+}\n+\n+/**\n+ * Checks if a reference pattern represents a circular reference\n+ * by analyzing if the reference path points back to an ancestor of the target path\n+ */\n+function isCircularPattern(targetPath: string, referencePath: string): boolean {\n+  const targetParts = targetPath.split(\".\");\n+  const refParts = referencePath.split(\".\");\n+\n+  // For circular references, the reference path often contains the target path as a prefix\n+  // Example: targetPath=\"user\", referencePath=\"user.details.user\"\n+  // This means user.details.user points back to user (circular)\n+\n+  // Check if reference path starts with target path + additional segments that loop back\n+  if (refParts.length > targetParts.length) {\n+    // Check if reference path starts with target path\n+    let isPrefix = true;\n+    for (let i = 0; i < targetParts.length; i++) {\n+      if (targetParts[i] !== refParts[i]) {\n+        isPrefix = false;\n+        break;\n+      }\n+    }\n+\n+    // If reference path starts with target path and ends with target path,\n+    // it's likely a circular reference (e.g., \"user\" -> \"user.details.user\")\n+    if (isPrefix && refParts[refParts.length - 1] === targetParts[targetParts.length - 1]) {\n+      return true;\n+    }\n+  }\n+\n+  return false;\n+}\ndiff --git a/packages/core/test/ioSerialization.test.ts b/packages/core/test/ioSerialization.test.ts\nindex ffb9b30753..d7bd90add8 100644\n--- a/packages/core/test/ioSerialization.test.ts\n+++ b/packages/core/test/ioSerialization.test.ts\n@@ -1,4 +1,4 @@\n-import { replaceSuperJsonPayload } from \"../src/v3/utils/ioSerialization.js\";\n+import { replaceSuperJsonPayload, prettyPrintPacket } from \"../src/v3/utils/ioSerialization.js\";\n \n describe(\"ioSerialization\", () => {\n   describe(\"replaceSuperJsonPayload\", () => {\n@@ -188,4 +188,160 @@ describe(\"ioSerialization\", () => {\n       await expect(replaceSuperJsonPayload(originalSerialized, invalidPayload)).rejects.toThrow();\n     });\n   });\n+\n+  describe(\"prettyPrintPacket\", () => {\n+    it(\"should return empty string for undefined data\", async () => {\n+      const result = await prettyPrintPacket(undefined);\n+      expect(result).toBe(\"\");\n+    });\n+\n+    it(\"should return string data as-is\", async () => {\n+      const result = await prettyPrintPacket(\"Hello, World!\");\n+      expect(result).toBe(\"Hello, World!\");\n+    });\n+\n+    it(\"should pretty print JSON data with default options\", async () => {\n+      const data = { name: \"John\", age: 30, nested: { value: true } };\n+      const result = await prettyPrintPacket(data, \"application/json\");\n+\n+      expect(result).toBe(JSON.stringify(data, null, 2));\n+    });\n+\n+    it(\"should handle JSON data as string\", async () => {\n+      const data = { name: \"John\", age: 30 };\n+      const jsonString = JSON.stringify(data);\n+      const result = await prettyPrintPacket(jsonString, \"application/json\");\n+\n+      expect(result).toBe(JSON.stringify(data, null, 2));\n+    });\n+\n+    it(\"should pretty print SuperJSON data\", async () => {\n+      const data = {\n+        name: \"John\",\n+        date: new Date(\"2023-01-01\"),\n+        bigInt: BigInt(123),\n+        set: new Set([\"a\", \"b\"]),\n+        map: new Map([[\"key\", \"value\"]]),\n+      };\n+\n+      const superjson = await import(\"superjson\");\n+      const serialized = superjson.stringify(data);\n+\n+      const result = await prettyPrintPacket(serialized, \"application/super+json\");\n+\n+      // Should deserialize and pretty print the data\n+      expect(result).toContain('\"name\": \"John\"');\n+      expect(result).toContain('\"date\": \"2023-01-01T00:00:00.000Z\"');\n+      expect(result).toContain('\"bigInt\": \"123\"');\n+      expect(result).toContain('\"set\": [\\n    \"a\",\\n    \"b\"\\n  ]');\n+      expect(result).toContain('\"map\": {\\n    \"key\": \"value\"\\n  }');\n+    });\n+\n+    it(\"should handle circular references\", async () => {\n+      const data: any = { name: \"John\" };\n+      data.self = data; // Create circular reference\n+\n+      // Create a SuperJSON serialized version to test the circular reference detection\n+      const superjson = await import(\"superjson\");\n+      const serialized = superjson.stringify(data);\n+\n+      const result = await prettyPrintPacket(serialized, \"application/super+json\");\n+\n+      expect(result).toContain('\"name\": \"John\"');\n+      expect(result).toContain('\"self\": \"[Circular]\"');\n+    });\n+\n+    it(\"should handle regular non-circular references\", async () => {\n+      const person = { name: \"John\" };\n+\n+      const data: any = { person1: person, person2: person };\n+\n+      // Create a SuperJSON serialized version to test the circular reference detection\n+      const superjson = await import(\"superjson\");\n+      const serialized = superjson.stringify(data);\n+\n+      const result = await prettyPrintPacket(serialized, \"application/super+json\");\n+\n+      expect(result).toContain('\"person1\": {');\n+      expect(result).toContain('\"person2\": {');\n+    });\n+\n+    it(\"should filter out specified keys\", async () => {\n+      const data = { name: \"John\", password: \"secret\", age: 30 };\n+      const result = await prettyPrintPacket(data, \"application/json\", {\n+        filteredKeys: [\"password\"],\n+      });\n+\n+      expect(result).toContain('\"name\": \"John\"');\n+      expect(result).toContain('\"age\": 30');\n+      expect(result).not.toContain('\"password\"');\n+    });\n+\n+    it(\"should handle BigInt values\", async () => {\n+      const data = { id: BigInt(123456789), name: \"John\" };\n+      const result = await prettyPrintPacket(data, \"application/json\");\n+\n+      expect(result).toContain('\"id\": \"123456789\"');\n+      expect(result).toContain('\"name\": \"John\"');\n+    });\n+\n+    it(\"should handle RegExp values\", async () => {\n+      const data = { pattern: /test/gi, name: \"John\" };\n+      const result = await prettyPrintPacket(data, \"application/json\");\n+\n+      expect(result).toContain('\"pattern\": \"/test/gi\"');\n+      expect(result).toContain('\"name\": \"John\"');\n+    });\n+\n+    it(\"should handle Set values\", async () => {\n+      const data = { tags: new Set([\"tag1\", \"tag2\"]), name: \"John\" };\n+      const result = await prettyPrintPacket(data, \"application/json\");\n+\n+      expect(result).toContain('\"tags\": [\\n    \"tag1\",\\n    \"tag2\"\\n  ]');\n+      expect(result).toContain('\"name\": \"John\"');\n+    });\n+\n+    it(\"should handle Map values\", async () => {\n+      const data = { mapping: new Map([[\"key1\", \"value1\"]]), name: \"John\" };\n+      const result = await prettyPrintPacket(data, \"application/json\");\n+\n+      expect(result).toContain('\"mapping\": {\\n    \"key1\": \"value1\"\\n  }');\n+      expect(result).toContain('\"name\": \"John\"');\n+    });\n+\n+    it(\"should handle complex nested data\", async () => {\n+      const data = {\n+        user: {\n+          id: BigInt(123),\n+          createdAt: new Date(\"2023-01-01\"),\n+          settings: {\n+            theme: \"dark\",\n+            tags: new Set([\"admin\", \"user\"]),\n+            config: new Map([[\"timeout\", \"30s\"]]),\n+          },\n+        },\n+        metadata: {\n+          version: 1,\n+          pattern: /^test$/,\n+        },\n+      };\n+\n+      const result = await prettyPrintPacket(data, \"application/json\");\n+\n+      expect(result).toContain('\"id\": \"123\"');\n+      expect(result).toContain('\"createdAt\": \"2023-01-01T00:00:00.000Z\"');\n+      expect(result).toContain('\"theme\": \"dark\"');\n+      expect(result).toContain('\"tags\": [\\n        \"admin\",\\n        \"user\"\\n      ]');\n+      expect(result).toContain('\"config\": {\\n        \"timeout\": \"30s\"\\n      }');\n+      expect(result).toContain('\"version\": 1');\n+      expect(result).toContain('\"pattern\": \"/^test$/\"');\n+    });\n+\n+    it(\"should handle data without dataType parameter\", async () => {\n+      const data = { name: \"John\", age: 30 };\n+      const result = await prettyPrintPacket(data);\n+\n+      expect(result).toBe(JSON.stringify(data, null, 2));\n+    });\n+  });\n });\ndiff --git a/references/hello-world/src/trigger/circularPayload.ts b/references/hello-world/src/trigger/circularPayload.ts\nnew file mode 100644\nindex 0000000000..3e9d0a9545\n--- /dev/null\n+++ b/references/hello-world/src/trigger/circularPayload.ts\n@@ -0,0 +1,149 @@\n+import { logger, schemaTask, task, tasks } from \"@trigger.dev/sdk\";\n+import { z } from \"zod/v3\";\n+\n+export const referentialPayloadParentTask = task({\n+  id: \"referential-payload-parent\",\n+  run: async (payload: any) => {\n+    // Shared objects\n+    const workflowData = {\n+      id: \"workflow-123\",\n+      formName: \"Contact Form\",\n+    };\n+\n+    const response = [\n+      {\n+        id: \"q1_name\",\n+        answer: \"John Doe\",\n+      },\n+      {\n+        id: \"q2_consent\",\n+        answer: \"yes\",\n+        leadAttribute: undefined, // Will be marked in meta\n+      },\n+    ];\n+\n+    const personAttributes = {\n+      ip: \"192.168.1.1\",\n+      visitedForm: 1,\n+    };\n+\n+    // Main object with shared references\n+    const originalObject = {\n+      workflowData: workflowData, // Root reference\n+      workflowContext: {\n+        leadId: undefined, // Will be marked in meta\n+        workflowJob: {\n+          workflowData: workflowData, // Same reference as root\n+          createdAt: new Date(\"2025-08-19T12:13:42.260Z\"), // Date object\n+        },\n+        responseData: {\n+          personAttributes: personAttributes, // Same reference as root\n+        },\n+        response: response, // Same reference as root\n+      },\n+      personAttributes: personAttributes, // Root reference\n+      response: response, // Root reference\n+      jobArgs: {\n+        response: response, // Same reference as root\n+        args: workflowData, // Same reference as root\n+      },\n+    };\n+\n+    await tasks.triggerAndWait<typeof referentialPayloadChildTask>(\n+      \"referential-payload-child\",\n+      originalObject\n+    );\n+\n+    return {\n+      message: \"Hello, world!\",\n+    };\n+  },\n+});\n+\n+// Define the circular schema using z.lazy() for the recursive reference\n+const WorkflowDataSchema = z.object({\n+  id: z.string(),\n+  formName: z.string(),\n+});\n+\n+const ResponseItemSchema = z.object({\n+  id: z.string(),\n+  answer: z.string(),\n+  leadAttribute: z.undefined().optional(),\n+});\n+\n+const PersonAttributesSchema = z.object({\n+  ip: z.string(),\n+  visitedForm: z.number(),\n+});\n+\n+const OriginalObjectSchema = z.object({\n+  workflowData: WorkflowDataSchema,\n+  workflowContext: z.object({\n+    leadId: z.undefined(),\n+    workflowJob: z.object({\n+      workflowData: WorkflowDataSchema, // Same reference\n+      createdAt: z.date(),\n+    }),\n+    responseData: z.object({\n+      personAttributes: PersonAttributesSchema, // Same reference\n+    }),\n+    response: z.array(ResponseItemSchema), // Same reference\n+  }),\n+  personAttributes: PersonAttributesSchema, // Root reference\n+  response: z.array(ResponseItemSchema), // Root reference\n+  jobArgs: z.object({\n+    response: z.array(ResponseItemSchema), // Same reference\n+    args: WorkflowDataSchema, // Same reference\n+  }),\n+});\n+\n+export const referentialPayloadChildTask = schemaTask({\n+  id: \"referential-payload-child\",\n+  schema: OriginalObjectSchema,\n+  run: async (payload) => {\n+    logger.info(\"Received circular payload\", { payload });\n+\n+    return {\n+      message: \"Hello, world!\",\n+    };\n+  },\n+});\n+\n+export const circularReferenceParentTask = task({\n+  id: \"circular-reference-parent\",\n+  run: async (payload: any) => {\n+    const user = {\n+      name: \"Alice\",\n+      details: {\n+        age: 30,\n+        email: \"alice@example.com\",\n+      },\n+    };\n+    // @ts-expect-error - This is a circular reference\n+    user.details.user = user;\n+\n+    await tasks.triggerAndWait<typeof circularReferenceChildTask>(\"circular-reference-child\", {\n+      // @ts-expect-error - This is a circular reference\n+      user,\n+    });\n+  },\n+});\n+\n+type CircularReferencePayload = {\n+  user: {\n+    name: string;\n+    details: {\n+      age: number;\n+      email: string;\n+      user: CircularReferencePayload;\n+    };\n+  };\n+};\n+\n+export const circularReferenceChildTask = task({\n+  id: \"circular-reference-child\",\n+  run: async (payload: CircularReferencePayload) => {\n+    logger.info(\"Received circular payload\", { payload });\n+  },\n+});\n",
    "test_patch": "",
    "problem_statement": "",
    "hints_text": "",
    "pr_mirror": "triggerdotdev__trigger.dev.d1c3bfb9",
    "bug_patch": "diff --git a/apps/webapp/app/routes/resources.taskruns.$runParam.replay.ts b/apps/webapp/app/routes/resources.taskruns.$runParam.replay.ts\nindex 57de763..0f45d9f 100644\n--- a/apps/webapp/app/routes/resources.taskruns.$runParam.replay.ts\n+++ b/apps/webapp/app/routes/resources.taskruns.$runParam.replay.ts\n@@ -108,8 +108,6 @@ export async function loader({ request, params }: LoaderFunctionArgs) {\n   const disableVersionSelection = environment.type === \"DEVELOPMENT\";\n   const allowArbitraryQueues = backgroundWorkers.at(0)?.engine === \"V1\";\n \n-  const payload = await prettyPrintPacket(run.payload, run.payloadType);\n-\n   return typedjson({\n     concurrencyKey: run.concurrencyKey,\n     maxAttempts: run.maxAttempts,\n@@ -118,7 +116,7 @@ export async function loader({ request, params }: LoaderFunctionArgs) {\n     ttlSeconds: run.ttl ? parseDuration(run.ttl, \"s\") ?? undefined : undefined,\n     idempotencyKey: run.idempotencyKey,\n     runTags: run.runTags,\n-    payload,\n+    payload: await prettyPrintPacket(run.payload, run.payloadType),\n     payloadType: run.payloadType,\n     queue: run.queue,\n     metadata: run.seedMetadata\n@@ -312,4 +310,4 @@ function listLatestBackgroundWorkers(environment: { id: string }, limit = 20) {\n     },\n     take: limit,\n   });\n-}\n+}\n\\ No newline at end of file\ndiff --git a/apps/webapp/test/fairDequeuingStrategy.test.ts b/apps/webapp/test/fairDequeuingStrategy.test.ts\nindex 0d8b708..9f21988 100644\n--- a/apps/webapp/test/fairDequeuingStrategy.test.ts\n+++ b/apps/webapp/test/fairDequeuingStrategy.test.ts\n@@ -270,8 +270,8 @@ describe(\"FairDequeuingStrategy\", () => {\n \n       console.log(\"Second distribution took\", distribute2Duration, \"ms\");\n \n-      // Make sure the second call is faster than the first\n-      expect(distribute2Duration).toBeLessThan(distribute1Duration);\n+      // Make sure the second call is more than 2 times faster than the first\n+      expect(distribute2Duration).toBeLessThan(withTolerance(distribute1Duration / 2));\n \n       const startDistribute3 = performance.now();\n \n@@ -284,8 +284,8 @@ describe(\"FairDequeuingStrategy\", () => {\n \n       console.log(\"Third distribution took\", distribute3Duration, \"ms\");\n \n-      // Make sure the third call is faster than the second\n-      expect(withTolerance(distribute3Duration)).toBeGreaterThan(distribute2Duration);\n+      // Make sure the third call is more than 4 times the second\n+      expect(withTolerance(distribute3Duration)).toBeGreaterThan(distribute2Duration * 4);\n     }\n   );\n \n@@ -422,1054 +422,4 @@ describe(\"FairDequeuingStrategy\", () => {\n       // Verify that each org and env gets a fair chance at first position\n       for (const [orgId, stats] of Object.entries(orgStats)) {\n         const firstPositionPercentage = (stats.firstPosition / iterations) * 100;\n-        expect(firstPositionPercentage).toBeGreaterThan(expectedFirstPositionPercentage * 0.7); // Within 30% of expected\n-        expect(firstPositionPercentage).toBeLessThan(expectedFirstPositionPercentage * 1.3);\n-      }\n-\n-      for (const [envId, stats] of Object.entries(envStats)) {\n-        const firstPositionPercentage = (stats.firstPosition / iterations) * 100;\n-        expect(firstPositionPercentage).toBeGreaterThan(expectedEnvFirstPositionPercentage * 0.7); // Within 30% of expected\n-        expect(firstPositionPercentage).toBeLessThan(expectedEnvFirstPositionPercentage * 1.3);\n-      }\n-\n-      // Verify average positions are reasonably distributed\n-      const avgPositionsOrgs = Object.values(orgStats).map(\n-        (stats) => stats.positionSums / stats.appearances\n-      );\n-      const avgPositionsEnvs = Object.values(envStats).map(\n-        (stats) => stats.positionSums / stats.appearances\n-      );\n-\n-      const avgPositionStdDevOrgs = calculateStandardDeviation(avgPositionsOrgs);\n-      const avgPositionStdDevEnvs = calculateStandardDeviation(avgPositionsEnvs);\n-\n-      expect(avgPositionStdDevOrgs).toBeLessThan(1); // Average positions should be fairly consistent\n-      expect(avgPositionStdDevEnvs).toBeLessThan(1);\n-    }\n-  );\n-\n-  redisTest(\n-    \"should shuffle environments while maintaining age order within environments\",\n-    async ({ redisOptions }) => {\n-      const redis = createRedisClient(redisOptions);\n-\n-      const keyProducer = createKeyProducer(\"test\");\n-      const strategy = new FairDequeuingStrategy({\n-        tracer,\n-        redis,\n-        keys: keyProducer,\n-        defaultEnvConcurrency: 5,\n-        parentQueueLimit: 100,\n-        seed: \"fixed-seed\",\n-      });\n-\n-      const now = Date.now();\n-\n-      // Setup three environments, each with two queues of different ages\n-      await Promise.all([\n-        // env-1: one old queue (3000ms old) and one new queue (1000ms old)\n-        setupQueue({\n-          redis,\n-          keyProducer,\n-          parentQueue: \"parent-queue\",\n-          score: now - 3000,\n-          queueId: \"queue-1-old\",\n-          orgId: \"org-1\",\n-          envId: \"env-1\",\n-        }),\n-        setupQueue({\n-          redis,\n-          keyProducer,\n-          parentQueue: \"parent-queue\",\n-          score: now - 1000,\n-          queueId: \"queue-1-new\",\n-          orgId: \"org-1\",\n-          envId: \"env-1\",\n-        }),\n-\n-        // env-2: same pattern\n-        setupQueue({\n-          redis,\n-          keyProducer,\n-          parentQueue: \"parent-queue\",\n-          score: now - 3000,\n-          queueId: \"queue-2-old\",\n-          orgId: \"org-1\",\n-          envId: \"env-2\",\n-        }),\n-        setupQueue({\n-          redis,\n-          keyProducer,\n-          parentQueue: \"parent-queue\",\n-          score: now - 1000,\n-          queueId: \"queue-2-new\",\n-          orgId: \"org-1\",\n-          envId: \"env-2\",\n-        }),\n-      ]);\n-\n-      // Setup basic concurrency settings\n-      await setupConcurrency({\n-        redis,\n-        keyProducer,\n-        env: { id: \"env-1\", currentConcurrency: 0, limit: 5 },\n-      });\n-      await setupConcurrency({\n-        redis,\n-        keyProducer,\n-        env: { id: \"env-2\", currentConcurrency: 0, limit: 5 },\n-      });\n-\n-      const envResult = await strategy.distributeFairQueuesFromParentQueue(\n-        \"parent-queue\",\n-        \"consumer-1\"\n-      );\n-      const result = flattenResults(envResult);\n-\n-      // Group queues by environment\n-      const queuesByEnv = result.reduce((acc, queueId) => {\n-        const envId = keyProducer.envIdFromQueue(queueId);\n-        if (!acc[envId]) {\n-          acc[envId] = [];\n-        }\n-        acc[envId].push(queueId);\n-        return acc;\n-      }, {} as Record<string, string[]>);\n-\n-      // Verify that:\n-      // 1. We got all queues\n-      expect(result).toHaveLength(4);\n-\n-      // 2. Queues are grouped by environment\n-      for (const envQueues of Object.values(queuesByEnv)) {\n-        expect(envQueues).toHaveLength(2);\n-\n-        // 3. Within each environment, older queue comes before newer queue\n-        const [firstQueue, secondQueue] = envQueues;\n-        expect(firstQueue).toContain(\"old\");\n-        expect(secondQueue).toContain(\"new\");\n-      }\n-    }\n-  );\n-\n-  redisTest(\n-    \"should bias shuffling based on concurrency limits and available capacity\",\n-    async ({ redisOptions }) => {\n-      const redis = createRedisClient(redisOptions);\n-\n-      const keyProducer = createKeyProducer(\"test\");\n-      const now = Date.now();\n-\n-      // Setup three environments with different concurrency settings\n-      const envSetups = [\n-        {\n-          envId: \"env-1\",\n-          limit: 100,\n-          current: 20, // Lots of available capacity\n-          queueCount: 3,\n-        },\n-        {\n-          envId: \"env-2\",\n-          limit: 50,\n-          current: 40, // Less available capacity\n-          queueCount: 3,\n-        },\n-        {\n-          envId: \"env-3\",\n-          limit: 10,\n-          current: 5, // Some available capacity\n-          queueCount: 3,\n-        },\n-      ];\n-\n-      // Setup queues and concurrency for each environment\n-      for (const setup of envSetups) {\n-        await setupConcurrency({\n-          redis,\n-          keyProducer,\n-          env: {\n-            id: setup.envId,\n-            currentConcurrency: setup.current,\n-            limit: setup.limit,\n-          },\n-        });\n-\n-        for (let i = 0; i < setup.queueCount; i++) {\n-          await setupQueue({\n-            redis,\n-            keyProducer,\n-            parentQueue: \"parent-queue\",\n-            score: now - 1000 * (i + 1),\n-            queueId: `queue-${i}`,\n-            orgId: \"org-1\",\n-            envId: setup.envId,\n-          });\n-        }\n-      }\n-\n-      // Create multiple strategies with different seeds\n-      const numStrategies = 5;\n-      const strategies = Array.from(\n-        { length: numStrategies },\n-        (_, i) =>\n-          new FairDequeuingStrategy({\n-            tracer,\n-            redis,\n-            keys: keyProducer,\n-            defaultEnvConcurrency: 5,\n-            parentQueueLimit: 100,\n-            seed: `test-seed-${i}`,\n-            biases: {\n-              concurrencyLimitBias: 0.8,\n-              availableCapacityBias: 0.5,\n-              queueAgeRandomization: 0.0,\n-            },\n-          })\n-      );\n-\n-      // Run iterations across all strategies\n-      const iterationsPerStrategy = 100;\n-      const allResults: Record<string, number>[] = [];\n-\n-      for (const strategy of strategies) {\n-        const firstPositionCounts: Record<string, number> = {};\n-\n-        for (let i = 0; i < iterationsPerStrategy; i++) {\n-          const envResult = await strategy.distributeFairQueuesFromParentQueue(\n-            \"parent-queue\",\n-            `consumer-${i % 3}`\n-          );\n-          const result = flattenResults(envResult);\n-\n-          expect(result.length).toBeGreaterThan(0);\n-\n-          const firstEnv = keyProducer.envIdFromQueue(result[0]);\n-          firstPositionCounts[firstEnv] = (firstPositionCounts[firstEnv] || 0) + 1;\n-        }\n-\n-        allResults.push(firstPositionCounts);\n-      }\n-\n-      // Calculate average distributions across all strategies\n-      const avgDistribution: Record<string, number> = {};\n-      const envIds = [\"env-1\", \"env-2\", \"env-3\"];\n-\n-      for (const envId of envIds) {\n-        const sum = allResults.reduce((acc, result) => acc + (result[envId] || 0), 0);\n-        avgDistribution[envId] = sum / numStrategies;\n-      }\n-\n-      // Log individual strategy results and the average\n-      console.log(\"\\nResults by strategy:\");\n-      allResults.forEach((result, i) => {\n-        console.log(`Strategy ${i + 1}:`, result);\n-      });\n-\n-      console.log(\"\\nAverage distribution:\", avgDistribution);\n-\n-      // Calculate percentages from average distribution\n-      const totalCount = Object.values(avgDistribution).reduce((sum, count) => sum + count, 0);\n-      const highLimitPercentage = (avgDistribution[\"env-1\"] / totalCount) * 100;\n-      const lowLimitPercentage = (avgDistribution[\"env-3\"] / totalCount) * 100;\n-\n-      console.log(\"\\nPercentages:\");\n-      console.log(\"High limit percentage:\", highLimitPercentage);\n-      console.log(\"Low limit percentage:\", lowLimitPercentage);\n-\n-      // Verify distribution across all strategies\n-      expect(highLimitPercentage).toBeLessThan(60);\n-      expect(lowLimitPercentage).toBeGreaterThan(10);\n-      expect(highLimitPercentage).toBeGreaterThan(lowLimitPercentage);\n-    }\n-  );\n-\n-  redisTest(\n-    \"should respect ageInfluence parameter for queue ordering\",\n-    async ({ redisOptions }) => {\n-      const redis = createRedisClient(redisOptions);\n-\n-      const keyProducer = createKeyProducer(\"test\");\n-      const now = Date.now();\n-\n-      // Setup queues with different ages in the same environment\n-      const queueAges = [\n-        { id: \"queue-1\", age: 5000 }, // oldest\n-        { id: \"queue-2\", age: 3000 },\n-        { id: \"queue-3\", age: 1000 }, // newest\n-      ];\n-\n-      // Helper function to run iterations with a specific age influence\n-      async function runWithQueueAgeRandomization(queueAgeRandomization: number) {\n-        const strategy = new FairDequeuingStrategy({\n-          tracer,\n-          redis,\n-          keys: keyProducer,\n-          defaultEnvConcurrency: 5,\n-          parentQueueLimit: 100,\n-          seed: \"fixed-seed\",\n-          biases: {\n-            concurrencyLimitBias: 0,\n-            availableCapacityBias: 0,\n-            queueAgeRandomization,\n-          },\n-        });\n-\n-        const positionCounts: Record<string, number[]> = {\n-          \"queue-1\": [0, 0, 0],\n-          \"queue-2\": [0, 0, 0],\n-          \"queue-3\": [0, 0, 0],\n-        };\n-\n-        const iterations = 1000;\n-        for (let i = 0; i < iterations; i++) {\n-          const envResult = await strategy.distributeFairQueuesFromParentQueue(\n-            \"parent-queue\",\n-            \"consumer-1\"\n-          );\n-          const result = flattenResults(envResult);\n-\n-          result.forEach((queueId, position) => {\n-            const baseQueueId = queueId.split(\":\").pop()!;\n-            positionCounts[baseQueueId][position]++;\n-          });\n-        }\n-\n-        return positionCounts;\n-      }\n-\n-      // Setup test data\n-      for (const { id, age } of queueAges) {\n-        await setupQueue({\n-          redis,\n-          keyProducer,\n-          parentQueue: \"parent-queue\",\n-          score: now - age,\n-          queueId: id,\n-          orgId: \"org-1\",\n-          envId: \"env-1\",\n-        });\n-      }\n-\n-      await setupConcurrency({\n-        redis,\n-        keyProducer,\n-        env: { id: \"env-1\", currentConcurrency: 0, limit: 5 },\n-      });\n-\n-      // Test with different age influence values\n-      const strictAge = await runWithQueueAgeRandomization(0); // Strict age-based ordering\n-      const mixed = await runWithQueueAgeRandomization(0.5); // Mix of age and random\n-      const fullyRandom = await runWithQueueAgeRandomization(1); // Completely random\n-\n-      console.log(\"Distribution with strict age ordering (0.0):\", strictAge);\n-      console.log(\"Distribution with mixed ordering (0.5):\", mixed);\n-      console.log(\"Distribution with random ordering (1.0):\", fullyRandom);\n-\n-      // With strict age ordering (0.0), oldest should always be first\n-      expect(strictAge[\"queue-1\"][0]).toBe(1000); // Always in first position\n-      expect(strictAge[\"queue-3\"][0]).toBe(0); // Never in first position\n-\n-      // With fully random (1.0), positions should still allow for some age bias\n-      const randomFirstPositionSpread = Math.abs(\n-        fullyRandom[\"queue-1\"][0] - fullyRandom[\"queue-3\"][0]\n-      );\n-      expect(randomFirstPositionSpread).toBeLessThan(200); // Allow for larger spread in distribution\n-\n-      // With mixed (0.5), should show preference for age but not absolute\n-      expect(mixed[\"queue-1\"][0]).toBeGreaterThan(mixed[\"queue-3\"][0]); // Older preferred\n-      expect(mixed[\"queue-3\"][0]).toBeGreaterThan(0); // But newer still gets chances\n-    }\n-  );\n-\n-  redisTest(\n-    \"should respect maximumEnvCount and select envs based on queue ages\",\n-    async ({ redisOptions }) => {\n-      const redis = createRedisClient(redisOptions);\n-\n-      const keyProducer = createKeyProducer(\"test\");\n-      const strategy = new FairDequeuingStrategy({\n-        tracer,\n-        redis,\n-        keys: keyProducer,\n-        defaultEnvConcurrency: 5,\n-        parentQueueLimit: 100,\n-        seed: \"test-seed-max-orgs\",\n-        maximumEnvCount: 2, // Only select top 2 orgs\n-      });\n-\n-      const now = Date.now();\n-\n-      // Setup 4 envs with different queue age profiles\n-      const envSetups = [\n-        {\n-          envId: \"env-1\",\n-          queues: [\n-            { age: 1000 }, // Average age: 1000\n-          ],\n-        },\n-        {\n-          envId: \"env-2\",\n-          queues: [\n-            { age: 5000 }, // Average age: 5000\n-            { age: 5000 },\n-          ],\n-        },\n-        {\n-          envId: \"env-3\",\n-          queues: [\n-            { age: 2000 }, // Average age: 2000\n-            { age: 2000 },\n-          ],\n-        },\n-        {\n-          envId: \"env-4\",\n-          queues: [\n-            { age: 500 }, // Average age: 500\n-            { age: 500 },\n-          ],\n-        },\n-      ];\n-\n-      // Setup queues and concurrency for each org\n-      for (const setup of envSetups) {\n-        await setupConcurrency({\n-          redis,\n-          keyProducer,\n-          env: { id: setup.envId, currentConcurrency: 0, limit: 5 },\n-        });\n-\n-        for (let i = 0; i < setup.queues.length; i++) {\n-          await setupQueue({\n-            redis,\n-            keyProducer,\n-            parentQueue: \"parent-queue\",\n-            score: now - setup.queues[i].age,\n-            queueId: `queue-${setup.envId}-${i}`,\n-            orgId: `org-${setup.envId}`,\n-            envId: setup.envId,\n-          });\n-        }\n-      }\n-\n-      // Run multiple iterations to verify consistent behavior\n-      const iterations = 100;\n-      const selectedEnvCounts: Record<string, number> = {};\n-\n-      for (let i = 0; i < iterations; i++) {\n-        const envResult = await strategy.distributeFairQueuesFromParentQueue(\n-          \"parent-queue\",\n-          `consumer-${i}`\n-        );\n-        const result = flattenResults(envResult);\n-\n-        // Track which orgs were included in the result\n-        const selectedEnvs = new Set(result.map((queueId) => keyProducer.envIdFromQueue(queueId)));\n-\n-        // Verify we never get more than maximumOrgCount orgs\n-        expect(selectedEnvs.size).toBeLessThanOrEqual(2);\n-\n-        for (const envId of selectedEnvs) {\n-          selectedEnvCounts[envId] = (selectedEnvCounts[envId] || 0) + 1;\n-        }\n-      }\n-\n-      console.log(\"Environment selection counts:\", selectedEnvCounts);\n-\n-      // org-2 should be selected most often (highest average age)\n-      expect(selectedEnvCounts[\"env-2\"]).toBeGreaterThan(selectedEnvCounts[\"env-4\"] || 0);\n-\n-      // org-4 should be selected least often (lowest average age)\n-      const env4Count = selectedEnvCounts[\"env-4\"] || 0;\n-      expect(env4Count).toBeLessThan(selectedEnvCounts[\"env-2\"]);\n-\n-      // Verify that envs with higher average queue age are selected more frequently\n-      const sortedEnvs = Object.entries(selectedEnvCounts).sort((a, b) => b[1] - a[1]);\n-      console.log(\"Sorted environment frequencies:\", sortedEnvs);\n-\n-      // The top 2 most frequently selected orgs should be env-2 and env-3\n-      // as they have the highest average queue ages\n-      const topTwoEnvs = new Set([sortedEnvs[0][0], sortedEnvs[1][0]]);\n-      expect(topTwoEnvs).toContain(\"env-2\"); // Highest average age\n-      expect(topTwoEnvs).toContain(\"env-3\"); // Second highest average age\n-\n-      // Calculate selection percentages\n-      const totalSelections = Object.values(selectedEnvCounts).reduce((a, b) => a + b, 0);\n-      const selectionPercentages = Object.entries(selectedEnvCounts).reduce(\n-        (acc, [orgId, count]) => {\n-          acc[orgId] = (count / totalSelections) * 100;\n-          return acc;\n-        },\n-        {} as Record<string, number>\n-      );\n-\n-      console.log(\"Environment selection percentages:\", selectionPercentages);\n-\n-      // Verify that env-2 (highest average age) gets selected in at least 40% of iterations\n-      expect(selectionPercentages[\"env-2\"]).toBeGreaterThan(40);\n-\n-      // Verify that env-4 (lowest average age) gets selected in less than 20% of iterations\n-      expect(selectionPercentages[\"env-4\"] || 0).toBeLessThan(20);\n-    }\n-  );\n-\n-  redisTest(\n-    \"should not overly bias picking environments when queue have priority offset ages\",\n-    async ({ redisOptions }) => {\n-      const redis = createRedisClient(redisOptions);\n-\n-      const keyProducer = createKeyProducer(\"test\");\n-      const strategy = new FairDequeuingStrategy({\n-        tracer,\n-        redis,\n-        keys: keyProducer,\n-        defaultEnvConcurrency: 5,\n-        parentQueueLimit: 100,\n-        seed: \"test-seed-max-orgs\",\n-        maximumEnvCount: 2, // Only select top 2 orgs\n-      });\n-\n-      const now = Date.now();\n-\n-      // Setup 4 envs with different queue age profiles\n-      const envSetups = [\n-        {\n-          envId: \"env-1\",\n-          queues: [\n-            { age: 1000 }, // Average age: 1000\n-          ],\n-        },\n-        {\n-          envId: \"env-2\",\n-          queues: [\n-            { age: 5000 + MARQS_RESUME_PRIORITY_TIMESTAMP_OFFSET }, // Average age: 5000 + 1 year\n-            { age: 5000 + MARQS_RESUME_PRIORITY_TIMESTAMP_OFFSET },\n-          ],\n-        },\n-        {\n-          envId: \"env-3\",\n-          queues: [\n-            { age: 2000 }, // Average age: 2000\n-            { age: 2000 },\n-          ],\n-        },\n-        {\n-          envId: \"env-4\",\n-          queues: [\n-            { age: 500 }, // Average age: 500\n-            { age: 500 },\n-          ],\n-        },\n-      ];\n-\n-      // Setup queues and concurrency for each org\n-      for (const setup of envSetups) {\n-        await setupConcurrency({\n-          redis,\n-          keyProducer,\n-          env: { id: setup.envId, currentConcurrency: 0, limit: 5 },\n-        });\n-\n-        for (let i = 0; i < setup.queues.length; i++) {\n-          await setupQueue({\n-            redis,\n-            keyProducer,\n-            parentQueue: \"parent-queue\",\n-            score: now - setup.queues[i].age,\n-            queueId: `queue-${setup.envId}-${i}`,\n-            orgId: `org-${setup.envId}`,\n-            envId: setup.envId,\n-          });\n-        }\n-      }\n-\n-      // Run multiple iterations to verify consistent behavior\n-      const iterations = 100;\n-      const selectedEnvCounts: Record<string, number> = {};\n-\n-      for (let i = 0; i < iterations; i++) {\n-        const envResult = await strategy.distributeFairQueuesFromParentQueue(\n-          \"parent-queue\",\n-          `consumer-${i}`\n-        );\n-        const result = flattenResults(envResult);\n-\n-        // Track which orgs were included in the result\n-        const selectedEnvs = new Set(result.map((queueId) => keyProducer.envIdFromQueue(queueId)));\n-\n-        // Verify we never get more than maximumOrgCount orgs\n-        expect(selectedEnvs.size).toBeLessThanOrEqual(2);\n-\n-        for (const envId of selectedEnvs) {\n-          selectedEnvCounts[envId] = (selectedEnvCounts[envId] || 0) + 1;\n-        }\n-      }\n-\n-      console.log(\"Environment selection counts:\", selectedEnvCounts);\n-\n-      // org-2 should be selected most often (highest average age)\n-      expect(selectedEnvCounts[\"env-2\"]).toBeGreaterThan(selectedEnvCounts[\"env-4\"] || 0);\n-\n-      // org-4 should be selected least often (lowest average age)\n-      const env4Count = selectedEnvCounts[\"env-4\"] || 0;\n-      expect(env4Count).toBeLessThan(selectedEnvCounts[\"env-2\"]);\n-\n-      // Verify that envs with higher average queue age are selected more frequently\n-      const sortedEnvs = Object.entries(selectedEnvCounts).sort((a, b) => b[1] - a[1]);\n-      console.log(\"Sorted environment frequencies:\", sortedEnvs);\n-\n-      // The top 2 most frequently selected orgs should be env-2 and env-3\n-      // as they have the highest average queue ages\n-      const topTwoEnvs = new Set([sortedEnvs[0][0], sortedEnvs[1][0]]);\n-      expect(topTwoEnvs).toContain(\"env-2\"); // Highest average age\n-      expect(topTwoEnvs).toContain(\"env-3\"); // Second highest average age\n-\n-      // Calculate selection percentages\n-      const totalSelections = Object.values(selectedEnvCounts).reduce((a, b) => a + b, 0);\n-      const selectionPercentages = Object.entries(selectedEnvCounts).reduce(\n-        (acc, [orgId, count]) => {\n-          acc[orgId] = (count / totalSelections) * 100;\n-          return acc;\n-        },\n-        {} as Record<string, number>\n-      );\n-\n-      console.log(\"Environment selection percentages:\", selectionPercentages);\n-\n-      // Verify that env-2 (highest average age) gets selected in at least 40% of iterations\n-      expect(selectionPercentages[\"env-2\"]).toBeGreaterThan(40);\n-\n-      // Verify that env-4 (lowest average age) gets selected in less than 20% of iterations\n-      expect(selectionPercentages[\"env-4\"] || 0).toBeLessThan(20);\n-    }\n-  );\n-\n-  redisTest(\n-    \"should respect maximumQueuePerEnvCount when distributing queues\",\n-    async ({ redisOptions }) => {\n-      const redis = createRedisClient(redisOptions);\n-\n-      const keyProducer = createKeyProducer(\"test\");\n-      const strategy = new FairDequeuingStrategy({\n-        tracer,\n-        redis,\n-        keys: keyProducer,\n-        defaultEnvConcurrency: 5,\n-        parentQueueLimit: 100,\n-        seed: \"test-seed-max-queues\",\n-        maximumQueuePerEnvCount: 2, // Only take 2 queues per env\n-      });\n-\n-      const now = Date.now();\n-\n-      // Setup two environments with different numbers of queues\n-      const envSetups = [\n-        {\n-          envId: \"env-1\",\n-          queues: [\n-            { age: 5000 }, // Oldest\n-            { age: 4000 },\n-            { age: 3000 }, // This should be excluded due to maximumQueuePerEnvCount\n-          ],\n-        },\n-        {\n-          envId: \"env-2\",\n-          queues: [\n-            { age: 2000 },\n-            { age: 1000 }, // Newest\n-          ],\n-        },\n-      ];\n-\n-      // Setup queues and concurrency for each env\n-      for (const setup of envSetups) {\n-        await setupConcurrency({\n-          redis,\n-          keyProducer,\n-          env: { id: setup.envId, currentConcurrency: 0, limit: 5 },\n-        });\n-\n-        for (let i = 0; i < setup.queues.length; i++) {\n-          await setupQueue({\n-            redis,\n-            keyProducer,\n-            parentQueue: \"parent-queue\",\n-            score: now - setup.queues[i].age,\n-            queueId: `queue-${setup.envId}-${i}`,\n-            orgId: `org-${setup.envId}`,\n-            envId: setup.envId,\n-          });\n-        }\n-      }\n-\n-      const result = await strategy.distributeFairQueuesFromParentQueue(\n-        \"parent-queue\",\n-        \"consumer-1\"\n-      );\n-\n-      // Verify that each environment has at most 2 queues\n-      for (const envQueues of result) {\n-        expect(envQueues.queues.length).toBeLessThanOrEqual(2);\n-      }\n-\n-      // Get queues for env-1 (which had 3 queues originally)\n-      const env1Queues = result.find((eq) => eq.envId === \"env-1\")?.queues ?? [];\n-\n-      // Should have exactly 2 queues\n-      expect(env1Queues.length).toBe(2);\n-\n-      // The queues should be the two oldest ones (queue-env-1-0 and queue-env-1-1)\n-      expect(env1Queues).toContain(keyProducer.queueKey(\"org-env-1\", \"env-1\", \"queue-env-1-0\"));\n-      expect(env1Queues).toContain(keyProducer.queueKey(\"org-env-1\", \"env-1\", \"queue-env-1-1\"));\n-      expect(env1Queues).not.toContain(keyProducer.queueKey(\"org-env-1\", \"env-1\", \"queue-env-1-2\"));\n-\n-      // Get queues for env-2 (which had 2 queues originally)\n-      const env2Queues = result.find((eq) => eq.envId === \"env-2\")?.queues ?? [];\n-\n-      // Should still have both queues since it was within the limit\n-      expect(env2Queues.length).toBe(2);\n-    }\n-  );\n-\n-  redisTest(\n-    \"should fairly distribute queues when using maximumQueuePerEnvCount over time\",\n-    async ({ redisOptions }) => {\n-      const redis = createRedisClient(redisOptions);\n-\n-      const keyProducer = createKeyProducer(\"test\");\n-      const strategy = new FairDequeuingStrategy({\n-        tracer,\n-        redis,\n-        keys: keyProducer,\n-        defaultEnvConcurrency: 5,\n-        parentQueueLimit: 100,\n-        seed: \"test-seed-fair-distribution\",\n-        maximumQueuePerEnvCount: 2, // Only take 2 queues at a time\n-        biases: {\n-          concurrencyLimitBias: 0,\n-          availableCapacityBias: 0,\n-          queueAgeRandomization: 0.3, // Add some randomization to allow newer queues a chance\n-        },\n-      });\n-\n-      const now = Date.now();\n-\n-      // Setup one environment with 5 queues of different ages\n-      const queues = [\n-        { age: 5000, id: \"queue-0\" }, // Oldest\n-        { age: 4000, id: \"queue-1\" },\n-        { age: 3000, id: \"queue-2\" },\n-        { age: 2000, id: \"queue-3\" },\n-        { age: 1000, id: \"queue-4\" }, // Newest\n-      ];\n-\n-      // Setup the environment and its queues\n-      await setupConcurrency({\n-        redis,\n-        keyProducer,\n-        env: { id: \"env-1\", currentConcurrency: 0, limit: 5 },\n-      });\n-\n-      for (const queue of queues) {\n-        await setupQueue({\n-          redis,\n-          keyProducer,\n-          parentQueue: \"parent-queue\",\n-          score: now - queue.age,\n-          queueId: queue.id,\n-          orgId: \"org-1\",\n-          envId: \"env-1\",\n-        });\n-      }\n-\n-      // Run multiple iterations and track which queues are selected\n-      const iterations = 1000;\n-      const queueSelectionCounts: Record<string, number> = {};\n-      const queuePairings: Record<string, number> = {};\n-\n-      for (let i = 0; i < iterations; i++) {\n-        const result = await strategy.distributeFairQueuesFromParentQueue(\n-          \"parent-queue\",\n-          `consumer-${i}`\n-        );\n-\n-        // There should be exactly one environment\n-        expect(result.length).toBe(1);\n-        const selectedQueues = result[0].queues;\n-\n-        // Should always get exactly 2 queues due to maximumQueuePerEnvCount\n-        expect(selectedQueues.length).toBe(2);\n-\n-        // Track individual queue selections\n-        for (const queueId of selectedQueues) {\n-          const baseQueueId = queueId.split(\":\").pop()!;\n-          queueSelectionCounts[baseQueueId] = (queueSelectionCounts[baseQueueId] || 0) + 1;\n-        }\n-\n-        // Track queue pairings to ensure variety\n-        const [first, second] = selectedQueues.map((qId) => qId.split(\":\").pop()!).sort();\n-        const pairingKey = `${first}-${second}`;\n-        queuePairings[pairingKey] = (queuePairings[pairingKey] || 0) + 1;\n-      }\n-\n-      console.log(\"\\nQueue Selection Statistics:\");\n-      for (const [queueId, count] of Object.entries(queueSelectionCounts)) {\n-        const percentage = (count / (iterations * 2)) * 100; // Times 2 because we select 2 queues each time\n-        console.log(`${queueId}: ${percentage.toFixed(2)}% (${count} times)`);\n-      }\n-\n-      console.log(\"\\nQueue Pairing Statistics:\");\n-      for (const [pair, count] of Object.entries(queuePairings)) {\n-        const percentage = (count / iterations) * 100;\n-        console.log(`${pair}: ${percentage.toFixed(2)}% (${count} times)`);\n-      }\n-\n-      // Verify that all queues were selected at least once\n-      for (const queue of queues) {\n-        expect(queueSelectionCounts[queue.id]).toBeGreaterThan(0);\n-      }\n-\n-      // Calculate standard deviation of selection percentages\n-      const selectionPercentages = Object.values(queueSelectionCounts).map(\n-        (count) => (count / (iterations * 2)) * 100\n-      );\n-      const stdDev = calculateStandardDeviation(selectionPercentages);\n-\n-      // The standard deviation should be reasonable given our age bias\n-      // Higher stdDev means more bias towards older queues\n-      // We expect some bias due to queueAgeRandomization being 0.3\n-      expect(stdDev).toBeLessThan(15); // Allow for age-based bias but not extreme\n-\n-      // Verify we get different pairings of queues\n-      const uniquePairings = Object.keys(queuePairings).length;\n-      // With 5 queues, we can have 10 possible unique pairs\n-      expect(uniquePairings).toBeGreaterThan(5); // Should see at least half of possible combinations\n-    }\n-  );\n-\n-  redisTest(\n-    \"should handle maximumQueuePerEnvCount larger than available queues\",\n-    async ({ redisOptions }) => {\n-      const redis = createRedisClient(redisOptions);\n-\n-      const keyProducer = createKeyProducer(\"test\");\n-      const strategy = new FairDequeuingStrategy({\n-        tracer,\n-        redis,\n-        keys: keyProducer,\n-        defaultEnvConcurrency: 5,\n-        parentQueueLimit: 100,\n-        seed: \"test-seed-max-larger\",\n-        maximumQueuePerEnvCount: 5, // Larger than the number of queues we'll create\n-      });\n-\n-      const now = Date.now();\n-\n-      // Setup two environments with different numbers of queues\n-      const envSetups = [\n-        {\n-          envId: \"env-1\",\n-          queues: [{ age: 5000 }, { age: 4000 }],\n-        },\n-        {\n-          envId: \"env-2\",\n-          queues: [{ age: 3000 }],\n-        },\n-      ];\n-\n-      // Setup queues and concurrency for each env\n-      for (const setup of envSetups) {\n-        await setupConcurrency({\n-          redis,\n-          keyProducer,\n-          env: { id: setup.envId, currentConcurrency: 0, limit: 5 },\n-        });\n-\n-        for (let i = 0; i < setup.queues.length; i++) {\n-          await setupQueue({\n-            redis,\n-            keyProducer,\n-            parentQueue: \"parent-queue\",\n-            score: now - setup.queues[i].age,\n-            queueId: `queue-${setup.envId}-${i}`,\n-            orgId: `org-${setup.envId}`,\n-            envId: setup.envId,\n-          });\n-        }\n-      }\n-\n-      const result = await strategy.distributeFairQueuesFromParentQueue(\n-        \"parent-queue\",\n-        \"consumer-1\"\n-      );\n-\n-      // Should get all queues from both environments\n-      const env1Queues = result.find((eq) => eq.envId === \"env-1\")?.queues ?? [];\n-      const env2Queues = result.find((eq) => eq.envId === \"env-2\")?.queues ?? [];\n-\n-      // env-1 should have both its queues\n-      expect(env1Queues.length).toBe(2);\n-      // env-2 should have its single queue\n-      expect(env2Queues.length).toBe(1);\n-    }\n-  );\n-\n-  redisTest(\n-    \"should handle empty environments with maximumQueuePerEnvCount\",\n-    async ({ redisOptions }) => {\n-      const redis = createRedisClient(redisOptions);\n-\n-      const keyProducer = createKeyProducer(\"test\");\n-      const strategy = new FairDequeuingStrategy({\n-        tracer,\n-        redis,\n-        keys: keyProducer,\n-        defaultEnvConcurrency: 5,\n-        parentQueueLimit: 100,\n-        seed: \"test-seed-empty-env\",\n-        maximumQueuePerEnvCount: 2,\n-      });\n-\n-      const now = Date.now();\n-\n-      // Setup two environments, one with queues, one without\n-      await setupConcurrency({\n-        redis,\n-        keyProducer,\n-        env: { id: \"env-1\", currentConcurrency: 0, limit: 5 },\n-      });\n-\n-      await setupConcurrency({\n-        redis,\n-        keyProducer,\n-        env: { id: \"env-2\", currentConcurrency: 0, limit: 5 },\n-      });\n-\n-      // Only add queues to env-1\n-      await setupQueue({\n-        redis,\n-        keyProducer,\n-        parentQueue: \"parent-queue\",\n-        score: now - 5000,\n-        queueId: \"queue-1\",\n-        orgId: \"org-1\",\n-        envId: \"env-1\",\n-      });\n-\n-      await setupQueue({\n-        redis,\n-        keyProducer,\n-        parentQueue: \"parent-queue\",\n-        score: now - 4000,\n-        queueId: \"queue-2\",\n-        orgId: \"org-1\",\n-        envId: \"env-1\",\n-      });\n-\n-      const result = await strategy.distributeFairQueuesFromParentQueue(\n-        \"parent-queue\",\n-        \"consumer-1\"\n-      );\n-\n-      // Should only get one environment in the result\n-      expect(result.length).toBe(1);\n-      expect(result[0].envId).toBe(\"env-1\");\n-      expect(result[0].queues.length).toBe(2);\n-    }\n-  );\n-\n-  redisTest(\n-    \"should respect maximumQueuePerEnvCount with priority offset queues\",\n-    async ({ redisOptions }) => {\n-      const redis = createRedisClient(redisOptions);\n-\n-      const keyProducer = createKeyProducer(\"test\");\n-      const strategy = new FairDequeuingStrategy({\n-        tracer,\n-        redis,\n-        keys: keyProducer,\n-        defaultEnvConcurrency: 5,\n-        parentQueueLimit: 100,\n-        seed: \"test-seed-priority\",\n-        maximumQueuePerEnvCount: 2,\n-        biases: {\n-          concurrencyLimitBias: 0,\n-          availableCapacityBias: 0,\n-          queueAgeRandomization: 0.3,\n-        },\n-      });\n-\n-      const now = Date.now();\n-\n-      // Setup queues with a mix of normal and priority offset ages\n-      const queues = [\n-        { age: 5000, id: \"queue-0\" }, // Normal age\n-        { age: 4000 + MARQS_RESUME_PRIORITY_TIMESTAMP_OFFSET, id: \"queue-1\" }, // Priority\n-        { age: 3000, id: \"queue-2\" }, // Normal age\n-        { age: 2000 + MARQS_RESUME_PRIORITY_TIMESTAMP_OFFSET, id: \"queue-3\" }, // Priority\n-        { age: 1000, id: \"queue-4\" }, // Normal age\n-      ];\n-\n-      await setupConcurrency({\n-        redis,\n-        keyProducer,\n-        env: { id: \"env-1\", currentConcurrency: 0, limit: 5 },\n-      });\n-\n-      for (const queue of queues) {\n-        await setupQueue({\n-          redis,\n-          keyProducer,\n-          parentQueue: \"parent-queue\",\n-          score: now - queue.age,\n-          queueId: queue.id,\n-          orgId: \"org-1\",\n-          envId: \"env-1\",\n-        });\n-      }\n-\n-      // Run multiple iterations to check distribution\n-      const iterations = 1000;\n-      const queueSelectionCounts: Record<string, number> = {};\n-\n-      for (let i = 0; i < iterations; i++) {\n-        const result = await strategy.distributeFairQueuesFromParentQueue(\n-          \"parent-queue\",\n-          `consumer-${i}`\n-        );\n-\n-        const selectedQueues = result[0].queues;\n-        for (const queueId of selectedQueues) {\n-          const baseQueueId = queueId.split(\":\").pop()!;\n-          queueSelectionCounts[baseQueueId] = (queueSelectionCounts[baseQueueId] || 0) + 1;\n-        }\n-      }\n-\n-      console.log(\"\\nPriority Queue Selection Statistics:\");\n-      for (const [queueId, count] of Object.entries(queueSelectionCounts)) {\n-        const percentage = (count / (iterations * 2)) * 100;\n-        const isPriority =\n-          queues.find((q) => q.id === queueId)?.age! > MARQS_RESUME_PRIORITY_TIMESTAMP_OFFSET;\n-        console.log(\n-          `${queueId}${isPriority ? \" (priority)\" : \"\"}: ${percentage.toFixed(2)}% (${count} times)`\n-        );\n-      }\n-\n-      // Verify all queues get selected\n-      for (const queue of queues) {\n-        expect(queueSelectionCounts[queue.id]).toBeGreaterThan(0);\n-      }\n-\n-      // Even with priority queues, we should still see a reasonable distribution\n-      const selectionPercentages = Object.values(queueSelectionCounts).map(\n-        (count) => (count / (iterations * 2)) * 100\n-      );\n-      const stdDev = calculateStandardDeviation(selectionPercentages);\n-      expect(stdDev).toBeLessThan(20); // Allow for slightly more variance due to priority queues\n-    }\n-  );\n-});\n-\n-// Helper function to flatten results for counting\n-function flattenResults(results: Array<EnvQueues>): string[] {\n-  return results.flatMap((envQueue) => envQueue.queues);\n-}\n+        expect(firstPositionPercentage).to\n\\ No newline at end of file\ndiff --git a/packages/core/src/v3/utils/ioSerialization.ts b/packages/core/src/v3/utils/ioSerialization.ts\nindex 9bacc41..433e7da 100644\n--- a/packages/core/src/v3/utils/ioSerialization.ts\n+++ b/packages/core/src/v3/utils/ioSerialization.ts\n@@ -1,4 +1,3 @@\n-import { JSONHeroPath } from \"@jsonhero/path\";\n import { Attributes, Span } from \"@opentelemetry/api\";\n import { z } from \"zod\";\n import { ApiClient } from \"../apiClient/index.js\";\n@@ -13,6 +12,7 @@ import { SemanticInternalAttributes } from \"../semanticInternalAttributes.js\";\n import { TriggerTracer } from \"../tracer.js\";\n import { zodfetch } from \"../zodfetch.js\";\n import { flattenAttributes } from \"./flattenAttributes.js\";\n+import { JSONHeroPath } from \"@jsonhero/path\";\n \n export type IOPacket = {\n   data?: string | undefined;\n@@ -389,40 +389,16 @@ export async function prettyPrintPacket(\n     if (typeof rawData === \"string\") {\n       rawData = safeJsonParse(rawData);\n     }\n-\n     const { deserialize } = await loadSuperJSON();\n \n-    const hasCircularReferences = rawData && rawData.meta && hasCircularReference(rawData.meta);\n-\n-    if (hasCircularReferences) {\n-      return await prettyPrintPacket(deserialize(rawData), \"application/json\", {\n-        ...options,\n-        cloneReferences: false,\n-      });\n-    }\n-\n-    return await prettyPrintPacket(deserialize(rawData), \"application/json\", {\n-      ...options,\n-      cloneReferences: true,\n-    });\n+    return await prettyPrintPacket(deserialize(rawData), \"application/json\");\n   }\n \n   if (dataType === \"application/json\") {\n     if (typeof rawData === \"string\") {\n       rawData = safeJsonParse(rawData);\n     }\n-\n-    try {\n-      return JSON.stringify(rawData, makeSafeReplacer(options), 2);\n-    } catch (error) {\n-      // If cloneReferences is true, it's possible if our hasCircularReference logic is incorrect that stringifying the data will fail with a circular reference error\n-      // So we will try to stringify the data with cloneReferences set to false\n-      if (options?.cloneReferences) {\n-        return JSON.stringify(rawData, makeSafeReplacer({ ...options, cloneReferences: false }), 2);\n-      }\n-\n-      throw error;\n-    }\n+    return JSON.stringify(rawData, makeSafeReplacer(options), 2);\n   }\n \n   if (typeof rawData === \"string\") {\n@@ -434,7 +410,6 @@ export async function prettyPrintPacket(\n \n interface ReplacerOptions {\n   filteredKeys?: string[];\n-  cloneReferences?: boolean;\n }\n \n function makeSafeReplacer(options?: ReplacerOptions) {\n@@ -443,10 +418,6 @@ function makeSafeReplacer(options?: ReplacerOptions) {\n   return function replacer(key: string, value: any) {\n     if (typeof value === \"object\" && value !== null) {\n       if (seen.has(value)) {\n-        if (options?.cloneReferences) {\n-          return structuredClone(value);\n-        }\n-\n         return \"[Circular]\";\n       }\n       seen.add(value);\n@@ -564,102 +535,4 @@ export async function replaceSuperJsonPayload(original: string, newPayload: stri\n       .filter(([, value]) => Array.isArray(value) && value.at(0) === \"undefined\")\n       .map(([key]) => key);\n \n-    const overridenUndefinedKeys = originalUndefinedKeys.filter(\n-      (key) => getKeyFromObject(newPayloadObject, key) !== undefined\n-    );\n-\n-    overridenUndefinedKeys.forEach((key) => {\n-      delete (meta.values as Record<string, any>)[key];\n-    });\n-  }\n-\n-  const newSuperJson = {\n-    json: newPayloadObject,\n-    meta,\n-  };\n-\n-  return superjson.deserialize(newSuperJson);\n-}\n-\n-function getKeyFromObject(object: unknown, key: string) {\n-  const jsonHeroPath = new JSONHeroPath(key);\n-\n-  return jsonHeroPath.first(object);\n-}\n-\n-/**\n- * Detects if a superjson serialization contains circular references\n- * by analyzing the meta.referentialEqualities structure.\n- *\n- * Based on superjson's ReferentialEqualityAnnotations type:\n- * Record<string, string[]> | [string[]] | [string[], Record<string, string[]>]\n- *\n- * Circular references are represented as:\n- * - [string[]] where strings are paths that reference back to root or ancestors\n- * - The first element in [string[], Record<string, string[]>] format\n- */\n-function hasCircularReference(meta: any): boolean {\n-  if (!meta?.referentialEqualities) {\n-    return false;\n-  }\n-\n-  const re = meta.referentialEqualities;\n-\n-  // Case 1: [string[]] - array containing only circular references\n-  if (Array.isArray(re) && re.length === 1 && Array.isArray(re[0])) {\n-    return re[0].length > 0; // Has circular references\n-  }\n-\n-  // Case 2: [string[], Record<string, string[]>] - mixed format\n-  if (Array.isArray(re) && re.length === 2 && Array.isArray(re[0])) {\n-    return re[0].length > 0; // First element contains circular references\n-  }\n-\n-  // Case 3: Record<string, string[]> - check for circular patterns in shared references\n-  if (!Array.isArray(re) && typeof re === \"object\") {\n-    // Check if any reference path points to an ancestor path\n-    for (const [targetPath, referencePaths] of Object.entries(re)) {\n-      for (const refPath of referencePaths as string[]) {\n-        if (isCircularPattern(targetPath, refPath)) {\n-          return true;\n-        }\n-      }\n-    }\n-    return false;\n-  }\n-\n-  return false;\n-}\n-\n-/**\n- * Checks if a reference pattern represents a circular reference\n- * by analyzing if the reference path points back to an ancestor of the target path\n- */\n-function isCircularPattern(targetPath: string, referencePath: string): boolean {\n-  const targetParts = targetPath.split(\".\");\n-  const refParts = referencePath.split(\".\");\n-\n-  // For circular references, the reference path often contains the target path as a prefix\n-  // Example: targetPath=\"user\", referencePath=\"user.details.user\"\n-  // This means user.details.user points back to user (circular)\n-\n-  // Check if reference path starts with target path + additional segments that loop back\n-  if (refParts.length > targetParts.length) {\n-    // Check if reference path starts with target path\n-    let isPrefix = true;\n-    for (let i = 0; i < targetParts.length; i++) {\n-      if (targetParts[i] !== refParts[i]) {\n-        isPrefix = false;\n-        break;\n-      }\n-    }\n-\n-    // If reference path starts with target path and ends with target path,\n-    // it's likely a circular reference (e.g., \"user\" -> \"user.details.user\")\n-    if (isPrefix && refParts[refParts.length - 1] === targetParts[targetParts.length - 1]) {\n-      return true;\n-    }\n-  }\n-\n-  return false;\n-}\n+    const over\n\\ No newline at end of file\ndiff --git a/packages/core/test/ioSerialization.test.ts b/packages/core/test/ioSerialization.test.ts\nindex d7bd90a..81524b3 100644\n--- a/packages/core/test/ioSerialization.test.ts\n+++ b/packages/core/test/ioSerialization.test.ts\n@@ -1,4 +1,4 @@\n-import { replaceSuperJsonPayload, prettyPrintPacket } from \"../src/v3/utils/ioSerialization.js\";\n+import { replaceSuperJsonPayload } from \"../src/v3/utils/ioSerialization.js\";\n \n describe(\"ioSerialization\", () => {\n   describe(\"replaceSuperJsonPayload\", () => {\n@@ -188,160 +188,4 @@ describe(\"ioSerialization\", () => {\n       await expect(replaceSuperJsonPayload(originalSerialized, invalidPayload)).rejects.toThrow();\n     });\n   });\n-\n-  describe(\"prettyPrintPacket\", () => {\n-    it(\"should return empty string for undefined data\", async () => {\n-      const result = await prettyPrintPacket(undefined);\n-      expect(result).toBe(\"\");\n-    });\n-\n-    it(\"should return string data as-is\", async () => {\n-      const result = await prettyPrintPacket(\"Hello, World!\");\n-      expect(result).toBe(\"Hello, World!\");\n-    });\n-\n-    it(\"should pretty print JSON data with default options\", async () => {\n-      const data = { name: \"John\", age: 30, nested: { value: true } };\n-      const result = await prettyPrintPacket(data, \"application/json\");\n-\n-      expect(result).toBe(JSON.stringify(data, null, 2));\n-    });\n-\n-    it(\"should handle JSON data as string\", async () => {\n-      const data = { name: \"John\", age: 30 };\n-      const jsonString = JSON.stringify(data);\n-      const result = await prettyPrintPacket(jsonString, \"application/json\");\n-\n-      expect(result).toBe(JSON.stringify(data, null, 2));\n-    });\n-\n-    it(\"should pretty print SuperJSON data\", async () => {\n-      const data = {\n-        name: \"John\",\n-        date: new Date(\"2023-01-01\"),\n-        bigInt: BigInt(123),\n-        set: new Set([\"a\", \"b\"]),\n-        map: new Map([[\"key\", \"value\"]]),\n-      };\n-\n-      const superjson = await import(\"superjson\");\n-      const serialized = superjson.stringify(data);\n-\n-      const result = await prettyPrintPacket(serialized, \"application/super+json\");\n-\n-      // Should deserialize and pretty print the data\n-      expect(result).toContain('\"name\": \"John\"');\n-      expect(result).toContain('\"date\": \"2023-01-01T00:00:00.000Z\"');\n-      expect(result).toContain('\"bigInt\": \"123\"');\n-      expect(result).toContain('\"set\": [\\n    \"a\",\\n    \"b\"\\n  ]');\n-      expect(result).toContain('\"map\": {\\n    \"key\": \"value\"\\n  }');\n-    });\n-\n-    it(\"should handle circular references\", async () => {\n-      const data: any = { name: \"John\" };\n-      data.self = data; // Create circular reference\n-\n-      // Create a SuperJSON serialized version to test the circular reference detection\n-      const superjson = await import(\"superjson\");\n-      const serialized = superjson.stringify(data);\n-\n-      const result = await prettyPrintPacket(serialized, \"application/super+json\");\n-\n-      expect(result).toContain('\"name\": \"John\"');\n-      expect(result).toContain('\"self\": \"[Circular]\"');\n-    });\n-\n-    it(\"should handle regular non-circular references\", async () => {\n-      const person = { name: \"John\" };\n-\n-      const data: any = { person1: person, person2: person };\n-\n-      // Create a SuperJSON serialized version to test the circular reference detection\n-      const superjson = await import(\"superjson\");\n-      const serialized = superjson.stringify(data);\n-\n-      const result = await prettyPrintPacket(serialized, \"application/super+json\");\n-\n-      expect(result).toContain('\"person1\": {');\n-      expect(result).toContain('\"person2\": {');\n-    });\n-\n-    it(\"should filter out specified keys\", async () => {\n-      const data = { name: \"John\", password: \"secret\", age: 30 };\n-      const result = await prettyPrintPacket(data, \"application/json\", {\n-        filteredKeys: [\"password\"],\n-      });\n-\n-      expect(result).toContain('\"name\": \"John\"');\n-      expect(result).toContain('\"age\": 30');\n-      expect(result).not.toContain('\"password\"');\n-    });\n-\n-    it(\"should handle BigInt values\", async () => {\n-      const data = { id: BigInt(123456789), name: \"John\" };\n-      const result = await prettyPrintPacket(data, \"application/json\");\n-\n-      expect(result).toContain('\"id\": \"123456789\"');\n-      expect(result).toContain('\"name\": \"John\"');\n-    });\n-\n-    it(\"should handle RegExp values\", async () => {\n-      const data = { pattern: /test/gi, name: \"John\" };\n-      const result = await prettyPrintPacket(data, \"application/json\");\n-\n-      expect(result).toContain('\"pattern\": \"/test/gi\"');\n-      expect(result).toContain('\"name\": \"John\"');\n-    });\n-\n-    it(\"should handle Set values\", async () => {\n-      const data = { tags: new Set([\"tag1\", \"tag2\"]), name: \"John\" };\n-      const result = await prettyPrintPacket(data, \"application/json\");\n-\n-      expect(result).toContain('\"tags\": [\\n    \"tag1\",\\n    \"tag2\"\\n  ]');\n-      expect(result).toContain('\"name\": \"John\"');\n-    });\n-\n-    it(\"should handle Map values\", async () => {\n-      const data = { mapping: new Map([[\"key1\", \"value1\"]]), name: \"John\" };\n-      const result = await prettyPrintPacket(data, \"application/json\");\n-\n-      expect(result).toContain('\"mapping\": {\\n    \"key1\": \"value1\"\\n  }');\n-      expect(result).toContain('\"name\": \"John\"');\n-    });\n-\n-    it(\"should handle complex nested data\", async () => {\n-      const data = {\n-        user: {\n-          id: BigInt(123),\n-          createdAt: new Date(\"2023-01-01\"),\n-          settings: {\n-            theme: \"dark\",\n-            tags: new Set([\"admin\", \"user\"]),\n-            config: new Map([[\"timeout\", \"30s\"]]),\n-          },\n-        },\n-        metadata: {\n-          version: 1,\n-          pattern: /^test$/,\n-        },\n-      };\n-\n-      const result = await prettyPrintPacket(data, \"application/json\");\n-\n-      expect(result).toContain('\"id\": \"123\"');\n-      expect(result).toContain('\"createdAt\": \"2023-01-01T00:00:00.000Z\"');\n-      expect(result).toContain('\"theme\": \"dark\"');\n-      expect(result).toContain('\"tags\": [\\n        \"admin\",\\n        \"user\"\\n      ]');\n-      expect(result).toContain('\"config\": {\\n        \"timeout\": \"30s\"\\n      }');\n-      expect(result).toContain('\"version\": 1');\n-      expect(result).toContain('\"pattern\": \"/^test$/\"');\n-    });\n-\n-    it(\"should handle data without dataType parameter\", async () => {\n-      const data = { name: \"John\", age: 30 };\n-      const result = await prettyPrintPacket(data);\n-\n-      expect(result).toBe(JSON.stringify(data, null, 2));\n-    });\n-  });\n-});\n+});\n\\ No newline at end of file\ndiff --git a/references/hello-world/src/trigger/circularPayload.ts b/references/hello-world/src/trigger/circularPayload.ts\ndeleted file mode 100644\nindex 3e9d0a9..0000000\n--- a/references/hello-world/src/trigger/circularPayload.ts\n+++ /dev/null\n@@ -1,149 +0,0 @@\n-import { logger, schemaTask, task, tasks } from \"@trigger.dev/sdk\";\n-import { z } from \"zod/v3\";\n-\n-export const referentialPayloadParentTask = task({\n-  id: \"referential-payload-parent\",\n-  run: async (payload: any) => {\n-    // Shared objects\n-    const workflowData = {\n-      id: \"workflow-123\",\n-      formName: \"Contact Form\",\n-    };\n-\n-    const response = [\n-      {\n-        id: \"q1_name\",\n-        answer: \"John Doe\",\n-      },\n-      {\n-        id: \"q2_consent\",\n-        answer: \"yes\",\n-        leadAttribute: undefined, // Will be marked in meta\n-      },\n-    ];\n-\n-    const personAttributes = {\n-      ip: \"192.168.1.1\",\n-      visitedForm: 1,\n-    };\n-\n-    // Main object with shared references\n-    const originalObject = {\n-      workflowData: workflowData, // Root reference\n-      workflowContext: {\n-        leadId: undefined, // Will be marked in meta\n-        workflowJob: {\n-          workflowData: workflowData, // Same reference as root\n-          createdAt: new Date(\"2025-08-19T12:13:42.260Z\"), // Date object\n-        },\n-        responseData: {\n-          personAttributes: personAttributes, // Same reference as root\n-        },\n-        response: response, // Same reference as root\n-      },\n-      personAttributes: personAttributes, // Root reference\n-      response: response, // Root reference\n-      jobArgs: {\n-        response: response, // Same reference as root\n-        args: workflowData, // Same reference as root\n-      },\n-    };\n-\n-    await tasks.triggerAndWait<typeof referentialPayloadChildTask>(\n-      \"referential-payload-child\",\n-      originalObject\n-    );\n-\n-    return {\n-      message: \"Hello, world!\",\n-    };\n-  },\n-});\n-\n-// Define the circular schema using z.lazy() for the recursive reference\n-const WorkflowDataSchema = z.object({\n-  id: z.string(),\n-  formName: z.string(),\n-});\n-\n-const ResponseItemSchema = z.object({\n-  id: z.string(),\n-  answer: z.string(),\n-  leadAttribute: z.undefined().optional(),\n-});\n-\n-const PersonAttributesSchema = z.object({\n-  ip: z.string(),\n-  visitedForm: z.number(),\n-});\n-\n-const OriginalObjectSchema = z.object({\n-  workflowData: WorkflowDataSchema,\n-  workflowContext: z.object({\n-    leadId: z.undefined(),\n-    workflowJob: z.object({\n-      workflowData: WorkflowDataSchema, // Same reference\n-      createdAt: z.date(),\n-    }),\n-    responseData: z.object({\n-      personAttributes: PersonAttributesSchema, // Same reference\n-    }),\n-    response: z.array(ResponseItemSchema), // Same reference\n-  }),\n-  personAttributes: PersonAttributesSchema, // Root reference\n-  response: z.array(ResponseItemSchema), // Root reference\n-  jobArgs: z.object({\n-    response: z.array(ResponseItemSchema), // Same reference\n-    args: WorkflowDataSchema, // Same reference\n-  }),\n-});\n-\n-export const referentialPayloadChildTask = schemaTask({\n-  id: \"referential-payload-child\",\n-  schema: OriginalObjectSchema,\n-  run: async (payload) => {\n-    logger.info(\"Received circular payload\", { payload });\n-\n-    return {\n-      message: \"Hello, world!\",\n-    };\n-  },\n-});\n-\n-export const circularReferenceParentTask = task({\n-  id: \"circular-reference-parent\",\n-  run: async (payload: any) => {\n-    const user = {\n-      name: \"Alice\",\n-      details: {\n-        age: 30,\n-        email: \"alice@example.com\",\n-      },\n-    };\n-    // @ts-expect-error - This is a circular reference\n-    user.details.user = user;\n-\n-    await tasks.triggerAndWait<typeof circularReferenceChildTask>(\"circular-reference-child\", {\n-      // @ts-expect-error - This is a circular reference\n-      user,\n-    });\n-  },\n-});\n-\n-type CircularReferencePayload = {\n-  user: {\n-    name: string;\n-    details: {\n-      age: number;\n-      email: string;\n-      user: CircularReferencePayload;\n-    };\n-  };\n-};\n-\n-export const circularReferenceChildTask = task({\n-  id: \"circular-reference-child\",\n-  run: async (payload: CircularReferencePayload) => {\n-    logger.info(\"Received circular payload\", { payload });\n-  },\n-});\n"
  },
  {
    "instance_id": "triggerdotdev__trigger.dev.d1c3bfb9.2523",
    "repo": "triggerdotdev__trigger.dev.d1c3bfb9",
    "base_commit": "a3ef6ea2363a6617296d6132a76c6d9a595f3a3e",
    "head_commit": "97160380d1ad0d7d49bed7b1d41e235c821daf51",
    "title": "fix(runner): reduce restore recovery time and deprecated runner false positives",
    "merged_at": "2025-09-18T15:59:44Z",
    "html_url": "https://github.com/triggerdotdev/trigger.dev/pull/2523",
    "test_files": [
      "packages/cli-v3/src/entryPoints/managed/snapshot.test.ts"
    ],
    "code_files": [
      "apps/supervisor/src/workloadServer/index.ts",
      "packages/cli-v3/src/entryPoints/managed/controller.ts",
      "packages/cli-v3/src/entryPoints/managed/execution.ts",
      "packages/cli-v3/src/entryPoints/managed/snapshot.ts",
      "packages/core/src/v3/runEngineWorker/workload/http.ts"
    ],
    "total_changes": 341,
    "num_files": 7,
    "pull_number": 2523,
    "patch": "diff --git a/.changeset/six-cougars-play.md b/.changeset/six-cougars-play.md\nnew file mode 100644\nindex 0000000000..75d128dddd\n--- /dev/null\n+++ b/.changeset/six-cougars-play.md\n@@ -0,0 +1,6 @@\n+---\n+\"trigger.dev\": patch\n+\"@trigger.dev/core\": patch\n+---\n+\n+Reduce restore recovery time and fix deprecated runner false positives\n\\ No newline at end of file\ndiff --git a/apps/supervisor/src/workloadServer/index.ts b/apps/supervisor/src/workloadServer/index.ts\nindex 6b24ffcf33..35d53d3609 100644\n--- a/apps/supervisor/src/workloadServer/index.ts\n+++ b/apps/supervisor/src/workloadServer/index.ts\n@@ -125,7 +125,7 @@ export class WorkloadServer extends EventEmitter<WorkloadServerEvents> {\n   }\n \n   private createHttpServer({ host, port }: { host: string; port: number }) {\n-    return new HttpServer({\n+    const httpServer = new HttpServer({\n       port,\n       host,\n       metrics: {\n@@ -346,23 +346,6 @@ export class WorkloadServer extends EventEmitter<WorkloadServerEvents> {\n           },\n         }\n       )\n-      .route(\"/api/v1/workload-actions/runs/:runFriendlyId/logs/debug\", \"POST\", {\n-        paramsSchema: WorkloadActionParams.pick({ runFriendlyId: true }),\n-        bodySchema: WorkloadDebugLogRequestBody,\n-        handler: async ({ req, reply, params, body }) => {\n-          reply.empty(204);\n-\n-          if (!env.SEND_RUN_DEBUG_LOGS) {\n-            return;\n-          }\n-\n-          await this.workerClient.sendDebugLog(\n-            params.runFriendlyId,\n-            body,\n-            this.runnerIdFromRequest(req)\n-          );\n-        },\n-      })\n       .route(\"/api/v1/workload-actions/deployments/:deploymentId/dequeue\", \"GET\", {\n         paramsSchema: z.object({\n           deploymentId: z.string(),\n@@ -387,6 +370,31 @@ export class WorkloadServer extends EventEmitter<WorkloadServerEvents> {\n           reply.json(dequeueResponse.data satisfies WorkloadDequeueFromVersionResponseBody);\n         },\n       });\n+\n+    if (env.SEND_RUN_DEBUG_LOGS) {\n+      httpServer.route(\"/api/v1/workload-actions/runs/:runFriendlyId/logs/debug\", \"POST\", {\n+        paramsSchema: WorkloadActionParams.pick({ runFriendlyId: true }),\n+        bodySchema: WorkloadDebugLogRequestBody,\n+        handler: async ({ req, reply, params, body }) => {\n+          reply.empty(204);\n+\n+          await this.workerClient.sendDebugLog(\n+            params.runFriendlyId,\n+            body,\n+            this.runnerIdFromRequest(req)\n+          );\n+        },\n+      });\n+    } else {\n+      // Lightweight mock route without schemas\n+      httpServer.route(\"/api/v1/workload-actions/runs/:runFriendlyId/logs/debug\", \"POST\", {\n+        handler: async ({ reply }) => {\n+          reply.empty(204);\n+        },\n+      });\n+    }\n+\n+    return httpServer;\n   }\n \n   private createWebsocketServer() {\ndiff --git a/packages/cli-v3/src/entryPoints/managed/controller.ts b/packages/cli-v3/src/entryPoints/managed/controller.ts\nindex 80bd744dfa..c721cefc56 100644\n--- a/packages/cli-v3/src/entryPoints/managed/controller.ts\n+++ b/packages/cli-v3/src/entryPoints/managed/controller.ts\n@@ -461,19 +461,6 @@ export class ManagedRunController {\n         runId: this.runFriendlyId,\n         message: \"Socket connected to supervisor\",\n       });\n-\n-      // This should handle the case where we reconnect after being restored\n-      if (\n-        this.runFriendlyId &&\n-        this.snapshotFriendlyId &&\n-        this.runFriendlyId !== this.env.TRIGGER_RUN_ID\n-      ) {\n-        this.sendDebugLog({\n-          runId: this.runFriendlyId,\n-          message: \"Subscribing to notifications for in-progress run\",\n-        });\n-        this.subscribeToRunNotifications(this.runFriendlyId, this.snapshotFriendlyId);\n-      }\n     });\n \n     socket.on(\"connect_error\", (error) => {\n@@ -514,7 +501,7 @@ export class ManagedRunController {\n           supervisorApiUrl: this.env.TRIGGER_SUPERVISOR_API_URL,\n         };\n \n-        await this.currentExecution.processEnvOverrides(\"socket disconnected\", true);\n+        const result = await this.currentExecution.processEnvOverrides(\"socket disconnected\", true);\n \n         const newEnv = {\n           workerInstanceName: this.env.TRIGGER_WORKER_INSTANCE_NAME,\n@@ -528,6 +515,43 @@ export class ManagedRunController {\n           properties: { reason, ...parseDescription(), currentEnv, newEnv },\n         });\n \n+        if (!result) {\n+          return;\n+        }\n+\n+        // If runner ID changed, we detected a restore\n+        if (result.runnerIdChanged) {\n+          this.sendDebugLog({\n+            runId: this.runFriendlyId,\n+            message: \"Runner ID changed - restore detected\",\n+            properties: {\n+              supervisorChanged: result.supervisorChanged,\n+            },\n+          });\n+\n+          if (!result.supervisorChanged) {\n+            return;\n+          }\n+\n+          // Only reconnect WebSocket if supervisor URL actually changed\n+          this.sendDebugLog({\n+            runId: this.runFriendlyId,\n+            message: \"Supervisor URL changed - creating new socket connection\",\n+          });\n+\n+          // First disconnect the old socket to avoid conflicts\n+          socket.removeAllListeners();\n+          socket.disconnect();\n+\n+          // Create a new socket with the updated URL and headers\n+          this.socket = this.createSupervisorSocket();\n+\n+          // Re-subscribe to notifications if we have an active execution\n+          if (this.runFriendlyId && this.snapshotFriendlyId) {\n+            this.subscribeToRunNotifications(this.runFriendlyId, this.snapshotFriendlyId);\n+          }\n+        }\n+\n         return;\n       }\n \ndiff --git a/packages/cli-v3/src/entryPoints/managed/execution.ts b/packages/cli-v3/src/entryPoints/managed/execution.ts\nindex 2b9e0c9c08..2dd3e6838e 100644\n--- a/packages/cli-v3/src/entryPoints/managed/execution.ts\n+++ b/packages/cli-v3/src/entryPoints/managed/execution.ts\n@@ -873,7 +873,23 @@ export class RunExecution {\n     );\n \n     if (!continuationResult.success) {\n-      throw new Error(continuationResult.error);\n+      // Check if we need to refresh metadata due to connection error\n+      if (continuationResult.isConnectionError) {\n+        this.sendDebugLog(\"restore: connection error detected, refreshing metadata\");\n+        await this.processEnvOverrides(\"restore connection error\");\n+\n+        // Retry the continuation after refreshing metadata\n+        const retryResult = await this.httpClient.continueRunExecution(\n+          this.runFriendlyId,\n+          this.snapshotManager.snapshotId\n+        );\n+\n+        if (!retryResult.success) {\n+          throw new Error(retryResult.error);\n+        }\n+      } else {\n+        throw new Error(continuationResult.error);\n+      }\n     }\n \n     // Track restore count\n@@ -899,11 +915,18 @@ export class RunExecution {\n   public async processEnvOverrides(\n     reason?: string,\n     shouldPollForSnapshotChanges?: boolean\n-  ): Promise<{ overrides: Metadata } | null> {\n+  ): Promise<{\n+    overrides: Metadata;\n+    runnerIdChanged?: boolean;\n+    supervisorChanged?: boolean;\n+  } | null> {\n     if (!this.metadataClient) {\n       return null;\n     }\n \n+    const previousRunnerId = this.env.TRIGGER_RUNNER_ID;\n+    const previousSupervisorUrl = this.env.TRIGGER_SUPERVISOR_API_URL;\n+\n     const [error, overrides] = await this.metadataClient.getEnvOverrides();\n \n     if (error) {\n@@ -931,6 +954,14 @@ export class RunExecution {\n     // Override the env with the new values\n     this.env.override(overrides);\n \n+    // Check if runner ID changed\n+    const newRunnerId = this.env.TRIGGER_RUNNER_ID;\n+    const runnerIdChanged = previousRunnerId !== newRunnerId;\n+\n+    // Check if supervisor URL changed\n+    const newSupervisorUrl = this.env.TRIGGER_SUPERVISOR_API_URL;\n+    const supervisorChanged = previousSupervisorUrl !== newSupervisorUrl;\n+\n     // Update services with new values\n     if (overrides.TRIGGER_SNAPSHOT_POLL_INTERVAL_SECONDS) {\n       this.snapshotPoller?.updateInterval(this.env.TRIGGER_SNAPSHOT_POLL_INTERVAL_SECONDS * 1000);\n@@ -954,6 +985,8 @@ export class RunExecution {\n \n     return {\n       overrides,\n+      runnerIdChanged,\n+      supervisorChanged,\n     };\n   }\n \n@@ -977,6 +1010,12 @@ export class RunExecution {\n \n     if (!response.success) {\n       this.sendDebugLog(\"heartbeat: failed\", { error: response.error });\n+\n+      // Check if we need to refresh metadata due to connection error\n+      if (response.isConnectionError) {\n+        this.sendDebugLog(\"heartbeat: connection error detected, refreshing metadata\");\n+        await this.processEnvOverrides(\"heartbeat connection error\");\n+      }\n     }\n \n     this.lastHeartbeat = new Date();\n@@ -1192,6 +1231,14 @@ export class RunExecution {\n         error: response.error,\n       });\n \n+      if (response.isConnectionError) {\n+        // Log this separately to make it more visible\n+        this.sendDebugLog(\n+          \"fetchAndProcessSnapshotChanges: connection error detected, refreshing metadata\"\n+        );\n+      }\n+\n+      // Always trigger metadata refresh on snapshot fetch errors\n       await this.processEnvOverrides(\"snapshots since error\");\n       return;\n     }\ndiff --git a/packages/cli-v3/src/entryPoints/managed/snapshot.test.ts b/packages/cli-v3/src/entryPoints/managed/snapshot.test.ts\nindex 05cba11f38..a3dbab3883 100644\n--- a/packages/cli-v3/src/entryPoints/managed/snapshot.test.ts\n+++ b/packages/cli-v3/src/entryPoints/managed/snapshot.test.ts\n@@ -697,6 +697,65 @@ describe(\"SnapshotManager\", () => {\n       true\n     );\n   });\n+\n+  it(\"should handle deprecated snapshot race condition - avoid false positives from stale polls\", async () => {\n+    const onSnapshotChange = vi.fn();\n+\n+    // Mock MetadataClient to simulate runner ID change (restore detected) on first call\n+    let isFirstCall = true;\n+    const mockMetadataClient = {\n+      getEnvOverrides: vi.fn().mockImplementation(() => {\n+        if (isFirstCall) {\n+          isFirstCall = false;\n+          return Promise.resolve([null, { TRIGGER_RUNNER_ID: \"test-runner-2\" }]); // Different runner ID = restore\n+        }\n+        return Promise.resolve([null, { TRIGGER_RUNNER_ID: \"test-runner-2\" }]); // Same runner ID afterward\n+      }),\n+    };\n+\n+    const manager = new SnapshotManager({\n+      runnerId: \"test-runner-1\",\n+      runFriendlyId: \"test-run-1\",\n+      initialSnapshotId: \"snapshot-1\",\n+      initialStatus: \"EXECUTING_WITH_WAITPOINTS\",\n+      logger: mockLogger,\n+      metadataClient: mockMetadataClient as any,\n+      onSnapshotChange,\n+      onSuspendable: mockSuspendableHandler,\n+    });\n+\n+    // First update: Process restore transition with deprecated statuses (normal case)\n+    // This simulates: EXECUTING_WITH_WAITPOINTS -> [SUSPENDED, QUEUED] -> PENDING_EXECUTING\n+    await manager.handleSnapshotChanges([\n+      createRunExecutionData({ snapshotId: \"snapshot-suspended\", executionStatus: \"SUSPENDED\" }),\n+      createRunExecutionData({ snapshotId: \"snapshot-queued\", executionStatus: \"QUEUED\" }),\n+      createRunExecutionData({ snapshotId: \"snapshot-2\", executionStatus: \"PENDING_EXECUTING\" }),\n+    ]);\n+\n+    // First call should be deprecated=false (restore detected)\n+    expect(onSnapshotChange).toHaveBeenCalledWith(\n+      expect.objectContaining({ snapshot: expect.objectContaining({ friendlyId: \"snapshot-2\" }) }),\n+      false\n+    );\n+\n+    onSnapshotChange.mockClear();\n+\n+    // Second update: Should only get new snapshot (race condition case)\n+    // This simulates a stale poll that returns: getSnapshotsSince(snapshot-1) -> [SUSPENDED, QUEUED, snapshot-2, snapshot-3]\n+    // The SUSPENDED/QUEUED should be ignored as already seen\n+    await manager.handleSnapshotChanges([\n+      createRunExecutionData({ snapshotId: \"snapshot-suspended\", executionStatus: \"SUSPENDED\" }), // Already seen\n+      createRunExecutionData({ snapshotId: \"snapshot-queued\", executionStatus: \"QUEUED\" }), // Already seen\n+      createRunExecutionData({ snapshotId: \"snapshot-2\", executionStatus: \"PENDING_EXECUTING\" }), // Already processed\n+      createRunExecutionData({ snapshotId: \"snapshot-3\", executionStatus: \"EXECUTING\" }), // New\n+    ]);\n+\n+    // Should call onSnapshotChange with deprecated = false (no new deprecated snapshots)\n+    expect(onSnapshotChange).toHaveBeenCalledWith(\n+      expect.objectContaining({ snapshot: expect.objectContaining({ friendlyId: \"snapshot-3\" }) }),\n+      false\n+    );\n+  });\n });\n \n // Helper to generate RunExecutionData with sensible defaults\ndiff --git a/packages/cli-v3/src/entryPoints/managed/snapshot.ts b/packages/cli-v3/src/entryPoints/managed/snapshot.ts\nindex 75d3d4b036..9703ea8f87 100644\n--- a/packages/cli-v3/src/entryPoints/managed/snapshot.ts\n+++ b/packages/cli-v3/src/entryPoints/managed/snapshot.ts\n@@ -49,6 +49,10 @@ export class SnapshotManager {\n   private changeQueue: QueuedChangeItem[] = [];\n   private isProcessingQueue = false;\n \n+  // Track seen deprecated snapshots to prevent false positives\n+  private seenDeprecatedSnapshotIds: string[] = [];\n+  private readonly maxSeenDeprecatedSnapshotIds = 50;\n+\n   constructor(opts: SnapshotManagerOptions) {\n     this.runFriendlyId = opts.runFriendlyId;\n     this.runnerId = opts.runnerId;\n@@ -284,9 +288,13 @@ export class SnapshotManager {\n \n         // Check if any previous snapshot is QUEUED or SUSPENDED\n         const deprecatedStatus: TaskRunExecutionStatus[] = [\"QUEUED\", \"SUSPENDED\"];\n-        const deprecatedSnapshots = previousSnapshots.filter((snap) =>\n-          deprecatedStatus.includes(snap.snapshot.executionStatus)\n-        );\n+        const deprecatedSnapshots = previousSnapshots.filter((snap) => {\n+          const isDeprecated = deprecatedStatus.includes(snap.snapshot.executionStatus);\n+          const previouslySeen = this.seenDeprecatedSnapshotIds.some(\n+            (s) => s === snap.snapshot.friendlyId\n+          );\n+          return isDeprecated && !previouslySeen;\n+        });\n \n         let deprecated = false;\n         if (deprecatedSnapshots.length > 0) {\n@@ -298,6 +306,18 @@ export class SnapshotManager {\n           } else {\n             deprecated = true;\n           }\n+\n+          // Add the deprecated snapshot IDs to the seen list\n+          this.seenDeprecatedSnapshotIds.push(\n+            ...deprecatedSnapshots.map((s) => s.snapshot.friendlyId)\n+          );\n+\n+          if (this.seenDeprecatedSnapshotIds.length > this.maxSeenDeprecatedSnapshotIds) {\n+            // Only keep the latest maxSeenDeprecatedSnapshotIds\n+            this.seenDeprecatedSnapshotIds = this.seenDeprecatedSnapshotIds.slice(\n+              -this.maxSeenDeprecatedSnapshotIds\n+            );\n+          }\n         }\n \n         const { snapshot } = latestSnapshot;\ndiff --git a/packages/core/src/v3/runEngineWorker/workload/http.ts b/packages/core/src/v3/runEngineWorker/workload/http.ts\nindex 57c7f06e35..93fa7bf03c 100644\n--- a/packages/core/src/v3/runEngineWorker/workload/http.ts\n+++ b/packages/core/src/v3/runEngineWorker/workload/http.ts\n@@ -52,18 +52,58 @@ export class WorkloadHttpClient {\n     });\n   }\n \n+  private isConnectionError(error: string): boolean {\n+    const connectionErrors = [\n+      \"Connection error\",\n+      \"ECONNREFUSED\",\n+      \"ETIMEDOUT\",\n+      \"ENOTFOUND\",\n+      \"ECONNRESET\",\n+      \"EHOSTUNREACH\",\n+      \"ENETUNREACH\",\n+      \"EPIPE\",\n+      \"ECONNABORTED\",\n+    ];\n+    return connectionErrors.some((errType) => error.includes(errType));\n+  }\n+\n+  private async withConnectionErrorDetection<T>(\n+    operation: () => Promise<{ success: true; data: T } | { success: false; error: string }>\n+  ): Promise<\n+    { success: true; data: T } | { success: false; error: string; isConnectionError?: boolean }\n+  > {\n+    const result = await operation();\n+\n+    if (result.success) {\n+      return result;\n+    }\n+\n+    // Check if this is a connection error\n+    if (this.isConnectionError(result.error)) {\n+      return {\n+        ...result,\n+        isConnectionError: true,\n+      };\n+    }\n+\n+    return result;\n+  }\n+\n   async heartbeatRun(runId: string, snapshotId: string, body?: WorkloadHeartbeatRequestBody) {\n-    return wrapZodFetch(\n-      WorkloadHeartbeatResponseBody,\n-      `${this.apiUrl}/api/v1/workload-actions/runs/${runId}/snapshots/${snapshotId}/heartbeat`,\n-      {\n-        method: \"POST\",\n-        headers: {\n-          ...this.defaultHeaders(),\n-          \"Content-Type\": \"application/json\",\n-        },\n-        body: JSON.stringify(body ?? {}),\n-      }\n+    return this.withConnectionErrorDetection(() =>\n+      wrapZodFetch(\n+        WorkloadHeartbeatResponseBody,\n+        `${this.apiUrl}/api/v1/workload-actions/runs/${runId}/snapshots/${snapshotId}/heartbeat`,\n+        {\n+          method: \"POST\",\n+          headers: {\n+            ...this.defaultHeaders(),\n+            \"Content-Type\": \"application/json\",\n+          },\n+          body: JSON.stringify(body ?? {}),\n+          signal: AbortSignal.timeout(10_000), // 10 second timeout\n+        }\n+      )\n     );\n   }\n \n@@ -81,15 +121,17 @@ export class WorkloadHttpClient {\n   }\n \n   async continueRunExecution(runId: string, snapshotId: string) {\n-    return wrapZodFetch(\n-      WorkloadContinueRunExecutionResponseBody,\n-      `${this.apiUrl}/api/v1/workload-actions/runs/${runId}/snapshots/${snapshotId}/continue`,\n-      {\n-        method: \"GET\",\n-        headers: {\n-          ...this.defaultHeaders(),\n-        },\n-      }\n+    return this.withConnectionErrorDetection(() =>\n+      wrapZodFetch(\n+        WorkloadContinueRunExecutionResponseBody,\n+        `${this.apiUrl}/api/v1/workload-actions/runs/${runId}/snapshots/${snapshotId}/continue`,\n+        {\n+          method: \"GET\",\n+          headers: {\n+            ...this.defaultHeaders(),\n+          },\n+        }\n+      )\n     );\n   }\n \n@@ -130,15 +172,18 @@ export class WorkloadHttpClient {\n   }\n \n   async getSnapshotsSince(runId: string, snapshotId: string) {\n-    return wrapZodFetch(\n-      WorkloadRunSnapshotsSinceResponseBody,\n-      `${this.apiUrl}/api/v1/workload-actions/runs/${runId}/snapshots/since/${snapshotId}`,\n-      {\n-        method: \"GET\",\n-        headers: {\n-          ...this.defaultHeaders(),\n-        },\n-      }\n+    return this.withConnectionErrorDetection(() =>\n+      wrapZodFetch(\n+        WorkloadRunSnapshotsSinceResponseBody,\n+        `${this.apiUrl}/api/v1/workload-actions/runs/${runId}/snapshots/since/${snapshotId}`,\n+        {\n+          method: \"GET\",\n+          headers: {\n+            ...this.defaultHeaders(),\n+          },\n+          signal: AbortSignal.timeout(10_000), // 10 second timeout\n+        }\n+      )\n     );\n   }\n \n",
    "test_patch": "",
    "problem_statement": "",
    "hints_text": "",
    "pr_mirror": "triggerdotdev__trigger.dev.d1c3bfb9",
    "bug_patch": "diff --git a/apps/supervisor/src/workloadServer/index.ts b/apps/supervisor/src/workloadServer/index.ts\nindex 35d53d3..0c9f83c 100644\n--- a/apps/supervisor/src/workloadServer/index.ts\n+++ b/apps/supervisor/src/workloadServer/index.ts\n@@ -125,7 +125,7 @@ export class WorkloadServer extends EventEmitter<WorkloadServerEvents> {\n   }\n \n   private createHttpServer({ host, port }: { host: string; port: number }) {\n-    const httpServer = new HttpServer({\n+    return new HttpServer({\n       port,\n       host,\n       metrics: {\n@@ -346,6 +346,23 @@ export class WorkloadServer extends EventEmitter<WorkloadServerEvents> {\n           },\n         }\n       )\n+      .route(\"/api/v1/workload-actions/runs/:runFriendlyId/logs/debug\", \"POST\", {\n+        paramsSchema: WorkloadActionParams.pick({ runFriendlyId: true }),\n+        bodySchema: WorkloadDebugLogRequestBody,\n+        handler: async ({ req, reply, params, body }) => {\n+          reply.empty(204);\n+\n+          if (!env.SEND_RUN_DEBUG_LOGS) {\n+            return;\n+          }\n+\n+          await this.workerClient.sendDebugLog(\n+            params.runFriendlyId,\n+            body,\n+            this.runnerIdFromRequest(req)\n+          );\n+        },\n+      })\n       .route(\"/api/v1/workload-actions/deployments/:deploymentId/dequeue\", \"GET\", {\n         paramsSchema: z.object({\n           deploymentId: z.string(),\n@@ -370,31 +387,6 @@ export class WorkloadServer extends EventEmitter<WorkloadServerEvents> {\n           reply.json(dequeueResponse.data satisfies WorkloadDequeueFromVersionResponseBody);\n         },\n       });\n-\n-    if (env.SEND_RUN_DEBUG_LOGS) {\n-      httpServer.route(\"/api/v1/workload-actions/runs/:runFriendlyId/logs/debug\", \"POST\", {\n-        paramsSchema: WorkloadActionParams.pick({ runFriendlyId: true }),\n-        bodySchema: WorkloadDebugLogRequestBody,\n-        handler: async ({ req, reply, params, body }) => {\n-          reply.empty(204);\n-\n-          await this.workerClient.sendDebugLog(\n-            params.runFriendlyId,\n-            body,\n-            this.runnerIdFromRequest(req)\n-          );\n-        },\n-      });\n-    } else {\n-      // Lightweight mock route without schemas\n-      httpServer.route(\"/api/v1/workload-actions/runs/:runFriendlyId/logs/debug\", \"POST\", {\n-        handler: async ({ reply }) => {\n-          reply.empty(204);\n-        },\n-      });\n-    }\n-\n-    return httpServer;\n   }\n \n   private createWebsocketServer() {\n@@ -479,120 +471,4 @@ export class WorkloadServer extends EventEmitter<WorkloadServerEvents> {\n \n         this.runSockets.set(friendlyId, socket);\n         this.emit(\"runConnected\", { run: { friendlyId } });\n-        socket.data.runFriendlyId = friendlyId;\n-      };\n-\n-      const runDisconnected = (friendlyId: string) => {\n-        socketLogger.debug(\"runDisconnected\", { ...getSocketMetadata() });\n-\n-        this.runSockets.delete(friendlyId);\n-        this.emit(\"runDisconnected\", { run: { friendlyId } });\n-        socket.data.runFriendlyId = undefined;\n-      };\n-\n-      socketLogger.log(\"wsServer socket connected\", { ...getSocketMetadata() });\n-\n-      // FIXME: where does this get set?\n-      if (socket.data.runFriendlyId) {\n-        runConnected(socket.data.runFriendlyId);\n-      }\n-\n-      socket.on(\"disconnecting\", (reason, description) => {\n-        socketLogger.log(\"Socket disconnecting\", { ...getSocketMetadata(), reason, description });\n-\n-        if (socket.data.runFriendlyId) {\n-          runDisconnected(socket.data.runFriendlyId);\n-        }\n-      });\n-\n-      socket.on(\"disconnect\", (reason, description) => {\n-        socketLogger.log(\"Socket disconnected\", { ...getSocketMetadata(), reason, description });\n-      });\n-\n-      socket.on(\"error\", (error) => {\n-        socketLogger.error(\"Socket error\", {\n-          ...getSocketMetadata(),\n-          error: {\n-            name: error.name,\n-            message: error.message,\n-            stack: error.stack,\n-          },\n-        });\n-      });\n-\n-      socket.on(\"run:start\", async (message) => {\n-        const log = socketLogger.child({\n-          eventName: \"run:start\",\n-          ...getSocketMetadata(),\n-          ...message,\n-        });\n-\n-        log.log(\"Handling run:start\");\n-\n-        try {\n-          runConnected(message.run.friendlyId);\n-        } catch (error) {\n-          log.error(\"run:start error\", { error });\n-        }\n-      });\n-\n-      socket.on(\"run:stop\", async (message) => {\n-        const log = socketLogger.child({\n-          eventName: \"run:stop\",\n-          ...getSocketMetadata(),\n-          ...message,\n-        });\n-\n-        log.log(\"Handling run:stop\");\n-\n-        try {\n-          runDisconnected(message.run.friendlyId);\n-        } catch (error) {\n-          log.error(\"run:stop error\", { error });\n-        }\n-      });\n-    });\n-\n-    return websocketServer;\n-  }\n-\n-  notifyRun({ run }: { run: { friendlyId: string } }) {\n-    try {\n-      const runSocket = this.runSockets.get(run.friendlyId);\n-\n-      if (!runSocket) {\n-        this.logger.debug(\"notifyRun: Run socket not found\", { run });\n-\n-        this.workerClient.sendDebugLog(run.friendlyId, {\n-          time: new Date(),\n-          message: \"run:notify socket not found on supervisor\",\n-        });\n-\n-        return;\n-      }\n-\n-      runSocket.emit(\"run:notify\", { version: \"1\", run });\n-      this.logger.debug(\"run:notify sent\", { run });\n-\n-      this.workerClient.sendDebugLog(run.friendlyId, {\n-        time: new Date(),\n-        message: \"run:notify supervisor -> runner\",\n-      });\n-    } catch (error) {\n-      this.logger.error(\"Error in notifyRun\", { run, error });\n-\n-      this.workerClient.sendDebugLog(run.friendlyId, {\n-        time: new Date(),\n-        message: \"run:notify error on supervisor\",\n-      });\n-    }\n-  }\n-\n-  async start() {\n-    await this.httpServer.start();\n-  }\n-\n-  async stop() {\n-    await this.httpServer.stop();\n-  }\n-}\n+        socket.\n\\ No newline at end of file\ndiff --git a/packages/cli-v3/src/entryPoints/managed/controller.ts b/packages/cli-v3/src/entryPoints/managed/controller.ts\nindex 54f0dba..330c776 100644\n--- a/packages/cli-v3/src/entryPoints/managed/controller.ts\n+++ b/packages/cli-v3/src/entryPoints/managed/controller.ts\n@@ -449,195 +449,4 @@ export class ManagedRunController {\n     this.currentExecution?.kill().catch(() => {});\n     this.taskRunProcessProvider.cleanup().catch(() => {});\n \n-    process.exit(code);\n-  }\n-\n-  createSupervisorSocket(): SupervisorSocket {\n-    const wsUrl = new URL(\"/workload\", this.workerApiUrl);\n-\n-    const socket: SupervisorSocket = io(wsUrl.href, {\n-      transports: [\"websocket\"],\n-      extraHeaders: {\n-        [WORKLOAD_HEADERS.DEPLOYMENT_ID]: this.env.TRIGGER_DEPLOYMENT_ID,\n-        [WORKLOAD_HEADERS.RUNNER_ID]: this.env.TRIGGER_RUNNER_ID,\n-      },\n-    });\n-\n-    socket.on(\"connect\", () => {\n-      this.sendDebugLog({\n-        runId: this.runFriendlyId,\n-        message: \"Socket connected to supervisor\",\n-      });\n-    });\n-\n-    socket.on(\"connect_error\", (error) => {\n-      this.sendDebugLog({\n-        runId: this.runFriendlyId,\n-        message: \"Socket connection error\",\n-        properties: { error: error instanceof Error ? error.message : String(error) },\n-      });\n-    });\n-\n-    socket.on(\"disconnect\", async (reason, description) => {\n-      const parseDescription = ():\n-        | {\n-            description: string;\n-            context?: string;\n-          }\n-        | undefined => {\n-        if (!description) {\n-          return undefined;\n-        }\n-\n-        if (description instanceof Error) {\n-          return {\n-            description: description.toString(),\n-          };\n-        }\n-\n-        return {\n-          description: description.description,\n-          context: description.context ? String(description.context) : undefined,\n-        };\n-      };\n-\n-      if (this.currentExecution) {\n-        const currentEnv = {\n-          workerInstanceName: this.env.TRIGGER_WORKER_INSTANCE_NAME,\n-          runnerId: this.env.TRIGGER_RUNNER_ID,\n-          supervisorApiUrl: this.env.TRIGGER_SUPERVISOR_API_URL,\n-        };\n-\n-        const result = await this.currentExecution.processEnvOverrides(\"socket disconnected\", true);\n-\n-        const newEnv = {\n-          workerInstanceName: this.env.TRIGGER_WORKER_INSTANCE_NAME,\n-          runnerId: this.env.TRIGGER_RUNNER_ID,\n-          supervisorApiUrl: this.env.TRIGGER_SUPERVISOR_API_URL,\n-        };\n-\n-        this.sendDebugLog({\n-          runId: this.runFriendlyId,\n-          message: \"Socket disconnected from supervisor - processed env overrides\",\n-          properties: { reason, ...parseDescription(), currentEnv, newEnv },\n-        });\n-\n-        if (!result) {\n-          return;\n-        }\n-\n-        // If runner ID changed, we detected a restore\n-        if (result.runnerIdChanged) {\n-          this.sendDebugLog({\n-            runId: this.runFriendlyId,\n-            message: \"Runner ID changed - restore detected\",\n-            properties: {\n-              supervisorChanged: result.supervisorChanged,\n-            },\n-          });\n-\n-          if (!result.supervisorChanged) {\n-            return;\n-          }\n-\n-          // Only reconnect WebSocket if supervisor URL actually changed\n-          this.sendDebugLog({\n-            runId: this.runFriendlyId,\n-            message: \"Supervisor URL changed - creating new socket connection\",\n-          });\n-\n-          // First disconnect the old socket to avoid conflicts\n-          socket.removeAllListeners();\n-          socket.disconnect();\n-\n-          // Create a new socket with the updated URL and headers\n-          this.socket = this.createSupervisorSocket();\n-\n-          // Re-subscribe to notifications if we have an active execution\n-          if (this.runFriendlyId && this.snapshotFriendlyId) {\n-            this.subscribeToRunNotifications(this.runFriendlyId, this.snapshotFriendlyId);\n-          }\n-        }\n-\n-        return;\n-      }\n-\n-      this.sendDebugLog({\n-        runId: this.runFriendlyId,\n-        message: \"Socket disconnected from supervisor\",\n-        properties: { reason, ...parseDescription() },\n-      });\n-    });\n-\n-    return socket;\n-  }\n-\n-  start() {\n-    this.sendDebugLog({\n-      runId: this.runFriendlyId,\n-      message: \"Starting up\",\n-    });\n-\n-    // If we have run and snapshot IDs, we can start an attempt immediately\n-    if (this.env.TRIGGER_RUN_ID && this.env.TRIGGER_SNAPSHOT_ID) {\n-      this.startRunExecution({\n-        runFriendlyId: this.env.TRIGGER_RUN_ID,\n-        snapshotFriendlyId: this.env.TRIGGER_SNAPSHOT_ID,\n-        dequeuedAt: this.env.TRIGGER_DEQUEUED_AT_MS,\n-        podScheduledAt: this.env.TRIGGER_POD_SCHEDULED_AT_MS,\n-      }).finally(() => {});\n-      return;\n-    }\n-\n-    // ..otherwise we need to wait for a run\n-    this.waitForNextRun();\n-    return;\n-  }\n-\n-  async cancelRunsAndExitProcess() {\n-    this.sendDebugLog({\n-      runId: this.runFriendlyId,\n-      message: \"Shutting down\",\n-    });\n-\n-    // Cancel the current execution\n-    const [error] = await tryCatch(this.currentExecution?.cancel());\n-\n-    if (error) {\n-      this.sendDebugLog({\n-        runId: this.runFriendlyId,\n-        message: \"Error during shutdown\",\n-        properties: { error: String(error) },\n-      });\n-    }\n-\n-    // Cleanup the task run process provider\n-    const [cleanupError] = await tryCatch(this.taskRunProcessProvider.cleanup());\n-\n-    if (cleanupError) {\n-      this.sendDebugLog({\n-        runId: this.runFriendlyId,\n-        message: \"Error during task run process provider cleanup\",\n-        properties: { error: String(cleanupError) },\n-      });\n-    }\n-\n-    // Close the socket\n-    this.socket.close();\n-\n-    // Exit the process\n-    this.exitProcess(this.successExitCode);\n-  }\n-\n-  sendDebugLog(opts: SendDebugLogOptions) {\n-    this.logger.sendDebugLog({\n-      ...opts,\n-      message: `[controller] ${opts.message}`,\n-      properties: {\n-        ...opts.properties,\n-        runnerWarmStartCount: this.warmStartCount,\n-        runnerRestoreCount: this.restoreCount,\n-      },\n-    });\n-  }\n-}\n+    process\n\\ No newline at end of file\ndiff --git a/packages/cli-v3/src/entryPoints/managed/execution.ts b/packages/cli-v3/src/entryPoints/managed/execution.ts\nindex 2dd3e68..49e26f5 100644\n--- a/packages/cli-v3/src/entryPoints/managed/execution.ts\n+++ b/packages/cli-v3/src/entryPoints/managed/execution.ts\n@@ -436,830 +436,4 @@ export class RunExecution {\n       this.sendDebugLog(\"error: invalid attempt number returned from start attempt\", {\n         attemptNumber: String(attemptNumber),\n       });\n-    }\n-\n-    const metrics = this.measureExecutionMetrics({\n-      attemptCreatedAt: attemptStartedAt,\n-      dequeuedAt: this.dequeuedAt?.getTime(),\n-      podScheduledAt: this.podScheduledAt?.getTime(),\n-    });\n-\n-    this.sendDebugLog(\"started attempt\", { start: start.data });\n-\n-    return { ...start.data, metrics };\n-  }\n-\n-  /**\n-   * Executes the run. This will return when the execution is complete and we should warm start.\n-   * When this returns, the child process will have been cleaned up.\n-   */\n-  public async execute(runOpts: RunExecutionRunOptions): Promise<void> {\n-    if (this.isShuttingDown) {\n-      throw new Error(\"execute called after execution shut down\");\n-    }\n-\n-    // Setup initial state\n-    this.runFriendlyId = runOpts.runFriendlyId;\n-\n-    // Create snapshot manager\n-    this.snapshotManager = new SnapshotManager({\n-      runFriendlyId: runOpts.runFriendlyId,\n-      runnerId: this.env.TRIGGER_RUNNER_ID,\n-      initialSnapshotId: runOpts.snapshotFriendlyId,\n-      // We're just guessing here, but \"PENDING_EXECUTING\" is probably fine\n-      initialStatus: \"PENDING_EXECUTING\",\n-      logger: this.logger,\n-      metadataClient: this.metadataClient,\n-      onSnapshotChange: this.processSnapshotChange.bind(this),\n-      onSuspendable: this.handleSuspendable.bind(this),\n-    });\n-\n-    this.dequeuedAt = runOpts.dequeuedAt;\n-    this.podScheduledAt = runOpts.podScheduledAt;\n-\n-    // Create and start services\n-    this.snapshotPoller = new RunExecutionSnapshotPoller({\n-      runFriendlyId: this.runFriendlyId,\n-      snapshotFriendlyId: this.snapshotManager.snapshotId,\n-      logger: this.logger,\n-      snapshotPollIntervalSeconds: this.env.TRIGGER_SNAPSHOT_POLL_INTERVAL_SECONDS,\n-      onPoll: this.fetchAndProcessSnapshotChanges.bind(this),\n-    }).start();\n-\n-    this.notifier = new RunNotifier({\n-      runFriendlyId: this.runFriendlyId,\n-      supervisorSocket: this.supervisorSocket,\n-      onNotify: this.fetchAndProcessSnapshotChanges.bind(this),\n-      logger: this.logger,\n-    }).start();\n-\n-    const [startError, start] = await tryCatch(\n-      this.startAttempt({ isWarmStart: runOpts.isWarmStart })\n-    );\n-\n-    if (startError) {\n-      this.sendDebugLog(\"failed to start attempt\", { error: startError.message });\n-\n-      this.shutdownExecution(\"failed to start attempt\");\n-      return;\n-    }\n-\n-    const [executeError] = await tryCatch(\n-      this.executeRunWrapper({ ...start, isWarmStart: runOpts.isWarmStart })\n-    );\n-\n-    if (executeError) {\n-      this.sendDebugLog(\"failed to execute run\", { error: executeError.message });\n-\n-      this.shutdownExecution(\"failed to execute run\");\n-      return;\n-    }\n-\n-    // This is here for safety, but it\n-    this.shutdownExecution(\"execute call finished\");\n-  }\n-\n-  private async executeRunWrapper({\n-    run,\n-    snapshot,\n-    envVars,\n-    execution,\n-    metrics,\n-    isWarmStart,\n-    isImmediateRetry,\n-  }: WorkloadRunAttemptStartResponseBody & {\n-    metrics: TaskRunExecutionMetrics;\n-    isWarmStart?: boolean;\n-    isImmediateRetry?: boolean;\n-  }) {\n-    this.currentTaskRunEnv = envVars;\n-\n-    const [executeError] = await tryCatch(\n-      this.executeRun({\n-        run,\n-        snapshot,\n-        envVars,\n-        execution,\n-        metrics,\n-        isWarmStart,\n-        isImmediateRetry,\n-      })\n-    );\n-\n-    if (!executeError) {\n-      return;\n-    }\n-\n-    if (executeError instanceof SuspendedProcessError) {\n-      this.sendDebugLog(\"execution was suspended\", {\n-        run: run.friendlyId,\n-        snapshot: snapshot.friendlyId,\n-        error: executeError.message,\n-      });\n-\n-      return;\n-    }\n-\n-    if (executeError instanceof ExecutionAbortError) {\n-      this.sendDebugLog(\"execution was aborted\", {\n-        run: run.friendlyId,\n-        snapshot: snapshot.friendlyId,\n-        error: executeError.message,\n-      });\n-\n-      return;\n-    }\n-\n-    this.sendDebugLog(\"error while executing attempt\", {\n-      error: executeError.message,\n-      runId: run.friendlyId,\n-      snapshotId: snapshot.friendlyId,\n-    });\n-\n-    const completion = {\n-      id: execution.run.id,\n-      ok: false,\n-      retry: undefined,\n-      error: TaskRunProcess.parseExecuteError(executeError),\n-    } satisfies TaskRunFailedExecutionResult;\n-\n-    const [completeError] = await tryCatch(this.complete({ completion }));\n-\n-    if (completeError) {\n-      this.sendDebugLog(\"failed to complete run\", { error: completeError.message });\n-    }\n-  }\n-\n-  private async executeRun({\n-    run,\n-    snapshot,\n-    envVars,\n-    execution,\n-    metrics,\n-    isWarmStart,\n-    isImmediateRetry,\n-  }: WorkloadRunAttemptStartResponseBody & {\n-    metrics: TaskRunExecutionMetrics;\n-    isWarmStart?: boolean;\n-    isImmediateRetry?: boolean;\n-  }) {\n-    if (isImmediateRetry) {\n-      await this.taskRunProcessProvider.handleImmediateRetry();\n-    }\n-\n-    const taskRunEnv = this.currentTaskRunEnv ?? envVars;\n-\n-    if (!this.taskRunProcess || this.taskRunProcess.isBeingKilled) {\n-      this.sendDebugLog(\"getting new task run process\", { runId: execution.run.id });\n-      this.taskRunProcess = await this.taskRunProcessProvider.getProcess({\n-        taskRunEnv: { ...taskRunEnv, TRIGGER_PROJECT_REF: execution.project.ref },\n-        isWarmStart,\n-      });\n-    } else {\n-      this.sendDebugLog(\"using prepared task run process\", { runId: execution.run.id });\n-    }\n-\n-    this.attachTaskRunProcessHandlers(this.taskRunProcess);\n-\n-    this.sendDebugLog(\"executing task run process\", { runId: execution.run.id });\n-\n-    const abortHandler = async () => {\n-      this.sendDebugLog(\"execution aborted during task run, cleaning up process\", {\n-        runId: execution.run.id,\n-      });\n-\n-      if (this.taskRunProcess) {\n-        await this.taskRunProcessProvider.handleProcessAbort(this.taskRunProcess);\n-      }\n-    };\n-\n-    // Set up an abort handler that will cleanup the task run process\n-    this.executionAbortController.signal.addEventListener(\"abort\", abortHandler);\n-\n-    const completion = await this.taskRunProcess.execute(\n-      {\n-        payload: {\n-          execution,\n-          traceContext: execution.run.traceContext ?? {},\n-          metrics,\n-        },\n-        messageId: run.friendlyId,\n-        env: envVars,\n-      },\n-      isWarmStart\n-    );\n-\n-    this.executionAbortController.signal.removeEventListener(\"abort\", abortHandler);\n-\n-    // If we get here, the task completed normally\n-    this.sendDebugLog(\"completed run attempt\", { attemptSuccess: completion.ok });\n-\n-    // Return the process to the provider - this handles all cleanup logic\n-    const [returnError] = await tryCatch(\n-      this.taskRunProcessProvider.returnProcess(this.taskRunProcess)\n-    );\n-\n-    if (returnError) {\n-      this.sendDebugLog(\"failed to return task run process, submitting completion anyway\", {\n-        error: returnError.message,\n-      });\n-    }\n-\n-    const [completionError] = await tryCatch(this.complete({ completion }));\n-\n-    if (completionError) {\n-      this.sendDebugLog(\"failed to complete run\", { error: completionError.message });\n-    }\n-  }\n-\n-  private async complete({ completion }: { completion: TaskRunExecutionResult }): Promise<void> {\n-    if (!this.runFriendlyId || !this.snapshotManager) {\n-      throw new Error(\"cannot complete run: missing run or snapshot manager\");\n-    }\n-\n-    this.isCompletingRun = true;\n-\n-    const completionResult = await this.httpClient.completeRunAttempt(\n-      this.runFriendlyId,\n-      this.snapshotManager.snapshotId,\n-      { completion }\n-    );\n-\n-    if (!completionResult.success) {\n-      throw new Error(`failed to submit completion: ${completionResult.error}`);\n-    }\n-\n-    await this.handleCompletionResult({\n-      completion,\n-      result: completionResult.data.result,\n-    });\n-  }\n-\n-  private async handleCompletionResult({\n-    completion,\n-    result,\n-  }: {\n-    completion: TaskRunExecutionResult;\n-    result: CompleteRunAttemptResult;\n-  }) {\n-    this.sendDebugLog(`completion result: ${result.attemptStatus}`, {\n-      attemptSuccess: completion.ok,\n-      attemptStatus: result.attemptStatus,\n-      snapshotId: result.snapshot.friendlyId,\n-      runId: result.run.friendlyId,\n-    });\n-\n-    const snapshotStatus = this.convertAttemptStatusToSnapshotStatus(result.attemptStatus);\n-\n-    // Update our snapshot ID to match the completion result to ensure any subsequent API calls use the correct snapshot\n-    this.updateSnapshotAfterCompletion(result.snapshot.friendlyId, snapshotStatus);\n-\n-    const { attemptStatus } = result;\n-\n-    switch (attemptStatus) {\n-      case \"RUN_FINISHED\":\n-      case \"RUN_PENDING_CANCEL\":\n-      case \"RETRY_QUEUED\": {\n-        return;\n-      }\n-      case \"RETRY_IMMEDIATELY\": {\n-        if (attemptStatus !== \"RETRY_IMMEDIATELY\") {\n-          return;\n-        }\n-\n-        if (completion.ok) {\n-          throw new Error(\"Should retry but completion OK.\");\n-        }\n-\n-        if (!completion.retry) {\n-          throw new Error(\"Should retry but missing retry params.\");\n-        }\n-\n-        await this.retryImmediately({ retryOpts: completion.retry });\n-        return;\n-      }\n-      default: {\n-        assertExhaustive(attemptStatus);\n-      }\n-    }\n-  }\n-\n-  private updateSnapshotAfterCompletion(snapshotId: string, status: TaskRunExecutionStatus) {\n-    this.snapshotManager?.updateSnapshot(snapshotId, status);\n-    this.snapshotPoller?.updateSnapshotId(snapshotId);\n-  }\n-\n-  private convertAttemptStatusToSnapshotStatus(\n-    attemptStatus: CompleteRunAttemptResult[\"attemptStatus\"]\n-  ): TaskRunExecutionStatus {\n-    switch (attemptStatus) {\n-      case \"RUN_FINISHED\":\n-        return \"FINISHED\";\n-      case \"RUN_PENDING_CANCEL\":\n-        return \"PENDING_CANCEL\";\n-      case \"RETRY_QUEUED\":\n-        return \"QUEUED\";\n-      case \"RETRY_IMMEDIATELY\":\n-        return \"EXECUTING\";\n-      default:\n-        assertExhaustive(attemptStatus);\n-    }\n-  }\n-\n-  private measureExecutionMetrics({\n-    attemptCreatedAt,\n-    dequeuedAt,\n-    podScheduledAt,\n-  }: {\n-    attemptCreatedAt: number;\n-    dequeuedAt?: number;\n-    podScheduledAt?: number;\n-  }): TaskRunExecutionMetrics {\n-    const metrics: TaskRunExecutionMetrics = [\n-      {\n-        name: \"start\",\n-        event: \"create_attempt\",\n-        timestamp: attemptCreatedAt,\n-        duration: Date.now() - attemptCreatedAt,\n-      },\n-    ];\n-\n-    if (dequeuedAt) {\n-      metrics.push({\n-        name: \"start\",\n-        event: \"dequeue\",\n-        timestamp: dequeuedAt,\n-        duration: 0,\n-      });\n-    }\n-\n-    if (podScheduledAt) {\n-      metrics.push({\n-        name: \"start\",\n-        event: \"pod_scheduled\",\n-        timestamp: podScheduledAt,\n-        duration: 0,\n-      });\n-    }\n-\n-    return metrics;\n-  }\n-\n-  private async retryImmediately({ retryOpts }: { retryOpts: TaskRunExecutionRetry }) {\n-    this.sendDebugLog(\"retrying run immediately\", {\n-      timestamp: retryOpts.timestamp,\n-      delay: retryOpts.delay,\n-    });\n-\n-    const delay = retryOpts.timestamp - Date.now();\n-\n-    if (delay > 0) {\n-      // Wait for retry delay to pass\n-      await sleep(delay);\n-    }\n-\n-    // Start and execute next attempt\n-    const [startError, start] = await tryCatch(\n-      this.enableIgnoreSnapshotChanges(() => this.startAttempt({ isWarmStart: true }))\n-    );\n-\n-    if (startError) {\n-      this.sendDebugLog(\"failed to start attempt for retry\", { error: startError.message });\n-\n-      this.shutdownExecution(\"retryImmediately: failed to start attempt\");\n-      return;\n-    }\n-\n-    const [executeError] = await tryCatch(\n-      this.executeRunWrapper({ ...start, isWarmStart: true, isImmediateRetry: true })\n-    );\n-\n-    if (executeError) {\n-      this.sendDebugLog(\"failed to execute run for retry\", { error: executeError.message });\n-\n-      this.shutdownExecution(\"retryImmediately: failed to execute run\");\n-      return;\n-    }\n-  }\n-\n-  private async enableIgnoreSnapshotChanges<T>(fn: () => Promise<T>): Promise<T> {\n-    this.ignoreSnapshotChanges = true;\n-    try {\n-      return await fn();\n-    } finally {\n-      this.ignoreSnapshotChanges = false;\n-    }\n-  }\n-\n-  /**\n-   * Restores a suspended execution from PENDING_EXECUTING\n-   */\n-  private async restore(): Promise<void> {\n-    this.sendDebugLog(\"restoring execution\");\n-\n-    if (!this.runFriendlyId || !this.snapshotManager) {\n-      throw new Error(\"Cannot restore: missing run or snapshot manager\");\n-    }\n-\n-    // Short delay to give websocket time to reconnect\n-    await sleep(100);\n-\n-    // Process any env overrides\n-    await this.processEnvOverrides(\"restore\");\n-\n-    const continuationResult = await this.httpClient.continueRunExecution(\n-      this.runFriendlyId,\n-      this.snapshotManager.snapshotId\n-    );\n-\n-    if (!continuationResult.success) {\n-      // Check if we need to refresh metadata due to connection error\n-      if (continuationResult.isConnectionError) {\n-        this.sendDebugLog(\"restore: connection error detected, refreshing metadata\");\n-        await this.processEnvOverrides(\"restore connection error\");\n-\n-        // Retry the continuation after refreshing metadata\n-        const retryResult = await this.httpClient.continueRunExecution(\n-          this.runFriendlyId,\n-          this.snapshotManager.snapshotId\n-        );\n-\n-        if (!retryResult.success) {\n-          throw new Error(retryResult.error);\n-        }\n-      } else {\n-        throw new Error(continuationResult.error);\n-      }\n-    }\n-\n-    // Track restore count\n-    this.restoreCount++;\n-  }\n-\n-  private async exitTaskRunProcessWithoutFailingRun({\n-    flush,\n-    reason,\n-  }: {\n-    flush: boolean;\n-    reason: string;\n-  }) {\n-    await this.taskRunProcessProvider.suspendProcess(flush, this.taskRunProcess);\n-\n-    // No services should be left running after this line - let's make sure of it\n-    this.shutdownExecution(`exitTaskRunProcessWithoutFailingRun: ${reason}`);\n-  }\n-\n-  /**\n-   * Processes env overrides from the metadata service. Generally called when we're resuming from a suspended state.\n-   */\n-  public async processEnvOverrides(\n-    reason?: string,\n-    shouldPollForSnapshotChanges?: boolean\n-  ): Promise<{\n-    overrides: Metadata;\n-    runnerIdChanged?: boolean;\n-    supervisorChanged?: boolean;\n-  } | null> {\n-    if (!this.metadataClient) {\n-      return null;\n-    }\n-\n-    const previousRunnerId = this.env.TRIGGER_RUNNER_ID;\n-    const previousSupervisorUrl = this.env.TRIGGER_SUPERVISOR_API_URL;\n-\n-    const [error, overrides] = await this.metadataClient.getEnvOverrides();\n-\n-    if (error) {\n-      this.sendDebugLog(\"[override] failed to fetch\", {\n-        reason,\n-        error: error.message,\n-      });\n-      return null;\n-    }\n-\n-    if (overrides.TRIGGER_RUN_ID && overrides.TRIGGER_RUN_ID !== this.runFriendlyId) {\n-      this.sendDebugLog(\"[override] run ID mismatch, ignoring overrides\", {\n-        reason,\n-        currentRunId: this.runFriendlyId,\n-        incomingRunId: overrides.TRIGGER_RUN_ID,\n-      });\n-      return null;\n-    }\n-\n-    this.sendDebugLog(`[override] processing: ${reason}`, {\n-      overrides,\n-      currentEnv: this.env.raw,\n-    });\n-\n-    // Override the env with the new values\n-    this.env.override(overrides);\n-\n-    // Check if runner ID changed\n-    const newRunnerId = this.env.TRIGGER_RUNNER_ID;\n-    const runnerIdChanged = previousRunnerId !== newRunnerId;\n-\n-    // Check if supervisor URL changed\n-    const newSupervisorUrl = this.env.TRIGGER_SUPERVISOR_API_URL;\n-    const supervisorChanged = previousSupervisorUrl !== newSupervisorUrl;\n-\n-    // Update services with new values\n-    if (overrides.TRIGGER_SNAPSHOT_POLL_INTERVAL_SECONDS) {\n-      this.snapshotPoller?.updateInterval(this.env.TRIGGER_SNAPSHOT_POLL_INTERVAL_SECONDS * 1000);\n-    }\n-    if (\n-      overrides.TRIGGER_SUPERVISOR_API_PROTOCOL ||\n-      overrides.TRIGGER_SUPERVISOR_API_DOMAIN ||\n-      overrides.TRIGGER_SUPERVISOR_API_PORT\n-    ) {\n-      this.httpClient.updateApiUrl(this.env.TRIGGER_SUPERVISOR_API_URL);\n-    }\n-    if (overrides.TRIGGER_RUNNER_ID) {\n-      this.httpClient.updateRunnerId(this.env.TRIGGER_RUNNER_ID);\n-    }\n-\n-    // Poll for snapshot changes immediately\n-    if (shouldPollForSnapshotChanges) {\n-      this.sendDebugLog(\"[override] polling for snapshot changes\", { reason });\n-      this.fetchAndProcessSnapshotChanges(\"restore\").catch(() => {});\n-    }\n-\n-    return {\n-      overrides,\n-      runnerIdChanged,\n-      supervisorChanged,\n-    };\n-  }\n-\n-  private async onHeartbeat() {\n-    if (!this.runFriendlyId) {\n-      this.sendDebugLog(\"heartbeat: missing run ID\");\n-      return;\n-    }\n-\n-    if (!this.snapshotManager) {\n-      this.sendDebugLog(\"heartbeat: missing snapshot manager\");\n-      return;\n-    }\n-\n-    this.sendDebugLog(\"heartbeat\");\n-\n-    const response = await this.httpClient.heartbeatRun(\n-      this.runFriendlyId,\n-      this.snapshotManager.snapshotId\n-    );\n-\n-    if (!response.success) {\n-      this.sendDebugLog(\"heartbeat: failed\", { error: response.error });\n-\n-      // Check if we need to refresh metadata due to connection error\n-      if (response.isConnectionError) {\n-        this.sendDebugLog(\"heartbeat: connection error detected, refreshing metadata\");\n-        await this.processEnvOverrides(\"heartbeat connection error\");\n-      }\n-    }\n-\n-    this.lastHeartbeat = new Date();\n-  }\n-\n-  private sendDebugLog(\n-    message: string,\n-    properties?: SendDebugLogOptions[\"properties\"],\n-    runIdOverride?: string\n-  ) {\n-    this.logger.sendDebugLog({\n-      runId: runIdOverride ?? this.runFriendlyId,\n-      message: `[execution] ${message}`,\n-      properties: {\n-        ...properties,\n-        runId: this.runFriendlyId,\n-        snapshotId: this.currentSnapshotFriendlyId,\n-        executionId: this.id,\n-        executionRestoreCount: this.restoreCount,\n-        lastHeartbeat: this.lastHeartbeat?.toISOString(),\n-      },\n-    });\n-  }\n-\n-  private sendRuntimeDebugLog(\n-    message: string,\n-    properties?: SendDebugLogOptions[\"properties\"],\n-    runIdOverride?: string\n-  ) {\n-    this.logger.sendDebugLog({\n-      runId: runIdOverride ?? this.runFriendlyId,\n-      message: `[runtime] ${message}`,\n-      print: false,\n-      properties: {\n-        ...properties,\n-        runId: this.runFriendlyId,\n-        snapshotId: this.currentSnapshotFriendlyId,\n-        executionId: this.id,\n-        executionRestoreCount: this.restoreCount,\n-        lastHeartbeat: this.lastHeartbeat?.toISOString(),\n-      },\n-    });\n-  }\n-\n-  private set suspendable(suspendable: boolean) {\n-    this.snapshotManager?.setSuspendable(suspendable).catch((error) => {\n-      this.sendDebugLog(\"failed to set suspendable\", { error: error.message });\n-    });\n-  }\n-\n-  // Ensure we can only set this once\n-  private set runFriendlyId(id: string) {\n-    if (this._runFriendlyId) {\n-      throw new Error(\"Run ID already set\");\n-    }\n-\n-    this._runFriendlyId = id;\n-  }\n-\n-  public get runFriendlyId(): string | undefined {\n-    return this._runFriendlyId;\n-  }\n-\n-  public get currentSnapshotFriendlyId(): string | undefined {\n-    return this.snapshotManager?.snapshotId;\n-  }\n-\n-  public get taskRunEnv(): Record<string, string> | undefined {\n-    return this.currentTaskRunEnv;\n-  }\n-\n-  public get metrics() {\n-    return {\n-      execution: {\n-        restoreCount: this.restoreCount,\n-        lastHeartbeat: this.lastHeartbeat,\n-      },\n-      poller: this.snapshotPoller?.metrics,\n-      notifier: this.notifier?.metrics,\n-    };\n-  }\n-\n-  get isAborted() {\n-    return this.executionAbortController.signal.aborted;\n-  }\n-\n-  private abortExecution() {\n-    if (this.isAborted) {\n-      this.sendDebugLog(\"execution already aborted\");\n-      return;\n-    }\n-\n-    this.executionAbortController.abort();\n-    this.shutdownExecution(\"abortExecution\");\n-  }\n-\n-  private shutdownExecution(reason: string) {\n-    if (this.isShuttingDown) {\n-      this.sendDebugLog(`[shutdown] ${reason} (already shutting down)`, {\n-        firstShutdownReason: this.shutdownReason,\n-      });\n-      return;\n-    }\n-\n-    this.sendDebugLog(`[shutdown] ${reason}`);\n-\n-    this.isShuttingDown = true;\n-    this.shutdownReason = reason;\n-\n-    this.snapshotPoller?.stop();\n-    this.snapshotManager?.stop();\n-    this.notifier?.stop();\n-\n-    this.taskRunProcess?.unsafeDetachEvtHandlers();\n-  }\n-\n-  private async handleSuspendable(suspendableSnapshot: SnapshotState) {\n-    this.sendDebugLog(\"handleSuspendable\", { suspendableSnapshot });\n-\n-    if (!this.snapshotManager) {\n-      this.sendDebugLog(\"handleSuspendable: missing snapshot manager\", { suspendableSnapshot });\n-      return;\n-    }\n-\n-    // Ensure this is the current snapshot\n-    if (suspendableSnapshot.id !== this.currentSnapshotFriendlyId) {\n-      this.sendDebugLog(\"snapshot changed before cleanup, abort\", {\n-        suspendableSnapshot,\n-        currentSnapshotId: this.currentSnapshotFriendlyId,\n-      });\n-      this.abortExecution();\n-      return;\n-    }\n-\n-    // First cleanup the task run process\n-    const [error] = await tryCatch(this.taskRunProcess?.cleanup(false));\n-\n-    if (error) {\n-      this.sendDebugLog(\"failed to cleanup task run process, carrying on\", {\n-        suspendableSnapshot,\n-        error: error.message,\n-      });\n-    }\n-\n-    // Double check snapshot hasn't changed after cleanup\n-    if (suspendableSnapshot.id !== this.currentSnapshotFriendlyId) {\n-      this.sendDebugLog(\"snapshot changed after cleanup, abort\", {\n-        suspendableSnapshot,\n-        currentSnapshotId: this.currentSnapshotFriendlyId,\n-      });\n-      this.abortExecution();\n-      return;\n-    }\n-\n-    if (!this.runFriendlyId) {\n-      this.sendDebugLog(\"missing run ID for suspension, abort\", { suspendableSnapshot });\n-      this.abortExecution();\n-      return;\n-    }\n-\n-    // Call the suspend API with the current snapshot ID\n-    const suspendResult = await this.httpClient.suspendRun(\n-      this.runFriendlyId,\n-      suspendableSnapshot.id\n-    );\n-\n-    if (!suspendResult.success) {\n-      this.sendDebugLog(\"suspension request failed, staying alive \ud83c\udfb6\", {\n-        suspendableSnapshot,\n-        error: suspendResult.error,\n-      });\n-\n-      // This is fine, we'll wait for the next status change\n-      return;\n-    }\n-\n-    if (!suspendResult.data.ok) {\n-      this.sendDebugLog(\"suspension request returned error, staying alive \ud83c\udfb6\", {\n-        suspendableSnapshot,\n-        error: suspendResult.data.error,\n-      });\n-\n-      // This is fine, we'll wait for the next status change\n-      return;\n-    }\n-\n-    this.sendDebugLog(\"suspending, any day now \ud83d\udeac\", { suspendableSnapshot });\n-  }\n-\n-  /**\n-   * Fetches the latest execution data and enqueues snapshot changes. Used by both poller and notification handlers.\n-   * @param source string - where this call originated (e.g. 'poller', 'notification')\n-   */\n-  public async fetchAndProcessSnapshotChanges(source: string): Promise<void> {\n-    if (!this.runFriendlyId) {\n-      this.sendDebugLog(`fetchAndProcessSnapshotChanges: missing runFriendlyId`, { source });\n-      return;\n-    }\n-\n-    // Use the last processed snapshot as the since parameter\n-    const sinceSnapshotId = this.currentSnapshotFriendlyId;\n-\n-    if (!sinceSnapshotId) {\n-      this.sendDebugLog(`fetchAndProcessSnapshotChanges: missing sinceSnapshotId`, { source });\n-      return;\n-    }\n-\n-    const response = await this.httpClient.getSnapshotsSince(this.runFriendlyId, sinceSnapshotId);\n-\n-    if (!response.success) {\n-      this.sendDebugLog(`fetchAndProcessSnapshotChanges: failed to get snapshots since`, {\n-        source,\n-        error: response.error,\n-      });\n-\n-      if (response.isConnectionError) {\n-        // Log this separately to make it more visible\n-        this.sendDebugLog(\n-          \"fetchAndProcessSnapshotChanges: connection error detected, refreshing metadata\"\n-        );\n-      }\n-\n-      // Always trigger metadata refresh on snapshot fetch errors\n-      await this.processEnvOverrides(\"snapshots since error\");\n-      return;\n-    }\n-\n-    const { snapshots } = response.data;\n-\n-    if (!snapshots.length) {\n-      return;\n-    }\n-\n-    const [error] = await tryCatch(this.enqueueSnapshotChangesAndWait(snapshots));\n-\n-    if (error) {\n-      this.sendDebugLog(\n-        `fetchAndProcessSnapshotChanges: failed to enqueue and process snapshot change`,\n-        {\n-          source,\n-          error: error.message,\n-        }\n-      );\n-      return;\n-    }\n-  }\n-}\n+    }\n\\ No newline at end of file\ndiff --git a/packages/cli-v3/src/entryPoints/managed/snapshot.test.ts b/packages/cli-v3/src/entryPoints/managed/snapshot.test.ts\nindex a3dbab3..5c07749 100644\n--- a/packages/cli-v3/src/entryPoints/managed/snapshot.test.ts\n+++ b/packages/cli-v3/src/entryPoints/managed/snapshot.test.ts\n@@ -391,404 +391,4 @@ describe(\"SnapshotManager\", () => {\n         executionTimes.push({ start, end, type: `snapshot:${data.snapshot.friendlyId}` });\n         currentlyExecuting = false;\n       },\n-      onSuspendable: async (state) => {\n-        if (currentlyExecuting) {\n-          throw new Error(\"Handler executed while another handler was running\");\n-        }\n-        currentlyExecuting = true;\n-        handlerExecutionCount++;\n-\n-        const start = Date.now();\n-        executionOrder.push(`suspendable:${state.id}`);\n-        await setTimeout(Math.random() * 20); // Random delay\n-        const end = Date.now();\n-\n-        executionTimes.push({ start, end, type: `suspendable:${state.id}` });\n-        currentlyExecuting = false;\n-      },\n-    });\n-\n-    // Test empty snapshot IDs\n-    await manager.handleSnapshotChanges([createRunExecutionData({ snapshotId: \"\" })]);\n-    expect(executionOrder).toEqual([]);\n-\n-    // Create a very long queue of mixed changes\n-    const promises: Promise<void>[] = [];\n-\n-    // Add 50 mixed changes\n-    for (let i = 1; i <= 50; i++) {\n-      if (i % 2 === 0) {\n-        promises.push(\n-          manager.handleSnapshotChanges([createRunExecutionData({ snapshotId: `snapshot-${i}` })])\n-        );\n-      } else {\n-        promises.push(manager.setSuspendable(i % 4 === 1));\n-      }\n-    }\n-\n-    // Add rapid toggling of suspendable state\n-    for (let i = 0; i < 20; i++) {\n-      promises.push(manager.setSuspendable(i % 2 === 0));\n-    }\n-\n-    // Add overlapping snapshot changes\n-    const snapshotIds = [\"A\", \"B\", \"C\", \"D\", \"E\"];\n-    for (const id of snapshotIds) {\n-      for (let i = 0; i < 5; i++) {\n-        promises.push(\n-          manager.handleSnapshotChanges([\n-            createRunExecutionData({ snapshotId: `snapshot-${id}-${i}` }),\n-          ])\n-        );\n-      }\n-    }\n-\n-    await Promise.all(promises);\n-\n-    // Verify handler execution exclusivity\n-    for (let i = 1; i < executionTimes.length; i++) {\n-      const previous = executionTimes[i - 1]!;\n-      const current = executionTimes[i]!;\n-      expect(current.start).toBeGreaterThanOrEqual(previous.end);\n-    }\n-\n-    // Verify all handlers executed in sequence\n-    expect(currentlyExecuting).toBe(false);\n-\n-    // Verify suspendable state is correctly maintained\n-    const finalSuspendableState = manager.suspendable;\n-    const lastSuspendableChange = executionOrder\n-      .filter((entry) => entry.startsWith(\"suspendable:\"))\n-      .pop();\n-\n-    // The last recorded suspendable change should match the final state\n-    if (finalSuspendableState) {\n-      expect(lastSuspendableChange).toBeDefined();\n-    }\n-\n-    // Verify snapshot ordering\n-    const snapshotExecutions = executionOrder\n-      .filter((entry) => entry.startsWith(\"snapshot:\"))\n-      .map((entry) => entry.split(\":\")[1]);\n-\n-    // Each snapshot should be greater than the previous one\n-    for (let i = 1; i < snapshotExecutions.length; i++) {\n-      expect(snapshotExecutions[i]! > snapshotExecutions[i - 1]!).toBe(true);\n-    }\n-  });\n-\n-  it(\"should handle queue processing and remaining edge cases\", async () => {\n-    const executionOrder: string[] = [];\n-    let processingCount = 0;\n-\n-    const manager = new SnapshotManager({\n-      runnerId: \"test-runner-1\",\n-      runFriendlyId: \"test-run-1\",\n-      initialSnapshotId: \"snapshot-1\",\n-      initialStatus: \"PENDING_EXECUTING\",\n-      logger: mockLogger,\n-      onSnapshotChange: async (data) => {\n-        processingCount++;\n-        executionOrder.push(`snapshot:${data.snapshot.friendlyId}`);\n-        await setTimeout(10);\n-        processingCount--;\n-      },\n-      onSuspendable: async (state) => {\n-        processingCount++;\n-        executionOrder.push(`suspendable:${state.id}`);\n-        await setTimeout(10);\n-        processingCount--;\n-      },\n-    });\n-\n-    // Test parallel queue processing prevention\n-    const parallelPromises = Array.from({ length: 5 }, (_, i) =>\n-      manager.handleSnapshotChanges([\n-        createRunExecutionData({\n-          snapshotId: `parallel-${i}`,\n-          executionStatus: \"EXECUTING\",\n-        }),\n-      ])\n-    );\n-\n-    // Add some suspendable changes in the middle\n-    parallelPromises.push(manager.setSuspendable(true));\n-    parallelPromises.push(manager.setSuspendable(false));\n-\n-    // Add more snapshot changes\n-    parallelPromises.push(\n-      ...Array.from({ length: 5 }, (_, i) =>\n-        manager.handleSnapshotChanges([\n-          createRunExecutionData({\n-            snapshotId: `parallel-${i + 5}`,\n-            executionStatus: \"EXECUTING\",\n-          }),\n-        ])\n-      )\n-    );\n-\n-    await Promise.all(parallelPromises);\n-\n-    // Verify processingCount never exceeded 1\n-    expect(processingCount).toBe(0);\n-\n-    // Test edge case: snapshot ID comparison with special characters\n-    const specialCharPromises = [\n-      manager.handleSnapshotChanges([\n-        createRunExecutionData({\n-          snapshotId: \"snapshot-1!\",\n-          executionStatus: \"EXECUTING\",\n-        }),\n-      ]),\n-      manager.handleSnapshotChanges([\n-        createRunExecutionData({\n-          snapshotId: \"snapshot-1@\",\n-          executionStatus: \"EXECUTING\",\n-        }),\n-      ]),\n-      manager.handleSnapshotChanges([\n-        createRunExecutionData({\n-          snapshotId: \"snapshot-1#\",\n-          executionStatus: \"EXECUTING\",\n-        }),\n-      ]),\n-    ];\n-\n-    await Promise.all(specialCharPromises);\n-\n-    // Test edge case: very long snapshot IDs\n-    const longIdPromises = [\n-      manager.handleSnapshotChanges([\n-        createRunExecutionData({\n-          snapshotId: \"a\".repeat(1000),\n-          executionStatus: \"EXECUTING\",\n-        }),\n-      ]),\n-      manager.handleSnapshotChanges([\n-        createRunExecutionData({\n-          snapshotId: \"b\".repeat(1000),\n-          executionStatus: \"EXECUTING\",\n-        }),\n-      ]),\n-    ];\n-\n-    await Promise.all(longIdPromises);\n-\n-    // Test edge case: rapid queue changes during processing\n-    let isProcessing = false;\n-    const rapidChangeManager = new SnapshotManager({\n-      runnerId: \"test-runner-1\",\n-      runFriendlyId: \"test-run-2\",\n-      initialSnapshotId: \"snapshot-1\",\n-      initialStatus: \"PENDING_EXECUTING\",\n-      logger: mockLogger,\n-      onSnapshotChange: async (data) => {\n-        if (isProcessing) {\n-          throw new Error(\"Parallel processing detected\");\n-        }\n-        isProcessing = true;\n-        await setTimeout(50); // Longer delay to test queue changes during processing\n-        executionOrder.push(`rapid:${data.snapshot.friendlyId}`);\n-        isProcessing = false;\n-      },\n-      onSuspendable: async () => {},\n-    });\n-\n-    // Start processing a snapshot\n-    const initialPromise = rapidChangeManager.handleSnapshotChanges([\n-      createRunExecutionData({\n-        runId: \"test-run-2\",\n-        snapshotId: \"snapshot-2\",\n-        executionStatus: \"EXECUTING\",\n-      }),\n-    ]);\n-\n-    // Queue more changes while the first one is processing\n-    await setTimeout(10);\n-    const queuePromises = [\n-      rapidChangeManager.handleSnapshotChanges([\n-        createRunExecutionData({\n-          runId: \"test-run-2\",\n-          snapshotId: \"snapshot-3\",\n-          executionStatus: \"EXECUTING\",\n-        }),\n-      ]),\n-      rapidChangeManager.handleSnapshotChanges([\n-        createRunExecutionData({\n-          runId: \"test-run-2\",\n-          snapshotId: \"snapshot-4\",\n-          executionStatus: \"EXECUTING\",\n-        }),\n-      ]),\n-    ];\n-\n-    await Promise.all([initialPromise, ...queuePromises]);\n-\n-    // Verify the rapid changes were processed in order\n-    const rapidChanges = executionOrder.filter((entry) => entry.startsWith(\"rapid:\"));\n-    expect(rapidChanges).toEqual([\"rapid:snapshot-2\", \"rapid:snapshot-3\", \"rapid:snapshot-4\"]);\n-  });\n-\n-  it(\"should detect restore and not deprecate restored runner\", async () => {\n-    // Mock MetadataClient\n-    let runnerId = \"test-runner-1\";\n-    const mockMetadataClient = {\n-      getEnvOverrides: vi.fn().mockImplementation(() => {\n-        return Promise.resolve([null, { TRIGGER_RUNNER_ID: runnerId }]);\n-      }),\n-    };\n-\n-    const onSnapshotChange = vi.fn();\n-    const manager = new SnapshotManager({\n-      runnerId: \"test-runner-1\",\n-      runFriendlyId: \"test-run-1\",\n-      initialSnapshotId: \"snapshot-1\",\n-      initialStatus: \"PENDING_EXECUTING\",\n-      logger: mockLogger,\n-      metadataClient: mockMetadataClient as any,\n-      onSnapshotChange,\n-      onSuspendable: async () => {},\n-    });\n-\n-    // Simulate some basic snapshot changes\n-    await manager.handleSnapshotChanges([\n-      createRunExecutionData({ snapshotId: \"snapshot-2\", executionStatus: \"EXECUTING\" }),\n-      createRunExecutionData({\n-        snapshotId: \"snapshot-3\",\n-        executionStatus: \"EXECUTING_WITH_WAITPOINTS\",\n-      }),\n-    ]);\n-\n-    // Should call onSnapshotChange with deprecated = false\n-    expect(onSnapshotChange).toHaveBeenCalledWith(\n-      expect.objectContaining({ snapshot: expect.objectContaining({ friendlyId: \"snapshot-3\" }) }),\n-      false\n-    );\n-\n-    // Reset the mock\n-    onSnapshotChange.mockClear();\n-\n-    // Simulate a series of snapshot changes with deprecation markers and a restored runner\n-    // (standard checkpoint / restore flow)\n-    runnerId = \"test-runner-2\";\n-    await manager.handleSnapshotChanges([\n-      createRunExecutionData({ snapshotId: \"snapshot-4\", executionStatus: \"SUSPENDED\" }),\n-      createRunExecutionData({ snapshotId: \"snapshot-5\", executionStatus: \"QUEUED\" }),\n-      createRunExecutionData({ snapshotId: \"snapshot-6\", executionStatus: \"EXECUTING\" }),\n-    ]);\n-\n-    // Should call onSnapshotChange with deprecated = false\n-    expect(onSnapshotChange).toHaveBeenCalledWith(\n-      expect.objectContaining({ snapshot: expect.objectContaining({ friendlyId: \"snapshot-6\" }) }),\n-      false\n-    );\n-\n-    // Reset the mock\n-    onSnapshotChange.mockClear();\n-\n-    // Simulate a new snapshot with a deprecation marker in previous snapshots, but no restore\n-    await manager.handleSnapshotChanges([\n-      createRunExecutionData({ snapshotId: \"snapshot-7\", executionStatus: \"QUEUED\" }),\n-      createRunExecutionData({ snapshotId: \"snapshot-8\", executionStatus: \"EXECUTING\" }),\n-    ]);\n-    // Should call onSnapshotChange with deprecated = true\n-    expect(onSnapshotChange).toHaveBeenCalledWith(\n-      expect.objectContaining({ snapshot: expect.objectContaining({ friendlyId: \"snapshot-8\" }) }),\n-      true\n-    );\n-  });\n-\n-  it(\"should handle deprecated snapshot race condition - avoid false positives from stale polls\", async () => {\n-    const onSnapshotChange = vi.fn();\n-\n-    // Mock MetadataClient to simulate runner ID change (restore detected) on first call\n-    let isFirstCall = true;\n-    const mockMetadataClient = {\n-      getEnvOverrides: vi.fn().mockImplementation(() => {\n-        if (isFirstCall) {\n-          isFirstCall = false;\n-          return Promise.resolve([null, { TRIGGER_RUNNER_ID: \"test-runner-2\" }]); // Different runner ID = restore\n-        }\n-        return Promise.resolve([null, { TRIGGER_RUNNER_ID: \"test-runner-2\" }]); // Same runner ID afterward\n-      }),\n-    };\n-\n-    const manager = new SnapshotManager({\n-      runnerId: \"test-runner-1\",\n-      runFriendlyId: \"test-run-1\",\n-      initialSnapshotId: \"snapshot-1\",\n-      initialStatus: \"EXECUTING_WITH_WAITPOINTS\",\n-      logger: mockLogger,\n-      metadataClient: mockMetadataClient as any,\n-      onSnapshotChange,\n-      onSuspendable: mockSuspendableHandler,\n-    });\n-\n-    // First update: Process restore transition with deprecated statuses (normal case)\n-    // This simulates: EXECUTING_WITH_WAITPOINTS -> [SUSPENDED, QUEUED] -> PENDING_EXECUTING\n-    await manager.handleSnapshotChanges([\n-      createRunExecutionData({ snapshotId: \"snapshot-suspended\", executionStatus: \"SUSPENDED\" }),\n-      createRunExecutionData({ snapshotId: \"snapshot-queued\", executionStatus: \"QUEUED\" }),\n-      createRunExecutionData({ snapshotId: \"snapshot-2\", executionStatus: \"PENDING_EXECUTING\" }),\n-    ]);\n-\n-    // First call should be deprecated=false (restore detected)\n-    expect(onSnapshotChange).toHaveBeenCalledWith(\n-      expect.objectContaining({ snapshot: expect.objectContaining({ friendlyId: \"snapshot-2\" }) }),\n-      false\n-    );\n-\n-    onSnapshotChange.mockClear();\n-\n-    // Second update: Should only get new snapshot (race condition case)\n-    // This simulates a stale poll that returns: getSnapshotsSince(snapshot-1) -> [SUSPENDED, QUEUED, snapshot-2, snapshot-3]\n-    // The SUSPENDED/QUEUED should be ignored as already seen\n-    await manager.handleSnapshotChanges([\n-      createRunExecutionData({ snapshotId: \"snapshot-suspended\", executionStatus: \"SUSPENDED\" }), // Already seen\n-      createRunExecutionData({ snapshotId: \"snapshot-queued\", executionStatus: \"QUEUED\" }), // Already seen\n-      createRunExecutionData({ snapshotId: \"snapshot-2\", executionStatus: \"PENDING_EXECUTING\" }), // Already processed\n-      createRunExecutionData({ snapshotId: \"snapshot-3\", executionStatus: \"EXECUTING\" }), // New\n-    ]);\n-\n-    // Should call onSnapshotChange with deprecated = false (no new deprecated snapshots)\n-    expect(onSnapshotChange).toHaveBeenCalledWith(\n-      expect.objectContaining({ snapshot: expect.objectContaining({ friendlyId: \"snapshot-3\" }) }),\n-      false\n-    );\n-  });\n-});\n-\n-// Helper to generate RunExecutionData with sensible defaults\n-function createRunExecutionData(\n-  overrides: {\n-    runId?: string;\n-    runFriendlyId?: string;\n-    snapshotId?: string;\n-    snapshotFriendlyId?: string;\n-    executionStatus?: TaskRunExecutionStatus;\n-    description?: string;\n-  } = {}\n-): RunExecutionData {\n-  const runId = overrides.runId ?? \"test-run-1\";\n-  const runFriendlyId = overrides.runFriendlyId ?? runId;\n-  const snapshotId = overrides.snapshotId ?? \"snapshot-1\";\n-  const snapshotFriendlyId = overrides.snapshotFriendlyId ?? snapshotId;\n-\n-  return {\n-    version: \"1\" as const,\n-    run: {\n-      id: runId,\n-      friendlyId: runFriendlyId,\n-      status: \"EXECUTING\",\n-      attemptNumber: 1,\n-    },\n-    snapshot: {\n-      id: snapshotId,\n-      friendlyId: snapshotFriendlyId,\n-      executionStatus: overrides.executionStatus ?? \"EXECUTING\",\n-      description: overrides.description ?? \"Test snapshot\",\n-      createdAt: new Date(),\n-    },\n-    completedWaitpoints: [],\n-  };\n-}\n+      on\n\\ No newline at end of file\ndiff --git a/packages/cli-v3/src/entryPoints/managed/snapshot.ts b/packages/cli-v3/src/entryPoints/managed/snapshot.ts\nindex 9703ea8..47a5185 100644\n--- a/packages/cli-v3/src/entryPoints/managed/snapshot.ts\n+++ b/packages/cli-v3/src/entryPoints/managed/snapshot.ts\n@@ -49,10 +49,6 @@ export class SnapshotManager {\n   private changeQueue: QueuedChangeItem[] = [];\n   private isProcessingQueue = false;\n \n-  // Track seen deprecated snapshots to prevent false positives\n-  private seenDeprecatedSnapshotIds: string[] = [];\n-  private readonly maxSeenDeprecatedSnapshotIds = 50;\n-\n   constructor(opts: SnapshotManagerOptions) {\n     this.runFriendlyId = opts.runFriendlyId;\n     this.runnerId = opts.runnerId;\n@@ -288,13 +284,9 @@ export class SnapshotManager {\n \n         // Check if any previous snapshot is QUEUED or SUSPENDED\n         const deprecatedStatus: TaskRunExecutionStatus[] = [\"QUEUED\", \"SUSPENDED\"];\n-        const deprecatedSnapshots = previousSnapshots.filter((snap) => {\n-          const isDeprecated = deprecatedStatus.includes(snap.snapshot.executionStatus);\n-          const previouslySeen = this.seenDeprecatedSnapshotIds.some(\n-            (s) => s === snap.snapshot.friendlyId\n-          );\n-          return isDeprecated && !previouslySeen;\n-        });\n+        const deprecatedSnapshots = previousSnapshots.filter((snap) =>\n+          deprecatedStatus.includes(snap.snapshot.executionStatus)\n+        );\n \n         let deprecated = false;\n         if (deprecatedSnapshots.length > 0) {\n@@ -306,18 +298,6 @@ export class SnapshotManager {\n           } else {\n             deprecated = true;\n           }\n-\n-          // Add the deprecated snapshot IDs to the seen list\n-          this.seenDeprecatedSnapshotIds.push(\n-            ...deprecatedSnapshots.map((s) => s.snapshot.friendlyId)\n-          );\n-\n-          if (this.seenDeprecatedSnapshotIds.length > this.maxSeenDeprecatedSnapshotIds) {\n-            // Only keep the latest maxSeenDeprecatedSnapshotIds\n-            this.seenDeprecatedSnapshotIds = this.seenDeprecatedSnapshotIds.slice(\n-              -this.maxSeenDeprecatedSnapshotIds\n-            );\n-          }\n         }\n \n         const { snapshot } = latestSnapshot;\n@@ -413,4 +393,4 @@ export class SnapshotManager {\n       },\n     });\n   }\n-}\n+}\n\\ No newline at end of file\ndiff --git a/packages/core/src/v3/runEngineWorker/workload/http.ts b/packages/core/src/v3/runEngineWorker/workload/http.ts\nindex 93fa7bf..a8c6f75 100644\n--- a/packages/core/src/v3/runEngineWorker/workload/http.ts\n+++ b/packages/core/src/v3/runEngineWorker/workload/http.ts\n@@ -52,58 +52,18 @@ export class WorkloadHttpClient {\n     });\n   }\n \n-  private isConnectionError(error: string): boolean {\n-    const connectionErrors = [\n-      \"Connection error\",\n-      \"ECONNREFUSED\",\n-      \"ETIMEDOUT\",\n-      \"ENOTFOUND\",\n-      \"ECONNRESET\",\n-      \"EHOSTUNREACH\",\n-      \"ENETUNREACH\",\n-      \"EPIPE\",\n-      \"ECONNABORTED\",\n-    ];\n-    return connectionErrors.some((errType) => error.includes(errType));\n-  }\n-\n-  private async withConnectionErrorDetection<T>(\n-    operation: () => Promise<{ success: true; data: T } | { success: false; error: string }>\n-  ): Promise<\n-    { success: true; data: T } | { success: false; error: string; isConnectionError?: boolean }\n-  > {\n-    const result = await operation();\n-\n-    if (result.success) {\n-      return result;\n-    }\n-\n-    // Check if this is a connection error\n-    if (this.isConnectionError(result.error)) {\n-      return {\n-        ...result,\n-        isConnectionError: true,\n-      };\n-    }\n-\n-    return result;\n-  }\n-\n   async heartbeatRun(runId: string, snapshotId: string, body?: WorkloadHeartbeatRequestBody) {\n-    return this.withConnectionErrorDetection(() =>\n-      wrapZodFetch(\n-        WorkloadHeartbeatResponseBody,\n-        `${this.apiUrl}/api/v1/workload-actions/runs/${runId}/snapshots/${snapshotId}/heartbeat`,\n-        {\n-          method: \"POST\",\n-          headers: {\n-            ...this.defaultHeaders(),\n-            \"Content-Type\": \"application/json\",\n-          },\n-          body: JSON.stringify(body ?? {}),\n-          signal: AbortSignal.timeout(10_000), // 10 second timeout\n-        }\n-      )\n+    return wrapZodFetch(\n+      WorkloadHeartbeatResponseBody,\n+      `${this.apiUrl}/api/v1/workload-actions/runs/${runId}/snapshots/${snapshotId}/heartbeat`,\n+      {\n+        method: \"POST\",\n+        headers: {\n+          ...this.defaultHeaders(),\n+          \"Content-Type\": \"application/json\",\n+        },\n+        body: JSON.stringify(body ?? {}),\n+      }\n     );\n   }\n \n@@ -121,17 +81,15 @@ export class WorkloadHttpClient {\n   }\n \n   async continueRunExecution(runId: string, snapshotId: string) {\n-    return this.withConnectionErrorDetection(() =>\n-      wrapZodFetch(\n-        WorkloadContinueRunExecutionResponseBody,\n-        `${this.apiUrl}/api/v1/workload-actions/runs/${runId}/snapshots/${snapshotId}/continue`,\n-        {\n-          method: \"GET\",\n-          headers: {\n-            ...this.defaultHeaders(),\n-          },\n-        }\n-      )\n+    return wrapZodFetch(\n+      WorkloadContinueRunExecutionResponseBody,\n+      `${this.apiUrl}/api/v1/workload-actions/runs/${runId}/snapshots/${snapshotId}/continue`,\n+      {\n+        method: \"GET\",\n+        headers: {\n+          ...this.defaultHeaders(),\n+        },\n+      }\n     );\n   }\n \n@@ -172,18 +130,15 @@ export class WorkloadHttpClient {\n   }\n \n   async getSnapshotsSince(runId: string, snapshotId: string) {\n-    return this.withConnectionErrorDetection(() =>\n-      wrapZodFetch(\n-        WorkloadRunSnapshotsSinceResponseBody,\n-        `${this.apiUrl}/api/v1/workload-actions/runs/${runId}/snapshots/since/${snapshotId}`,\n-        {\n-          method: \"GET\",\n-          headers: {\n-            ...this.defaultHeaders(),\n-          },\n-          signal: AbortSignal.timeout(10_000), // 10 second timeout\n-        }\n-      )\n+    return wrapZodFetch(\n+      WorkloadRunSnapshotsSinceResponseBody,\n+      `${this.apiUrl}/api/v1/workload-actions/runs/${runId}/snapshots/since/${snapshotId}`,\n+      {\n+        method: \"GET\",\n+        headers: {\n+          ...this.defaultHeaders(),\n+        },\n+      }\n     );\n   }\n \n@@ -223,4 +178,4 @@ export class WorkloadHttpClient {\n       }\n     );\n   }\n-}\n+}\n\\ No newline at end of file\n"
  },
  {
    "instance_id": "triggerdotdev__trigger.dev.d1c3bfb9.2583",
    "repo": "triggerdotdev__trigger.dev.d1c3bfb9",
    "base_commit": "cdd1a8838cc24c489997ea50a294e60b1ed41c0b",
    "head_commit": "efe15f5804649ac233ad85dee5eff18ed624c94d",
    "title": "fix(otel): propagate the task event store to run descendants",
    "merged_at": "2025-10-04T14:28:17Z",
    "html_url": "https://github.com/triggerdotdev/trigger.dev/pull/2583",
    "test_files": [
      "apps/webapp/test/engine/triggerTask.test.ts"
    ],
    "code_files": [
      "apps/webapp/app/runEngine/concerns/idempotencyKeys.server.ts",
      "apps/webapp/app/runEngine/concerns/traceEvents.server.ts",
      "apps/webapp/app/runEngine/services/triggerTask.server.ts",
      "apps/webapp/app/runEngine/types.ts",
      "apps/webapp/app/v3/eventRepository/index.server.ts",
      "apps/webapp/app/v3/services/triggerTask.server.ts",
      "apps/webapp/app/v3/services/triggerTaskV1.server.ts"
    ],
    "total_changes": 265,
    "num_files": 8,
    "pull_number": 2583,
    "patch": "diff --git a/apps/webapp/app/runEngine/concerns/idempotencyKeys.server.ts b/apps/webapp/app/runEngine/concerns/idempotencyKeys.server.ts\nindex 3080ae871a..d22c8020d2 100644\n--- a/apps/webapp/app/runEngine/concerns/idempotencyKeys.server.ts\n+++ b/apps/webapp/app/runEngine/concerns/idempotencyKeys.server.ts\n@@ -17,7 +17,10 @@ export class IdempotencyKeyConcern {\n     private readonly traceEventConcern: TraceEventConcern\n   ) {}\n \n-  async handleTriggerRequest(request: TriggerTaskRequest): Promise<IdempotencyKeyConcernResult> {\n+  async handleTriggerRequest(\n+    request: TriggerTaskRequest,\n+    parentStore: string | undefined\n+  ): Promise<IdempotencyKeyConcernResult> {\n     const idempotencyKey = request.options?.idempotencyKey ?? request.body.options?.idempotencyKey;\n     const idempotencyKeyExpiresAt =\n       request.options?.idempotencyKeyExpiresAt ??\n@@ -83,6 +86,7 @@ export class IdempotencyKeyConcern {\n       if (associatedWaitpoint && resumeParentOnCompletion && parentRunId) {\n         await this.traceEventConcern.traceIdempotentRun(\n           request,\n+          parentStore,\n           {\n             existingRun,\n             idempotencyKey,\ndiff --git a/apps/webapp/app/runEngine/concerns/traceEvents.server.ts b/apps/webapp/app/runEngine/concerns/traceEvents.server.ts\nindex 7d880a5e57..634df34e4a 100644\n--- a/apps/webapp/app/runEngine/concerns/traceEvents.server.ts\n+++ b/apps/webapp/app/runEngine/concerns/traceEvents.server.ts\n@@ -1,39 +1,26 @@\n-import { EventRepository } from \"~/v3/eventRepository/eventRepository.server\";\n-import { TracedEventSpan, TraceEventConcern, TriggerTaskRequest } from \"../types\";\n import { SemanticInternalAttributes } from \"@trigger.dev/core/v3/semanticInternalAttributes\";\n import { TaskRun } from \"@trigger.dev/database\";\n-import { getTaskEventStore } from \"~/v3/taskEventStore.server\";\n-import { ClickhouseEventRepository } from \"~/v3/eventRepository/clickhouseEventRepository.server\";\n import { IEventRepository } from \"~/v3/eventRepository/eventRepository.types\";\n-import { FEATURE_FLAG, flags } from \"~/v3/featureFlags.server\";\n-import { env } from \"~/env.server\";\n import { getEventRepository } from \"~/v3/eventRepository/index.server\";\n+import { TracedEventSpan, TraceEventConcern, TriggerTaskRequest } from \"../types\";\n \n export class DefaultTraceEventsConcern implements TraceEventConcern {\n-  private readonly eventRepository: EventRepository;\n-  private readonly clickhouseEventRepository: ClickhouseEventRepository;\n-\n-  constructor(\n-    eventRepository: EventRepository,\n-    clickhouseEventRepository: ClickhouseEventRepository\n-  ) {\n-    this.eventRepository = eventRepository;\n-    this.clickhouseEventRepository = clickhouseEventRepository;\n-  }\n-\n   async #getEventRepository(\n-    request: TriggerTaskRequest\n+    request: TriggerTaskRequest,\n+    parentStore: string | undefined\n   ): Promise<{ repository: IEventRepository; store: string }> {\n     return await getEventRepository(\n-      request.environment.organization.featureFlags as Record<string, unknown>\n+      request.environment.organization.featureFlags as Record<string, unknown>,\n+      parentStore\n     );\n   }\n \n   async traceRun<T>(\n     request: TriggerTaskRequest,\n+    parentStore: string | undefined,\n     callback: (span: TracedEventSpan, store: string) => Promise<T>\n   ): Promise<T> {\n-    const { repository, store } = await this.#getEventRepository(request);\n+    const { repository, store } = await this.#getEventRepository(request, parentStore);\n \n     return await repository.traceEvent(\n       request.taskId,\n@@ -73,6 +60,7 @@ export class DefaultTraceEventsConcern implements TraceEventConcern {\n \n   async traceIdempotentRun<T>(\n     request: TriggerTaskRequest,\n+    parentStore: string | undefined,\n     options: {\n       existingRun: TaskRun;\n       idempotencyKey: string;\n@@ -82,7 +70,7 @@ export class DefaultTraceEventsConcern implements TraceEventConcern {\n     callback: (span: TracedEventSpan, store: string) => Promise<T>\n   ): Promise<T> {\n     const { existingRun, idempotencyKey, incomplete, isError } = options;\n-    const { repository, store } = await this.#getEventRepository(request);\n+    const { repository, store } = await this.#getEventRepository(request, parentStore);\n \n     return await repository.traceEvent(\n       `${request.taskId} (cached)`,\n@@ -107,7 +95,7 @@ export class DefaultTraceEventsConcern implements TraceEventConcern {\n       },\n       async (event, traceContext, traceparent) => {\n         //log a message\n-        await this.eventRepository.recordEvent(\n+        await repository.recordEvent(\n           `There's an existing run for idempotencyKey: ${idempotencyKey}`,\n           {\n             taskSlug: request.taskId,\ndiff --git a/apps/webapp/app/runEngine/services/triggerTask.server.ts b/apps/webapp/app/runEngine/services/triggerTask.server.ts\nindex 4916e237bb..144d9b3178 100644\n--- a/apps/webapp/app/runEngine/services/triggerTask.server.ts\n+++ b/apps/webapp/app/runEngine/services/triggerTask.server.ts\n@@ -197,7 +197,8 @@ export class RunEngineTriggerTaskService {\n       }\n \n       const idempotencyKeyConcernResult = await this.idempotencyKeyConcern.handleTriggerRequest(\n-        triggerRequest\n+        triggerRequest,\n+        parentRun?.taskEventStore\n       );\n \n       if (idempotencyKeyConcernResult.isCached) {\n@@ -266,105 +267,109 @@ export class RunEngineTriggerTaskService {\n       const workerQueue = await this.queueConcern.getWorkerQueue(environment, body.options?.region);\n \n       try {\n-        return await this.traceEventConcern.traceRun(triggerRequest, async (event, store) => {\n-          const result = await this.runNumberIncrementer.incrementRunNumber(\n-            triggerRequest,\n-            async (num) => {\n-              event.setAttribute(\"queueName\", queueName);\n-              span.setAttribute(\"queueName\", queueName);\n-              event.setAttribute(\"runId\", runFriendlyId);\n-              span.setAttribute(\"runId\", runFriendlyId);\n-\n-              const payloadPacket = await this.payloadProcessor.process(triggerRequest);\n-\n-              const taskRun = await this.engine.trigger(\n-                {\n-                  number: num,\n-                  friendlyId: runFriendlyId,\n-                  environment: environment,\n-                  idempotencyKey,\n-                  idempotencyKeyExpiresAt: idempotencyKey ? idempotencyKeyExpiresAt : undefined,\n-                  taskIdentifier: taskId,\n-                  payload: payloadPacket.data ?? \"\",\n-                  payloadType: payloadPacket.dataType,\n-                  context: body.context,\n-                  traceContext: this.#propagateExternalTraceContext(\n-                    event.traceContext,\n-                    parentRun?.traceContext,\n-                    event.traceparent?.spanId\n-                  ),\n-                  traceId: event.traceId,\n-                  spanId: event.spanId,\n-                  parentSpanId:\n-                    options.parentAsLinkType === \"replay\" ? undefined : event.traceparent?.spanId,\n-                  replayedFromTaskRunFriendlyId: options.replayedFromTaskRunFriendlyId,\n-                  lockedToVersionId: lockedToBackgroundWorker?.id,\n-                  taskVersion: lockedToBackgroundWorker?.version,\n-                  sdkVersion: lockedToBackgroundWorker?.sdkVersion,\n-                  cliVersion: lockedToBackgroundWorker?.cliVersion,\n-                  concurrencyKey: body.options?.concurrencyKey,\n-                  queue: queueName,\n-                  lockedQueueId,\n-                  workerQueue,\n-                  isTest: body.options?.test ?? false,\n-                  delayUntil,\n-                  queuedAt: delayUntil ? undefined : new Date(),\n-                  maxAttempts: body.options?.maxAttempts,\n-                  taskEventStore: store,\n-                  ttl,\n-                  tags,\n-                  oneTimeUseToken: options.oneTimeUseToken,\n-                  parentTaskRunId: parentRun?.id,\n-                  rootTaskRunId: parentRun?.rootTaskRunId ?? parentRun?.id,\n-                  batch: options?.batchId\n-                    ? {\n-                        id: options.batchId,\n-                        index: options.batchIndex ?? 0,\n-                      }\n-                    : undefined,\n-                  resumeParentOnCompletion: body.options?.resumeParentOnCompletion,\n-                  depth,\n-                  metadata: metadataPacket?.data,\n-                  metadataType: metadataPacket?.dataType,\n-                  seedMetadata: metadataPacket?.data,\n-                  seedMetadataType: metadataPacket?.dataType,\n-                  maxDurationInSeconds: body.options?.maxDuration\n-                    ? clampMaxDuration(body.options.maxDuration)\n-                    : undefined,\n-                  machine: body.options?.machine,\n-                  priorityMs: body.options?.priority ? body.options.priority * 1_000 : undefined,\n-                  queueTimestamp:\n-                    options.queueTimestamp ??\n-                    (parentRun && body.options?.resumeParentOnCompletion\n-                      ? parentRun.queueTimestamp ?? undefined\n-                      : undefined),\n-                  scheduleId: options.scheduleId,\n-                  scheduleInstanceId: options.scheduleInstanceId,\n-                  createdAt: options.overrideCreatedAt,\n-                  bulkActionId: body.options?.bulkActionId,\n-                  planType,\n-                },\n-                this.prisma\n-              );\n-\n-              const error = taskRun.error ? TaskRunError.parse(taskRun.error) : undefined;\n-\n-              if (error) {\n-                event.failWithError(error);\n+        return await this.traceEventConcern.traceRun(\n+          triggerRequest,\n+          parentRun?.taskEventStore,\n+          async (event, store) => {\n+            const result = await this.runNumberIncrementer.incrementRunNumber(\n+              triggerRequest,\n+              async (num) => {\n+                event.setAttribute(\"queueName\", queueName);\n+                span.setAttribute(\"queueName\", queueName);\n+                event.setAttribute(\"runId\", runFriendlyId);\n+                span.setAttribute(\"runId\", runFriendlyId);\n+\n+                const payloadPacket = await this.payloadProcessor.process(triggerRequest);\n+\n+                const taskRun = await this.engine.trigger(\n+                  {\n+                    number: num,\n+                    friendlyId: runFriendlyId,\n+                    environment: environment,\n+                    idempotencyKey,\n+                    idempotencyKeyExpiresAt: idempotencyKey ? idempotencyKeyExpiresAt : undefined,\n+                    taskIdentifier: taskId,\n+                    payload: payloadPacket.data ?? \"\",\n+                    payloadType: payloadPacket.dataType,\n+                    context: body.context,\n+                    traceContext: this.#propagateExternalTraceContext(\n+                      event.traceContext,\n+                      parentRun?.traceContext,\n+                      event.traceparent?.spanId\n+                    ),\n+                    traceId: event.traceId,\n+                    spanId: event.spanId,\n+                    parentSpanId:\n+                      options.parentAsLinkType === \"replay\" ? undefined : event.traceparent?.spanId,\n+                    replayedFromTaskRunFriendlyId: options.replayedFromTaskRunFriendlyId,\n+                    lockedToVersionId: lockedToBackgroundWorker?.id,\n+                    taskVersion: lockedToBackgroundWorker?.version,\n+                    sdkVersion: lockedToBackgroundWorker?.sdkVersion,\n+                    cliVersion: lockedToBackgroundWorker?.cliVersion,\n+                    concurrencyKey: body.options?.concurrencyKey,\n+                    queue: queueName,\n+                    lockedQueueId,\n+                    workerQueue,\n+                    isTest: body.options?.test ?? false,\n+                    delayUntil,\n+                    queuedAt: delayUntil ? undefined : new Date(),\n+                    maxAttempts: body.options?.maxAttempts,\n+                    taskEventStore: store,\n+                    ttl,\n+                    tags,\n+                    oneTimeUseToken: options.oneTimeUseToken,\n+                    parentTaskRunId: parentRun?.id,\n+                    rootTaskRunId: parentRun?.rootTaskRunId ?? parentRun?.id,\n+                    batch: options?.batchId\n+                      ? {\n+                          id: options.batchId,\n+                          index: options.batchIndex ?? 0,\n+                        }\n+                      : undefined,\n+                    resumeParentOnCompletion: body.options?.resumeParentOnCompletion,\n+                    depth,\n+                    metadata: metadataPacket?.data,\n+                    metadataType: metadataPacket?.dataType,\n+                    seedMetadata: metadataPacket?.data,\n+                    seedMetadataType: metadataPacket?.dataType,\n+                    maxDurationInSeconds: body.options?.maxDuration\n+                      ? clampMaxDuration(body.options.maxDuration)\n+                      : undefined,\n+                    machine: body.options?.machine,\n+                    priorityMs: body.options?.priority ? body.options.priority * 1_000 : undefined,\n+                    queueTimestamp:\n+                      options.queueTimestamp ??\n+                      (parentRun && body.options?.resumeParentOnCompletion\n+                        ? parentRun.queueTimestamp ?? undefined\n+                        : undefined),\n+                    scheduleId: options.scheduleId,\n+                    scheduleInstanceId: options.scheduleInstanceId,\n+                    createdAt: options.overrideCreatedAt,\n+                    bulkActionId: body.options?.bulkActionId,\n+                    planType,\n+                  },\n+                  this.prisma\n+                );\n+\n+                const error = taskRun.error ? TaskRunError.parse(taskRun.error) : undefined;\n+\n+                if (error) {\n+                  event.failWithError(error);\n+                }\n+\n+                return { run: taskRun, error, isCached: false };\n               }\n+            );\n \n-              return { run: taskRun, error, isCached: false };\n+            if (result?.error) {\n+              throw new ServiceValidationError(\n+                taskRunErrorToString(taskRunErrorEnhancer(result.error))\n+              );\n             }\n-          );\n \n-          if (result?.error) {\n-            throw new ServiceValidationError(\n-              taskRunErrorToString(taskRunErrorEnhancer(result.error))\n-            );\n+            return result;\n           }\n-\n-          return result;\n-        });\n+        );\n       } catch (error) {\n         if (error instanceof RunDuplicateIdempotencyKeyError) {\n           //retry calling this function, because this time it will return the idempotent run\ndiff --git a/apps/webapp/app/runEngine/types.ts b/apps/webapp/app/runEngine/types.ts\nindex 2324edc6b8..0aa52d0a40 100644\n--- a/apps/webapp/app/runEngine/types.ts\n+++ b/apps/webapp/app/runEngine/types.ts\n@@ -143,10 +143,12 @@ export type TracedEventSpan = {\n export interface TraceEventConcern {\n   traceRun<T>(\n     request: TriggerTaskRequest,\n+    parentStore: string | undefined,\n     callback: (span: TracedEventSpan, store: string) => Promise<T>\n   ): Promise<T>;\n   traceIdempotentRun<T>(\n     request: TriggerTaskRequest,\n+    parentStore: string | undefined,\n     options: {\n       existingRun: TaskRun;\n       idempotencyKey: string;\ndiff --git a/apps/webapp/app/v3/eventRepository/index.server.ts b/apps/webapp/app/v3/eventRepository/index.server.ts\nindex cda9e58940..3bf77fcd76 100644\n--- a/apps/webapp/app/v3/eventRepository/index.server.ts\n+++ b/apps/webapp/app/v3/eventRepository/index.server.ts\n@@ -18,8 +18,17 @@ export function resolveEventRepositoryForStore(store: string | undefined): IEven\n }\n \n export async function getEventRepository(\n-  featureFlags: Record<string, unknown> | undefined\n+  featureFlags: Record<string, unknown> | undefined,\n+  parentStore: string | undefined\n ): Promise<{ repository: IEventRepository; store: string }> {\n+  if (typeof parentStore === \"string\") {\n+    if (parentStore === \"clickhouse\") {\n+      return { repository: clickhouseEventRepository, store: \"clickhouse\" };\n+    } else {\n+      return { repository: eventRepository, store: getTaskEventStore() };\n+    }\n+  }\n+\n   const taskEventRepository = await resolveTaskEventRepositoryFlag(featureFlags);\n \n   if (taskEventRepository === \"clickhouse\") {\ndiff --git a/apps/webapp/app/v3/services/triggerTask.server.ts b/apps/webapp/app/v3/services/triggerTask.server.ts\nindex 5f56a35af2..235dddd7d6 100644\n--- a/apps/webapp/app/v3/services/triggerTask.server.ts\n+++ b/apps/webapp/app/v3/services/triggerTask.server.ts\n@@ -1,5 +1,6 @@\n import { TriggerTaskRequestBody } from \"@trigger.dev/core/v3\";\n import { RunEngineVersion, TaskRun } from \"@trigger.dev/database\";\n+import { env } from \"~/env.server\";\n import { IdempotencyKeyConcern } from \"~/runEngine/concerns/idempotencyKeys.server\";\n import { DefaultPayloadProcessor } from \"~/runEngine/concerns/payloads.server\";\n import { DefaultQueueManager } from \"~/runEngine/concerns/queues.server\";\n@@ -9,12 +10,9 @@ import { RunEngineTriggerTaskService } from \"~/runEngine/services/triggerTask.se\n import { DefaultTriggerTaskValidator } from \"~/runEngine/validators/triggerTaskValidator\";\n import { AuthenticatedEnvironment } from \"~/services/apiAuth.server\";\n import { determineEngineVersion } from \"../engineVersion.server\";\n-import { eventRepository } from \"../eventRepository/eventRepository.server\";\n import { tracer } from \"../tracer.server\";\n import { WithRunEngine } from \"./baseService.server\";\n import { TriggerTaskServiceV1 } from \"./triggerTaskV1.server\";\n-import { env } from \"~/env.server\";\n-import { clickhouseEventRepository } from \"../eventRepository/clickhouseEventRepositoryInstance.server\";\n \n export type TriggerTaskServiceOptions = {\n   idempotencyKey?: string;\n@@ -94,10 +92,7 @@ export class TriggerTaskService extends WithRunEngine {\n     body: TriggerTaskRequestBody,\n     options: TriggerTaskServiceOptions = {}\n   ): Promise<TriggerTaskServiceResult | undefined> {\n-    const traceEventConcern = new DefaultTraceEventsConcern(\n-      eventRepository,\n-      clickhouseEventRepository\n-    );\n+    const traceEventConcern = new DefaultTraceEventsConcern();\n \n     const service = new RunEngineTriggerTaskService({\n       prisma: this._prisma,\ndiff --git a/apps/webapp/app/v3/services/triggerTaskV1.server.ts b/apps/webapp/app/v3/services/triggerTaskV1.server.ts\nindex c193f142d6..5e6ac7c9f1 100644\n--- a/apps/webapp/app/v3/services/triggerTaskV1.server.ts\n+++ b/apps/webapp/app/v3/services/triggerTaskV1.server.ts\n@@ -179,6 +179,7 @@ export class TriggerTaskServiceV1 extends BaseService {\n                   depth: true,\n                   queueTimestamp: true,\n                   queue: true,\n+                  taskEventStore: true,\n                 },\n               },\n             },\n@@ -216,6 +217,7 @@ export class TriggerTaskServiceV1 extends BaseService {\n                   taskIdentifier: true,\n                   rootTaskRunId: true,\n                   depth: true,\n+                  taskEventStore: true,\n                 },\n               },\n             },\n@@ -237,6 +239,7 @@ export class TriggerTaskServiceV1 extends BaseService {\n                       depth: true,\n                       queueTimestamp: true,\n                       queue: true,\n+                      taskEventStore: true,\n                     },\n                   },\n                 },\n@@ -289,7 +292,10 @@ export class TriggerTaskServiceV1 extends BaseService {\n         : undefined;\n \n       const { repository, store } = await getEventRepository(\n-        environment.organization.featureFlags as Record<string, unknown>\n+        environment.organization.featureFlags as Record<string, unknown>,\n+        dependentAttempt?.taskRun.taskEventStore ??\n+          parentAttempt?.taskRun.taskEventStore ??\n+          dependentBatchRun?.dependentTaskAttempt?.taskRun.taskEventStore\n       );\n \n       try {\ndiff --git a/apps/webapp/test/engine/triggerTask.test.ts b/apps/webapp/test/engine/triggerTask.test.ts\nindex 36dabd008c..aa0e059156 100644\n--- a/apps/webapp/test/engine/triggerTask.test.ts\n+++ b/apps/webapp/test/engine/triggerTask.test.ts\n@@ -79,6 +79,7 @@ class MockTriggerTaskValidator implements TriggerTaskValidator {\n class MockTraceEventConcern implements TraceEventConcern {\n   async traceRun<T>(\n     request: TriggerTaskRequest,\n+    parentStore: string | undefined,\n     callback: (span: TracedEventSpan, store: string) => Promise<T>\n   ): Promise<T> {\n     return await callback(\n@@ -96,6 +97,7 @@ class MockTraceEventConcern implements TraceEventConcern {\n \n   async traceIdempotentRun<T>(\n     request: TriggerTaskRequest,\n+    parentStore: string | undefined,\n     options: {\n       existingRun: TaskRun;\n       idempotencyKey: string;\n",
    "test_patch": "",
    "problem_statement": "",
    "hints_text": "",
    "pr_mirror": "triggerdotdev__trigger.dev.d1c3bfb9",
    "bug_patch": "diff --git a/apps/webapp/app/runEngine/concerns/idempotencyKeys.server.ts b/apps/webapp/app/runEngine/concerns/idempotencyKeys.server.ts\nindex d22c802..e21b571 100644\n--- a/apps/webapp/app/runEngine/concerns/idempotencyKeys.server.ts\n+++ b/apps/webapp/app/runEngine/concerns/idempotencyKeys.server.ts\n@@ -17,10 +17,7 @@ export class IdempotencyKeyConcern {\n     private readonly traceEventConcern: TraceEventConcern\n   ) {}\n \n-  async handleTriggerRequest(\n-    request: TriggerTaskRequest,\n-    parentStore: string | undefined\n-  ): Promise<IdempotencyKeyConcernResult> {\n+  async handleTriggerRequest(request: TriggerTaskRequest): Promise<IdempotencyKeyConcernResult> {\n     const idempotencyKey = request.options?.idempotencyKey ?? request.body.options?.idempotencyKey;\n     const idempotencyKeyExpiresAt =\n       request.options?.idempotencyKeyExpiresAt ??\n@@ -86,7 +83,6 @@ export class IdempotencyKeyConcern {\n       if (associatedWaitpoint && resumeParentOnCompletion && parentRunId) {\n         await this.traceEventConcern.traceIdempotentRun(\n           request,\n-          parentStore,\n           {\n             existingRun,\n             idempotencyKey,\n@@ -125,4 +121,4 @@ export class IdempotencyKeyConcern {\n \n     return { isCached: false, idempotencyKey, idempotencyKeyExpiresAt };\n   }\n-}\n+}\n\\ No newline at end of file\ndiff --git a/apps/webapp/app/runEngine/concerns/traceEvents.server.ts b/apps/webapp/app/runEngine/concerns/traceEvents.server.ts\nindex 634df34..4539a49 100644\n--- a/apps/webapp/app/runEngine/concerns/traceEvents.server.ts\n+++ b/apps/webapp/app/runEngine/concerns/traceEvents.server.ts\n@@ -1,26 +1,39 @@\n+import { EventRepository } from \"~/v3/eventRepository/eventRepository.server\";\n+import { TracedEventSpan, TraceEventConcern, TriggerTaskRequest } from \"../types\";\n import { SemanticInternalAttributes } from \"@trigger.dev/core/v3/semanticInternalAttributes\";\n import { TaskRun } from \"@trigger.dev/database\";\n+import { getTaskEventStore } from \"~/v3/taskEventStore.server\";\n+import { ClickhouseEventRepository } from \"~/v3/eventRepository/clickhouseEventRepository.server\";\n import { IEventRepository } from \"~/v3/eventRepository/eventRepository.types\";\n+import { FEATURE_FLAG, flags } from \"~/v3/featureFlags.server\";\n+import { env } from \"~/env.server\";\n import { getEventRepository } from \"~/v3/eventRepository/index.server\";\n-import { TracedEventSpan, TraceEventConcern, TriggerTaskRequest } from \"../types\";\n \n export class DefaultTraceEventsConcern implements TraceEventConcern {\n+  private readonly eventRepository: EventRepository;\n+  private readonly clickhouseEventRepository: ClickhouseEventRepository;\n+\n+  constructor(\n+    eventRepository: EventRepository,\n+    clickhouseEventRepository: ClickhouseEventRepository\n+  ) {\n+    this.eventRepository = eventRepository;\n+    this.clickhouseEventRepository = clickhouseEventRepository;\n+  }\n+\n   async #getEventRepository(\n-    request: TriggerTaskRequest,\n-    parentStore: string | undefined\n+    request: TriggerTaskRequest\n   ): Promise<{ repository: IEventRepository; store: string }> {\n     return await getEventRepository(\n-      request.environment.organization.featureFlags as Record<string, unknown>,\n-      parentStore\n+      request.environment.organization.featureFlags as Record<string, unknown>\n     );\n   }\n \n   async traceRun<T>(\n     request: TriggerTaskRequest,\n-    parentStore: string | undefined,\n     callback: (span: TracedEventSpan, store: string) => Promise<T>\n   ): Promise<T> {\n-    const { repository, store } = await this.#getEventRepository(request, parentStore);\n+    const { repository, store } = await this.#getEventRepository(request);\n \n     return await repository.traceEvent(\n       request.taskId,\n@@ -60,7 +73,6 @@ export class DefaultTraceEventsConcern implements TraceEventConcern {\n \n   async traceIdempotentRun<T>(\n     request: TriggerTaskRequest,\n-    parentStore: string | undefined,\n     options: {\n       existingRun: TaskRun;\n       idempotencyKey: string;\n@@ -70,7 +82,7 @@ export class DefaultTraceEventsConcern implements TraceEventConcern {\n     callback: (span: TracedEventSpan, store: string) => Promise<T>\n   ): Promise<T> {\n     const { existingRun, idempotencyKey, incomplete, isError } = options;\n-    const { repository, store } = await this.#getEventRepository(request, parentStore);\n+    const { repository, store } = await this.#getEventRepository(request);\n \n     return await repository.traceEvent(\n       `${request.taskId} (cached)`,\n@@ -95,7 +107,7 @@ export class DefaultTraceEventsConcern implements TraceEventConcern {\n       },\n       async (event, traceContext, traceparent) => {\n         //log a message\n-        await repository.recordEvent(\n+        await this.eventRepository.recordEvent(\n           `There's an existing run for idempotencyKey: ${idempotencyKey}`,\n           {\n             taskSlug: request.taskId,\n@@ -122,4 +134,4 @@ export class DefaultTraceEventsConcern implements TraceEventConcern {\n       }\n     );\n   }\n-}\n+}\n\\ No newline at end of file\ndiff --git a/apps/webapp/app/runEngine/services/triggerTask.server.ts b/apps/webapp/app/runEngine/services/triggerTask.server.ts\nindex f19404b..cdb30ad 100644\n--- a/apps/webapp/app/runEngine/services/triggerTask.server.ts\n+++ b/apps/webapp/app/runEngine/services/triggerTask.server.ts\n@@ -197,8 +197,7 @@ export class RunEngineTriggerTaskService {\n       }\n \n       const idempotencyKeyConcernResult = await this.idempotencyKeyConcern.handleTriggerRequest(\n-        triggerRequest,\n-        parentRun?.taskEventStore\n+        triggerRequest\n       );\n \n       if (idempotencyKeyConcernResult.isCached) {\n@@ -267,110 +266,105 @@ export class RunEngineTriggerTaskService {\n       const workerQueue = await this.queueConcern.getWorkerQueue(environment, body.options?.region);\n \n       try {\n-        return await this.traceEventConcern.traceRun(\n-          triggerRequest,\n-          parentRun?.taskEventStore,\n-          async (event, store) => {\n-            const result = await this.runNumberIncrementer.incrementRunNumber(\n-              triggerRequest,\n-              async (num) => {\n-                event.setAttribute(\"queueName\", queueName);\n-                span.setAttribute(\"queueName\", queueName);\n-                event.setAttribute(\"runId\", runFriendlyId);\n-                span.setAttribute(\"runId\", runFriendlyId);\n-\n-                const payloadPacket = await this.payloadProcessor.process(triggerRequest);\n-\n-                const taskRun = await this.engine.trigger(\n-                  {\n-                    number: num,\n-                    friendlyId: runFriendlyId,\n-                    environment: environment,\n-                    idempotencyKey,\n-                    idempotencyKeyExpiresAt: idempotencyKey ? idempotencyKeyExpiresAt : undefined,\n-                    taskIdentifier: taskId,\n-                    payload: payloadPacket.data ?? \"\",\n-                    payloadType: payloadPacket.dataType,\n-                    context: body.context,\n-                    traceContext: this.#propagateExternalTraceContext(\n-                      event.traceContext,\n-                      parentRun?.traceContext,\n-                      event.traceparent?.spanId\n-                    ),\n-                    traceId: event.traceId,\n-                    spanId: event.spanId,\n-                    parentSpanId:\n-                      options.parentAsLinkType === \"replay\" ? undefined : event.traceparent?.spanId,\n-                    replayedFromTaskRunFriendlyId: options.replayedFromTaskRunFriendlyId,\n-                    lockedToVersionId: lockedToBackgroundWorker?.id,\n-                    taskVersion: lockedToBackgroundWorker?.version,\n-                    sdkVersion: lockedToBackgroundWorker?.sdkVersion,\n-                    cliVersion: lockedToBackgroundWorker?.cliVersion,\n-                    concurrencyKey: body.options?.concurrencyKey,\n-                    queue: queueName,\n-                    lockedQueueId,\n-                    workerQueue,\n-                    isTest: body.options?.test ?? false,\n-                    delayUntil,\n-                    queuedAt: delayUntil ? undefined : new Date(),\n-                    maxAttempts: body.options?.maxAttempts,\n-                    taskEventStore: store,\n-                    ttl,\n-                    tags,\n-                    oneTimeUseToken: options.oneTimeUseToken,\n-                    parentTaskRunId: parentRun?.id,\n-                    rootTaskRunId: parentRun?.rootTaskRunId ?? parentRun?.id,\n-                    batch: options?.batchId\n-                      ? {\n-                          id: options.batchId,\n-                          index: options.batchIndex ?? 0,\n-                        }\n-                      : undefined,\n-                    resumeParentOnCompletion: body.options?.resumeParentOnCompletion,\n-                    depth,\n-                    metadata: metadataPacket?.data,\n-                    metadataType: metadataPacket?.dataType,\n-                    seedMetadata: metadataPacket?.data,\n-                    seedMetadataType: metadataPacket?.dataType,\n-                    maxDurationInSeconds: body.options?.maxDuration\n-                      ? clampMaxDuration(body.options.maxDuration)\n-                      : undefined,\n-                    machine: body.options?.machine,\n-                    priorityMs: body.options?.priority ? body.options.priority * 1_000 : undefined,\n-                    queueTimestamp:\n-                      options.queueTimestamp ??\n-                      (parentRun && body.options?.resumeParentOnCompletion\n-                        ? parentRun.queueTimestamp ?? undefined\n-                        : undefined),\n-                    scheduleId: options.scheduleId,\n-                    scheduleInstanceId: options.scheduleInstanceId,\n-                    createdAt: options.overrideCreatedAt,\n-                    bulkActionId: body.options?.bulkActionId,\n-                    planType,\n-                    realtimeStreamsVersion: options.realtimeStreamsVersion,\n-                  },\n-                  this.prisma\n-                );\n-\n-                const error = taskRun.error ? TaskRunError.parse(taskRun.error) : undefined;\n-\n-                if (error) {\n-                  event.failWithError(error);\n-                }\n-\n-                return { run: taskRun, error, isCached: false };\n+        return await this.traceEventConcern.traceRun(triggerRequest, async (event, store) => {\n+          const result = await this.runNumberIncrementer.incrementRunNumber(\n+            triggerRequest,\n+            async (num) => {\n+              event.setAttribute(\"queueName\", queueName);\n+              span.setAttribute(\"queueName\", queueName);\n+              event.setAttribute(\"runId\", runFriendlyId);\n+              span.setAttribute(\"runId\", runFriendlyId);\n+\n+              const payloadPacket = await this.payloadProcessor.process(triggerRequest);\n+\n+              const taskRun = await this.engine.trigger(\n+                {\n+                  number: num,\n+                  friendlyId: runFriendlyId,\n+                  environment: environment,\n+                  idempotencyKey,\n+                  idempotencyKeyExpiresAt: idempotencyKey ? idempotencyKeyExpiresAt : undefined,\n+                  taskIdentifier: taskId,\n+                  payload: payloadPacket.data ?? \"\",\n+                  payloadType: payloadPacket.dataType,\n+                  context: body.context,\n+                  traceContext: this.#propagateExternalTraceContext(\n+                    event.traceContext,\n+                    parentRun?.traceContext,\n+                    event.traceparent?.spanId\n+                  ),\n+                  traceId: event.traceId,\n+                  spanId: event.spanId,\n+                  parentSpanId:\n+                    options.parentAsLinkType === \"replay\" ? undefined : event.traceparent?.spanId,\n+                  replayedFromTaskRunFriendlyId: options.replayedFromTaskRunFriendlyId,\n+                  lockedToVersionId: lockedToBackgroundWorker?.id,\n+                  taskVersion: lockedToBackgroundWorker?.version,\n+                  sdkVersion: lockedToBackgroundWorker?.sdkVersion,\n+                  cliVersion: lockedToBackgroundWorker?.cliVersion,\n+                  concurrencyKey: body.options?.concurrencyKey,\n+                  queue: queueName,\n+                  lockedQueueId,\n+                  workerQueue,\n+                  isTest: body.options?.test ?? false,\n+                  delayUntil,\n+                  queuedAt: delayUntil ? undefined : new Date(),\n+                  maxAttempts: body.options?.maxAttempts,\n+                  taskEventStore: store,\n+                  ttl,\n+                  tags,\n+                  oneTimeUseToken: options.oneTimeUseToken,\n+                  parentTaskRunId: parentRun?.id,\n+                  rootTaskRunId: parentRun?.rootTaskRunId ?? parentRun?.id,\n+                  batch: options?.batchId\n+                    ? {\n+                        id: options.batchId,\n+                        index: options.batchIndex ?? 0,\n+                      }\n+                    : undefined,\n+                  resumeParentOnCompletion: body.options?.resumeParentOnCompletion,\n+                  depth,\n+                  metadata: metadataPacket?.data,\n+                  metadataType: metadataPacket?.dataType,\n+                  seedMetadata: metadataPacket?.data,\n+                  seedMetadataType: metadataPacket?.dataType,\n+                  maxDurationInSeconds: body.options?.maxDuration\n+                    ? clampMaxDuration(body.options.maxDuration)\n+                    : undefined,\n+                  machine: body.options?.machine,\n+                  priorityMs: body.options?.priority ? body.options.priority * 1_000 : undefined,\n+                  queueTimestamp:\n+                    options.queueTimestamp ??\n+                    (parentRun && body.options?.resumeParentOnCompletion\n+                      ? parentRun.queueTimestamp ?? undefined\n+                      : undefined),\n+                  scheduleId: options.scheduleId,\n+                  scheduleInstanceId: options.scheduleInstanceId,\n+                  createdAt: options.overrideCreatedAt,\n+                  bulkActionId: body.options?.bulkActionId,\n+                  planType,\n+                },\n+                this.prisma\n+              );\n+\n+              const error = taskRun.error ? TaskRunError.parse(taskRun.error) : undefined;\n+\n+              if (error) {\n+                event.failWithError(error);\n               }\n-            );\n \n-            if (result?.error) {\n-              throw new ServiceValidationError(\n-                taskRunErrorToString(taskRunErrorEnhancer(result.error))\n-              );\n+              return { run: taskRun, error, isCached: false };\n             }\n+          );\n \n-            return result;\n+          if (result?.error) {\n+            throw new ServiceValidationError(\n+              taskRunErrorToString(taskRunErrorEnhancer(result.error))\n+            );\n           }\n-        );\n+\n+          return result;\n+        });\n       } catch (error) {\n         if (error instanceof RunDuplicateIdempotencyKeyError) {\n           //retry calling this function, because this time it will return the idempotent run\n@@ -419,18 +413,4 @@ export class RunEngineTriggerTaskService {\n       return traceContext;\n     }\n \n-    const newExternalTraceparent = serializeTraceparent(\n-      parsedTraceparent.traceId,\n-      parentSpanId ?? parsedTraceparent.spanId,\n-      parsedTraceparent.traceFlags\n-    );\n-\n-    return {\n-      ...traceContext,\n-      external: {\n-        ...external,\n-        traceparent: newExternalTraceparent,\n-      },\n-    };\n-  }\n-}\n+    const newExternalTraceparent =\n\\ No newline at end of file\ndiff --git a/apps/webapp/app/runEngine/types.ts b/apps/webapp/app/runEngine/types.ts\nindex 0aa52d0..5aa1806 100644\n--- a/apps/webapp/app/runEngine/types.ts\n+++ b/apps/webapp/app/runEngine/types.ts\n@@ -143,12 +143,10 @@ export type TracedEventSpan = {\n export interface TraceEventConcern {\n   traceRun<T>(\n     request: TriggerTaskRequest,\n-    parentStore: string | undefined,\n     callback: (span: TracedEventSpan, store: string) => Promise<T>\n   ): Promise<T>;\n   traceIdempotentRun<T>(\n     request: TriggerTaskRequest,\n-    parentStore: string | undefined,\n     options: {\n       existingRun: TaskRun;\n       idempotencyKey: string;\n@@ -163,4 +161,4 @@ export type TriggerRacepoints = \"idempotencyKey\";\n \n export interface TriggerRacepointSystem {\n   waitForRacepoint(options: { racepoint: TriggerRacepoints; id: string }): Promise<void>;\n-}\n+}\n\\ No newline at end of file\ndiff --git a/apps/webapp/app/v3/eventRepository/index.server.ts b/apps/webapp/app/v3/eventRepository/index.server.ts\nindex a8f66da..20da977 100644\n--- a/apps/webapp/app/v3/eventRepository/index.server.ts\n+++ b/apps/webapp/app/v3/eventRepository/index.server.ts\n@@ -25,20 +25,8 @@ export function resolveEventRepositoryForStore(store: string | undefined): IEven\n }\n \n export async function getEventRepository(\n-  featureFlags: Record<string, unknown> | undefined,\n-  parentStore: string | undefined\n+  featureFlags: Record<string, unknown> | undefined\n ): Promise<{ repository: IEventRepository; store: string }> {\n-  if (typeof parentStore === \"string\") {\n-    if (parentStore === \"clickhouse_v2\") {\n-      return { repository: clickhouseEventRepositoryV2, store: \"clickhouse_v2\" };\n-    }\n-    if (parentStore === \"clickhouse\") {\n-      return { repository: clickhouseEventRepository, store: \"clickhouse\" };\n-    } else {\n-      return { repository: eventRepository, store: getTaskEventStore() };\n-    }\n-  }\n-\n   const taskEventRepository = await resolveTaskEventRepositoryFlag(featureFlags);\n \n   if (taskEventRepository === \"clickhouse_v2\") {\n@@ -230,4 +218,4 @@ async function findRunForEventCreation(runId: string) {\n       },\n     },\n   });\n-}\n+}\n\\ No newline at end of file\ndiff --git a/apps/webapp/app/v3/services/triggerTask.server.ts b/apps/webapp/app/v3/services/triggerTask.server.ts\nindex f68b238..dce7d9a 100644\n--- a/apps/webapp/app/v3/services/triggerTask.server.ts\n+++ b/apps/webapp/app/v3/services/triggerTask.server.ts\n@@ -1,6 +1,5 @@\n import { TriggerTaskRequestBody } from \"@trigger.dev/core/v3\";\n import { RunEngineVersion, TaskRun } from \"@trigger.dev/database\";\n-import { env } from \"~/env.server\";\n import { IdempotencyKeyConcern } from \"~/runEngine/concerns/idempotencyKeys.server\";\n import { DefaultPayloadProcessor } from \"~/runEngine/concerns/payloads.server\";\n import { DefaultQueueManager } from \"~/runEngine/concerns/queues.server\";\n@@ -10,9 +9,12 @@ import { RunEngineTriggerTaskService } from \"~/runEngine/services/triggerTask.se\n import { DefaultTriggerTaskValidator } from \"~/runEngine/validators/triggerTaskValidator\";\n import { AuthenticatedEnvironment } from \"~/services/apiAuth.server\";\n import { determineEngineVersion } from \"../engineVersion.server\";\n+import { eventRepository } from \"../eventRepository/eventRepository.server\";\n import { tracer } from \"../tracer.server\";\n import { WithRunEngine } from \"./baseService.server\";\n import { TriggerTaskServiceV1 } from \"./triggerTaskV1.server\";\n+import { env } from \"~/env.server\";\n+import { clickhouseEventRepository } from \"../eventRepository/clickhouseEventRepositoryInstance.server\";\n \n export type TriggerTaskServiceOptions = {\n   idempotencyKey?: string;\n@@ -93,7 +95,10 @@ export class TriggerTaskService extends WithRunEngine {\n     body: TriggerTaskRequestBody,\n     options: TriggerTaskServiceOptions = {}\n   ): Promise<TriggerTaskServiceResult | undefined> {\n-    const traceEventConcern = new DefaultTraceEventsConcern();\n+    const traceEventConcern = new DefaultTraceEventsConcern(\n+      eventRepository,\n+      clickhouseEventRepository\n+    );\n \n     const service = new RunEngineTriggerTaskService({\n       prisma: this._prisma,\n@@ -119,4 +124,4 @@ export class TriggerTaskService extends WithRunEngine {\n       options,\n     });\n   }\n-}\n+}\n\\ No newline at end of file\ndiff --git a/apps/webapp/app/v3/services/triggerTaskV1.server.ts b/apps/webapp/app/v3/services/triggerTaskV1.server.ts\nindex efc6510..3421b05 100644\n--- a/apps/webapp/app/v3/services/triggerTaskV1.server.ts\n+++ b/apps/webapp/app/v3/services/triggerTaskV1.server.ts\n@@ -179,7 +179,6 @@ export class TriggerTaskServiceV1 extends BaseService {\n                   depth: true,\n                   queueTimestamp: true,\n                   queue: true,\n-                  taskEventStore: true,\n                 },\n               },\n             },\n@@ -217,7 +216,6 @@ export class TriggerTaskServiceV1 extends BaseService {\n                   taskIdentifier: true,\n                   rootTaskRunId: true,\n                   depth: true,\n-                  taskEventStore: true,\n                 },\n               },\n             },\n@@ -239,7 +237,6 @@ export class TriggerTaskServiceV1 extends BaseService {\n                       depth: true,\n                       queueTimestamp: true,\n                       queue: true,\n-                      taskEventStore: true,\n                     },\n                   },\n                 },\n@@ -291,10 +288,8 @@ export class TriggerTaskServiceV1 extends BaseService {\n           })\n         : undefined;\n \n-      const { repository, store } = await getV3EventRepository(\n-        dependentAttempt?.taskRun.taskEventStore ??\n-          parentAttempt?.taskRun.taskEventStore ??\n-          dependentBatchRun?.dependentTaskAttempt?.taskRun.taskEventStore\n+      const { repository, store } = await getEventRepository(\n+        environment.organization.featureFlags as Record<string, unknown>\n       );\n \n       try {\n@@ -398,380 +393,4 @@ export class TriggerTaskServiceV1 extends BaseService {\n                     taskVersion: lockedToBackgroundWorker?.version,\n                     sdkVersion: lockedToBackgroundWorker?.sdkVersion,\n                     cliVersion: lockedToBackgroundWorker?.cliVersion,\n-                    concurrencyKey: body.options?.concurrencyKey,\n-                    queue: queueName,\n-                    isTest: body.options?.test ?? false,\n-                    delayUntil,\n-                    queuedAt: delayUntil ? undefined : new Date(),\n-                    queueTimestamp,\n-                    maxAttempts: body.options?.maxAttempts,\n-                    taskEventStore: store,\n-                    ttl,\n-                    tags:\n-                      tagIds.length === 0\n-                        ? undefined\n-                        : {\n-                            connect: tagIds.map((id) => ({ id })),\n-                          },\n-                    parentTaskRunId:\n-                      dependentAttempt?.taskRun.id ??\n-                      parentAttempt?.taskRun.id ??\n-                      dependentBatchRun?.dependentTaskAttempt?.taskRun.id,\n-                    parentTaskRunAttemptId:\n-                      dependentAttempt?.id ??\n-                      parentAttempt?.id ??\n-                      dependentBatchRun?.dependentTaskAttempt?.id,\n-                    rootTaskRunId:\n-                      dependentAttempt?.taskRun.rootTaskRunId ??\n-                      dependentAttempt?.taskRun.id ??\n-                      parentAttempt?.taskRun.rootTaskRunId ??\n-                      parentAttempt?.taskRun.id ??\n-                      dependentBatchRun?.dependentTaskAttempt?.taskRun.rootTaskRunId ??\n-                      dependentBatchRun?.dependentTaskAttempt?.taskRun.id,\n-                    replayedFromTaskRunFriendlyId: options.replayedFromTaskRunFriendlyId,\n-                    batchId: dependentBatchRun?.id ?? parentBatchRun?.id,\n-                    resumeParentOnCompletion: !!(dependentAttempt ?? dependentBatchRun),\n-                    depth,\n-                    metadata: metadataPacket?.data,\n-                    metadataType: metadataPacket?.dataType,\n-                    seedMetadata: metadataPacket?.data,\n-                    seedMetadataType: metadataPacket?.dataType,\n-                    maxDurationInSeconds: body.options?.maxDuration\n-                      ? clampMaxDuration(body.options.maxDuration)\n-                      : undefined,\n-                    runTags: bodyTags,\n-                    oneTimeUseToken: options.oneTimeUseToken,\n-                    machinePreset: body.options?.machine,\n-                    scheduleId: options.scheduleId,\n-                    scheduleInstanceId: options.scheduleInstanceId,\n-                    createdAt: options.overrideCreatedAt,\n-                    bulkActionGroupIds: body.options?.bulkActionId\n-                      ? [body.options.bulkActionId]\n-                      : undefined,\n-                  },\n-                });\n-\n-                event.setAttribute(\"runId\", taskRun.friendlyId);\n-                span.setAttribute(\"runId\", taskRun.friendlyId);\n-\n-                if (dependentAttempt) {\n-                  await tx.taskRunDependency.create({\n-                    data: {\n-                      taskRunId: taskRun.id,\n-                      dependentAttemptId: dependentAttempt.id,\n-                    },\n-                  });\n-                } else if (dependentBatchRun) {\n-                  await tx.taskRunDependency.create({\n-                    data: {\n-                      taskRunId: taskRun.id,\n-                      dependentBatchRunId: dependentBatchRun.id,\n-                    },\n-                  });\n-                }\n-\n-                if (body.options?.queue) {\n-                  const concurrencyLimit =\n-                    typeof body.options.queue?.concurrencyLimit === \"number\"\n-                      ? Math.max(\n-                          Math.min(\n-                            body.options.queue.concurrencyLimit,\n-                            environment.maximumConcurrencyLimit\n-                          ),\n-                          0\n-                        )\n-                      : body.options.queue?.concurrencyLimit;\n-\n-                  let taskQueue = await tx.taskQueue.findFirst({\n-                    where: {\n-                      runtimeEnvironmentId: environment.id,\n-                      name: queueName,\n-                    },\n-                  });\n-\n-                  if (!taskQueue) {\n-                    // handle conflicts with existing queues\n-                    taskQueue = await tx.taskQueue.create({\n-                      data: {\n-                        friendlyId: generateFriendlyId(\"queue\"),\n-                        name: queueName,\n-                        concurrencyLimit,\n-                        runtimeEnvironmentId: environment.id,\n-                        projectId: environment.projectId,\n-                        type: \"NAMED\",\n-                      },\n-                    });\n-                  }\n-\n-                  if (typeof concurrencyLimit === \"number\") {\n-                    logger.debug(\"TriggerTaskService: updating concurrency limit\", {\n-                      runId: taskRun.id,\n-                      friendlyId: taskRun.friendlyId,\n-                      taskQueue,\n-                      orgId: environment.organizationId,\n-                      projectId: environment.projectId,\n-                      concurrencyLimit,\n-                      queueOptions: body.options?.queue,\n-                    });\n-\n-                    await updateQueueConcurrencyLimits(\n-                      environment,\n-                      taskQueue.name,\n-                      concurrencyLimit\n-                    );\n-                  } else if (concurrencyLimit === null) {\n-                    logger.debug(\"TriggerTaskService: removing concurrency limit\", {\n-                      runId: taskRun.id,\n-                      friendlyId: taskRun.friendlyId,\n-                      taskQueue,\n-                      orgId: environment.organizationId,\n-                      projectId: environment.projectId,\n-                      queueOptions: body.options?.queue,\n-                    });\n-\n-                    await removeQueueConcurrencyLimits(environment, taskQueue.name);\n-                  }\n-                }\n-\n-                if (taskRun.delayUntil) {\n-                  await EnqueueDelayedRunService.enqueue(taskRun.id, taskRun.delayUntil);\n-                }\n-\n-                if (!taskRun.delayUntil && taskRun.ttl) {\n-                  const expireAt = parseNaturalLanguageDuration(taskRun.ttl);\n-\n-                  if (expireAt) {\n-                    await ExpireEnqueuedRunService.enqueue(taskRun.id, expireAt);\n-                  }\n-                }\n-\n-                return taskRun;\n-              },\n-              async (_, tx) => {\n-                const counter = await tx.taskRunNumberCounter.findUnique({\n-                  where: {\n-                    taskIdentifier_environmentId: {\n-                      taskIdentifier: taskId,\n-                      environmentId: environment.id,\n-                    },\n-                  },\n-                  select: { lastNumber: true },\n-                });\n-\n-                return counter?.lastNumber;\n-              },\n-              this._prisma\n-            );\n-\n-            if (!run) {\n-              return;\n-            }\n-\n-            // Now enqueue the run if it's not delayed\n-            if (run.status === \"PENDING\") {\n-              const enqueueResult = await enqueueRun({\n-                env: environment,\n-                run,\n-                dependentRun:\n-                  dependentAttempt?.taskRun ?? dependentBatchRun?.dependentTaskAttempt?.taskRun,\n-              });\n-\n-              if (!enqueueResult.ok) {\n-                // Now we need to fail the run with enqueueResult.error and make sure and\n-                // set the traced event to failed as well\n-                await this._prisma.taskRun.update({\n-                  where: { id: run.id },\n-                  data: {\n-                    status: \"SYSTEM_FAILURE\",\n-                    completedAt: new Date(),\n-                    error: enqueueResult.error,\n-                  },\n-                });\n-\n-                event.failWithError(enqueueResult.error);\n-\n-                return {\n-                  run,\n-                  isCached: false,\n-                  error: enqueueResult.error,\n-                };\n-              }\n-            }\n-\n-            return { run, isCached: false };\n-          }\n-        );\n-\n-        if (result?.error) {\n-          throw new ServiceValidationError(\n-            taskRunErrorToString(taskRunErrorEnhancer(result.error))\n-          );\n-        }\n-\n-        const run = result?.run;\n-\n-        if (!run) {\n-          return;\n-        }\n-\n-        return {\n-          run,\n-          isCached: result?.isCached,\n-        };\n-      } catch (error) {\n-        // Detect a prisma transaction Unique constraint violation\n-        if (error instanceof Prisma.PrismaClientKnownRequestError) {\n-          logger.debug(\"TriggerTask: Prisma transaction error\", {\n-            code: error.code,\n-            message: error.message,\n-            meta: error.meta,\n-          });\n-\n-          if (error.code === \"P2002\") {\n-            const target = error.meta?.target;\n-\n-            if (\n-              Array.isArray(target) &&\n-              target.length > 0 &&\n-              typeof target[0] === \"string\" &&\n-              target[0].includes(\"oneTimeUseToken\")\n-            ) {\n-              throw new ServiceValidationError(\n-                `Cannot trigger ${taskId} with a one-time use token as it has already been used.`\n-              );\n-            } else if (\n-              Array.isArray(target) &&\n-              target.length == 2 &&\n-              typeof target[0] === \"string\" &&\n-              typeof target[1] === \"string\" &&\n-              target[0] == \"runtimeEnvironmentId\" &&\n-              target[1] == \"name\" &&\n-              error.message.includes(\"prisma.taskQueue.create\")\n-            ) {\n-              throw new Error(\n-                `Failed to trigger ${taskId} as the queue could not be created do to a unique constraint error, please try again.`\n-              );\n-            } else if (\n-              Array.isArray(target) &&\n-              target.length == 3 &&\n-              typeof target[0] === \"string\" &&\n-              typeof target[1] === \"string\" &&\n-              typeof target[2] === \"string\" &&\n-              target[0] == \"runtimeEnvironmentId\" &&\n-              target[1] == \"taskIdentifier\" &&\n-              target[2] == \"idempotencyKey\"\n-            ) {\n-              logger.debug(\"TriggerTask: Idempotency key violation, retrying...\", {\n-                taskId,\n-                environmentId: environment.id,\n-                idempotencyKey,\n-              });\n-              // We need to retry the task run creation as the idempotency key has been used\n-              return await this.call(taskId, environment, body, options, attempt + 1);\n-            } else {\n-              throw new ServiceValidationError(\n-                `Cannot trigger ${taskId} as it has already been triggered with the same idempotency key.`\n-              );\n-            }\n-          }\n-        }\n-\n-        throw error;\n-      }\n-    });\n-  }\n-\n-  async #getQueueName(taskId: string, environment: AuthenticatedEnvironment, queueName?: string) {\n-    if (queueName) {\n-      return queueName;\n-    }\n-\n-    const defaultQueueName = `task/${taskId}`;\n-\n-    const worker = await findCurrentWorkerFromEnvironment(environment);\n-\n-    if (!worker) {\n-      logger.debug(\"Failed to get queue name: No worker found\", {\n-        taskId,\n-        environmentId: environment.id,\n-      });\n-\n-      return defaultQueueName;\n-    }\n-\n-    const task = await this._prisma.backgroundWorkerTask.findFirst({\n-      where: {\n-        workerId: worker.id,\n-        slug: taskId,\n-      },\n-    });\n-\n-    if (!task) {\n-      console.log(\"Failed to get queue name: No task found\", {\n-        taskId,\n-        environmentId: environment.id,\n-      });\n-\n-      return defaultQueueName;\n-    }\n-\n-    const queueConfig = QueueOptions.optional().nullable().safeParse(task.queueConfig);\n-\n-    if (!queueConfig.success) {\n-      console.log(\"Failed to get queue name: Invalid queue config\", {\n-        taskId,\n-        environmentId: environment.id,\n-        queueConfig: task.queueConfig,\n-      });\n-\n-      return defaultQueueName;\n-    }\n-\n-    return queueConfig.data?.name ?? defaultQueueName;\n-  }\n-\n-  async #handlePayloadPacket(\n-    payload: any,\n-    payloadType: string,\n-    pathPrefix: string,\n-    environment: AuthenticatedEnvironment\n-  ) {\n-    return await startActiveSpan(\"handlePayloadPacket()\", async (span) => {\n-      const packet = this.#createPayloadPacket(payload, payloadType);\n-\n-      if (!packet.data) {\n-        return packet;\n-      }\n-\n-      const { needsOffloading, size } = packetRequiresOffloading(\n-        packet,\n-        env.TASK_PAYLOAD_OFFLOAD_THRESHOLD\n-      );\n-\n-      if (!needsOffloading) {\n-        return packet;\n-      }\n-\n-      const filename = `${pathPrefix}/payload.json`;\n-\n-      await uploadPacketToObjectStore(filename, packet.data, packet.dataType, environment);\n-\n-      return {\n-        data: filename,\n-        dataType: \"application/store\",\n-      };\n-    });\n-  }\n-\n-  #createPayloadPacket(payload: any, payloadType: string): IOPacket {\n-    if (payloadType === \"application/json\") {\n-      return { data: JSON.stringify(payload), dataType: \"application/json\" };\n-    }\n-\n-    if (typeof payload === \"string\") {\n-      return { data: payload, dataType: payloadType };\n-    }\n-\n-    return { dataType: payloadType };\n-  }\n-}\n+                    concurrencyKey: body.options?.concurrencyKey,\n\\ No newline at end of file\ndiff --git a/apps/webapp/test/engine/triggerTask.test.ts b/apps/webapp/test/engine/triggerTask.test.ts\nindex aa0e059..178e29e 100644\n--- a/apps/webapp/test/engine/triggerTask.test.ts\n+++ b/apps/webapp/test/engine/triggerTask.test.ts\n@@ -79,7 +79,6 @@ class MockTriggerTaskValidator implements TriggerTaskValidator {\n class MockTraceEventConcern implements TraceEventConcern {\n   async traceRun<T>(\n     request: TriggerTaskRequest,\n-    parentStore: string | undefined,\n     callback: (span: TracedEventSpan, store: string) => Promise<T>\n   ): Promise<T> {\n     return await callback(\n@@ -97,7 +96,6 @@ class MockTraceEventConcern implements TraceEventConcern {\n \n   async traceIdempotentRun<T>(\n     request: TriggerTaskRequest,\n-    parentStore: string | undefined,\n     options: {\n       existingRun: TaskRun;\n       idempotencyKey: string;\n@@ -464,271 +462,4 @@ describe(\"RunEngineTriggerTaskService\", () => {\n         engine,\n         prisma,\n         runNumberIncrementer: new MockRunNumberIncrementer(),\n-        payloadProcessor: new MockPayloadProcessor(),\n-        queueConcern: queuesManager,\n-        idempotencyKeyConcern,\n-        validator: new MockTriggerTaskValidator(),\n-        traceEventConcern: new MockTraceEventConcern(),\n-        tracer: trace.getTracer(\"test\", \"0.0.0\"),\n-        metadataMaximumSize: 1024 * 1024 * 1, // 1MB\n-        triggerRacepointSystem,\n-      });\n-\n-      const idempotencyKey = \"test-idempotency-key\";\n-\n-      const racepoint = triggerRacepointSystem.registerRacepoint(\"idempotencyKey\", idempotencyKey);\n-\n-      const childTriggerPromise1 = triggerTaskService.call({\n-        taskId: taskIdentifier,\n-        environment: authenticatedEnvironment,\n-        body: {\n-          payload: { test: \"test\" },\n-          options: {\n-            idempotencyKey,\n-            parentRunId: parentRun1.friendlyId,\n-            resumeParentOnCompletion: true,\n-          },\n-        },\n-      });\n-\n-      const childTriggerPromise2 = triggerTaskService.call({\n-        taskId: taskIdentifier,\n-        environment: authenticatedEnvironment,\n-        body: {\n-          payload: { test: \"test\" },\n-          options: {\n-            idempotencyKey,\n-            parentRunId: parentRun2.friendlyId,\n-            resumeParentOnCompletion: true,\n-          },\n-        },\n-      });\n-\n-      await setTimeout(500);\n-\n-      // Now we can resolve the racepoint\n-      racepoint.resolve();\n-\n-      const result = await childTriggerPromise1;\n-      const result2 = await childTriggerPromise2;\n-\n-      expect(result).toBeDefined();\n-      expect(result?.run.friendlyId).toBeDefined();\n-      expect(result?.run.status).toBe(\"PENDING\");\n-\n-      const run = await prisma.taskRun.findUnique({\n-        where: {\n-          id: result?.run.id,\n-        },\n-      });\n-\n-      expect(run).toBeDefined();\n-      expect(run?.friendlyId).toBe(result?.run.friendlyId);\n-      expect(run?.engine).toBe(\"V2\");\n-      expect(run?.queuedAt).toBeDefined();\n-      expect(run?.queue).toBe(`task/${taskIdentifier}`);\n-\n-      expect(result2).toBeDefined();\n-      expect(result2?.run.friendlyId).toBe(result?.run.friendlyId);\n-\n-      const parent1ExecutionData = await engine.getRunExecutionData({ runId: parentRun1.id });\n-      assertNonNullable(parent1ExecutionData);\n-      expect(parent1ExecutionData.snapshot.executionStatus).toBe(\"EXECUTING_WITH_WAITPOINTS\");\n-\n-      const parent2ExecutionData = await engine.getRunExecutionData({ runId: parentRun2.id });\n-      assertNonNullable(parent2ExecutionData);\n-      expect(parent2ExecutionData.snapshot.executionStatus).toBe(\"EXECUTING_WITH_WAITPOINTS\");\n-\n-      const parent1RunWaitpoint = await prisma.taskRunWaitpoint.findFirst({\n-        where: {\n-          taskRunId: parentRun1.id,\n-        },\n-        include: {\n-          waitpoint: true,\n-        },\n-      });\n-\n-      assertNonNullable(parent1RunWaitpoint);\n-      expect(parent1RunWaitpoint.waitpoint.type).toBe(\"RUN\");\n-      expect(parent1RunWaitpoint.waitpoint.completedByTaskRunId).toBe(result?.run.id);\n-\n-      const parent2RunWaitpoint = await prisma.taskRunWaitpoint.findFirst({\n-        where: {\n-          taskRunId: parentRun2.id,\n-        },\n-        include: {\n-          waitpoint: true,\n-        },\n-      });\n-\n-      assertNonNullable(parent2RunWaitpoint);\n-      expect(parent2RunWaitpoint.waitpoint.type).toBe(\"RUN\");\n-      expect(parent2RunWaitpoint.waitpoint.completedByTaskRunId).toBe(result2?.run.id);\n-\n-      await engine.quit();\n-    }\n-  );\n-\n-  containerTest(\n-    \"should resolve queue names correctly when locked to version\",\n-    async ({ prisma, redisOptions }) => {\n-      const engine = new RunEngine({\n-        prisma,\n-        worker: {\n-          redis: redisOptions,\n-          workers: 1,\n-          tasksPerWorker: 10,\n-          pollIntervalMs: 100,\n-        },\n-        queue: {\n-          redis: redisOptions,\n-        },\n-        runLock: {\n-          redis: redisOptions,\n-        },\n-        machines: {\n-          defaultMachine: \"small-1x\",\n-          machines: {\n-            \"small-1x\": {\n-              name: \"small-1x\" as const,\n-              cpu: 0.5,\n-              memory: 0.5,\n-              centsPerMs: 0.0001,\n-            },\n-          },\n-          baseCostInCents: 0.0005,\n-        },\n-        tracer: trace.getTracer(\"test\", \"0.0.0\"),\n-      });\n-\n-      const authenticatedEnvironment = await setupAuthenticatedEnvironment(prisma, \"PRODUCTION\");\n-      const taskIdentifier = \"test-task\";\n-\n-      // Create a background worker with a specific version\n-      const worker = await setupBackgroundWorker(engine, authenticatedEnvironment, taskIdentifier, {\n-        preset: \"small-1x\",\n-      });\n-\n-      // Create a specific queue for this worker\n-      const specificQueue = await prisma.taskQueue.create({\n-        data: {\n-          name: \"specific-queue\",\n-          friendlyId: \"specific-queue\",\n-          projectId: authenticatedEnvironment.projectId,\n-          runtimeEnvironmentId: authenticatedEnvironment.id,\n-          workers: {\n-            connect: {\n-              id: worker.worker.id,\n-            },\n-          },\n-        },\n-      });\n-\n-      // Associate the task with the queue\n-      await prisma.backgroundWorkerTask.update({\n-        where: {\n-          workerId_slug: {\n-            workerId: worker.worker.id,\n-            slug: taskIdentifier,\n-          },\n-        },\n-        data: {\n-          queueId: specificQueue.id,\n-        },\n-      });\n-\n-      const queuesManager = new DefaultQueueManager(prisma, engine);\n-      const idempotencyKeyConcern = new IdempotencyKeyConcern(\n-        prisma,\n-        engine,\n-        new MockTraceEventConcern()\n-      );\n-\n-      const triggerTaskService = new RunEngineTriggerTaskService({\n-        engine,\n-        prisma,\n-        runNumberIncrementer: new MockRunNumberIncrementer(),\n-        payloadProcessor: new MockPayloadProcessor(),\n-        queueConcern: queuesManager,\n-        idempotencyKeyConcern,\n-        validator: new MockTriggerTaskValidator(),\n-        traceEventConcern: new MockTraceEventConcern(),\n-        tracer: trace.getTracer(\"test\", \"0.0.0\"),\n-        metadataMaximumSize: 1024 * 1024 * 1, // 1MB\n-      });\n-\n-      // Test case 1: Trigger with lockToVersion but no specific queue\n-      const result1 = await triggerTaskService.call({\n-        taskId: taskIdentifier,\n-        environment: authenticatedEnvironment,\n-        body: {\n-          payload: { test: \"test\" },\n-          options: {\n-            lockToVersion: worker.worker.version,\n-          },\n-        },\n-      });\n-\n-      expect(result1).toBeDefined();\n-      expect(result1?.run.queue).toBe(\"specific-queue\");\n-\n-      // Test case 2: Trigger with lockToVersion and specific queue\n-      const result2 = await triggerTaskService.call({\n-        taskId: taskIdentifier,\n-        environment: authenticatedEnvironment,\n-        body: {\n-          payload: { test: \"test\" },\n-          options: {\n-            lockToVersion: worker.worker.version,\n-            queue: {\n-              name: \"specific-queue\",\n-            },\n-          },\n-        },\n-      });\n-\n-      expect(result2).toBeDefined();\n-      expect(result2?.run.queue).toBe(\"specific-queue\");\n-      expect(result2?.run.lockedQueueId).toBe(specificQueue.id);\n-\n-      // Test case 3: Try to use non-existent queue with locked version (should throw)\n-      await expect(\n-        triggerTaskService.call({\n-          taskId: taskIdentifier,\n-          environment: authenticatedEnvironment,\n-          body: {\n-            payload: { test: \"test\" },\n-            options: {\n-              lockToVersion: worker.worker.version,\n-              queue: {\n-                name: \"non-existent-queue\",\n-              },\n-            },\n-          },\n-        })\n-      ).rejects.toThrow(\n-        `Specified queue 'non-existent-queue' not found or not associated with locked version '${worker.worker.version}'`\n-      );\n-\n-      // Test case 4: Trigger with a non-existent queue without a locked version\n-      const result4 = await triggerTaskService.call({\n-        taskId: taskIdentifier,\n-        environment: authenticatedEnvironment,\n-        body: {\n-          payload: { test: \"test\" },\n-          options: {\n-            queue: {\n-              name: \"non-existent-queue\",\n-            },\n-          },\n-        },\n-      });\n-\n-      expect(result4).toBeDefined();\n-      expect(result4?.run.queue).toBe(\"non-existent-queue\");\n-      expect(result4?.run.status).toBe(\"PENDING\");\n-\n-      await engine.quit();\n-    }\n-  );\n-});\n+        payloadProcessor: new MockPayloadProcessor(),\n\\ No newline at end of file\n"
  },
  {
    "instance_id": "triggerdotdev__trigger.dev.d1c3bfb9.2669",
    "repo": "triggerdotdev__trigger.dev.d1c3bfb9",
    "base_commit": "d0ad38d684dda13c2accdd81a818822e4d985f88",
    "head_commit": "1289a3150d3791a3527aeb6b7823d8ea415177e3",
    "title": "fix(streams): buffer v1 streams on read to prevent split chunks",
    "merged_at": "2025-11-11T21:08:49Z",
    "html_url": "https://github.com/triggerdotdev/trigger.dev/pull/2669",
    "test_files": [
      "apps/webapp/test/redisRealtimeStreams.test.ts"
    ],
    "code_files": [
      "apps/webapp/app/services/realtime/redisRealtimeStreams.server.ts",
      "references/realtime-streams/src/trigger/streams.ts"
    ],
    "total_changes": 163,
    "num_files": 3,
    "pull_number": 2669,
    "patch": "diff --git a/apps/webapp/app/services/realtime/redisRealtimeStreams.server.ts b/apps/webapp/app/services/realtime/redisRealtimeStreams.server.ts\nindex 9db3809b52..b5c8c57322 100644\n--- a/apps/webapp/app/services/realtime/redisRealtimeStreams.server.ts\n+++ b/apps/webapp/app/services/realtime/redisRealtimeStreams.server.ts\n@@ -204,20 +204,52 @@ export class RedisRealtimeStreams implements StreamIngestor, StreamResponder {\n       },\n     })\n       .pipeThrough(\n-        // Transform 1: Split data content by newlines, preserving metadata\n-        new TransformStream<StreamChunk, StreamChunk & { line?: string }>({\n-          transform(chunk, controller) {\n-            if (chunk.type === \"ping\") {\n-              controller.enqueue(chunk);\n-            } else if (chunk.type === \"data\" || chunk.type === \"legacy-data\") {\n-              // Split data by newlines, emit separate chunks with same metadata\n-              const lines = chunk.data.split(\"\\n\").filter((line) => line.trim().length > 0);\n-              for (const line of lines) {\n-                controller.enqueue({ ...chunk, line });\n+        // Transform 1: Buffer partial lines across Redis entries\n+        (() => {\n+          let buffer = \"\";\n+          let lastRedisId = \"0\";\n+\n+          return new TransformStream<StreamChunk, StreamChunk & { line: string }>({\n+            transform(chunk, controller) {\n+              if (chunk.type === \"ping\") {\n+                controller.enqueue(chunk as any);\n+              } else if (chunk.type === \"data\" || chunk.type === \"legacy-data\") {\n+                // Buffer partial lines: accumulate until we see newlines\n+                buffer += chunk.data;\n+\n+                // Split on newlines\n+                const lines = buffer.split(\"\\n\");\n+\n+                // The last element might be incomplete, hold it back in buffer\n+                buffer = lines.pop() || \"\";\n+\n+                // Emit complete lines with the Redis ID of the chunk that completed them\n+                for (const line of lines) {\n+                  if (line.trim().length > 0) {\n+                    controller.enqueue({\n+                      ...chunk,\n+                      line,\n+                    });\n+                  }\n+                }\n+\n+                // Update last Redis ID for next iteration\n+                lastRedisId = chunk.redisId;\n               }\n-            }\n-          },\n-        })\n+            },\n+            flush(controller) {\n+              // On stream end, emit any leftover buffered text\n+              if (buffer.trim().length > 0) {\n+                controller.enqueue({\n+                  type: \"data\",\n+                  redisId: lastRedisId,\n+                  data: \"\",\n+                  line: buffer.trim(),\n+                });\n+              }\n+            },\n+          });\n+        })()\n       )\n       .pipeThrough(\n         // Transform 2: Format as SSE\ndiff --git a/apps/webapp/test/redisRealtimeStreams.test.ts b/apps/webapp/test/redisRealtimeStreams.test.ts\nindex e441e4ace6..0511754393 100644\n--- a/apps/webapp/test/redisRealtimeStreams.test.ts\n+++ b/apps/webapp/test/redisRealtimeStreams.test.ts\n@@ -1417,4 +1417,108 @@ describe(\"RedisRealtimeStreams\", () => {\n       await redis.quit();\n     }\n   );\n+\n+  redisTest(\n+    \"Should handle chunks split mid-line (regression test)\",\n+    { timeout: 30_000 },\n+    async ({ redisOptions }) => {\n+      const redis = new Redis(redisOptions);\n+      const redisRealtimeStreams = new RedisRealtimeStreams({\n+        redis: redisOptions,\n+      });\n+\n+      const runId = \"run_split_test\";\n+      const streamId = \"test-split-stream\";\n+\n+      // Simulate what happens in production: a JSON line split across multiple network chunks\n+      // This reproduces the issue where we see partial chunks like:\n+      // - \"{\\\"timestamp\\\":\"\n+      // - \"1762880245493,\\\"chunkIndex\\\":780,\\\"data\\\":\\\"Chunk 781/1000\\\"}\"\n+      const fullLine = JSON.stringify({\n+        timestamp: 1762880245493,\n+        chunkIndex: 780,\n+        data: \"Chunk 781/1000\",\n+      });\n+\n+      // Split the line at an arbitrary position (in the middle of the JSON)\n+      const splitPoint = 16; // Splits after '{\"timestamp\":'\n+      const chunk1 = fullLine.substring(0, splitPoint);\n+      const chunk2 = fullLine.substring(splitPoint);\n+\n+      // Create a ReadableStream that sends split chunks\n+      const encoder = new TextEncoder();\n+      const stream = new ReadableStream({\n+        start(controller) {\n+          controller.enqueue(encoder.encode(chunk1));\n+          controller.enqueue(encoder.encode(chunk2 + \"\\n\")); // Add newline at end\n+          controller.close();\n+        },\n+      });\n+\n+      // Ingest the split data\n+      await redisRealtimeStreams.ingestData(stream, runId, streamId, \"client1\");\n+\n+      // Now consume the stream and verify we get the complete line, not split chunks\n+      const abortController = new AbortController();\n+      const response = await redisRealtimeStreams.streamResponse(\n+        new Request(\"http://localhost/test\"),\n+        runId,\n+        streamId,\n+        abortController.signal\n+      );\n+\n+      const reader = response.body!.getReader();\n+      const decoder = new TextDecoder();\n+      let receivedData = \"\";\n+\n+      // Read all chunks from the response\n+      const readTimeout = setTimeout(() => {\n+        abortController.abort();\n+      }, 5000);\n+\n+      try {\n+        while (true) {\n+          const { done, value } = await reader.read();\n+          if (done) break;\n+\n+          receivedData += decoder.decode(value, { stream: true });\n+\n+          // Once we have data, we can stop\n+          if (receivedData.includes(\"data: \")) {\n+            break;\n+          }\n+        }\n+      } finally {\n+        clearTimeout(readTimeout);\n+        abortController.abort();\n+        reader.releaseLock();\n+      }\n+\n+      // Parse the SSE data\n+      const lines = receivedData.split(\"\\n\").filter((line) => line.startsWith(\"data: \"));\n+\n+      // We should receive exactly ONE complete line, not two partial lines\n+      expect(lines.length).toBe(1);\n+\n+      // Extract the data (remove \"data: \" prefix)\n+      const dataLine = lines[0].substring(6);\n+\n+      // Verify it's the complete, valid JSON\n+      expect(dataLine).toBe(fullLine);\n+\n+      // Verify it parses correctly as JSON\n+      const parsed = JSON.parse(dataLine) as {\n+        timestamp: number;\n+        chunkIndex: number;\n+        data: string;\n+      };\n+      expect(parsed.timestamp).toBe(1762880245493);\n+      expect(parsed.chunkIndex).toBe(780);\n+      expect(parsed.data).toBe(\"Chunk 781/1000\");\n+\n+      // Cleanup\n+      await redis.del(`stream:${runId}:${streamId}`);\n+      await redis.quit();\n+    }\n+  );\n });\ndiff --git a/references/realtime-streams/src/trigger/streams.ts b/references/realtime-streams/src/trigger/streams.ts\nindex cfa64618ce..388ff960aa 100644\n--- a/references/realtime-streams/src/trigger/streams.ts\n+++ b/references/realtime-streams/src/trigger/streams.ts\n@@ -822,7 +822,6 @@ const streamsStressTesterTask = task({\n \n     switch (payload.streamsVersion) {\n       case \"v1\": {\n-        assert.ok(chunks.length < 2000, \"Expected less than 2000 chunks\");\n         break;\n       }\n       case \"v2\": {\n",
    "test_patch": "",
    "problem_statement": "",
    "hints_text": "",
    "pr_mirror": "triggerdotdev__trigger.dev.d1c3bfb9",
    "bug_patch": "diff --git a/apps/webapp/app/services/realtime/redisRealtimeStreams.server.ts b/apps/webapp/app/services/realtime/redisRealtimeStreams.server.ts\nindex 25fb2d0..45d80c1 100644\n--- a/apps/webapp/app/services/realtime/redisRealtimeStreams.server.ts\n+++ b/apps/webapp/app/services/realtime/redisRealtimeStreams.server.ts\n@@ -204,52 +204,20 @@ export class RedisRealtimeStreams implements StreamIngestor, StreamResponder {\n       },\n     })\n       .pipeThrough(\n-        // Transform 1: Buffer partial lines across Redis entries\n-        (() => {\n-          let buffer = \"\";\n-          let lastRedisId = \"0\";\n-\n-          return new TransformStream<StreamChunk, StreamChunk & { line: string }>({\n-            transform(chunk, controller) {\n-              if (chunk.type === \"ping\") {\n-                controller.enqueue(chunk as any);\n-              } else if (chunk.type === \"data\" || chunk.type === \"legacy-data\") {\n-                // Buffer partial lines: accumulate until we see newlines\n-                buffer += chunk.data;\n-\n-                // Split on newlines\n-                const lines = buffer.split(\"\\n\");\n-\n-                // The last element might be incomplete, hold it back in buffer\n-                buffer = lines.pop() || \"\";\n-\n-                // Emit complete lines with the Redis ID of the chunk that completed them\n-                for (const line of lines) {\n-                  if (line.trim().length > 0) {\n-                    controller.enqueue({\n-                      ...chunk,\n-                      line,\n-                    });\n-                  }\n-                }\n-\n-                // Update last Redis ID for next iteration\n-                lastRedisId = chunk.redisId;\n-              }\n-            },\n-            flush(controller) {\n-              // On stream end, emit any leftover buffered text\n-              if (buffer.trim().length > 0) {\n-                controller.enqueue({\n-                  type: \"data\",\n-                  redisId: lastRedisId,\n-                  data: \"\",\n-                  line: buffer.trim(),\n-                });\n+        // Transform 1: Split data content by newlines, preserving metadata\n+        new TransformStream<StreamChunk, StreamChunk & { line?: string }>({\n+          transform(chunk, controller) {\n+            if (chunk.type === \"ping\") {\n+              controller.enqueue(chunk);\n+            } else if (chunk.type === \"data\" || chunk.type === \"legacy-data\") {\n+              // Split data by newlines, emit separate chunks with same metadata\n+              const lines = chunk.data.split(\"\\n\").filter((line) => line.trim().length > 0);\n+              for (const line of lines) {\n+                controller.enqueue({ ...chunk, line });\n               }\n-            },\n-          });\n-        })()\n+            }\n+          },\n+        })\n       )\n       .pipeThrough(\n         // Transform 2: Format as SSE\n@@ -466,4 +434,4 @@ export class RedisRealtimeStreams implements StreamIngestor, StreamResponder {\n       });\n     }\n   }\n-}\n+}\n\\ No newline at end of file\ndiff --git a/apps/webapp/test/redisRealtimeStreams.test.ts b/apps/webapp/test/redisRealtimeStreams.test.ts\nindex 0511754..27a70f8 100644\n--- a/apps/webapp/test/redisRealtimeStreams.test.ts\n+++ b/apps/webapp/test/redisRealtimeStreams.test.ts\n@@ -445,1080 +445,4 @@ describe(\"RedisRealtimeStreams\", () => {\n       const mockRequest = new Request(\"http://localhost/test\");\n       const abortController = new AbortController();\n \n-      const response = await redisRealtimeStreams.streamResponse(\n-        mockRequest,\n-        runId,\n-        streamId,\n-        abortController.signal\n-      );\n-\n-      expect(response.status).toBe(200);\n-\n-      // Read the stream\n-      const reader = response.body!.getReader();\n-      const decoder = new TextDecoder();\n-      const receivedData: string[] = [];\n-\n-      let done = false;\n-      while (!done && receivedData.length < 2) {\n-        const { value, done: streamDone } = await reader.read();\n-        done = streamDone;\n-\n-        if (value) {\n-          const text = decoder.decode(value);\n-          const events = text.split(\"\\n\\n\").filter((event) => event.trim());\n-          for (const event of events) {\n-            const lines = event.split(\"\\n\");\n-            for (const line of lines) {\n-              if (line.startsWith(\"data: \")) {\n-                const data = line.substring(6).trim();\n-                if (data) {\n-                  receivedData.push(data);\n-                }\n-              }\n-            }\n-          }\n-        }\n-      }\n-\n-      // Cancel the stream\n-      abortController.abort();\n-      reader.releaseLock();\n-\n-      // Verify we received both legacy chunks\n-      expect(receivedData.length).toBe(2);\n-      expect(receivedData[0]).toBe(\"legacy chunk 1\");\n-      expect(receivedData[1]).toBe(\"legacy chunk 2\");\n-\n-      // getLastChunkIndex should return -1 for legacy format (no chunkIndex field)\n-      const lastChunkIndex = await redisRealtimeStreams.getLastChunkIndex(\n-        runId,\n-        streamId,\n-        \"default\"\n-      );\n-      expect(lastChunkIndex).toBe(-1);\n-\n-      // Cleanup\n-      await redis.del(streamKey);\n-      await redis.quit();\n-    }\n-  );\n-\n-  redisTest(\n-    \"Should handle concurrent ingestion to the same stream\",\n-    { timeout: 30_000 },\n-    async ({ redisOptions }) => {\n-      const redis = new Redis(redisOptions);\n-      const redisRealtimeStreams = new RedisRealtimeStreams({\n-        redis: redisOptions,\n-      });\n-\n-      const runId = \"run_concurrent_test\";\n-      const streamId = \"concurrent-stream\";\n-\n-      // Create two sets of chunks that will be ingested concurrently\n-      const chunks1 = [\n-        JSON.stringify({ source: \"A\", chunk: 0, data: \"A-chunk 0\" }),\n-        JSON.stringify({ source: \"A\", chunk: 1, data: \"A-chunk 1\" }),\n-        JSON.stringify({ source: \"A\", chunk: 2, data: \"A-chunk 2\" }),\n-      ];\n-\n-      const chunks2 = [\n-        JSON.stringify({ source: \"B\", chunk: 0, data: \"B-chunk 0\" }),\n-        JSON.stringify({ source: \"B\", chunk: 1, data: \"B-chunk 1\" }),\n-        JSON.stringify({ source: \"B\", chunk: 2, data: \"B-chunk 2\" }),\n-      ];\n-\n-      const encoder = new TextEncoder();\n-\n-      // Create two streams\n-      const stream1 = new ReadableStream({\n-        start(controller) {\n-          for (const chunk of chunks1) {\n-            controller.enqueue(encoder.encode(chunk + \"\\n\"));\n-          }\n-          controller.close();\n-        },\n-      });\n-\n-      const stream2 = new ReadableStream({\n-        start(controller) {\n-          for (const chunk of chunks2) {\n-            controller.enqueue(encoder.encode(chunk + \"\\n\"));\n-          }\n-          controller.close();\n-        },\n-      });\n-\n-      // Ingest both streams concurrently - both starting from chunk 0\n-      // Note: Using the same clientId will cause duplicate chunk indices (not recommended in practice)\n-      const [response1, response2] = await Promise.all([\n-        redisRealtimeStreams.ingestData(stream1, runId, streamId, \"default\", 0),\n-        redisRealtimeStreams.ingestData(stream2, runId, streamId, \"default\", 0),\n-      ]);\n-\n-      expect(response1.status).toBe(200);\n-      expect(response2.status).toBe(200);\n-\n-      // Verify both sets of chunks were stored\n-      const streamKey = `stream:${runId}:${streamId}`;\n-      const entries = await redis.xrange(streamKey, \"-\", \"+\");\n-\n-      // Should have 6 total chunks (3 from each stream)\n-      expect(entries.length).toBe(6);\n-\n-      // Verify we have chunks from both sources (though order may be interleaved)\n-      const sourceACounts = entries.filter(([_id, fields]) => {\n-        for (let j = 0; j < fields.length; j += 2) {\n-          if (fields[j] === \"data\" && fields[j + 1].includes('\"source\":\"A\"')) {\n-            return true;\n-          }\n-        }\n-        return false;\n-      });\n-\n-      const sourceBCounts = entries.filter(([_id, fields]) => {\n-        for (let j = 0; j < fields.length; j += 2) {\n-          if (fields[j] === \"data\" && fields[j + 1].includes('\"source\":\"B\"')) {\n-            return true;\n-          }\n-        }\n-        return false;\n-      });\n-\n-      expect(sourceACounts.length).toBe(3);\n-      expect(sourceBCounts.length).toBe(3);\n-\n-      // Note: Both streams write chunks 0, 1, 2, so we'll have duplicate indices\n-      // This is expected behavior - the last-write-wins with Redis XADD\n-\n-      // Cleanup\n-      await redis.del(streamKey);\n-      await redis.quit();\n-    }\n-  );\n-\n-  redisTest(\n-    \"Should handle concurrent ingestion with different clients and resume points\",\n-    { timeout: 30_000 },\n-    async ({ redisOptions }) => {\n-      const redis = new Redis(redisOptions);\n-      const redisRealtimeStreams = new RedisRealtimeStreams({\n-        redis: redisOptions,\n-      });\n-\n-      const runId = \"run_concurrent_resume_test\";\n-      const streamId = \"concurrent-resume-stream\";\n-\n-      // Client A writes initial chunks 0-2\n-      const clientAInitial = [\n-        JSON.stringify({ client: \"A\", phase: \"initial\", chunk: 0 }),\n-        JSON.stringify({ client: \"A\", phase: \"initial\", chunk: 1 }),\n-        JSON.stringify({ client: \"A\", phase: \"initial\", chunk: 2 }),\n-      ];\n-\n-      const encoder = new TextEncoder();\n-      const streamA1 = new ReadableStream({\n-        start(controller) {\n-          for (const chunk of clientAInitial) {\n-            controller.enqueue(encoder.encode(chunk + \"\\n\"));\n-          }\n-          controller.close();\n-        },\n-      });\n-\n-      await redisRealtimeStreams.ingestData(streamA1, runId, streamId, \"client-A\", 0);\n-\n-      // Client B writes initial chunks 0-1\n-      const clientBInitial = [\n-        JSON.stringify({ client: \"B\", phase: \"initial\", chunk: 0 }),\n-        JSON.stringify({ client: \"B\", phase: \"initial\", chunk: 1 }),\n-      ];\n-\n-      const streamB1 = new ReadableStream({\n-        start(controller) {\n-          for (const chunk of clientBInitial) {\n-            controller.enqueue(encoder.encode(chunk + \"\\n\"));\n-          }\n-          controller.close();\n-        },\n-      });\n-\n-      await redisRealtimeStreams.ingestData(streamB1, runId, streamId, \"client-B\", 0);\n-\n-      // Verify each client's initial state\n-      let lastChunkA = await redisRealtimeStreams.getLastChunkIndex(runId, streamId, \"client-A\");\n-      let lastChunkB = await redisRealtimeStreams.getLastChunkIndex(runId, streamId, \"client-B\");\n-      expect(lastChunkA).toBe(2);\n-      expect(lastChunkB).toBe(1);\n-\n-      // Now both clients resume concurrently from their own resume points\n-      const clientAResume = [\n-        JSON.stringify({ client: \"A\", phase: \"resume\", chunk: 3 }),\n-        JSON.stringify({ client: \"A\", phase: \"resume\", chunk: 4 }),\n-      ];\n-\n-      const clientBResume = [\n-        JSON.stringify({ client: \"B\", phase: \"resume\", chunk: 2 }),\n-        JSON.stringify({ client: \"B\", phase: \"resume\", chunk: 3 }),\n-      ];\n-\n-      const streamA2 = new ReadableStream({\n-        start(controller) {\n-          for (const chunk of clientAResume) {\n-            controller.enqueue(encoder.encode(chunk + \"\\n\"));\n-          }\n-          controller.close();\n-        },\n-      });\n-\n-      const streamB2 = new ReadableStream({\n-        start(controller) {\n-          for (const chunk of clientBResume) {\n-            controller.enqueue(encoder.encode(chunk + \"\\n\"));\n-          }\n-          controller.close();\n-        },\n-      });\n-\n-      // Both resume concurrently from their own points\n-      const [response1, response2] = await Promise.all([\n-        redisRealtimeStreams.ingestData(streamA2, runId, streamId, \"client-A\", 3),\n-        redisRealtimeStreams.ingestData(streamB2, runId, streamId, \"client-B\", 2),\n-      ]);\n-\n-      expect(response1.status).toBe(200);\n-      expect(response2.status).toBe(200);\n-\n-      // Verify each client's final state\n-      lastChunkA = await redisRealtimeStreams.getLastChunkIndex(runId, streamId, \"client-A\");\n-      lastChunkB = await redisRealtimeStreams.getLastChunkIndex(runId, streamId, \"client-B\");\n-\n-      expect(lastChunkA).toBe(4); // Client A: chunks 0-4\n-      expect(lastChunkB).toBe(3); // Client B: chunks 0-3\n-\n-      // Verify total chunks in stream\n-      const streamKey = `stream:${runId}:${streamId}`;\n-      const entries = await redis.xrange(streamKey, \"-\", \"+\");\n-\n-      // 5 from client A (0-4) + 4 from client B (0-3) = 9 total\n-      expect(entries.length).toBe(9);\n-\n-      // Cleanup\n-      await redis.del(streamKey);\n-      await redis.quit();\n-    }\n-  );\n-\n-  redisTest(\n-    \"Should track chunk indices independently for different clients\",\n-    { timeout: 30_000 },\n-    async ({ redisOptions }) => {\n-      const redis = new Redis(redisOptions);\n-      const redisRealtimeStreams = new RedisRealtimeStreams({\n-        redis: redisOptions,\n-      });\n-\n-      const runId = \"run_multi_client_test\";\n-      const streamId = \"multi-client-stream\";\n-\n-      // Client A writes chunks 0-2\n-      const clientAChunks = [\n-        JSON.stringify({ client: \"A\", chunk: 0, data: \"A0\" }),\n-        JSON.stringify({ client: \"A\", chunk: 1, data: \"A1\" }),\n-        JSON.stringify({ client: \"A\", chunk: 2, data: \"A2\" }),\n-      ];\n-\n-      const encoder = new TextEncoder();\n-      const streamA = new ReadableStream({\n-        start(controller) {\n-          for (const chunk of clientAChunks) {\n-            controller.enqueue(encoder.encode(chunk + \"\\n\"));\n-          }\n-          controller.close();\n-        },\n-      });\n-\n-      await redisRealtimeStreams.ingestData(streamA, runId, streamId, \"client-A\", 0);\n-\n-      // Client B writes chunks 0-1\n-      const clientBChunks = [\n-        JSON.stringify({ client: \"B\", chunk: 0, data: \"B0\" }),\n-        JSON.stringify({ client: \"B\", chunk: 1, data: \"B1\" }),\n-      ];\n-\n-      const streamB = new ReadableStream({\n-        start(controller) {\n-          for (const chunk of clientBChunks) {\n-            controller.enqueue(encoder.encode(chunk + \"\\n\"));\n-          }\n-          controller.close();\n-        },\n-      });\n-\n-      await redisRealtimeStreams.ingestData(streamB, runId, streamId, \"client-B\", 0);\n-\n-      // Verify last chunk index for each client independently\n-      const lastChunkA = await redisRealtimeStreams.getLastChunkIndex(runId, streamId, \"client-A\");\n-      const lastChunkB = await redisRealtimeStreams.getLastChunkIndex(runId, streamId, \"client-B\");\n-\n-      expect(lastChunkA).toBe(2); // Client A wrote 3 chunks (0-2)\n-      expect(lastChunkB).toBe(1); // Client B wrote 2 chunks (0-1)\n-\n-      // Verify total chunks in stream (5 chunks total)\n-      const streamKey = `stream:${runId}:${streamId}`;\n-      const entries = await redis.xrange(streamKey, \"-\", \"+\");\n-\n-      expect(entries.length).toBe(5);\n-\n-      // Verify each chunk has correct clientId\n-      let clientACount = 0;\n-      let clientBCount = 0;\n-\n-      for (const [_id, fields] of entries) {\n-        let clientId: string | null = null;\n-        for (let j = 0; j < fields.length; j += 2) {\n-          if (fields[j] === \"clientId\") {\n-            clientId = fields[j + 1];\n-          }\n-        }\n-\n-        if (clientId === \"client-A\") clientACount++;\n-        if (clientId === \"client-B\") clientBCount++;\n-      }\n-\n-      expect(clientACount).toBe(3);\n-      expect(clientBCount).toBe(2);\n-\n-      // Cleanup\n-      await redis.del(streamKey);\n-      await redis.quit();\n-    }\n-  );\n-\n-  redisTest(\n-    \"Should handle one client resuming while another client is writing new chunks\",\n-    { timeout: 30_000 },\n-    async ({ redisOptions }) => {\n-      const redis = new Redis(redisOptions);\n-      const redisRealtimeStreams = new RedisRealtimeStreams({\n-        redis: redisOptions,\n-      });\n-\n-      const runId = \"run_client_resume_test\";\n-      const streamId = \"client-resume-stream\";\n-\n-      // Client A writes initial chunks 0-2\n-      const clientAInitial = [\n-        JSON.stringify({ client: \"A\", chunk: 0 }),\n-        JSON.stringify({ client: \"A\", chunk: 1 }),\n-        JSON.stringify({ client: \"A\", chunk: 2 }),\n-      ];\n-\n-      const encoder = new TextEncoder();\n-      const streamA1 = new ReadableStream({\n-        start(controller) {\n-          for (const chunk of clientAInitial) {\n-            controller.enqueue(encoder.encode(chunk + \"\\n\"));\n-          }\n-          controller.close();\n-        },\n-      });\n-\n-      await redisRealtimeStreams.ingestData(streamA1, runId, streamId, \"client-A\", 0);\n-\n-      // Verify client A's last chunk\n-      let lastChunkA = await redisRealtimeStreams.getLastChunkIndex(runId, streamId, \"client-A\");\n-      expect(lastChunkA).toBe(2);\n-\n-      // Client B writes chunks 0-1 (different client, independent sequence)\n-      const clientBChunks = [\n-        JSON.stringify({ client: \"B\", chunk: 0 }),\n-        JSON.stringify({ client: \"B\", chunk: 1 }),\n-      ];\n-\n-      const streamB = new ReadableStream({\n-        start(controller) {\n-          for (const chunk of clientBChunks) {\n-            controller.enqueue(encoder.encode(chunk + \"\\n\"));\n-          }\n-          controller.close();\n-        },\n-      });\n-\n-      await redisRealtimeStreams.ingestData(streamB, runId, streamId, \"client-B\", 0);\n-\n-      // Verify client B's last chunk\n-      const lastChunkB = await redisRealtimeStreams.getLastChunkIndex(runId, streamId, \"client-B\");\n-      expect(lastChunkB).toBe(1);\n-\n-      // Client A resumes from chunk 3\n-      const clientAResume = [\n-        JSON.stringify({ client: \"A\", chunk: 3 }),\n-        JSON.stringify({ client: \"A\", chunk: 4 }),\n-      ];\n-\n-      const streamA2 = new ReadableStream({\n-        start(controller) {\n-          for (const chunk of clientAResume) {\n-            controller.enqueue(encoder.encode(chunk + \"\\n\"));\n-          }\n-          controller.close();\n-        },\n-      });\n-\n-      await redisRealtimeStreams.ingestData(streamA2, runId, streamId, \"client-A\", 3);\n-\n-      // Verify final state\n-      lastChunkA = await redisRealtimeStreams.getLastChunkIndex(runId, streamId, \"client-A\");\n-      expect(lastChunkA).toBe(4); // Client A now has chunks 0-4\n-\n-      // Client B's last chunk should be unchanged\n-      const lastChunkBAfter = await redisRealtimeStreams.getLastChunkIndex(\n-        runId,\n-        streamId,\n-        \"client-B\"\n-      );\n-      expect(lastChunkBAfter).toBe(1); // Still 1\n-\n-      // Verify stream has chunks from both clients\n-      const streamKey = `stream:${runId}:${streamId}`;\n-      const entries = await redis.xrange(streamKey, \"-\", \"+\");\n-\n-      // 5 from client A + 2 from client B = 7 total\n-      expect(entries.length).toBe(7);\n-\n-      // Cleanup\n-      await redis.del(streamKey);\n-      await redis.quit();\n-    }\n-  );\n-\n-  redisTest(\n-    \"Should return -1 for client that has never written to stream\",\n-    { timeout: 30_000 },\n-    async ({ redisOptions }) => {\n-      const redis = new Redis(redisOptions);\n-      const redisRealtimeStreams = new RedisRealtimeStreams({\n-        redis: redisOptions,\n-      });\n-\n-      const runId = \"run_client_not_found_test\";\n-      const streamId = \"client-not-found-stream\";\n-\n-      // Client A writes some chunks\n-      const clientAChunks = [\n-        JSON.stringify({ client: \"A\", chunk: 0 }),\n-        JSON.stringify({ client: \"A\", chunk: 1 }),\n-      ];\n-\n-      const encoder = new TextEncoder();\n-      const streamA = new ReadableStream({\n-        start(controller) {\n-          for (const chunk of clientAChunks) {\n-            controller.enqueue(encoder.encode(chunk + \"\\n\"));\n-          }\n-          controller.close();\n-        },\n-      });\n-\n-      await redisRealtimeStreams.ingestData(streamA, runId, streamId, \"client-A\", 0);\n-\n-      // Client A's last chunk should be 1\n-      const lastChunkA = await redisRealtimeStreams.getLastChunkIndex(runId, streamId, \"client-A\");\n-      expect(lastChunkA).toBe(1);\n-\n-      // Client B never wrote anything, should return -1\n-      const lastChunkB = await redisRealtimeStreams.getLastChunkIndex(runId, streamId, \"client-B\");\n-      expect(lastChunkB).toBe(-1);\n-\n-      // Cleanup\n-      const streamKey = `stream:${runId}:${streamId}`;\n-      await redis.del(streamKey);\n-      await redis.quit();\n-    }\n-  );\n-\n-  redisTest(\n-    \"Should skip legacy END_SENTINEL entries when reading and finding last chunk\",\n-    { timeout: 30_000 },\n-    async ({ redisOptions }) => {\n-      const redis = new Redis(redisOptions);\n-      const redisRealtimeStreams = new RedisRealtimeStreams({\n-        redis: redisOptions,\n-      });\n-\n-      const runId = \"run_backward_compat_test\";\n-      const streamId = \"backward-compat-stream\";\n-      const streamKey = `stream:${runId}:${streamId}`;\n-\n-      // Manually create a stream with mix of new format and legacy END_SENTINEL\n-      await redis.xadd(\n-        streamKey,\n-        \"*\",\n-        \"clientId\",\n-        \"client-A\",\n-        \"chunkIndex\",\n-        \"0\",\n-        \"data\",\n-        \"chunk 0\\n\"\n-      );\n-      await redis.xadd(\n-        streamKey,\n-        \"*\",\n-        \"clientId\",\n-        \"client-A\",\n-        \"chunkIndex\",\n-        \"1\",\n-        \"data\",\n-        \"chunk 1\\n\"\n-      );\n-      await redis.xadd(streamKey, \"*\", \"data\", \"<<CLOSE_STREAM>>\"); // Legacy END_SENTINEL\n-      await redis.xadd(\n-        streamKey,\n-        \"*\",\n-        \"clientId\",\n-        \"client-A\",\n-        \"chunkIndex\",\n-        \"2\",\n-        \"data\",\n-        \"chunk 2\\n\"\n-      );\n-      await redis.xadd(streamKey, \"*\", \"data\", \"<<CLOSE_STREAM>>\"); // Another legacy END_SENTINEL\n-\n-      // getLastChunkIndex should skip END_SENTINELs and find chunk 2\n-      const lastChunkIndex = await redisRealtimeStreams.getLastChunkIndex(\n-        runId,\n-        streamId,\n-        \"client-A\"\n-      );\n-      expect(lastChunkIndex).toBe(2);\n-\n-      // streamResponse should skip END_SENTINELs and only return actual data\n-      const mockRequest = new Request(\"http://localhost/test\");\n-      const abortController = new AbortController();\n-\n-      const response = await redisRealtimeStreams.streamResponse(\n-        mockRequest,\n-        runId,\n-        streamId,\n-        abortController.signal\n-      );\n-\n-      expect(response.status).toBe(200);\n-\n-      // Read the stream\n-      const reader = response.body!.getReader();\n-      const decoder = new TextDecoder();\n-      const receivedData: string[] = [];\n-\n-      let done = false;\n-      while (!done && receivedData.length < 3) {\n-        const { value, done: streamDone } = await reader.read();\n-        done = streamDone;\n-\n-        if (value) {\n-          const text = decoder.decode(value);\n-          const events = text.split(\"\\n\\n\").filter((event) => event.trim());\n-          for (const event of events) {\n-            const lines = event.split(\"\\n\");\n-            for (const line of lines) {\n-              if (line.startsWith(\"data: \")) {\n-                const data = line.substring(6).trim();\n-                if (data) {\n-                  receivedData.push(data);\n-                }\n-              }\n-            }\n-          }\n-        }\n-      }\n-\n-      // Cancel the stream\n-      abortController.abort();\n-      reader.releaseLock();\n-\n-      // Should receive 3 chunks (END_SENTINELs skipped)\n-      expect(receivedData.length).toBe(3);\n-      expect(receivedData[0]).toBe(\"chunk 0\");\n-      expect(receivedData[1]).toBe(\"chunk 1\");\n-      expect(receivedData[2]).toBe(\"chunk 2\");\n-\n-      // Cleanup\n-      await redis.del(streamKey);\n-      await redis.quit();\n-    }\n-  );\n-\n-  redisTest(\n-    \"Should close stream after inactivity timeout\",\n-    { timeout: 30_000 },\n-    async ({ redisOptions }) => {\n-      const redis = new Redis(redisOptions);\n-      const redisRealtimeStreams = new RedisRealtimeStreams({\n-        redis: redisOptions,\n-        inactivityTimeoutMs: 2000, // 2 seconds for faster test\n-      });\n-\n-      const runId = \"run_inactivity_test\";\n-      const streamId = \"inactivity-stream\";\n-\n-      // Write 2 chunks\n-      const chunks = [JSON.stringify({ chunk: 0 }), JSON.stringify({ chunk: 1 })];\n-\n-      const encoder = new TextEncoder();\n-      const stream = new ReadableStream({\n-        start(controller) {\n-          for (const chunk of chunks) {\n-            controller.enqueue(encoder.encode(chunk + \"\\n\"));\n-          }\n-          controller.close();\n-        },\n-      });\n-\n-      await redisRealtimeStreams.ingestData(stream, runId, streamId, \"default\");\n-\n-      // Start streaming\n-      const mockRequest = new Request(\"http://localhost/test\");\n-      const abortController = new AbortController();\n-\n-      const response = await redisRealtimeStreams.streamResponse(\n-        mockRequest,\n-        runId,\n-        streamId,\n-        abortController.signal\n-      );\n-\n-      expect(response.status).toBe(200);\n-\n-      // Read the stream\n-      const reader = response.body!.getReader();\n-      const decoder = new TextDecoder();\n-      const receivedData: string[] = [];\n-\n-      const startTime = Date.now();\n-      let streamClosed = false;\n-\n-      try {\n-        while (true) {\n-          const { value, done } = await reader.read();\n-\n-          if (done) {\n-            streamClosed = true;\n-            break;\n-          }\n-\n-          if (value) {\n-            const text = decoder.decode(value);\n-            const events = text.split(\"\\n\\n\").filter((event) => event.trim());\n-            for (const event of events) {\n-              const lines = event.split(\"\\n\");\n-              for (const line of lines) {\n-                if (line.startsWith(\"data: \")) {\n-                  const data = line.substring(6).trim();\n-                  if (data) {\n-                    receivedData.push(data);\n-                  }\n-                }\n-              }\n-            }\n-          }\n-        }\n-      } catch (error) {\n-        // Expected to eventually close\n-      } finally {\n-        reader.releaseLock();\n-      }\n-\n-      const elapsedMs = Date.now() - startTime;\n-\n-      // Verify stream closed naturally\n-      expect(streamClosed).toBe(true);\n-\n-      // Should have received both chunks\n-      expect(receivedData.length).toBe(2);\n-\n-      // Should have closed after inactivity timeout + one BLOCK cycle\n-      // BLOCK time is 5000ms, so minimum time is ~5s (one full BLOCK timeout)\n-      // The inactivity is checked AFTER the BLOCK returns\n-      expect(elapsedMs).toBeGreaterThan(4000); // At least one BLOCK cycle\n-      expect(elapsedMs).toBeLessThan(8000); // But not more than 2 cycles\n-\n-      // Cleanup\n-      await redis.del(`stream:${runId}:${streamId}`);\n-      await redis.quit();\n-    }\n-  );\n-\n-  redisTest(\n-    \"Should format response with event IDs from Redis stream\",\n-    { timeout: 30_000 },\n-    async ({ redisOptions }) => {\n-      const redis = new Redis(redisOptions);\n-      const redisRealtimeStreams = new RedisRealtimeStreams({\n-        redis: redisOptions,\n-      });\n-\n-      const runId = \"run_event_id_test\";\n-      const streamId = \"event-id-stream\";\n-\n-      // Ingest some data with specific clientId\n-      const chunks = [\n-        JSON.stringify({ message: \"chunk 0\" }),\n-        JSON.stringify({ message: \"chunk 1\" }),\n-        JSON.stringify({ message: \"chunk 2\" }),\n-      ];\n-\n-      const encoder = new TextEncoder();\n-      const ingestStream = new ReadableStream({\n-        start(controller) {\n-          for (const chunk of chunks) {\n-            controller.enqueue(encoder.encode(chunk + \"\\n\"));\n-          }\n-          controller.close();\n-        },\n-      });\n-\n-      await redisRealtimeStreams.ingestData(ingestStream, runId, streamId, \"test-client-123\");\n-\n-      // Stream the response\n-      const mockRequest = new Request(\"http://localhost/test\");\n-      const abortController = new AbortController();\n-\n-      const response = await redisRealtimeStreams.streamResponse(\n-        mockRequest,\n-        runId,\n-        streamId,\n-        abortController.signal\n-      );\n-\n-      expect(response.status).toBe(200);\n-      expect(response.headers.get(\"Content-Type\")).toBe(\"text/event-stream\");\n-\n-      // Read the stream\n-      const reader = response.body!.getReader();\n-      const decoder = new TextDecoder();\n-      const receivedEvents: Array<{ id: string; data: string }> = [];\n-\n-      let done = false;\n-      while (!done && receivedEvents.length < 3) {\n-        const { value, done: streamDone } = await reader.read();\n-        done = streamDone;\n-\n-        if (value) {\n-          const text = decoder.decode(value);\n-          // Split by double newline to get individual events\n-          const events = text.split(\"\\n\\n\").filter((event) => event.trim());\n-\n-          for (const event of events) {\n-            const lines = event.split(\"\\n\");\n-            let id: string | null = null;\n-            let data: string | null = null;\n-\n-            for (const line of lines) {\n-              if (line.startsWith(\"id: \")) {\n-                id = line.substring(4);\n-              } else if (line.startsWith(\"data: \")) {\n-                data = line.substring(6);\n-              }\n-            }\n-\n-            if (id && data) {\n-              receivedEvents.push({ id, data });\n-            }\n-          }\n-        }\n-      }\n-\n-      // Cancel the stream\n-      abortController.abort();\n-      reader.releaseLock();\n-\n-      // Verify we received all chunks with correct event IDs\n-      expect(receivedEvents.length).toBe(3);\n-\n-      // Verify event IDs are Redis stream IDs (format: timestamp-sequence like \"1234567890123-0\")\n-      for (let i = 0; i < 3; i++) {\n-        expect(receivedEvents[i].id).toMatch(/^\\d+-\\d+$/);\n-        expect(receivedEvents[i].data).toBe(chunks[i]);\n-      }\n-\n-      // Verify IDs are in order (each ID should be > previous)\n-      expect(receivedEvents[1].id > receivedEvents[0].id).toBe(true);\n-      expect(receivedEvents[2].id > receivedEvents[1].id).toBe(true);\n-\n-      // Cleanup\n-      await redis.del(`stream:${runId}:${streamId}`);\n-      await redis.quit();\n-    }\n-  );\n-\n-  redisTest(\n-    \"Should support resuming from Last-Event-ID\",\n-    { timeout: 30_000 },\n-    async ({ redisOptions }) => {\n-      const redis = new Redis(redisOptions);\n-      const redisRealtimeStreams = new RedisRealtimeStreams({\n-        redis: redisOptions,\n-      });\n-\n-      const runId = \"run_resume_test\";\n-      const streamId = \"resume-stream\";\n-\n-      // Ingest data in two batches\n-      const firstBatch = [\n-        JSON.stringify({ batch: 1, chunk: 0 }),\n-        JSON.stringify({ batch: 1, chunk: 1 }),\n-        JSON.stringify({ batch: 1, chunk: 2 }),\n-      ];\n-\n-      const encoder = new TextEncoder();\n-      const firstStream = new ReadableStream({\n-        start(controller) {\n-          for (const chunk of firstBatch) {\n-            controller.enqueue(encoder.encode(chunk + \"\\n\"));\n-          }\n-          controller.close();\n-        },\n-      });\n-\n-      await redisRealtimeStreams.ingestData(firstStream, runId, streamId, \"client-A\");\n-\n-      // Stream and read first batch\n-      const mockRequest1 = new Request(\"http://localhost/test\");\n-      const abortController1 = new AbortController();\n-\n-      const response1 = await redisRealtimeStreams.streamResponse(\n-        mockRequest1,\n-        runId,\n-        streamId,\n-        abortController1.signal\n-      );\n-\n-      expect(response1.status).toBe(200);\n-\n-      const reader1 = response1.body!.getReader();\n-      const decoder1 = new TextDecoder();\n-      const firstEvents: Array<{ id: string; data: string }> = [];\n-\n-      let done1 = false;\n-      while (!done1 && firstEvents.length < 3) {\n-        const { value, done: streamDone } = await reader1.read();\n-        done1 = streamDone;\n-\n-        if (value) {\n-          const text = decoder1.decode(value);\n-          const events = text.split(\"\\n\\n\").filter((event) => event.trim());\n-\n-          for (const event of events) {\n-            const lines = event.split(\"\\n\");\n-            let id: string | null = null;\n-            let data: string | null = null;\n-\n-            for (const line of lines) {\n-              if (line.startsWith(\"id: \")) {\n-                id = line.substring(4);\n-              } else if (line.startsWith(\"data: \")) {\n-                data = line.substring(6);\n-              }\n-            }\n-\n-            if (id && data) {\n-              firstEvents.push({ id, data });\n-            }\n-          }\n-        }\n-      }\n-\n-      abortController1.abort();\n-      reader1.releaseLock();\n-\n-      expect(firstEvents.length).toBe(3);\n-      const lastEventId = firstEvents[firstEvents.length - 1].id;\n-\n-      // Ingest second batch\n-      const secondBatch = [\n-        JSON.stringify({ batch: 2, chunk: 0 }),\n-        JSON.stringify({ batch: 2, chunk: 1 }),\n-      ];\n-\n-      const secondStream = new ReadableStream({\n-        start(controller) {\n-          for (const chunk of secondBatch) {\n-            controller.enqueue(encoder.encode(chunk + \"\\n\"));\n-          }\n-          controller.close();\n-        },\n-      });\n-\n-      await redisRealtimeStreams.ingestData(secondStream, runId, streamId, \"client-A\");\n-\n-      // Resume streaming from lastEventId\n-      const mockRequest2 = new Request(\"http://localhost/test\");\n-      const abortController2 = new AbortController();\n-\n-      const response2 = await redisRealtimeStreams.streamResponse(\n-        mockRequest2,\n-        runId,\n-        streamId,\n-        abortController2.signal,\n-        { lastEventId }\n-      );\n-\n-      expect(response2.status).toBe(200);\n-\n-      const reader2 = response2.body!.getReader();\n-      const decoder2 = new TextDecoder();\n-      const resumedEvents: Array<{ id: string; data: string }> = [];\n-\n-      let done2 = false;\n-      while (!done2 && resumedEvents.length < 2) {\n-        const { value, done: streamDone } = await reader2.read();\n-        done2 = streamDone;\n-\n-        if (value) {\n-          const text = decoder2.decode(value);\n-          const events = text.split(\"\\n\\n\").filter((event) => event.trim());\n-\n-          for (const event of events) {\n-            const lines = event.split(\"\\n\");\n-            let id: string | null = null;\n-            let data: string | null = null;\n-\n-            for (const line of lines) {\n-              if (line.startsWith(\"id: \")) {\n-                id = line.substring(4);\n-              } else if (line.startsWith(\"data: \")) {\n-                data = line.substring(6);\n-              }\n-            }\n-\n-            if (id && data) {\n-              resumedEvents.push({ id, data });\n-            }\n-          }\n-        }\n-      }\n-\n-      abortController2.abort();\n-      reader2.releaseLock();\n-\n-      // Verify we only received the second batch (events after lastEventId)\n-      expect(resumedEvents.length).toBe(2);\n-      expect(resumedEvents[0].data).toBe(secondBatch[0]);\n-      expect(resumedEvents[1].data).toBe(secondBatch[1]);\n-\n-      // Verify the resumed events have IDs greater than lastEventId\n-      expect(resumedEvents[0].id > lastEventId).toBe(true);\n-      expect(resumedEvents[1].id > lastEventId).toBe(true);\n-\n-      // Cleanup\n-      await redis.del(`stream:${runId}:${streamId}`);\n-      await redis.quit();\n-    }\n-  );\n-\n-  redisTest(\n-    \"Should handle chunks split mid-line (regression test)\",\n-    { timeout: 30_000 },\n-    async ({ redisOptions }) => {\n-      const redis = new Redis(redisOptions);\n-      const redisRealtimeStreams = new RedisRealtimeStreams({\n-        redis: redisOptions,\n-      });\n-\n-      const runId = \"run_split_test\";\n-      const streamId = \"test-split-stream\";\n-\n-      // Simulate what happens in production: a JSON line split across multiple network chunks\n-      // This reproduces the issue where we see partial chunks like:\n-      // - \"{\\\"timestamp\\\":\"\n-      // - \"1762880245493,\\\"chunkIndex\\\":780,\\\"data\\\":\\\"Chunk 781/1000\\\"}\"\n-      const fullLine = JSON.stringify({\n-        timestamp: 1762880245493,\n-        chunkIndex: 780,\n-        data: \"Chunk 781/1000\",\n-      });\n-\n-      // Split the line at an arbitrary position (in the middle of the JSON)\n-      const splitPoint = 16; // Splits after '{\"timestamp\":'\n-      const chunk1 = fullLine.substring(0, splitPoint);\n-      const chunk2 = fullLine.substring(splitPoint);\n-\n-      // Create a ReadableStream that sends split chunks\n-      const encoder = new TextEncoder();\n-      const stream = new ReadableStream({\n-        start(controller) {\n-          controller.enqueue(encoder.encode(chunk1));\n-          controller.enqueue(encoder.encode(chunk2 + \"\\n\")); // Add newline at end\n-          controller.close();\n-        },\n-      });\n-\n-      // Ingest the split data\n-      await redisRealtimeStreams.ingestData(stream, runId, streamId, \"client1\");\n-\n-      // Now consume the stream and verify we get the complete line, not split chunks\n-      const abortController = new AbortController();\n-      const response = await redisRealtimeStreams.streamResponse(\n-        new Request(\"http://localhost/test\"),\n-        runId,\n-        streamId,\n-        abortController.signal\n-      );\n-\n-      const reader = response.body!.getReader();\n-      const decoder = new TextDecoder();\n-      let receivedData = \"\";\n-\n-      // Read all chunks from the response\n-      const readTimeout = setTimeout(() => {\n-        abortController.abort();\n-      }, 5000);\n-\n-      try {\n-        while (true) {\n-          const { done, value } = await reader.read();\n-          if (done) break;\n-\n-          receivedData += decoder.decode(value, { stream: true });\n-\n-          // Once we have data, we can stop\n-          if (receivedData.includes(\"data: \")) {\n-            break;\n-          }\n-        }\n-      } finally {\n-        clearTimeout(readTimeout);\n-        abortController.abort();\n-        reader.releaseLock();\n-      }\n-\n-      // Parse the SSE data\n-      const lines = receivedData.split(\"\\n\").filter((line) => line.startsWith(\"data: \"));\n-\n-      // We should receive exactly ONE complete line, not two partial lines\n-      expect(lines.length).toBe(1);\n-\n-      // Extract the data (remove \"data: \" prefix)\n-      const dataLine = lines[0].substring(6);\n-\n-      // Verify it's the complete, valid JSON\n-      expect(dataLine).toBe(fullLine);\n-\n-      // Verify it parses correctly as JSON\n-      const parsed = JSON.parse(dataLine) as {\n-        timestamp: number;\n-        chunkIndex: number;\n-        data: string;\n-      };\n-      expect(parsed.timestamp).toBe(1762880245493);\n-      expect(parsed.chunkIndex).toBe(780);\n-      expect(parsed.data).toBe(\"Chunk 781/1000\");\n-\n-      // Cleanup\n-      await redis.del(`stream:${runId}:${streamId}`);\n-      await redis.quit();\n-    }\n-  );\n-});\n+      const response = await redisRealtimeStreams\n\\ No newline at end of file\ndiff --git a/references/realtime-streams/src/trigger/streams.ts b/references/realtime-streams/src/trigger/streams.ts\nindex 388ff96..c18b185 100644\n--- a/references/realtime-streams/src/trigger/streams.ts\n+++ b/references/realtime-streams/src/trigger/streams.ts\n@@ -431,739 +431,4 @@ const streamAppendTesterTask = task({\n \n     const testChunks = [];\n \n-    for await (const chunk of await testStream.read(ctx.run.id, { timeoutInSeconds: 5 })) {\n-      testChunks.push(chunk);\n-    }\n-\n-    assert.strictEqual(testChunks.length, 3, \"Expected 3 chunks\");\n-    assert.ok(testChunks.includes(\"chunk 1\"), \"Expected chunk 1\");\n-    assert.ok(testChunks.includes(\"chunk 2\"), \"Expected chunk 2\");\n-    assert.ok(testChunks.includes(\"chunk 3\"), \"Expected chunk 3\");\n-\n-    await streamAppendChildTask.triggerAndWait(\n-      {},\n-      {},\n-      { clientConfig: { future: { v2RealtimeStreams: true } } }\n-    );\n-\n-    const childChunks = [];\n-\n-    for await (const chunk of await streams.read(ctx.run.id, \"child\", { timeoutInSeconds: 5 })) {\n-      childChunks.push(chunk);\n-    }\n-\n-    assert.strictEqual(childChunks.length, 3, \"Expected 3 chunks\");\n-    assert.ok(childChunks.includes(\"child chunk 1\"), \"Expected child chunk 1\");\n-    assert.ok(childChunks.includes(\"child chunk 2\"), \"Expected child chunk 2\");\n-    assert.ok(childChunks.includes(\"child chunk 3\"), \"Expected child chunk 3\");\n-\n-    return {\n-      message: \"Stream append completed\",\n-    };\n-  },\n-});\n-\n-const streamAppendChildTask = task({\n-  id: \"stream-append-child\",\n-  run: async (payload: any, { ctx }) => {\n-    await streams.append(\"child\", \"child chunk 1\", { target: ctx.run.parentTaskRunId });\n-    await streams.append(\"child\", \"child chunk 2\", { target: \"parent\" });\n-    await streams.append(\"child\", \"child chunk 3\", { target: \"parent\" });\n-  },\n-});\n-\n-const streamPipeTesterTask = task({\n-  id: \"stream-pipe-tester\",\n-  run: async (payload: any, { ctx }) => {\n-    const { waitUntilComplete } = streams.pipe(\n-      new ReadableStream({\n-        start(controller) {\n-          controller.enqueue(\"chunk 1\");\n-          controller.enqueue(\"chunk 2\");\n-          controller.enqueue(\"chunk 3\");\n-          controller.close();\n-        },\n-      })\n-    );\n-\n-    await waitUntilComplete();\n-\n-    const chunks = [];\n-\n-    for await (const chunk of await streams.read(ctx.run.id, { timeoutInSeconds: 5 })) {\n-      chunks.push(chunk);\n-    }\n-\n-    assert.strictEqual(chunks.length, 3, \"Expected 3 chunks\");\n-    assert.ok(chunks.includes(\"chunk 1\"), \"Expected chunk 1\");\n-    assert.ok(chunks.includes(\"chunk 2\"), \"Expected chunk 2\");\n-    assert.ok(chunks.includes(\"chunk 3\"), \"Expected chunk 3\");\n-\n-    const { waitUntilComplete: waitUntilComplete2 } = streams.pipe(\n-      \"named\",\n-      new ReadableStream({\n-        start(controller) {\n-          controller.enqueue(\"chunk 1\");\n-          controller.enqueue(\"chunk 2\");\n-          controller.enqueue(\"chunk 3\");\n-          controller.close();\n-        },\n-      })\n-    );\n-\n-    await waitUntilComplete2();\n-\n-    const namedChunks = [];\n-\n-    for await (const chunk of await streams.read(ctx.run.id, \"named\", { timeoutInSeconds: 5 })) {\n-      namedChunks.push(chunk);\n-    }\n-\n-    assert.strictEqual(namedChunks.length, 3, \"Expected 3 chunks\");\n-    assert.ok(namedChunks.includes(\"chunk 1\"), \"Expected chunk 1\");\n-    assert.ok(namedChunks.includes(\"chunk 2\"), \"Expected chunk 2\");\n-    assert.ok(namedChunks.includes(\"chunk 3\"), \"Expected chunk 3\");\n-\n-    const { waitUntilComplete: waitUntilComplete3 } = testStream.pipe(\n-      new ReadableStream({\n-        start(controller) {\n-          controller.enqueue(\"chunk 1\");\n-          controller.enqueue(\"chunk 2\");\n-          controller.enqueue(\"chunk 3\");\n-          controller.close();\n-        },\n-      })\n-    );\n-\n-    await waitUntilComplete3();\n-\n-    const testChunks = [];\n-\n-    for await (const chunk of await testStream.read(ctx.run.id, { timeoutInSeconds: 5 })) {\n-      testChunks.push(chunk);\n-    }\n-\n-    assert.strictEqual(testChunks.length, 3, \"Expected 3 chunks\");\n-    assert.ok(testChunks.includes(\"chunk 1\"), \"Expected chunk 1\");\n-    assert.ok(testChunks.includes(\"chunk 2\"), \"Expected chunk 2\");\n-    assert.ok(testChunks.includes(\"chunk 3\"), \"Expected chunk 3\");\n-\n-    return {\n-      message: \"Stream pipe completed\",\n-    };\n-  },\n-});\n-\n-const streamWriterTesterTask = task({\n-  id: \"stream-writer-tester\",\n-  run: async (payload: any, { ctx }) => {\n-    const { waitUntilComplete, stream } = streams.writer({\n-      execute: async ({ write, merge }) => {\n-        write(\"chunk 1\");\n-        write(\"chunk 2\");\n-        write(\"chunk 3\");\n-      },\n-    });\n-\n-    await waitUntilComplete();\n-\n-    const chunks = [];\n-\n-    for await (const chunk of await streams.read<string>(ctx.run.id, { timeoutInSeconds: 5 })) {\n-      chunks.push(chunk);\n-    }\n-\n-    assert.strictEqual(chunks.length, 3, \"Expected 3 chunks\");\n-    assert.ok(chunks.includes(\"chunk 1\"), \"Expected chunk 1\");\n-    assert.ok(chunks.includes(\"chunk 2\"), \"Expected chunk 2\");\n-    assert.ok(chunks.includes(\"chunk 3\"), \"Expected chunk 3\");\n-\n-    const { waitUntilComplete: waitUntilComplete2 } = streams.writer(\"named\", {\n-      execute: async ({ write, merge }) => {\n-        write(\"chunk 1\");\n-        write(\"chunk 2\");\n-        write(\"chunk 3\");\n-      },\n-    });\n-\n-    await waitUntilComplete2();\n-\n-    const namedChunks = [];\n-\n-    for await (const chunk of await streams.read(ctx.run.id, \"named\", { timeoutInSeconds: 5 })) {\n-      namedChunks.push(chunk);\n-    }\n-\n-    assert.strictEqual(namedChunks.length, 3, \"Expected 3 chunks\");\n-    assert.ok(namedChunks.includes(\"chunk 1\"), \"Expected chunk 1\");\n-    assert.ok(namedChunks.includes(\"chunk 2\"), \"Expected chunk 2\");\n-    assert.ok(namedChunks.includes(\"chunk 3\"), \"Expected chunk 3\");\n-\n-    const { waitUntilComplete: waitUntilComplete3 } = testStream.writer({\n-      execute: async ({ write, merge }) => {\n-        write(\"chunk 1\");\n-        write(\"chunk 2\");\n-        write(\"chunk 3\");\n-      },\n-    });\n-\n-    await waitUntilComplete3();\n-\n-    const testChunks = [];\n-\n-    for await (const chunk of await testStream.read(ctx.run.id, { timeoutInSeconds: 5 })) {\n-      testChunks.push(chunk);\n-    }\n-\n-    assert.strictEqual(testChunks.length, 3, \"Expected 3 chunks\");\n-    assert.ok(testChunks.includes(\"chunk 1\"), \"Expected chunk 1\");\n-    assert.ok(testChunks.includes(\"chunk 2\"), \"Expected chunk 2\");\n-    assert.ok(testChunks.includes(\"chunk 3\"), \"Expected chunk 3\");\n-\n-    const { waitUntilComplete: waitUntilComplete4 } = streams.writer(\"merging\", {\n-      execute: async ({ write, merge }) => {\n-        merge(\n-          new ReadableStream({\n-            start(controller) {\n-              controller.enqueue(\"chunk 1\");\n-              controller.enqueue(\"chunk 2\");\n-              controller.enqueue(\"chunk 3\");\n-              controller.close();\n-            },\n-          })\n-        );\n-      },\n-    });\n-\n-    await waitUntilComplete4();\n-\n-    const mergingChunks = [];\n-\n-    for await (const chunk of await streams.read(ctx.run.id, \"merging\", { timeoutInSeconds: 5 })) {\n-      mergingChunks.push(chunk);\n-    }\n-\n-    assert.strictEqual(mergingChunks.length, 3, \"Expected 3 chunks\");\n-    assert.ok(mergingChunks.includes(\"chunk 1\"), \"Expected chunk 1\");\n-    assert.ok(mergingChunks.includes(\"chunk 2\"), \"Expected chunk 2\");\n-    assert.ok(mergingChunks.includes(\"chunk 3\"), \"Expected chunk 3\");\n-\n-    return {\n-      message: \"Stream writer completed\",\n-    };\n-  },\n-});\n-\n-const streamWaitUntilTesterTask = task({\n-  id: \"stream-wait-until-tester\",\n-  run: async (payload: any, { ctx }) => {\n-    const result = await streamWaitUntilTesterChildTask.triggerAndWait(\n-      {},\n-      {},\n-      { clientConfig: { future: { v2RealtimeStreams: true } } }\n-    );\n-\n-    const chunks = [];\n-\n-    for await (const chunk of await streams.read(result.id, { timeoutInSeconds: 5 })) {\n-      chunks.push(chunk);\n-    }\n-\n-    const generator = generateContinuousTokenStream(10, 100);\n-    const stream = createStreamFromGenerator(generator);\n-\n-    const expectedChunks = await convertReadableStreamToArray(stream);\n-\n-    assert.strictEqual(chunks.length, expectedChunks.length, \"Expected chunks to be the same\");\n-    assert.deepStrictEqual(chunks, expectedChunks, \"Expected chunks to be the same\");\n-\n-    return {\n-      message: \"Stream wait until tester completed\",\n-    };\n-  },\n-});\n-\n-const streamWaitUntilTesterChildTask = task({\n-  id: \"stream-wait-until-tester\",\n-  run: async (payload: any, { ctx }) => {\n-    const generator = generateContinuousTokenStream(10, 100);\n-    const stream = createStreamFromGenerator(generator);\n-\n-    streams.pipe(stream); // This should register with the waitUntil system\n-\n-    return;\n-  },\n-});\n-\n-const metadataTesterTask = task({\n-  id: \"metadata-tester\",\n-  run: async (payload: { parentId?: string }, { ctx }) => {\n-    await metadata.stream(\n-      \"default\",\n-      new ReadableStream({\n-        start(controller) {\n-          controller.enqueue(\"chunk 1\");\n-          controller.enqueue(\"chunk 2\");\n-          controller.enqueue(\"chunk 3\");\n-          controller.close();\n-        },\n-      })\n-    );\n-\n-    const chunks = [];\n-\n-    for await (const chunk of await streams.read(ctx.run.id, \"default\", { timeoutInSeconds: 5 })) {\n-      chunks.push(chunk);\n-    }\n-\n-    assert.strictEqual(chunks.length, 3, \"Expected 3 chunks\");\n-    assert.ok(chunks.includes(\"chunk 1\"), \"Expected chunk 1\");\n-    assert.ok(chunks.includes(\"chunk 2\"), \"Expected chunk 2\");\n-    assert.ok(chunks.includes(\"chunk 3\"), \"Expected chunk 3\");\n-\n-    if (payload.parentId) {\n-      await metadata.parent.stream(\n-        \"parent\",\n-        new ReadableStream({\n-          start(controller) {\n-            controller.enqueue(\"chunk 1\");\n-            controller.enqueue(\"chunk 2\");\n-            controller.enqueue(\"chunk 3\");\n-            controller.close();\n-          },\n-        })\n-      );\n-\n-      const parentChunks = [];\n-\n-      for await (const chunk of await streams.read(payload.parentId, \"parent\", {\n-        timeoutInSeconds: 5,\n-      })) {\n-        parentChunks.push(chunk);\n-      }\n-\n-      assert.strictEqual(parentChunks.length, 3, \"Expected 3 chunks\");\n-      assert.ok(parentChunks.includes(\"chunk 1\"), \"Expected chunk 1\");\n-      assert.ok(parentChunks.includes(\"chunk 2\"), \"Expected chunk 2\");\n-      assert.ok(parentChunks.includes(\"chunk 3\"), \"Expected chunk 3\");\n-    } else {\n-      await metadataTesterTask.triggerAndWait(\n-        { parentId: ctx.run.id },\n-        {},\n-        { clientConfig: { future: { v2RealtimeStreams: true } } }\n-      );\n-    }\n-  },\n-});\n-\n-const streamReadTesterTask = task({\n-  id: \"stream-read-tester\",\n-  run: async (payload: any, { ctx }) => {\n-    const { waitUntilComplete } = streams.pipe(\n-      new ReadableStream({\n-        start(controller) {\n-          controller.enqueue(\"chunk 1\");\n-          controller.enqueue(\"chunk 2\");\n-          controller.enqueue(\"chunk 3\");\n-          controller.enqueue(\"chunk 4\");\n-          controller.enqueue(\"chunk 5\");\n-          controller.enqueue(\"chunk 6\");\n-          controller.close();\n-        },\n-      })\n-    );\n-\n-    await waitUntilComplete();\n-\n-    const chunks = [];\n-    for await (const chunk of await streams.read(ctx.run.id, { timeoutInSeconds: 5 })) {\n-      chunks.push(chunk);\n-    }\n-\n-    assert.strictEqual(chunks.length, 6, \"Expected 6 chunks\");\n-\n-    // Now read starting from the 4th chunk\n-    // This only properly works with v2 realtime streams\n-    const chunks2 = [];\n-    for await (const chunk of await streams.read(ctx.run.id, {\n-      timeoutInSeconds: 5,\n-      startIndex: 3,\n-    })) {\n-      chunks2.push(chunk);\n-    }\n-\n-    assert.strictEqual(chunks2.length, 3, \"Expected 3 chunks\");\n-\n-    return {\n-      message: \"Stream read tester completed\",\n-    };\n-  },\n-});\n-\n-const streamsStressTesterTask = task({\n-  id: \"streams-stress-tester\",\n-  run: async (payload: { streamsVersion: \"v1\" | \"v2\" }, { ctx }) => {\n-    const stream = createStreamFromGenerator(generateContinuousTokenStream(60, 5));\n-\n-    const { waitUntilComplete } = streams.pipe(stream);\n-\n-    await waitUntilComplete();\n-\n-    const chunks = [];\n-\n-    for await (const chunk of await streams.read(ctx.run.id, { timeoutInSeconds: 10 })) {\n-      chunks.push(chunk);\n-    }\n-\n-    logger.info(\"Received chunks\", {\n-      chunks: chunks.length,\n-      streamsVersion: payload.streamsVersion,\n-    });\n-\n-    switch (payload.streamsVersion) {\n-      case \"v1\": {\n-        break;\n-      }\n-      case \"v2\": {\n-        assert.ok(chunks.length > 2000, \"Expected more than 2000 chunks\");\n-        break;\n-      }\n-    }\n-\n-    return {\n-      message: \"Streams stress tester completed\",\n-    };\n-  },\n-});\n-\n-const endToEndLatencyTesterTask = task({\n-  id: \"end-to-end-latency-tester\",\n-  run: async (payload: any, { ctx }) => {\n-    console.log(\n-      `Starting end to end latency tester task for ${payload.streamsVersion} streams version`\n-    );\n-\n-    const stream = createStreamFromGenerator(generatePerformanceStream(1000, 10));\n-\n-    const { waitUntilComplete } = streams.pipe(stream);\n-\n-    const latencies = [];\n-\n-    const abortController = new AbortController();\n-\n-    for await (const chunk of await streams.read(ctx.run.id, {\n-      timeoutInSeconds: 120,\n-      signal: abortController.signal,\n-    })) {\n-      const performanceChunk = JSON.parse(chunk as any) as PerformanceChunk;\n-\n-      // Calculate the latency\n-      const latency = Date.now() - performanceChunk.timestamp;\n-\n-      latencies.push({ latency, index: performanceChunk.chunkIndex });\n-\n-      if (latencies.length === 1000) {\n-        console.log(\"1000 chunks received, aborting\");\n-        abortController.abort();\n-      }\n-    }\n-\n-    await waitUntilComplete();\n-\n-    // Calculate the min, max, p50 and p95 latencies\n-    const minLatency = Math.min(...latencies.map((l) => l.latency));\n-    const maxLatency = Math.max(...latencies.map((l) => l.latency));\n-    const p50Latency = latencies.sort((a, b) => a.latency - b.latency)[\n-      Math.floor(latencies.length * 0.5)\n-    ];\n-    const p95Latency = latencies.sort((a, b) => a.latency - b.latency)[\n-      Math.floor(latencies.length * 0.95)\n-    ];\n-\n-    const p50LatencyValue = p50Latency.latency;\n-    const p95LatencyValue = p95Latency.latency;\n-\n-    console.log(`Min latency: ${minLatency}ms`);\n-    console.log(`Max latency: ${maxLatency}ms`);\n-    console.log(`P50 latency: ${p50LatencyValue}ms`);\n-    console.log(`P95 latency: ${p95LatencyValue}ms`);\n-\n-    return {\n-      message: \"End to end latency tester completed\",\n-    };\n-  },\n-});\n-\n-async function* generateLLMTokenStream(\n-  includePing: boolean = false,\n-  stallDurationMs: number = 10 * 60 * 1000\n-) {\n-  // Simulate initial LLM tokens (faster, like a real LLM)\n-  const initialTokens = [\n-    \"Hello\",\n-    \" there\",\n-    \"!\",\n-    \" I'm\",\n-    \" going\",\n-    \" to\",\n-    \" tell\",\n-    \" you\",\n-    \" a\",\n-    \" story\",\n-    \".\",\n-    \"\\n\",\n-    \" Once\",\n-    \" upon\",\n-    \" a\",\n-    \" time\",\n-  ];\n-\n-  // Stream initial tokens with realistic LLM timing\n-  for (const token of initialTokens) {\n-    await setTimeout(Math.random() * 10 + 5); // 5-15ms delay\n-    yield token;\n-  }\n-\n-  // \"Stall\" window - emit a token every 30 seconds\n-  const stallIntervalMs = 30 * 1000; // 30 seconds\n-  const stallTokenCount = Math.floor(stallDurationMs / stallIntervalMs);\n-  logger.info(\n-    `Entering stall window for ${stallDurationMs}ms (${\n-      stallDurationMs / 1000 / 60\n-    } minutes) - emitting ${stallTokenCount} tokens`\n-  );\n-\n-  for (let i = 0; i < stallTokenCount; i++) {\n-    await setTimeout(stallIntervalMs);\n-    if (includePing) {\n-      yield \".\"; // Emit a single period token every 30 seconds\n-    }\n-  }\n-\n-  logger.info(\"Resuming normal stream after stall window\");\n-\n-  // Continue with more LLM tokens after stall\n-  const continuationTokens = [\n-    \" there\",\n-    \" was\",\n-    \" a\",\n-    \" developer\",\n-    \" who\",\n-    \" needed\",\n-    \" to\",\n-    \" test\",\n-    \" streaming\",\n-    \".\",\n-    \" They\",\n-    \" used\",\n-    \" Trigger\",\n-    \".dev\",\n-    \" and\",\n-    \" it\",\n-    \" worked\",\n-    \" perfectly\",\n-    \"!\",\n-  ];\n-\n-  for (const token of continuationTokens) {\n-    await setTimeout(Math.random() * 10 + 5); // 5-15ms delay\n-    yield token;\n-  }\n-}\n-\n-// Continuous stream: emit tokens at regular intervals for a specified duration\n-async function* generateContinuousTokenStream(durationSec: number, intervalMs: number) {\n-  const words = [\n-    \"The\",\n-    \"quick\",\n-    \"brown\",\n-    \"fox\",\n-    \"jumps\",\n-    \"over\",\n-    \"the\",\n-    \"lazy\",\n-    \"dog\",\n-    \"while\",\n-    \"streaming\",\n-    \"tokens\",\n-    \"continuously\",\n-    \"at\",\n-    \"regular\",\n-    \"intervals\",\n-    \"to\",\n-    \"test\",\n-    \"real-time\",\n-    \"data\",\n-    \"flow\",\n-  ];\n-\n-  const endTime = Date.now() + durationSec * 1000;\n-  let wordIndex = 0;\n-\n-  while (Date.now() < endTime) {\n-    await setTimeout(intervalMs);\n-    yield words[wordIndex % words.length] + \" \";\n-    wordIndex++;\n-  }\n-\n-  yield \"\\n[Stream completed]\";\n-}\n-\n-// Burst stream: emit rapid bursts of tokens with pauses between bursts\n-async function* generateBurstTokenStream(\n-  burstCount: number,\n-  tokensPerBurst: number,\n-  burstIntervalMs: number,\n-  pauseBetweenBurstsMs: number\n-) {\n-  const tokens = \"abcdefghijklmnopqrstuvwxyz\".split(\"\");\n-\n-  for (let burst = 0; burst < burstCount; burst++) {\n-    yield `\\n[Burst ${burst + 1}/${burstCount}] `;\n-\n-    // Emit tokens rapidly in this burst\n-    for (let token = 0; token < tokensPerBurst; token++) {\n-      await setTimeout(burstIntervalMs);\n-      yield tokens[token % tokens.length];\n-    }\n-\n-    // Pause between bursts (except after the last burst)\n-    if (burst < burstCount - 1) {\n-      await setTimeout(pauseBetweenBurstsMs);\n-    }\n-  }\n-\n-  yield \"\\n[All bursts completed]\";\n-}\n-\n-// Slow steady stream: emit tokens at longer intervals over many minutes\n-async function* generateSlowSteadyTokenStream(durationMin: number, tokenIntervalSec: number) {\n-  const sentences = [\n-    \"This is a slow and steady stream.\",\n-    \"Each token arrives after several seconds.\",\n-    \"Perfect for testing long-running connections.\",\n-    \"The stream maintains a consistent pace.\",\n-    \"Patience is key when testing reliability.\",\n-    \"Connections should remain stable throughout.\",\n-    \"This helps verify timeout handling.\",\n-    \"Real-world streams often have variable timing.\",\n-    \"Testing edge cases is important.\",\n-    \"Almost done with the slow stream test.\",\n-  ];\n-\n-  const endTime = Date.now() + durationMin * 60 * 1000;\n-  let sentenceIndex = 0;\n-\n-  while (Date.now() < endTime) {\n-    const sentence = sentences[sentenceIndex % sentences.length];\n-    yield `${sentence} `;\n-\n-    sentenceIndex++;\n-    await setTimeout(tokenIntervalSec * 1000);\n-  }\n-\n-  yield \"\\n[Long stream completed successfully]\";\n-}\n-\n-// Markdown stream: emit realistic markdown content as tokens (8 characters at a time)\n-async function* generateMarkdownTokenStream(tokenDelayMs: number) {\n-  const markdownContent =\n-    \"# Streaming Markdown Example\\n\\n\" +\n-    \"This is a demonstration of **streaming markdown** content in real-time. The content is being generated *token by token*, simulating how an LLM might generate formatted text.\\n\\n\" +\n-    \"## Features\\n\\n\" +\n-    \"Here are some key features being tested:\\n\\n\" +\n-    \"- **Bold text** for emphasis\\n\" +\n-    \"- *Italic text* for subtle highlighting\\n\" +\n-    \"- `inline code` for technical terms\\n\" +\n-    \"- [Links](https://trigger.dev) to external resources\\n\\n\" +\n-    \"### Code Examples\\n\\n\" +\n-    \"You can also stream code blocks:\\n\\n\" +\n-    \"```typescript\\n\" +\n-    'import { task, metadata } from \"@trigger.dev/sdk\";\\n\\n' +\n-    \"export const myTask = task({\\n\" +\n-    '  id: \"example-task\",\\n' +\n-    \"  run: async (payload) => {\\n\" +\n-    '    const stream = await metadata.stream(\"output\", myStream);\\n' +\n-    \"    \\n\" +\n-    \"    for await (const chunk of stream) {\\n\" +\n-    \"      console.log(chunk);\\n\" +\n-    \"    }\\n\" +\n-    \"    \\n\" +\n-    \"    return { success: true };\\n\" +\n-    \"  },\\n\" +\n-    \"});\\n\" +\n-    \"```\\n\\n\" +\n-    \"### Lists and Structure\\n\\n\" +\n-    \"Numbered lists work great too:\\n\\n\" +\n-    \"1. First item with important details\\n\" +\n-    \"2. Second item with more context\\n\" +\n-    \"3. Third item completing the sequence\\n\\n\" +\n-    \"#### Nested Content\\n\\n\" +\n-    \"> Blockquotes are useful for highlighting important information or quoting external sources.\\n\\n\" +\n-    \"You can combine **_bold and italic_** text, or use ~~strikethrough~~ for corrections.\\n\\n\" +\n-    \"## Technical Details\\n\\n\" +\n-    \"| Feature | Status | Notes |\\n\" +\n-    \"|---------|--------|-------|\\n\" +\n-    \"| Streaming | \u2713 | Working perfectly |\\n\" +\n-    \"| Markdown | \u2713 | Full support |\\n\" +\n-    \"| Realtime | \u2713 | Sub-second latency |\\n\\n\" +\n-    \"### Conclusion\\n\\n\" +\n-    \"This markdown streaming scenario demonstrates how formatted content can be transmitted in real-time, maintaining proper structure and formatting throughout the stream.\\n\\n\" +\n-    \"---\\n\\n\" +\n-    \"*Generated with Trigger.dev realtime streams* \ud83d\ude80\\n\";\n-\n-  // Stream tokens of 8 characters at a time with 5ms delay\n-  // Use Array.from() to properly handle Unicode characters\n-  const CHARACTERS_PER_TOKEN = 8;\n-  const DELAY_MS = 5;\n-\n-  const characters = Array.from(markdownContent);\n-\n-  for (let i = 0; i < characters.length; i += CHARACTERS_PER_TOKEN) {\n-    await setTimeout(DELAY_MS);\n-    yield characters.slice(i, i + CHARACTERS_PER_TOKEN).join(\"\");\n-  }\n-}\n-\n-// Performance stream: emit JSON chunks with timestamps for latency measurement\n-async function* generatePerformanceStream(chunkCount: number, chunkIntervalMs: number) {\n-  for (let i = 0; i < chunkCount; i++) {\n-    await setTimeout(chunkIntervalMs);\n-\n-    const chunk: PerformanceChunk = {\n-      timestamp: Date.now(),\n-      chunkIndex: i,\n-      data: `Chunk ${i + 1}/${chunkCount}`,\n-    };\n-\n-    yield JSON.stringify(chunk);\n-  }\n-}\n-\n-// Convert to ReadableStream\n-function createStreamFromGenerator(generator: AsyncGenerator<string>) {\n-  return new ReadableStream({\n-    async start(controller) {\n-      for await (const chunk of generator) {\n-        controller.enqueue(chunk);\n-      }\n-\n-      controller.close();\n-    },\n-  });\n-}\n-\n-async function convertReadableStreamToArray<TPart>(\n-  stream: ReadableStream<TPart>\n-): Promise<TPart[]> {\n-  const chunks: TPart[] = [];\n-  const reader = stream.getReader();\n-  while (true) {\n-    const { done, value } = await reader.read();\n-    if (done) break;\n-    chunks.push(value);\n-  }\n-\n-  reader.releaseLock();\n-  return chunks;\n-}\n+    for await (const chunk of await testStream.read(ctx.run.id, { timeoutInSeconds:\n\\ No newline at end of file\n"
  }
]