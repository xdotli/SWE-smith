{
    "cost": 0.8975950000000001,
    "rewrites": {
        "PostHog__posthog.main/plugin-server/src/ingestion/ingestion-e2e.test.ts": {
            "output": "import { DateTime } from 'luxon'\nimport { Message } from 'node-rdkafka'\nimport { v4 } from 'uuid'\n\nimport { waitForExpect } from '~/tests/helpers/expectations'\nimport { resetKafka } from '~/tests/helpers/kafka'\n\nimport { Clickhouse } from '../../tests/helpers/clickhouse'\nimport { createUserTeamAndOrganization, fetchPostgresPersons, resetTestDatabase } from '../../tests/helpers/sql'\nimport { Hub, InternalPerson, PipelineEvent, PluginsServerConfig, ProjectId, RawClickHouseEvent, Team } from '../types'\nimport { closeHub, createHub } from '../utils/db/hub'\nimport { parseRawClickHouseEvent } from '../utils/event'\nimport { parseJSON } from '../utils/json-parse'\nimport { UUIDT } from '../utils/utils'\nimport { fetchDistinctIds } from '../worker/ingestion/persons/repositories/test-helpers'\nimport { IngestionConsumer } from './ingestion-consumer'\n\n// Mock the limiter so it always returns true\njest.mock('~/utils/token-bucket', () => {\n    const mockConsume = jest.fn().mockReturnValue(true)\n    return {\n        IngestionWarningLimiter: {\n            consume: mockConsume,\n        },\n    }\n})\n\nconst waitForKafkaMessages = async (hub: Hub) => {\n    await hub.db.kafkaProducer.flush()\n}\n\nclass EventBuilder {\n    private event: Partial<PipelineEvent> = {}\n\n    constructor(team: Team, distinctId: string = new UUIDT().toString()) {\n        this.event = {\n            event: 'custom event',\n            properties: {},\n            timestamp: new Date().toISOString(),\n            now: new Date().toISOString(),\n            ip: null,\n            site_url: 'https://example.com',\n            uuid: new UUIDT().toString(),\n        }\n        this.event.distinct_id = distinctId\n        this.event.team_id = team.id\n        this.event.token = team.api_token\n    }\n\n    withEvent(event: string) {\n        this.event.event = event\n        return this\n    }\n\n    withProperties(properties: Record<string, any>) {\n        this.event.properties = properties\n        return this\n    }\n\n    withOverrides(overrides: Record<string, any>) {\n        this.event = { ...this.event, ...overrides }\n        return this\n    }\n\n    withTimestamp(timestamp: number) {\n        const date = DateTime.fromMillis(timestamp)\n        this.event.timestamp = date.toString()\n        this.event.now = date.toString()\n        return this\n    }\n\n    withNow(now: number) {\n        const date = DateTime.fromMillis(now)\n        this.event.now = date.toString()\n        return this\n    }\n\n    withGroupProperties(groupType: string, groupKey: string, groupSet?: Record<string, any>) {\n        this.event.properties = {\n            ...this.event.properties,\n            $group_type: groupType,\n            $group_key: groupKey,\n            ...(groupSet ? { $group_set: groupSet } : {}),\n        }\n        return this\n    }\n\n    withToken(token: string) {\n        this.event.token = token\n        return this\n    }\n\n    build(): PipelineEvent {\n        return this.event as PipelineEvent\n    }\n}\n\njest.mock('../utils/logger')\n\nconst DEFAULT_TEAM: Team = {\n    id: 2,\n    project_id: 2 as ProjectId,\n    organization_id: '2',\n    uuid: v4(),\n    name: '2',\n    anonymize_ips: true,\n    api_token: 'api_token',\n    slack_incoming_webhook: 'slack_incoming_webhook',\n    session_recording_opt_in: true,\n    person_processing_opt_out: null,\n    heatmaps_opt_in: null,\n    ingested_event: true,\n    person_display_name_properties: null,\n    test_account_filters: null,\n    cookieless_server_hash_mode: null,\n    timezone: 'UTC',\n    available_features: [],\n    drop_events_older_than_seconds: null,\n}\n\nlet offsetIncrementer = 0\n\nconst createKafkaMessage = (event: PipelineEvent, timestamp: number = DateTime.now().toMillis()): Message => {\n    // TRICKY: This is the slightly different format that capture sends\n    const captureEvent = {\n        uuid: event.uuid,\n        distinct_id: event.distinct_id,\n        ip: event.ip,\n        now: event.now,\n        token: event.token,\n        data: JSON.stringify(event),\n    }\n    return {\n        key: `${event.token}:${event.distinct_id}`,\n        value: Buffer.from(JSON.stringify(captureEvent)),\n        size: 1,\n        topic: 'test',\n        offset: offsetIncrementer++,\n        timestamp: timestamp + offsetIncrementer,\n        partition: 1,\n    }\n}\n\nexport const createKafkaMessages: (events: PipelineEvent[]) => Message[] = (events) => {\n    return events.map(createKafkaMessage)\n}\n\nconst testWithTeamIngester = (\n    name: string,\n    config: { teamOverrides?: Partial<Team>; pluginServerConfig?: Partial<PluginsServerConfig> } = {},\n    testFn: (ingester: IngestionConsumer, hub: Hub, team: Team) => Promise<void>\n) => {\n    test(name, async () => {\n        const hub = await createHub({\n            PLUGINS_DEFAULT_LOG_LEVEL: 0,\n            APP_METRICS_FLUSH_FREQUENCY_MS: 0,\n            ...config.pluginServerConfig,\n        })\n\n        const teamId = Math.floor((Date.now() % 1000000000) + Math.random() * 1000000)\n        const userId = teamId\n        const organizationId = new UUIDT().toString()\n\n        const newTeam: Team = {\n            ...DEFAULT_TEAM,\n            id: teamId,\n            project_id: teamId as ProjectId,\n            organization_id: organizationId,\n            uuid: v4(),\n            name: teamId.toString(),\n            ...config.teamOverrides,\n        }\n        const userUuid = new UUIDT().toString()\n        const organizationMembershipId = new UUIDT().toString()\n\n        await createUserTeamAndOrganization(\n            hub.db.postgres,\n            newTeam.id,\n            userId,\n            userUuid,\n            newTeam.organization_id,\n            organizationMembershipId,\n            config.teamOverrides\n        )\n\n        // Fetch the team from the database to ensure we have the actual persisted data\n        const fetchedTeam = await hub.teamManager.getTeam(newTeam.id)\n        if (!fetchedTeam) {\n            throw new Error(`Failed to fetch team ${newTeam.id} from database`)\n        }\n\n        const ingester = new IngestionConsumer(hub)\n        // NOTE: We don't actually use kafka so we skip instantiation for faster tests\n        ingester['kafkaConsumer'] = {\n            connect: jest.fn(),\n            disconnect: jest.fn(),\n            isHealthy: jest.fn(),\n        } as any\n\n        jest.spyOn(hub.groupRepository, 'fetchGroup')\n        jest.spyOn(hub.groupRepository, 'insertGroup')\n        jest.spyOn(hub.groupRepository, 'updateGroup')\n        jest.spyOn(hub.groupRepository, 'updateGroupOptimistically')\n\n        await ingester.start()\n        await testFn(ingester, hub, fetchedTeam)\n        await ingester.stop()\n        await closeHub(hub)\n    })\n}\n\ndescribe('Event Pipeline E2E tests', () => {\n    let clickhouse: Clickhouse\n    beforeAll(async () => {\n        console.log('Creating Clickhouse client')\n        clickhouse = Clickhouse.create()\n        await resetKafka()\n        await resetTestDatabase()\n        await clickhouse.resetTestDatabase()\n        process.env.SITE_URL = 'https://example.com'\n    })\n\n    afterAll(async () => {\n        await resetTestDatabase()\n        await clickhouse.resetTestDatabase()\n        clickhouse.close()\n    })\n\n    testWithTeamIngester('should handle $$client_ingestion_warning events', {}, async (ingester, hub, team) => {\n        const events = [\n            new EventBuilder(team)\n                .withEvent('$$client_ingestion_warning')\n                .withProperties({ $$client_ingestion_warning_message: 'test message' })\n                .build(),\n        ]\n\n        await ingester.handleKafkaBatch(createKafkaMessages(events))\n\n        await waitForExpect(async () => {\n            await waitForKafkaMessages(hub)\n            const warnings = await fetchIngestionWarnings(hub, team.id)\n            expect(warnings).toEqual([\n                expect.objectContaining({\n                    type: 'client_ingestion_warning',\n                    team_id: team.id,\n                    details: expect.objectContaining({ message: 'test message' }),\n                }),\n            ])\n        })\n    })\n\n    testWithTeamIngester('should process events without a team_id', {}, async (ingester, hub, team) => {\n        const events = [new EventBuilder(team).withEvent('test event').build()]\n\n        await ingester.handleKafkaBatch(createKafkaMessages(events))\n\n        await waitForKafkaMessages(hub)\n\n        await waitForExpect(async () => {\n            const events = await fetchEvents(hub, team.id)\n            expect(events.length).toBe(1)\n            expect(events[0].team_id).toBe(team.id)\n        })\n    })\n\n    testWithTeamIngester(\n        'can set and update group properties with $groupidentify events',\n        {},\n        async (ingester, hub, team) => {\n            const groupKey = 'group_key'\n            const distinctId = new UUIDT().toString()\n\n            const events = [\n                new EventBuilder(team, distinctId)\n                    .withEvent('$groupidentify')\n                    .withGroupProperties('organization', groupKey, { foo: 'bar' })\n                    .build(),\n            ]\n\n            await ingester.handleKafkaBatch(createKafkaMessages(events))\n\n            await waitForKafkaMessages(hub)\n            await waitForExpect(async () => {\n                const group = await hub.groupRepository.fetchGroup(team.id, 0, groupKey)\n                expect(group).toEqual(\n                    expect.objectContaining({\n                        team_id: team.id,\n                        group_type_index: 0,\n                        group_properties: { foo: 'bar' },\n                        group_key: groupKey,\n                        version: 1,\n                    })\n                )\n            })\n\n            const updateEvents = [\n                new EventBuilder(team, distinctId)\n                    .withEvent('$groupidentify')\n                    .withGroupProperties('organization', groupKey, { prop: 'value' })\n                    .build(),\n            ]\n\n            await ingester.handleKafkaBatch(createKafkaMessages(updateEvents))\n\n            await waitForKafkaMessages(hub)\n\n            await waitForExpect(async () => {\n                const group = await hub.groupRepository.fetchGroup(team.id, 0, groupKey)\n                expect(group).toEqual(\n                    expect.objectContaining({\n                        team_id: team.id,\n                        group_type_index: 0,\n                        group_properties: { foo: 'bar', prop: 'value' },\n                        group_key: groupKey,\n                        version: 2,\n                    })\n                )\n            })\n\n            await waitForExpect(async () => {\n                const events = await fetchEvents(hub, team.id)\n                expect(events.length).toEqual(2)\n                expect(events[0].event).toEqual('$groupidentify')\n                expect(events[0].properties.$group_set).toEqual({ foo: 'bar' })\n                expect(events[1].event).toEqual('$groupidentify')\n                expect(events[1].properties.$group_set).toEqual({ prop: 'value' })\n            })\n\n            // Should have fetched the group 4 times:\n            // 1 for each event and 2 in test check\n            expect(hub.groupRepository.fetchGroup).toHaveBeenCalledTimes(4)\n        }\n    )\n\n    testWithTeamIngester('can handle high amount of $groupidentify in same batch', {}, async (ingester, hub, team) => {\n        const n = 150\n        const distinctId = new UUIDT().toString()\n        const events = []\n        for (let i = 0; i < n; i++) {\n            const m: Record<string, number> = {}\n            m[i.toString()] = i\n            events.push(\n                new EventBuilder(team, distinctId)\n                    .withEvent('$groupidentify')\n                    .withGroupProperties('organization', 'group_key', m)\n                    .build()\n            )\n        }\n\n        await ingester.handleKafkaBatch(createKafkaMessages(events))\n\n        await waitForKafkaMessages(hub)\n\n        await waitForExpect(async () => {\n            const events = await fetchEvents(hub, team.id)\n            expect(events.length).toEqual(n)\n        })\n\n        expect(hub.groupRepository.fetchGroup).toHaveBeenCalledTimes(1)\n        expect(hub.groupRepository.insertGroup).toHaveBeenCalledTimes(1)\n        expect(hub.groupRepository.updateGroup).toHaveBeenCalledTimes(0)\n        expect(hub.groupRepository.updateGroupOptimistically).toHaveBeenCalledTimes(1)\n    })\n\n    testWithTeamIngester('can handle multiple $groupidentify in same batch', {}, async (ingester, hub, team) => {\n        const timestamp = DateTime.now().toMillis()\n        const distinctId = new UUIDT().toString()\n        const groupKey = 'group_key'\n\n        const events = [\n            new EventBuilder(team, distinctId)\n                .withEvent('$groupidentify')\n                .withGroupProperties('organization', groupKey, { k1: 'v1' })\n                .withTimestamp(timestamp)\n                .build(),\n            new EventBuilder(team, distinctId)\n                .withEvent('$groupidentify')\n                .withGroupProperties('organization', groupKey, { k2: 'v2', k3: 'v2' })\n                .withTimestamp(timestamp + 1)\n                .build(),\n            new EventBuilder(team, distinctId)\n                .withEvent('$groupidentify')\n                .withGroupProperties('organization', groupKey, { k2: 'v3', k4: 'v3' })\n                .withTimestamp(timestamp + 2)\n                .build(),\n        ]\n\n        await ingester.handleKafkaBatch(createKafkaMessages(events))\n\n        await waitForExpect(async () => {\n            await waitForKafkaMessages(hub)\n            const events = await fetchEvents(hub, team.id)\n            expect(events.length).toEqual(3)\n            expect(events[0].event).toEqual('$groupidentify')\n            expect(events[0].properties.$group_set).toEqual({ k1: 'v1' })\n            expect(events[1].event).toEqual('$groupidentify')\n            expect(events[1].properties.$group_set).toEqual({ k2: 'v2', k3: 'v2' })\n            expect(events[2].event).toEqual('$groupidentify')\n            expect(events[2].properties.$group_set).toEqual({ k2: 'v3', k4: 'v3' })\n        })\n\n        expect(hub.groupRepository.fetchGroup).toHaveBeenCalledTimes(1)\n        expect(hub.groupRepository.insertGroup).toHaveBeenCalledTimes(1)\n        expect(hub.groupRepository.updateGroup).toHaveBeenCalledTimes(0)",
            "output_extracted": "import { DateTime } from 'luxon'\nimport { Message } from 'node-rdkafka'\nimport { v4 } from 'uuid'\n\nimport { waitForExpect } from '~/tests/helpers/expectations'\nimport { resetKafka } from '~/tests/helpers/kafka'\n\nimport { Clickhouse } from '../../tests/helpers/clickhouse'\nimport { createUserTeamAndOrganization, fetchPostgresPersons, resetTestDatabase } from '../../tests/helpers/sql'\nimport { Hub, InternalPerson, PipelineEvent, PluginsServerConfig, ProjectId, RawClickHouseEvent, Team } from '../types'\nimport { closeHub, createHub } from '../utils/db/hub'\nimport { parseRawClickHouseEvent } from '../utils/event'\nimport { parseJSON } from '../utils/json-parse'\nimport { UUIDT } from '../utils/utils'\nimport { fetchDistinctIds } from '../worker/ingestion/persons/repositories/test-helpers'\nimport { IngestionConsumer } from './ingestion-consumer'\n\n// Mock the limiter so it always returns true\njest.mock('~/utils/token-bucket', () => {\n    const mockConsume = jest.fn().mockReturnValue(true)\n    return {\n        IngestionWarningLimiter: {\n            consume: mockConsume,\n        },\n    }\n})\n\nconst waitForKafkaMessages = async (hub: Hub) => {\n    await hub.db.kafkaProducer.flush()\n}\n\nclass EventBuilder {\n    private event: Partial<PipelineEvent> = {}\n\n    constructor(team: Team, distinctId: string = new UUIDT().toString()) {\n        this.event = {\n            event: 'custom event',\n            properties: {},\n            timestamp: new Date().toISOString(),\n            now: new Date().toISOString(),\n            ip: null,\n            site_url: 'https://example.com',\n            uuid: new UUIDT().toString(),\n        }\n        this.event.distinct_id = distinctId\n        this.event.team_id = team.id\n        this.event.token = team.api_token\n    }\n\n    withEvent(event: string) {\n        this.event.event = event\n        return this\n    }\n\n    withProperties(properties: Record<string, any>) {\n        this.event.properties = properties\n        return this\n    }\n\n    withOverrides(overrides: Record<string, any>) {\n        this.event = { ...this.event, ...overrides }\n        return this\n    }\n\n    withTimestamp(timestamp: number) {\n        const date = DateTime.fromMillis(timestamp)\n        this.event.timestamp = date.toString()\n        this.event.now = date.toString()\n        return this\n    }\n\n    withNow(now: number) {\n        const date = DateTime.fromMillis(now)\n        this.event.now = date.toString()\n        return this\n    }\n\n    withGroupProperties(groupType: string, groupKey: string, groupSet?: Record<string, any>) {\n        this.event.properties = {\n            ...this.event.properties,\n            $group_type: groupType,\n            $group_key: groupKey,\n            ...(groupSet ? { $group_set: groupSet } : {}),\n        }\n        return this\n    }\n\n    withToken(token: string) {\n        this.event.token = token\n        return this\n    }\n\n    build(): PipelineEvent {\n        return this.event as PipelineEvent\n    }\n}\n\njest.mock('../utils/logger')\n\nconst DEFAULT_TEAM: Team = {\n    id: 2,\n    project_id: 2 as ProjectId,\n    organization_id: '2',\n    uuid: v4(),\n    name: '2',\n    anonymize_ips: true,\n    api_token: 'api_token',\n    slack_incoming_webhook: 'slack_incoming_webhook',\n    session_recording_opt_in: true,\n    person_processing_opt_out: null,\n    heatmaps_opt_in: null,\n    ingested_event: true,\n    person_display_name_properties: null,\n    test_account_filters: null,\n    cookieless_server_hash_mode: null,\n    timezone: 'UTC',\n    available_features: [],\n    drop_events_older_than_seconds: null,\n}\n\nlet offsetIncrementer = 0\n\nconst createKafkaMessage = (event: PipelineEvent, timestamp: number = DateTime.now().toMillis()): Message => {\n    // TRICKY: This is the slightly different format that capture sends\n    const captureEvent = {\n        uuid: event.uuid,\n        distinct_id: event.distinct_id,\n        ip: event.ip,\n        now: event.now,\n        token: event.token,\n        data: JSON.stringify(event),\n    }\n    return {\n        key: `${event.token}:${event.distinct_id}`,\n        value: Buffer.from(JSON.stringify(captureEvent)),\n        size: 1,\n        topic: 'test',\n        offset: offsetIncrementer++,\n        timestamp: timestamp + offsetIncrementer,\n        partition: 1,\n    }\n}\n\nexport const createKafkaMessages: (events: PipelineEvent[]) => Message[] = (events) => {\n    return events.map(createKafkaMessage)\n}\n\nconst testWithTeamIngester = (\n    name: string,\n    config: { teamOverrides?: Partial<Team>; pluginServerConfig?: Partial<PluginsServerConfig> } = {},\n    testFn: (ingester: IngestionConsumer, hub: Hub, team: Team) => Promise<void>\n) => {\n    test(name, async () => {\n        const hub = await createHub({\n            PLUGINS_DEFAULT_LOG_LEVEL: 0,\n            APP_METRICS_FLUSH_FREQUENCY_MS: 0,\n            ...config.pluginServerConfig,\n        })\n\n        const teamId = Math.floor((Date.now() % 1000000000) + Math.random() * 1000000)\n        const userId = teamId\n        const organizationId = new UUIDT().toString()\n\n        const newTeam: Team = {\n            ...DEFAULT_TEAM,\n            id: teamId,\n            project_id: teamId as ProjectId,\n            organization_id: organizationId,\n            uuid: v4(),\n            name: teamId.toString(),\n            ...config.teamOverrides,\n        }\n        const userUuid = new UUIDT().toString()\n        const organizationMembershipId = new UUIDT().toString()\n\n        await createUserTeamAndOrganization(\n            hub.db.postgres,\n            newTeam.id,\n            userId,\n            userUuid,\n            newTeam.organization_id,\n            organizationMembershipId,\n            config.teamOverrides\n        )\n\n        // Fetch the team from the database to ensure we have the actual persisted data\n        const fetchedTeam = await hub.teamManager.getTeam(newTeam.id)\n        if (!fetchedTeam) {\n            throw new Error(`Failed to fetch team ${newTeam.id} from database`)\n        }\n\n        const ingester = new IngestionConsumer(hub)\n        // NOTE: We don't actually use kafka so we skip instantiation for faster tests\n        ingester['kafkaConsumer'] = {\n            connect: jest.fn(),\n            disconnect: jest.fn(),\n            isHealthy: jest.fn(),\n        } as any\n\n        jest.spyOn(hub.groupRepository, 'fetchGroup')\n        jest.spyOn(hub.groupRepository, 'insertGroup')\n        jest.spyOn(hub.groupRepository, 'updateGroup')\n        jest.spyOn(hub.groupRepository, 'updateGroupOptimistically')\n\n        await ingester.start()\n        await testFn(ingester, hub, fetchedTeam)\n        await ingester.stop()\n        await closeHub(hub)\n    })\n}\n\ndescribe('Event Pipeline E2E tests', () => {\n    let clickhouse: Clickhouse\n    beforeAll(async () => {\n        console.log('Creating Clickhouse client')\n        clickhouse = Clickhouse.create()\n        await resetKafka()\n        await resetTestDatabase()\n        await clickhouse.resetTestDatabase()\n        process.env.SITE_URL = 'https://example.com'\n    })\n\n    afterAll(async () => {\n        await resetTestDatabase()\n        await clickhouse.resetTestDatabase()\n        clickhouse.close()\n    })\n\n    testWithTeamIngester('should handle $$client_ingestion_warning events', {}, async (ingester, hub, team) => {\n        const events = [\n            new EventBuilder(team)\n                .withEvent('$$client_ingestion_warning')\n                .withProperties({ $$client_ingestion_warning_message: 'test message' })\n                .build(),\n        ]\n\n        await ingester.handleKafkaBatch(createKafkaMessages(events))\n\n        await waitForExpect(async () => {\n            await waitForKafkaMessages(hub)\n            const warnings = await fetchIngestionWarnings(hub, team.id)\n            expect(warnings).toEqual([\n                expect.objectContaining({\n                    type: 'client_ingestion_warning',\n                    team_id: team.id,\n                    details: expect.objectContaining({ message: 'test message' }),\n                }),\n            ])\n        })\n    })\n\n    testWithTeamIngester('should process events without a team_id', {}, async (ingester, hub, team) => {\n        const events = [new EventBuilder(team).withEvent('test event').build()]\n\n        await ingester.handleKafkaBatch(createKafkaMessages(events))\n\n        await waitForKafkaMessages(hub)\n\n        await waitForExpect(async () => {\n            const events = await fetchEvents(hub, team.id)\n            expect(events.length).toBe(1)\n            expect(events[0].team_id).toBe(team.id)\n        })\n    })\n\n    testWithTeamIngester(\n        'can set and update group properties with $groupidentify events',\n        {},\n        async (ingester, hub, team) => {\n            const groupKey = 'group_key'\n            const distinctId = new UUIDT().toString()\n\n            const events = [\n                new EventBuilder(team, distinctId)\n                    .withEvent('$groupidentify')\n                    .withGroupProperties('organization', groupKey, { foo: 'bar' })\n                    .build(),\n            ]\n\n            await ingester.handleKafkaBatch(createKafkaMessages(events))\n\n            await waitForKafkaMessages(hub)\n            await waitForExpect(async () => {\n                const group = await hub.groupRepository.fetchGroup(team.id, 0, groupKey)\n                expect(group).toEqual(\n                    expect.objectContaining({\n                        team_id: team.id,\n                        group_type_index: 0,\n                        group_properties: { foo: 'bar' },\n                        group_key: groupKey,\n                        version: 1,\n                    })\n                )\n            })\n\n            const updateEvents = [\n                new EventBuilder(team, distinctId)\n                    .withEvent('$groupidentify')\n                    .withGroupProperties('organization', groupKey, { prop: 'value' })\n                    .build(),\n            ]\n\n            await ingester.handleKafkaBatch(createKafkaMessages(updateEvents))\n\n            await waitForKafkaMessages(hub)\n\n            await waitForExpect(async () => {\n                const group = await hub.groupRepository.fetchGroup(team.id, 0, groupKey)\n                expect(group).toEqual(\n                    expect.objectContaining({\n                        team_id: team.id,\n                        group_type_index: 0,\n                        group_properties: { foo: 'bar', prop: 'value' },\n                        group_key: groupKey,\n                        version: 2,\n                    })\n                )\n            })\n\n            await waitForExpect(async () => {\n                const events = await fetchEvents(hub, team.id)\n                expect(events.length).toEqual(2)\n                expect(events[0].event).toEqual('$groupidentify')\n                expect(events[0].properties.$group_set).toEqual({ foo: 'bar' })\n                expect(events[1].event).toEqual('$groupidentify')\n                expect(events[1].properties.$group_set).toEqual({ prop: 'value' })\n            })\n\n            // Should have fetched the group 4 times:\n            // 1 for each event and 2 in test check\n            expect(hub.groupRepository.fetchGroup).toHaveBeenCalledTimes(4)\n        }\n    )\n\n    testWithTeamIngester('can handle high amount of $groupidentify in same batch', {}, async (ingester, hub, team) => {\n        const n = 150\n        const distinctId = new UUIDT().toString()\n        const events = []\n        for (let i = 0; i < n; i++) {\n            const m: Record<string, number> = {}\n            m[i.toString()] = i\n            events.push(\n                new EventBuilder(team, distinctId)\n                    .withEvent('$groupidentify')\n                    .withGroupProperties('organization', 'group_key', m)\n                    .build()\n            )\n        }\n\n        await ingester.handleKafkaBatch(createKafkaMessages(events))\n\n        await waitForKafkaMessages(hub)\n\n        await waitForExpect(async () => {\n            const events = await fetchEvents(hub, team.id)\n            expect(events.length).toEqual(n)\n        })\n\n        expect(hub.groupRepository.fetchGroup).toHaveBeenCalledTimes(1)\n        expect(hub.groupRepository.insertGroup).toHaveBeenCalledTimes(1)\n        expect(hub.groupRepository.updateGroup).toHaveBeenCalledTimes(0)\n        expect(hub.groupRepository.updateGroupOptimistically).toHaveBeenCalledTimes(1)\n    })\n\n    testWithTeamIngester('can handle multiple $groupidentify in same batch', {}, async (ingester, hub, team) => {\n        const timestamp = DateTime.now().toMillis()\n        const distinctId = new UUIDT().toString()\n        const groupKey = 'group_key'\n\n        const events = [\n            new EventBuilder(team, distinctId)\n                .withEvent('$groupidentify')\n                .withGroupProperties('organization', groupKey, { k1: 'v1' })\n                .withTimestamp(timestamp)\n                .build(),\n            new EventBuilder(team, distinctId)\n                .withEvent('$groupidentify')\n                .withGroupProperties('organization', groupKey, { k2: 'v2', k3: 'v2' })\n                .withTimestamp(timestamp + 1)\n                .build(),\n            new EventBuilder(team, distinctId)\n                .withEvent('$groupidentify')\n                .withGroupProperties('organization', groupKey, { k2: 'v3', k4: 'v3' })\n                .withTimestamp(timestamp + 2)\n                .build(),\n        ]\n\n        await ingester.handleKafkaBatch(createKafkaMessages(events))\n\n        await waitForExpect(async () => {\n            await waitForKafkaMessages(hub)\n            const events = await fetchEvents(hub, team.id)\n            expect(events.length).toEqual(3)\n            expect(events[0].event).toEqual('$groupidentify')\n            expect(events[0].properties.$group_set).toEqual({ k1: 'v1' })\n            expect(events[1].event).toEqual('$groupidentify')\n            expect(events[1].properties.$group_set).toEqual({ k2: 'v2', k3: 'v2' })\n            expect(events[2].event).toEqual('$groupidentify')\n            expect(events[2].properties.$group_set).toEqual({ k2: 'v3', k4: 'v3' })\n        })\n\n        expect(hub.groupRepository.fetchGroup).toHaveBeenCalledTimes(1)\n        expect(hub.groupRepository.insertGroup).toHaveBeenCalledTimes(1)\n        expect(hub.groupRepository.updateGroup).toHaveBeenCalledTimes(0)",
            "cost": 0.251655
        },
        "PostHog__posthog.main/plugin-server/src/worker/ingestion/persons/batch-writing-person-store.test.ts": {
            "output": "import { DateTime } from 'luxon'\n\nimport { InternalPerson, TeamId } from '~/types'\nimport { DB } from '~/utils/db/db'\nimport { MessageSizeTooLarge } from '~/utils/db/error'\n\nimport { captureIngestionWarning } from '../utils'\nimport { BatchWritingPersonsStore, BatchWritingPersonsStoreForBatch } from './batch-writing-person-store'\nimport {\n    personProfileBatchIgnoredPropertiesCounter,\n    personProfileBatchUpdateOutcomeCounter,\n    personPropertyKeyUpdateCounter,\n} from './metrics'\nimport { fromInternalPerson } from './person-update-batch'\n\n// Mock the utils module\njest.mock('../utils', () => ({\n    captureIngestionWarning: jest.fn().mockResolvedValue(undefined),\n}))\n\n// Mock metrics\njest.mock('./metrics', () => ({\n    observeLatencyByVersion: jest.fn(),\n    personCacheOperationsCounter: { inc: jest.fn() },\n    personCacheSizeHistogram: { observe: jest.fn() },\n    personDatabaseOperationsPerBatchHistogram: { observe: jest.fn() },\n    personFallbackOperationsCounter: { inc: jest.fn() },\n    personFetchForCheckingCacheOperationsCounter: { inc: jest.fn() },\n    personFetchForUpdateCacheOperationsCounter: { inc: jest.fn() },\n    personFlushBatchSizeHistogram: { observe: jest.fn() },\n    personFlushLatencyHistogram: { observe: jest.fn() },\n    personFlushOperationsCounter: { inc: jest.fn() },\n    personMethodCallsPerBatchHistogram: { observe: jest.fn() },\n    personOptimisticUpdateConflictsPerBatchCounter: { inc: jest.fn() },\n    personProfileBatchIgnoredPropertiesCounter: { labels: jest.fn().mockReturnValue({ inc: jest.fn() }) },\n    personProfileBatchUpdateOutcomeCounter: { labels: jest.fn().mockReturnValue({ inc: jest.fn() }) },\n    personPropertyKeyUpdateCounter: { labels: jest.fn().mockReturnValue({ inc: jest.fn() }) },\n    personRetryAttemptsHistogram: { observe: jest.fn() },\n    personWriteMethodAttemptCounter: { inc: jest.fn() },\n    personWriteMethodLatencyHistogram: { observe: jest.fn() },\n    totalPersonUpdateLatencyPerBatchHistogram: { observe: jest.fn() },\n}))\n\ndescribe('BatchWritingPersonStore', () => {\n    let db: DB\n    let personStore: BatchWritingPersonsStore\n    let mockRepo: any\n    let teamId: TeamId\n    let person: InternalPerson\n\n    beforeEach(() => {\n        teamId = 1\n        person = {\n            id: '1',\n            team_id: teamId,\n            properties: {\n                test: 'test',\n            },\n            created_at: DateTime.now(),\n            version: 1,\n            properties_last_updated_at: {},\n            properties_last_operation: {},\n            is_user_id: null,\n            is_identified: false,\n            uuid: '1',\n        }\n\n        let dbCounter = 0\n        db = {\n            postgres: {\n                transaction: jest.fn().mockImplementation(async (_usage, _tag, transaction) => {\n                    return await transaction(transaction)\n                }),\n            },\n            updatePerson: jest.fn().mockImplementation(() => {\n                dbCounter++\n                const personCopy = { ...person, version: dbCounter }\n                return Promise.resolve([personCopy, []])\n            }),\n            moveDistinctIds: jest.fn().mockImplementation(() => {\n                return Promise.resolve([])\n            }),\n        } as unknown as DB\n\n        mockRepo = createMockRepository()\n        personStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer)\n    })\n\n    afterEach(() => {\n        jest.clearAllMocks()\n    })\n\n    const getBatchStoreForBatch = () => personStore.forBatch() as BatchWritingPersonsStoreForBatch\n\n    const createMockRepository = () => {\n        const mockRepo = {\n            fetchPerson: jest.fn().mockResolvedValue(person),\n            fetchPersonDistinctIds: jest.fn().mockResolvedValue([]),\n            fetchPersonsByDistinctIds: jest.fn().mockResolvedValue([]),\n            createPerson: jest.fn().mockResolvedValue([person, []]),\n            updatePerson: jest.fn().mockResolvedValue([person, [], false]),\n            updatePersonAssertVersion: jest.fn().mockResolvedValue([person.version + 1, []]),\n            deletePerson: jest.fn().mockResolvedValue([]),\n            addDistinctId: jest.fn().mockResolvedValue([]),\n            moveDistinctIds: jest.fn().mockResolvedValue({ success: true, messages: [], distinctIdsMoved: [] }),\n            addPersonlessDistinctId: jest.fn().mockResolvedValue(true),\n            addPersonlessDistinctIdForMerge: jest.fn().mockResolvedValue(true),\n            personPropertiesSize: jest.fn().mockResolvedValue(1024),\n            updateCohortsAndFeatureFlagsForMerge: jest.fn().mockResolvedValue(undefined),\n            inTransaction: jest.fn().mockImplementation(async (description, transaction) => {\n                return await transaction(transaction)\n            }),\n        }\n        return mockRepo\n    }\n\n    const createMockTransaction = () => {\n        const mockTransaction = {\n            fetchPersonDistinctIds: jest.fn().mockResolvedValue([]),\n            createPerson: jest.fn().mockResolvedValue([person, []]),\n            updatePerson: jest.fn().mockResolvedValue([person, [], false]),\n            deletePerson: jest.fn().mockResolvedValue([]),\n            addDistinctId: jest.fn().mockResolvedValue([]),\n            moveDistinctIds: jest.fn().mockResolvedValue({ success: true, messages: [], distinctIdsMoved: [] }),\n            addPersonlessDistinctIdForMerge: jest.fn().mockResolvedValue(true),\n            updateCohortsAndFeatureFlagsForMerge: jest.fn().mockResolvedValue(undefined),\n        }\n        return mockTransaction\n    }\n\n    it('should update person in cache', async () => {\n        const personStoreForBatch = getBatchStoreForBatch()\n        const response = await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(\n            person,\n            { new_value: 'new_value' },\n            [],\n            {},\n            'test'\n        )\n        expect(response).toEqual([\n            { ...person, version: 1, properties: { test: 'test', new_value: 'new_value' } },\n            [],\n            false,\n        ])\n\n        // Validate cache - should contain a PersonUpdate object\n        const cache = (personStoreForBatch as any)['personUpdateCache']\n        const cachedUpdate = cache.get(`${teamId}:${person.id}`)\n        expect(cachedUpdate).toBeDefined()\n        expect(cachedUpdate.distinct_id).toBe('test')\n        expect(cachedUpdate.needs_write).toBe(true)\n        expect(cachedUpdate.properties).toEqual({ test: 'test' }) // Original properties from database\n        expect(cachedUpdate.properties_to_set).toEqual({ new_value: 'new_value' }) // New properties to set\n        expect(cachedUpdate.properties_to_unset).toEqual([]) // No properties to unset\n        expect(cachedUpdate.team_id).toBe(1)\n        expect(cachedUpdate.id).toBe('1')\n    })\n\n    it('should handle unsetting properties', async () => {\n        const personStoreForBatch = getBatchStoreForBatch()\n        const response = await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(\n            person,\n            {\n                value_to_unset: 'value_to_unset',\n            },\n            [],\n            {},\n            'test'\n        )\n        expect(response).toEqual([\n            { ...person, version: 1, properties: { test: 'test', value_to_unset: 'value_to_unset' } },\n            [],\n            false,\n        ])\n\n        const response2 = await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(\n            person,\n            {},\n            ['value_to_unset'],\n            {},\n            'test'\n        )\n        expect(response2).toEqual([{ ...person, version: 1, properties: { test: 'test' } }, [], false])\n\n        // Check cache contains merged updates with conflict resolution\n        // When unsetting a property that was previously set, it should be removed from properties_to_set\n        const cache = personStoreForBatch.getUpdateCache()\n        const cachedUpdate = cache.get(`${teamId}:${person.id}`)!\n        expect(cachedUpdate.properties).toEqual({ test: 'test' })\n        expect(cachedUpdate.properties_to_set).toEqual({ test: 'test' })\n        expect(cachedUpdate.properties_to_unset).toEqual(['value_to_unset'])\n        expect(cachedUpdate.needs_write).toBe(true)\n\n        await personStoreForBatch.flush()\n\n        expect(mockRepo.updatePerson).toHaveBeenCalledWith(\n            expect.objectContaining({\n                properties: { test: 'test' },\n            }),\n            expect.anything(),\n            'updatePersonNoAssert'\n        )\n    })\n\n    it('should handle setting a property after unsetting it (re-setting)', async () => {\n        const personStoreForBatch = getBatchStoreForBatch()\n\n        // First, unset a property\n        await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(person, {}, ['prop_to_toggle'], {}, 'test')\n\n        // Then, set the same property again\n        await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(\n            person,\n            { prop_to_toggle: 'new_value' },\n            [],\n            {},\n            'test'\n        )\n\n        // Check cache - property should be in properties_to_set and NOT in properties_to_unset\n        const cache = personStoreForBatch.getUpdateCache()\n        const cachedUpdate = cache.get(`${teamId}:${person.id}`)!\n        expect(cachedUpdate.properties_to_set).toEqual({ test: 'test', prop_to_toggle: 'new_value' })\n        expect(cachedUpdate.properties_to_unset).toEqual([])\n\n        await personStoreForBatch.flush()\n\n        expect(mockRepo.updatePerson).toHaveBeenCalledWith(\n            expect.objectContaining({\n                properties: { test: 'test', prop_to_toggle: 'new_value' },\n            }),\n            expect.anything(),\n            'updatePersonNoAssert'\n        )\n    })\n\n    it('should handle unsetting a property after setting it', async () => {\n        const personStoreForBatch = getBatchStoreForBatch()\n\n        // First, set a property\n        await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(\n            person,\n            { prop_to_toggle: 'some_value' },\n            [],\n            {},\n            'test'\n        )\n\n        // Then, unset the same property\n        await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(person, {}, ['prop_to_toggle'], {}, 'test')\n\n        // Check cache - property should be in properties_to_unset and NOT in properties_to_set\n        const cache = personStoreForBatch.getUpdateCache()\n        const cachedUpdate = cache.get(`${teamId}:${person.id}`)!\n        expect(cachedUpdate.properties_to_set).toEqual({ test: 'test' })\n        expect(cachedUpdate.properties_to_unset).toEqual(['prop_to_toggle'])\n\n        await personStoreForBatch.flush()\n\n        expect(mockRepo.updatePerson).toHaveBeenCalledWith(\n            expect.objectContaining({\n                properties: { test: 'test' },\n            }),\n            expect.anything(),\n            'updatePersonNoAssert'\n        )\n    })\n\n    it('should remove person from caches when deleted', async () => {\n        const mockRepo = createMockRepository()\n        const testPersonStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer)\n        const personStoreForBatch = testPersonStore.forBatch() as BatchWritingPersonsStoreForBatch\n\n        // Add person to cache using the proper PersonUpdate structure\n        let updateCache = personStoreForBatch.getUpdateCache()\n        const personUpdate = fromInternalPerson(person, 'test')\n        personUpdate.properties = { new_value: 'new_value' }\n        personUpdate.needs_write = false\n        updateCache.set(`${teamId}:${person.id}`, personUpdate)\n\n        let checkCache = personStoreForBatch.getCheckCache()\n        checkCache.set(`${teamId}:test`, person)\n\n        personStoreForBatch.setDistinctIdToPersonId(teamId, 'test', person.id)\n\n        const response = await personStoreForBatch.deletePerson(person, 'test')\n        expect(response).toEqual([])\n        // The cached person update should be passed to deletePerson\n        expect(mockRepo.deletePerson).toHaveBeenCalledWith(\n            expect.objectContaining({\n                ...person,\n                properties: { new_value: 'new_value' },\n            })\n        )\n\n        // Validate cache\n        updateCache = personStoreForBatch.getUpdateCache()\n        checkCache = personStoreForBatch.getCheckCache()\n        expect(updateCache.get(`${teamId}:${person.id}`)).toBeUndefined()\n        expect(checkCache.get(`${teamId}:${person.id}`)).toBeUndefined()\n    })\n\n    it('should flush person updates with default NO_ASSERT mode', async () => {\n        const personStoreForBatch = personStore.forBatch()\n\n        // Add a person update to cache\n        await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(\n            person,\n            { new_value: 'new_value' },\n            [],\n            {},\n            'test'\n        )\n\n        // Flush should call updatePerson (NO_ASSERT default mode)\n        await personStoreForBatch.flush()\n\n        expect(mockRepo.updatePerson).toHaveBeenCalledTimes(1)\n        expect(mockRepo.updatePersonAssertVersion).not.toHaveBeenCalled()\n    })\n\n    it('should fallback to direct update when optimistic update fails', async () => {\n        // Use ASSERT_VERSION mode for this test since it tests optimistic behavior\n        const assertVersionStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer, {\n            dbWriteMode: 'ASSERT_VERSION',\n        })\n        const personStoreForBatch = assertVersionStore.forBatch()\n\n        // Mock optimistic update to fail (version mismatch)\n        mockRepo.updatePersonAssertVersion = jest.fn().mockResolvedValue([undefined, []])\n\n        // Add a person update to cache\n        await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(\n            person,\n            { new_value: 'new_value' },\n            [],\n            {},\n            'test'\n        )\n\n        // Flush should retry optimistically then fallback to direct update\n        await personStoreForBatch.flush()\n\n        expect(mockRepo.updatePersonAssertVersion).toHaveBeenCalled()\n        expect(mockRepo.fetchPerson).toHaveBeenCalled() // Called during conflict resolution\n        expect(mockRepo.updatePerson).toHaveBeenCalled() // Fallback\n    })\n\n    it('should merge multiple updates for same person', async () => {\n        const personStoreForBatch = getBatchStoreForBatch()\n\n        // First update\n        await personStoreForBatch.updatePersonWithPropertiesDiffFor",
            "output_extracted": "import { DateTime } from 'luxon'\n\nimport { InternalPerson, TeamId } from '~/types'\nimport { DB } from '~/utils/db/db'\nimport { MessageSizeTooLarge } from '~/utils/db/error'\n\nimport { captureIngestionWarning } from '../utils'\nimport { BatchWritingPersonsStore, BatchWritingPersonsStoreForBatch } from './batch-writing-person-store'\nimport {\n    personProfileBatchIgnoredPropertiesCounter,\n    personProfileBatchUpdateOutcomeCounter,\n    personPropertyKeyUpdateCounter,\n} from './metrics'\nimport { fromInternalPerson } from './person-update-batch'\n\n// Mock the utils module\njest.mock('../utils', () => ({\n    captureIngestionWarning: jest.fn().mockResolvedValue(undefined),\n}))\n\n// Mock metrics\njest.mock('./metrics', () => ({\n    observeLatencyByVersion: jest.fn(),\n    personCacheOperationsCounter: { inc: jest.fn() },\n    personCacheSizeHistogram: { observe: jest.fn() },\n    personDatabaseOperationsPerBatchHistogram: { observe: jest.fn() },\n    personFallbackOperationsCounter: { inc: jest.fn() },\n    personFetchForCheckingCacheOperationsCounter: { inc: jest.fn() },\n    personFetchForUpdateCacheOperationsCounter: { inc: jest.fn() },\n    personFlushBatchSizeHistogram: { observe: jest.fn() },\n    personFlushLatencyHistogram: { observe: jest.fn() },\n    personFlushOperationsCounter: { inc: jest.fn() },\n    personMethodCallsPerBatchHistogram: { observe: jest.fn() },\n    personOptimisticUpdateConflictsPerBatchCounter: { inc: jest.fn() },\n    personProfileBatchIgnoredPropertiesCounter: { labels: jest.fn().mockReturnValue({ inc: jest.fn() }) },\n    personProfileBatchUpdateOutcomeCounter: { labels: jest.fn().mockReturnValue({ inc: jest.fn() }) },\n    personPropertyKeyUpdateCounter: { labels: jest.fn().mockReturnValue({ inc: jest.fn() }) },\n    personRetryAttemptsHistogram: { observe: jest.fn() },\n    personWriteMethodAttemptCounter: { inc: jest.fn() },\n    personWriteMethodLatencyHistogram: { observe: jest.fn() },\n    totalPersonUpdateLatencyPerBatchHistogram: { observe: jest.fn() },\n}))\n\ndescribe('BatchWritingPersonStore', () => {\n    let db: DB\n    let personStore: BatchWritingPersonsStore\n    let mockRepo: any\n    let teamId: TeamId\n    let person: InternalPerson\n\n    beforeEach(() => {\n        teamId = 1\n        person = {\n            id: '1',\n            team_id: teamId,\n            properties: {\n                test: 'test',\n            },\n            created_at: DateTime.now(),\n            version: 1,\n            properties_last_updated_at: {},\n            properties_last_operation: {},\n            is_user_id: null,\n            is_identified: false,\n            uuid: '1',\n        }\n\n        let dbCounter = 0\n        db = {\n            postgres: {\n                transaction: jest.fn().mockImplementation(async (_usage, _tag, transaction) => {\n                    return await transaction(transaction)\n                }),\n            },\n            updatePerson: jest.fn().mockImplementation(() => {\n                dbCounter++\n                const personCopy = { ...person, version: dbCounter }\n                return Promise.resolve([personCopy, []])\n            }),\n            moveDistinctIds: jest.fn().mockImplementation(() => {\n                return Promise.resolve([])\n            }),\n        } as unknown as DB\n\n        mockRepo = createMockRepository()\n        personStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer)\n    })\n\n    afterEach(() => {\n        jest.clearAllMocks()\n    })\n\n    const getBatchStoreForBatch = () => personStore.forBatch() as BatchWritingPersonsStoreForBatch\n\n    const createMockRepository = () => {\n        const mockRepo = {\n            fetchPerson: jest.fn().mockResolvedValue(person),\n            fetchPersonDistinctIds: jest.fn().mockResolvedValue([]),\n            fetchPersonsByDistinctIds: jest.fn().mockResolvedValue([]),\n            createPerson: jest.fn().mockResolvedValue([person, []]),\n            updatePerson: jest.fn().mockResolvedValue([person, [], false]),\n            updatePersonAssertVersion: jest.fn().mockResolvedValue([person.version + 1, []]),\n            deletePerson: jest.fn().mockResolvedValue([]),\n            addDistinctId: jest.fn().mockResolvedValue([]),\n            moveDistinctIds: jest.fn().mockResolvedValue({ success: true, messages: [], distinctIdsMoved: [] }),\n            addPersonlessDistinctId: jest.fn().mockResolvedValue(true),\n            addPersonlessDistinctIdForMerge: jest.fn().mockResolvedValue(true),\n            personPropertiesSize: jest.fn().mockResolvedValue(1024),\n            updateCohortsAndFeatureFlagsForMerge: jest.fn().mockResolvedValue(undefined),\n            inTransaction: jest.fn().mockImplementation(async (description, transaction) => {\n                return await transaction(transaction)\n            }),\n        }\n        return mockRepo\n    }\n\n    const createMockTransaction = () => {\n        const mockTransaction = {\n            fetchPersonDistinctIds: jest.fn().mockResolvedValue([]),\n            createPerson: jest.fn().mockResolvedValue([person, []]),\n            updatePerson: jest.fn().mockResolvedValue([person, [], false]),\n            deletePerson: jest.fn().mockResolvedValue([]),\n            addDistinctId: jest.fn().mockResolvedValue([]),\n            moveDistinctIds: jest.fn().mockResolvedValue({ success: true, messages: [], distinctIdsMoved: [] }),\n            addPersonlessDistinctIdForMerge: jest.fn().mockResolvedValue(true),\n            updateCohortsAndFeatureFlagsForMerge: jest.fn().mockResolvedValue(undefined),\n        }\n        return mockTransaction\n    }\n\n    it('should update person in cache', async () => {\n        const personStoreForBatch = getBatchStoreForBatch()\n        const response = await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(\n            person,\n            { new_value: 'new_value' },\n            [],\n            {},\n            'test'\n        )\n        expect(response).toEqual([\n            { ...person, version: 1, properties: { test: 'test', new_value: 'new_value' } },\n            [],\n            false,\n        ])\n\n        // Validate cache - should contain a PersonUpdate object\n        const cache = (personStoreForBatch as any)['personUpdateCache']\n        const cachedUpdate = cache.get(`${teamId}:${person.id}`)\n        expect(cachedUpdate).toBeDefined()\n        expect(cachedUpdate.distinct_id).toBe('test')\n        expect(cachedUpdate.needs_write).toBe(true)\n        expect(cachedUpdate.properties).toEqual({ test: 'test' }) // Original properties from database\n        expect(cachedUpdate.properties_to_set).toEqual({ new_value: 'new_value' }) // New properties to set\n        expect(cachedUpdate.properties_to_unset).toEqual([]) // No properties to unset\n        expect(cachedUpdate.team_id).toBe(1)\n        expect(cachedUpdate.id).toBe('1')\n    })\n\n    it('should handle unsetting properties', async () => {\n        const personStoreForBatch = getBatchStoreForBatch()\n        const response = await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(\n            person,\n            {\n                value_to_unset: 'value_to_unset',\n            },\n            [],\n            {},\n            'test'\n        )\n        expect(response).toEqual([\n            { ...person, version: 1, properties: { test: 'test', value_to_unset: 'value_to_unset' } },\n            [],\n            false,\n        ])\n\n        const response2 = await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(\n            person,\n            {},\n            ['value_to_unset'],\n            {},\n            'test'\n        )\n        expect(response2).toEqual([{ ...person, version: 1, properties: { test: 'test' } }, [], false])\n\n        // Check cache contains merged updates with conflict resolution\n        // When unsetting a property that was previously set, it should be removed from properties_to_set\n        const cache = personStoreForBatch.getUpdateCache()\n        const cachedUpdate = cache.get(`${teamId}:${person.id}`)!\n        expect(cachedUpdate.properties).toEqual({ test: 'test' })\n        expect(cachedUpdate.properties_to_set).toEqual({ test: 'test' })\n        expect(cachedUpdate.properties_to_unset).toEqual(['value_to_unset'])\n        expect(cachedUpdate.needs_write).toBe(true)\n\n        await personStoreForBatch.flush()\n\n        expect(mockRepo.updatePerson).toHaveBeenCalledWith(\n            expect.objectContaining({\n                properties: { test: 'test' },\n            }),\n            expect.anything(),\n            'updatePersonNoAssert'\n        )\n    })\n\n    it('should handle setting a property after unsetting it (re-setting)', async () => {\n        const personStoreForBatch = getBatchStoreForBatch()\n\n        // First, unset a property\n        await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(person, {}, ['prop_to_toggle'], {}, 'test')\n\n        // Then, set the same property again\n        await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(\n            person,\n            { prop_to_toggle: 'new_value' },\n            [],\n            {},\n            'test'\n        )\n\n        // Check cache - property should be in properties_to_set and NOT in properties_to_unset\n        const cache = personStoreForBatch.getUpdateCache()\n        const cachedUpdate = cache.get(`${teamId}:${person.id}`)!\n        expect(cachedUpdate.properties_to_set).toEqual({ test: 'test', prop_to_toggle: 'new_value' })\n        expect(cachedUpdate.properties_to_unset).toEqual([])\n\n        await personStoreForBatch.flush()\n\n        expect(mockRepo.updatePerson).toHaveBeenCalledWith(\n            expect.objectContaining({\n                properties: { test: 'test', prop_to_toggle: 'new_value' },\n            }),\n            expect.anything(),\n            'updatePersonNoAssert'\n        )\n    })\n\n    it('should handle unsetting a property after setting it', async () => {\n        const personStoreForBatch = getBatchStoreForBatch()\n\n        // First, set a property\n        await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(\n            person,\n            { prop_to_toggle: 'some_value' },\n            [],\n            {},\n            'test'\n        )\n\n        // Then, unset the same property\n        await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(person, {}, ['prop_to_toggle'], {}, 'test')\n\n        // Check cache - property should be in properties_to_unset and NOT in properties_to_set\n        const cache = personStoreForBatch.getUpdateCache()\n        const cachedUpdate = cache.get(`${teamId}:${person.id}`)!\n        expect(cachedUpdate.properties_to_set).toEqual({ test: 'test' })\n        expect(cachedUpdate.properties_to_unset).toEqual(['prop_to_toggle'])\n\n        await personStoreForBatch.flush()\n\n        expect(mockRepo.updatePerson).toHaveBeenCalledWith(\n            expect.objectContaining({\n                properties: { test: 'test' },\n            }),\n            expect.anything(),\n            'updatePersonNoAssert'\n        )\n    })\n\n    it('should remove person from caches when deleted', async () => {\n        const mockRepo = createMockRepository()\n        const testPersonStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer)\n        const personStoreForBatch = testPersonStore.forBatch() as BatchWritingPersonsStoreForBatch\n\n        // Add person to cache using the proper PersonUpdate structure\n        let updateCache = personStoreForBatch.getUpdateCache()\n        const personUpdate = fromInternalPerson(person, 'test')\n        personUpdate.properties = { new_value: 'new_value' }\n        personUpdate.needs_write = false\n        updateCache.set(`${teamId}:${person.id}`, personUpdate)\n\n        let checkCache = personStoreForBatch.getCheckCache()\n        checkCache.set(`${teamId}:test`, person)\n\n        personStoreForBatch.setDistinctIdToPersonId(teamId, 'test', person.id)\n\n        const response = await personStoreForBatch.deletePerson(person, 'test')\n        expect(response).toEqual([])\n        // The cached person update should be passed to deletePerson\n        expect(mockRepo.deletePerson).toHaveBeenCalledWith(\n            expect.objectContaining({\n                ...person,\n                properties: { new_value: 'new_value' },\n            })\n        )\n\n        // Validate cache\n        updateCache = personStoreForBatch.getUpdateCache()\n        checkCache = personStoreForBatch.getCheckCache()\n        expect(updateCache.get(`${teamId}:${person.id}`)).toBeUndefined()\n        expect(checkCache.get(`${teamId}:${person.id}`)).toBeUndefined()\n    })\n\n    it('should flush person updates with default NO_ASSERT mode', async () => {\n        const personStoreForBatch = personStore.forBatch()\n\n        // Add a person update to cache\n        await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(\n            person,\n            { new_value: 'new_value' },\n            [],\n            {},\n            'test'\n        )\n\n        // Flush should call updatePerson (NO_ASSERT default mode)\n        await personStoreForBatch.flush()\n\n        expect(mockRepo.updatePerson).toHaveBeenCalledTimes(1)\n        expect(mockRepo.updatePersonAssertVersion).not.toHaveBeenCalled()\n    })\n\n    it('should fallback to direct update when optimistic update fails', async () => {\n        // Use ASSERT_VERSION mode for this test since it tests optimistic behavior\n        const assertVersionStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer, {\n            dbWriteMode: 'ASSERT_VERSION',\n        })\n        const personStoreForBatch = assertVersionStore.forBatch()\n\n        // Mock optimistic update to fail (version mismatch)\n        mockRepo.updatePersonAssertVersion = jest.fn().mockResolvedValue([undefined, []])\n\n        // Add a person update to cache\n        await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(\n            person,\n            { new_value: 'new_value' },\n            [],\n            {},\n            'test'\n        )\n\n        // Flush should retry optimistically then fallback to direct update\n        await personStoreForBatch.flush()\n\n        expect(mockRepo.updatePersonAssertVersion).toHaveBeenCalled()\n        expect(mockRepo.fetchPerson).toHaveBeenCalled() // Called during conflict resolution\n        expect(mockRepo.updatePerson).toHaveBeenCalled() // Fallback\n    })\n\n    it('should merge multiple updates for same person', async () => {\n        const personStoreForBatch = getBatchStoreForBatch()\n\n        // First update\n        await personStoreForBatch.updatePersonWithPropertiesDiffFor",
            "cost": 0.242985
        },
        "PostHog__posthog.main/plugin-server/src/worker/ingestion/persons/batch-writing-person-store.ts": {
            "output": "import { DateTime } from 'luxon'\nimport pLimit from 'p-limit'\n\nimport { Properties } from '@posthog/plugin-scaffold'\n\nimport { NoRowsUpdatedError } from '~/utils/utils'\n\nimport { KafkaProducerWrapper, TopicMessage } from '../../../kafka/producer'\nimport {\n    InternalPerson,\n    PersonBatchWritingDbWriteMode,\n    PropertiesLastOperation,\n    PropertiesLastUpdatedAt,\n    Team,\n} from '../../../types'\nimport { CreatePersonResult, MoveDistinctIdsResult } from '../../../utils/db/db'\nimport { MessageSizeTooLarge } from '../../../utils/db/error'\nimport { logger } from '../../../utils/logger'\nimport { BatchWritingStore } from '../stores/batch-writing-store'\nimport { captureIngestionWarning } from '../utils'\nimport {\n    observeLatencyByVersion,\n    personCacheOperationsCounter,\n    personDatabaseOperationsPerBatchHistogram,\n    personFallbackOperationsCounter,\n    personFetchForCheckingCacheOperationsCounter,\n    personFetchForUpdateCacheOperationsCounter,\n    personFlushBatchSizeHistogram,\n    personFlushLatencyHistogram,\n    personFlushOperationsCounter,\n    personMethodCallsPerBatchHistogram,\n    personOptimisticUpdateConflictsPerBatchCounter,\n    personProfileBatchIgnoredPropertiesCounter,\n    personProfileBatchUpdateOutcomeCounter,\n    personPropertyKeyUpdateCounter,\n    personWriteMethodAttemptCounter,\n    totalPersonUpdateLatencyPerBatchHistogram,\n} from './metrics'\nimport { isFilteredPersonUpdateProperty } from './person-property-utils'\nimport { getMetricKey } from './person-update'\nimport { PersonUpdate, fromInternalPerson, toInternalPerson } from './person-update-batch'\nimport { PersonsStore } from './persons-store'\nimport { FlushResult, PersonsStoreForBatch } from './persons-store-for-batch'\nimport { PersonsStoreTransaction } from './persons-store-transaction'\nimport { PersonPropertiesSizeViolationError, PersonRepository } from './repositories/person-repository'\nimport { PersonRepositoryTransaction } from './repositories/person-repository-transaction'\n\ntype MethodName =\n    | 'fetchForChecking'\n    | 'fetchForUpdate'\n    | 'fetchPerson'\n    | 'updatePersonAssertVersion'\n    | 'updatePersonNoAssert'\n    | 'createPerson'\n    | 'updatePersonWithPropertiesDiffForUpdate'\n    | 'updatePersonForMerge'\n    | 'deletePerson'\n    | 'addDistinctId'\n    | 'moveDistinctIds'\n    | 'fetchPersonDistinctIds'\n    | 'updateCohortsAndFeatureFlagsForMerge'\n    | 'addPersonlessDistinctId'\n    | 'addPersonlessDistinctIdForMerge'\n    | 'addPersonUpdateToBatch'\n\ntype UpdateType = 'updatePersonAssertVersion' | 'updatePersonNoAssert'\n\ninterface PersonUpdateResult {\n    success: boolean\n    messages: TopicMessage[]\n    // If there's a updated person update, it will be returned here.\n    // This is useful for the optimistic update case, where we need to update the cache with the latest version.\n    personUpdate?: PersonUpdate\n}\n\nclass MaxRetriesError extends Error {\n    constructor(\n        message: string,\n        public latestPersonUpdate: PersonUpdate\n    ) {\n        super(message)\n        this.name = 'MaxRetriesError'\n    }\n}\n\nexport interface BatchWritingPersonsStoreOptions {\n    maxConcurrentUpdates: number\n    dbWriteMode: PersonBatchWritingDbWriteMode\n    maxOptimisticUpdateRetries: number\n    optimisticUpdateRetryInterval: number\n}\n\nconst DEFAULT_OPTIONS: BatchWritingPersonsStoreOptions = {\n    dbWriteMode: 'NO_ASSERT',\n    maxConcurrentUpdates: 10,\n    maxOptimisticUpdateRetries: 5,\n    optimisticUpdateRetryInterval: 50,\n}\n\ninterface CacheMetrics {\n    updateCacheHits: number\n    updateCacheMisses: number\n    checkCacheHits: number\n    checkCacheMisses: number\n}\n\nexport class BatchWritingPersonsStore implements PersonsStore {\n    private options: BatchWritingPersonsStoreOptions\n\n    constructor(\n        private personRepository: PersonRepository,\n        private kafkaProducer: KafkaProducerWrapper,\n        options?: Partial<BatchWritingPersonsStoreOptions>\n    ) {\n        this.options = { ...DEFAULT_OPTIONS, ...options }\n    }\n\n    forBatch(): PersonsStoreForBatch {\n        return new BatchWritingPersonsStoreForBatch(this.personRepository, this.kafkaProducer, this.options)\n    }\n}\n\n/**\n * This class is used to write persons to the database in batches.\n * It will use a cache to avoid reading the same person from the database multiple times.\n * And will accumulate all changes for the same person in a single batch. At the\n * end of the batch processing, it flushes all changes to the database.\n */\nexport class BatchWritingPersonsStoreForBatch implements PersonsStoreForBatch, BatchWritingStore {\n    private personCheckCache: Map<string, InternalPerson | null>\n    private distinctIdToPersonId: Map<string, string>\n    private personUpdateCache: Map<string, PersonUpdate | null>\n    private fetchPromisesForUpdate: Map<string, Promise<InternalPerson | null>>\n    private fetchPromisesForChecking: Map<string, Promise<InternalPerson | null>>\n    private methodCountsPerDistinctId: Map<string, Map<MethodName, number>>\n    private databaseOperationCountsPerDistinctId: Map<string, Map<MethodName, number>>\n    private updateLatencyPerDistinctIdSeconds: Map<string, Map<UpdateType, number>>\n    private cacheMetrics: CacheMetrics\n    private options: BatchWritingPersonsStoreOptions\n\n    constructor(\n        private personRepository: PersonRepository,\n        private kafkaProducer: KafkaProducerWrapper,\n        options?: Partial<BatchWritingPersonsStoreOptions>\n    ) {\n        this.options = { ...DEFAULT_OPTIONS, ...options }\n        this.distinctIdToPersonId = new Map()\n        this.personUpdateCache = new Map()\n        this.personCheckCache = new Map()\n        this.fetchPromisesForUpdate = new Map()\n        this.fetchPromisesForChecking = new Map()\n        this.methodCountsPerDistinctId = new Map()\n        this.databaseOperationCountsPerDistinctId = new Map()\n        this.updateLatencyPerDistinctIdSeconds = new Map()\n        this.cacheMetrics = {\n            updateCacheHits: 0,\n            updateCacheMisses: 0,\n            checkCacheHits: 0,\n            checkCacheMisses: 0,\n        }\n    }\n\n    /**\n     * Check if a person update should trigger a database write.\n     * Returns the outcome: 'changed' (should write), 'ignored' (filtered properties only), or 'no_change' (no properties changed)\n     *\n     * Also tracks metrics for ignored properties at the batch level.\n     */\n    private getPersonUpdateOutcome(update: PersonUpdate): 'changed' | 'ignored' | 'no_change' {\n        const hasNonPropertyChanges =\n            update.is_identified !== update.original_is_identified ||\n            !update.created_at.equals(update.original_created_at)\n\n        if (hasNonPropertyChanges) {\n            return 'changed'\n        }\n\n        const hasPropertyChanges =\n            Object.keys(update.properties_to_set).length > 0 || update.properties_to_unset.length > 0\n\n        if (!hasPropertyChanges) {\n            return 'no_change'\n        }\n\n        // If force_update is set (from $identify, $set events), bypass filtering and always write\n        if (update.force_update) {\n            return 'changed'\n        }\n\n        // If there are properties to unset, always write\n        if (update.properties_to_unset.length > 0) {\n            return 'changed'\n        }\n\n        // Check if there are any properties_to_set that should trigger an update\n        const ignoredProperties: string[] = []\n        const hasPropertyTriggeringUpdate = Object.keys(update.properties_to_set).some((key) => {\n            // Check if this is a new property (not in current properties)\n            const isNewProperty = !(key in update.properties)\n            const valueChanged = update.properties[key] !== update.properties_to_set[key]\n\n            if (!valueChanged) {\n                return false\n            }\n\n            if (isNewProperty) {\n                return true\n            }\n\n            const isFiltered = isFilteredPersonUpdateProperty(key)\n            if (isFiltered) {\n                ignoredProperties.push(key)\n                return false\n            }\n            return true\n        })\n\n        if (!hasPropertyTriggeringUpdate) {\n            // Only track as ignored if ALL properties are filtered\n            ignoredProperties.forEach((property) => {\n                personProfileBatchIgnoredPropertiesCounter.labels({ property }).inc()\n            })\n            return 'ignored'\n        }\n\n        return 'changed'\n    }\n\n    async flush(): Promise<FlushResult[]> {\n        const flushStartTime = performance.now()\n\n        // Track outcomes for all person updates that were actually modified and filter to only those that should write\n        const updateEntries = Array.from(this.personUpdateCache.entries()).filter(\n            (entry): entry is [string, PersonUpdate] => {\n                const [_, update] = entry\n\n                // Skip null entries - these are deleted persons or cleared cache entries\n                if (!update) {\n                    return false\n                }\n\n                // Skip entries not marked for write - these are read-only cache entries from fetchForUpdate\n                // that were cached but never modified (no events tried to update their properties)\n                if (!update.needs_write) {\n                    return false\n                }\n\n                // Determine outcome and track metrics for this person update\n                const outcome = this.getPersonUpdateOutcome(update)\n                personProfileBatchUpdateOutcomeCounter.labels({ outcome }).inc()\n\n                // Track which property keys caused person updates (only for 'changed' outcomes)\n                if (outcome === 'changed') {\n                    const metricsKeys = new Set<string>()\n                    Object.keys(update.properties_to_set).forEach((key) => {\n                        metricsKeys.add(getMetricKey(key))\n                    })\n                    update.properties_to_unset.forEach((key) => {\n                        metricsKeys.add(getMetricKey(key))\n                    })\n                    metricsKeys.forEach((key) => personPropertyKeyUpdateCounter.labels({ key: key }).inc())\n                }\n\n                // Only write to database if outcome is 'changed'\n                return outcome === 'changed'\n            }\n        )\n\n        const batchSize = updateEntries.length\n        personFlushBatchSizeHistogram.observe({ db_write_mode: this.options.dbWriteMode }, batchSize)\n\n        if (batchSize === 0) {\n            personFlushLatencyHistogram.observe({ db_write_mode: this.options.dbWriteMode }, 0)\n            personFlushOperationsCounter.inc({ db_write_mode: this.options.dbWriteMode, outcome: 'success' })\n            return []\n        }\n\n        const limit = pLimit(this.options.maxConcurrentUpdates)\n\n        try {\n            const results = await Promise.all(\n                updateEntries.map(([cacheKey, update]) =>\n                    limit(async (): Promise<FlushResult[]> => {\n                        try {\n                            personWriteMethodAttemptCounter.inc({\n                                db_write_mode: this.options.dbWriteMode,\n                                method: this.options.dbWriteMode,\n                                outcome: 'attempt',\n                            })\n\n                            let kafkaMessages: FlushResult[] = []\n                            switch (this.options.dbWriteMode) {\n                                case 'NO_ASSERT': {\n                                    const result = await this.withMergeRetry(\n                                        update,\n                                        this.updatePersonNoAssert.bind(this),\n                                        'updatePersonNoAssert',\n                                        this.options.maxOptimisticUpdateRetries,\n                                        this.options.optimisticUpdateRetryInterval\n                                    )\n                                    kafkaMessages = result.messages.map((message) => ({\n                                        topicMessage: message,\n                                        teamId: update.team_id,\n                                        uuid: update.uuid,\n                                        distinctId: update.distinct_id,\n                                    }))\n                                    break\n                                }\n                                case 'ASSERT_VERSION': {\n                                    const result = await this.withMergeRetry(\n                                        update,\n                                        this.updatePersonAssertVersion.bind(this),\n                                        'updatePersonAssertVersion',\n                                        this.options.maxOptimisticUpdateRetries,\n                                        this.options.optimisticUpdateRetryInterval\n                                    )\n                                    kafkaMessages = result.messages.map((message) => ({\n                                        topicMessage: message,\n                                        teamId: update.team_id,\n                                        uuid: update.uuid,\n                                        distinctId: update.distinct_id,\n                                    }))\n                                    break\n                                }\n                            }\n\n                            personWriteMethodAttemptCounter.inc({\n                                db_write_mode: this.options.dbWriteMode,\n                                method: this.options.dbWriteMode,\n                                outcome: 'success',\n                            })\n\n                            return kafkaMessages\n                        } catch (error) {\n                            // If the Kafka message is too large, we can't retry, so we need to capture a warning and stop retrying\n                            if (error instanceof MessageSizeTooLarge) {\n                                await captureIngestionWarning(\n                                    this.kafkaProducer,\n                                    update.team_id,\n                                    'person_upsert_message_size_too_large',\n                                    {\n                                        personId: update.id,\n                                        distinctId: update.distinct_id,\n                                    }\n                                )\n                                personWriteMethodAttemptCounter.inc({\n                                    db_write_mode: this.options.dbWriteMode,\n                                    method: this.options.dbWriteMode,\n                                    outcome: 'error',\n                                })\n                                return []\n                            }\n\n                            if (error instanceof PersonPropertiesSizeViolationError) {\n                                await captureIngestionWarning(\n                                    this.kafkaProducer,\n                                    update.team_id,\n                                    'person_properties_size_violation',\n                                    {\n                                        personId: update.id,\n                                        distinctId: update.distinct_id,\n                                        teamId: update.team_id,\n                                        message: 'Person properties exceeds size limit and was rejected',\n                                    }\n                                )\n                                personWriteMethodAttemptCounter.inc({\n                                    db_write_mode: this.options.dbWriteMode,\n                                    method: this.options.dbWriteMode,\n                                    outcome: 'properties_size_violation',\n                                })\n                                return []\n                            }\n\n                            // Handle max retries error with the latest person update\n                            if (error instanceof MaxRetriesError) {\n                                logger.warn('\u26a0\ufe0f', 'Falling back to direct update after max retries', {\n                                    teamId: error.latestPersonUpdate.team_id,\n                                    personId: error.latestPersonUpdate.id,\n                                    distinctId: error.latestPersonUpdate.distinct_id,\n                                })\n\n                                personFallbackOperationsCounter.inc({\n                                    db_write_mode: this.options.dbWriteMode,\n                                    fallback_reason: 'max_retries',\n                                })\n\n                                const fallbackResult",
            "output_extracted": "import { DateTime } from 'luxon'\nimport pLimit from 'p-limit'\n\nimport { Properties } from '@posthog/plugin-scaffold'\n\nimport { NoRowsUpdatedError } from '~/utils/utils'\n\nimport { KafkaProducerWrapper, TopicMessage } from '../../../kafka/producer'\nimport {\n    InternalPerson,\n    PersonBatchWritingDbWriteMode,\n    PropertiesLastOperation,\n    PropertiesLastUpdatedAt,\n    Team,\n} from '../../../types'\nimport { CreatePersonResult, MoveDistinctIdsResult } from '../../../utils/db/db'\nimport { MessageSizeTooLarge } from '../../../utils/db/error'\nimport { logger } from '../../../utils/logger'\nimport { BatchWritingStore } from '../stores/batch-writing-store'\nimport { captureIngestionWarning } from '../utils'\nimport {\n    observeLatencyByVersion,\n    personCacheOperationsCounter,\n    personDatabaseOperationsPerBatchHistogram,\n    personFallbackOperationsCounter,\n    personFetchForCheckingCacheOperationsCounter,\n    personFetchForUpdateCacheOperationsCounter,\n    personFlushBatchSizeHistogram,\n    personFlushLatencyHistogram,\n    personFlushOperationsCounter,\n    personMethodCallsPerBatchHistogram,\n    personOptimisticUpdateConflictsPerBatchCounter,\n    personProfileBatchIgnoredPropertiesCounter,\n    personProfileBatchUpdateOutcomeCounter,\n    personPropertyKeyUpdateCounter,\n    personWriteMethodAttemptCounter,\n    totalPersonUpdateLatencyPerBatchHistogram,\n} from './metrics'\nimport { isFilteredPersonUpdateProperty } from './person-property-utils'\nimport { getMetricKey } from './person-update'\nimport { PersonUpdate, fromInternalPerson, toInternalPerson } from './person-update-batch'\nimport { PersonsStore } from './persons-store'\nimport { FlushResult, PersonsStoreForBatch } from './persons-store-for-batch'\nimport { PersonsStoreTransaction } from './persons-store-transaction'\nimport { PersonPropertiesSizeViolationError, PersonRepository } from './repositories/person-repository'\nimport { PersonRepositoryTransaction } from './repositories/person-repository-transaction'\n\ntype MethodName =\n    | 'fetchForChecking'\n    | 'fetchForUpdate'\n    | 'fetchPerson'\n    | 'updatePersonAssertVersion'\n    | 'updatePersonNoAssert'\n    | 'createPerson'\n    | 'updatePersonWithPropertiesDiffForUpdate'\n    | 'updatePersonForMerge'\n    | 'deletePerson'\n    | 'addDistinctId'\n    | 'moveDistinctIds'\n    | 'fetchPersonDistinctIds'\n    | 'updateCohortsAndFeatureFlagsForMerge'\n    | 'addPersonlessDistinctId'\n    | 'addPersonlessDistinctIdForMerge'\n    | 'addPersonUpdateToBatch'\n\ntype UpdateType = 'updatePersonAssertVersion' | 'updatePersonNoAssert'\n\ninterface PersonUpdateResult {\n    success: boolean\n    messages: TopicMessage[]\n    // If there's a updated person update, it will be returned here.\n    // This is useful for the optimistic update case, where we need to update the cache with the latest version.\n    personUpdate?: PersonUpdate\n}\n\nclass MaxRetriesError extends Error {\n    constructor(\n        message: string,\n        public latestPersonUpdate: PersonUpdate\n    ) {\n        super(message)\n        this.name = 'MaxRetriesError'\n    }\n}\n\nexport interface BatchWritingPersonsStoreOptions {\n    maxConcurrentUpdates: number\n    dbWriteMode: PersonBatchWritingDbWriteMode\n    maxOptimisticUpdateRetries: number\n    optimisticUpdateRetryInterval: number\n}\n\nconst DEFAULT_OPTIONS: BatchWritingPersonsStoreOptions = {\n    dbWriteMode: 'NO_ASSERT',\n    maxConcurrentUpdates: 10,\n    maxOptimisticUpdateRetries: 5,\n    optimisticUpdateRetryInterval: 50,\n}\n\ninterface CacheMetrics {\n    updateCacheHits: number\n    updateCacheMisses: number\n    checkCacheHits: number\n    checkCacheMisses: number\n}\n\nexport class BatchWritingPersonsStore implements PersonsStore {\n    private options: BatchWritingPersonsStoreOptions\n\n    constructor(\n        private personRepository: PersonRepository,\n        private kafkaProducer: KafkaProducerWrapper,\n        options?: Partial<BatchWritingPersonsStoreOptions>\n    ) {\n        this.options = { ...DEFAULT_OPTIONS, ...options }\n    }\n\n    forBatch(): PersonsStoreForBatch {\n        return new BatchWritingPersonsStoreForBatch(this.personRepository, this.kafkaProducer, this.options)\n    }\n}\n\n/**\n * This class is used to write persons to the database in batches.\n * It will use a cache to avoid reading the same person from the database multiple times.\n * And will accumulate all changes for the same person in a single batch. At the\n * end of the batch processing, it flushes all changes to the database.\n */\nexport class BatchWritingPersonsStoreForBatch implements PersonsStoreForBatch, BatchWritingStore {\n    private personCheckCache: Map<string, InternalPerson | null>\n    private distinctIdToPersonId: Map<string, string>\n    private personUpdateCache: Map<string, PersonUpdate | null>\n    private fetchPromisesForUpdate: Map<string, Promise<InternalPerson | null>>\n    private fetchPromisesForChecking: Map<string, Promise<InternalPerson | null>>\n    private methodCountsPerDistinctId: Map<string, Map<MethodName, number>>\n    private databaseOperationCountsPerDistinctId: Map<string, Map<MethodName, number>>\n    private updateLatencyPerDistinctIdSeconds: Map<string, Map<UpdateType, number>>\n    private cacheMetrics: CacheMetrics\n    private options: BatchWritingPersonsStoreOptions\n\n    constructor(\n        private personRepository: PersonRepository,\n        private kafkaProducer: KafkaProducerWrapper,\n        options?: Partial<BatchWritingPersonsStoreOptions>\n    ) {\n        this.options = { ...DEFAULT_OPTIONS, ...options }\n        this.distinctIdToPersonId = new Map()\n        this.personUpdateCache = new Map()\n        this.personCheckCache = new Map()\n        this.fetchPromisesForUpdate = new Map()\n        this.fetchPromisesForChecking = new Map()\n        this.methodCountsPerDistinctId = new Map()\n        this.databaseOperationCountsPerDistinctId = new Map()\n        this.updateLatencyPerDistinctIdSeconds = new Map()\n        this.cacheMetrics = {\n            updateCacheHits: 0,\n            updateCacheMisses: 0,\n            checkCacheHits: 0,\n            checkCacheMisses: 0,\n        }\n    }\n\n    /**\n     * Check if a person update should trigger a database write.\n     * Returns the outcome: 'changed' (should write), 'ignored' (filtered properties only), or 'no_change' (no properties changed)\n     *\n     * Also tracks metrics for ignored properties at the batch level.\n     */\n    private getPersonUpdateOutcome(update: PersonUpdate): 'changed' | 'ignored' | 'no_change' {\n        const hasNonPropertyChanges =\n            update.is_identified !== update.original_is_identified ||\n            !update.created_at.equals(update.original_created_at)\n\n        if (hasNonPropertyChanges) {\n            return 'changed'\n        }\n\n        const hasPropertyChanges =\n            Object.keys(update.properties_to_set).length > 0 || update.properties_to_unset.length > 0\n\n        if (!hasPropertyChanges) {\n            return 'no_change'\n        }\n\n        // If force_update is set (from $identify, $set events), bypass filtering and always write\n        if (update.force_update) {\n            return 'changed'\n        }\n\n        // If there are properties to unset, always write\n        if (update.properties_to_unset.length > 0) {\n            return 'changed'\n        }\n\n        // Check if there are any properties_to_set that should trigger an update\n        const ignoredProperties: string[] = []\n        const hasPropertyTriggeringUpdate = Object.keys(update.properties_to_set).some((key) => {\n            // Check if this is a new property (not in current properties)\n            const isNewProperty = !(key in update.properties)\n            const valueChanged = update.properties[key] !== update.properties_to_set[key]\n\n            if (!valueChanged) {\n                return false\n            }\n\n            if (isNewProperty) {\n                return true\n            }\n\n            const isFiltered = isFilteredPersonUpdateProperty(key)\n            if (isFiltered) {\n                ignoredProperties.push(key)\n                return false\n            }\n            return true\n        })\n\n        if (!hasPropertyTriggeringUpdate) {\n            // Only track as ignored if ALL properties are filtered\n            ignoredProperties.forEach((property) => {\n                personProfileBatchIgnoredPropertiesCounter.labels({ property }).inc()\n            })\n            return 'ignored'\n        }\n\n        return 'changed'\n    }\n\n    async flush(): Promise<FlushResult[]> {\n        const flushStartTime = performance.now()\n\n        // Track outcomes for all person updates that were actually modified and filter to only those that should write\n        const updateEntries = Array.from(this.personUpdateCache.entries()).filter(\n            (entry): entry is [string, PersonUpdate] => {\n                const [_, update] = entry\n\n                // Skip null entries - these are deleted persons or cleared cache entries\n                if (!update) {\n                    return false\n                }\n\n                // Skip entries not marked for write - these are read-only cache entries from fetchForUpdate\n                // that were cached but never modified (no events tried to update their properties)\n                if (!update.needs_write) {\n                    return false\n                }\n\n                // Determine outcome and track metrics for this person update\n                const outcome = this.getPersonUpdateOutcome(update)\n                personProfileBatchUpdateOutcomeCounter.labels({ outcome }).inc()\n\n                // Track which property keys caused person updates (only for 'changed' outcomes)\n                if (outcome === 'changed') {\n                    const metricsKeys = new Set<string>()\n                    Object.keys(update.properties_to_set).forEach((key) => {\n                        metricsKeys.add(getMetricKey(key))\n                    })\n                    update.properties_to_unset.forEach((key) => {\n                        metricsKeys.add(getMetricKey(key))\n                    })\n                    metricsKeys.forEach((key) => personPropertyKeyUpdateCounter.labels({ key: key }).inc())\n                }\n\n                // Only write to database if outcome is 'changed'\n                return outcome === 'changed'\n            }\n        )\n\n        const batchSize = updateEntries.length\n        personFlushBatchSizeHistogram.observe({ db_write_mode: this.options.dbWriteMode }, batchSize)\n\n        if (batchSize === 0) {\n            personFlushLatencyHistogram.observe({ db_write_mode: this.options.dbWriteMode }, 0)\n            personFlushOperationsCounter.inc({ db_write_mode: this.options.dbWriteMode, outcome: 'success' })\n            return []\n        }\n\n        const limit = pLimit(this.options.maxConcurrentUpdates)\n\n        try {\n            const results = await Promise.all(\n                updateEntries.map(([cacheKey, update]) =>\n                    limit(async (): Promise<FlushResult[]> => {\n                        try {\n                            personWriteMethodAttemptCounter.inc({\n                                db_write_mode: this.options.dbWriteMode,\n                                method: this.options.dbWriteMode,\n                                outcome: 'attempt',\n                            })\n\n                            let kafkaMessages: FlushResult[] = []\n                            switch (this.options.dbWriteMode) {\n                                case 'NO_ASSERT': {\n                                    const result = await this.withMergeRetry(\n                                        update,\n                                        this.updatePersonNoAssert.bind(this),\n                                        'updatePersonNoAssert',\n                                        this.options.maxOptimisticUpdateRetries,\n                                        this.options.optimisticUpdateRetryInterval\n                                    )\n                                    kafkaMessages = result.messages.map((message) => ({\n                                        topicMessage: message,\n                                        teamId: update.team_id,\n                                        uuid: update.uuid,\n                                        distinctId: update.distinct_id,\n                                    }))\n                                    break\n                                }\n                                case 'ASSERT_VERSION': {\n                                    const result = await this.withMergeRetry(\n                                        update,\n                                        this.updatePersonAssertVersion.bind(this),\n                                        'updatePersonAssertVersion',\n                                        this.options.maxOptimisticUpdateRetries,\n                                        this.options.optimisticUpdateRetryInterval\n                                    )\n                                    kafkaMessages = result.messages.map((message) => ({\n                                        topicMessage: message,\n                                        teamId: update.team_id,\n                                        uuid: update.uuid,\n                                        distinctId: update.distinct_id,\n                                    }))\n                                    break\n                                }\n                            }\n\n                            personWriteMethodAttemptCounter.inc({\n                                db_write_mode: this.options.dbWriteMode,\n                                method: this.options.dbWriteMode,\n                                outcome: 'success',\n                            })\n\n                            return kafkaMessages\n                        } catch (error) {\n                            // If the Kafka message is too large, we can't retry, so we need to capture a warning and stop retrying\n                            if (error instanceof MessageSizeTooLarge) {\n                                await captureIngestionWarning(\n                                    this.kafkaProducer,\n                                    update.team_id,\n                                    'person_upsert_message_size_too_large',\n                                    {\n                                        personId: update.id,\n                                        distinctId: update.distinct_id,\n                                    }\n                                )\n                                personWriteMethodAttemptCounter.inc({\n                                    db_write_mode: this.options.dbWriteMode,\n                                    method: this.options.dbWriteMode,\n                                    outcome: 'error',\n                                })\n                                return []\n                            }\n\n                            if (error instanceof PersonPropertiesSizeViolationError) {\n                                await captureIngestionWarning(\n                                    this.kafkaProducer,\n                                    update.team_id,\n                                    'person_properties_size_violation',\n                                    {\n                                        personId: update.id,\n                                        distinctId: update.distinct_id,\n                                        teamId: update.team_id,\n                                        message: 'Person properties exceeds size limit and was rejected',\n                                    }\n                                )\n                                personWriteMethodAttemptCounter.inc({\n                                    db_write_mode: this.options.dbWriteMode,\n                                    method: this.options.dbWriteMode,\n                                    outcome: 'properties_size_violation',\n                                })\n                                return []\n                            }\n\n                            // Handle max retries error with the latest person update\n                            if (error instanceof MaxRetriesError) {\n                                logger.warn('\u26a0\ufe0f', 'Falling back to direct update after max retries', {\n                                    teamId: error.latestPersonUpdate.team_id,\n                                    personId: error.latestPersonUpdate.id,\n                                    distinctId: error.latestPersonUpdate.distinct_id,\n                                })\n\n                                personFallbackOperationsCounter.inc({\n                                    db_write_mode: this.options.dbWriteMode,\n                                    fallback_reason: 'max_retries',\n                                })\n\n                                const fallbackResult",
            "cost": 0.181515
        },
        "PostHog__posthog.main/plugin-server/src/worker/ingestion/persons/person-update.test.ts": {
            "output": "import { PluginEvent } from '@posthog/plugin-scaffold'\n\nimport { personProfileIgnoredPropertiesCounter, personProfileUpdateOutcomeCounter } from './metrics'\nimport { FILTERED_PERSON_UPDATE_PROPERTIES } from './person-property-utils'\nimport { applyEventPropertyUpdates, computeEventPropertyUpdates } from './person-update'\n\njest.mock('./metrics', () => ({\n    personProfileUpdateOutcomeCounter: {\n        labels: jest.fn().mockReturnValue({\n            inc: jest.fn(),\n        }),\n    },\n    personProfileIgnoredPropertiesCounter: {\n        labels: jest.fn().mockReturnValue({\n            inc: jest.fn(),\n        }),\n    },\n}))\n\nconst mockPersonProfileUpdateOutcomeCounter = personProfileUpdateOutcomeCounter as jest.Mocked<\n    typeof personProfileUpdateOutcomeCounter\n>\nconst mockPersonProfileIgnoredPropertiesCounter = personProfileIgnoredPropertiesCounter as jest.Mocked<\n    typeof personProfileIgnoredPropertiesCounter\n>\n\ndescribe('person-update', () => {\n    beforeEach(() => {\n        jest.clearAllMocks()\n    })\n    describe('computeEventPropertyUpdates', () => {\n        describe('property changes', () => {\n            it('should compute updates when custom properties are updated', () => {\n                const event: PluginEvent = {\n                    event: 'pageview',\n                    properties: {\n                        $set: { custom_prop: 'new_value' },\n                    },\n                } as any\n\n                const personProperties = { custom_prop: 'old_value' }\n\n                const result = computeEventPropertyUpdates(event, personProperties)\n\n                expect(result.hasChanges).toBe(true)\n                expect(result.toSet).toEqual({ custom_prop: 'new_value' })\n                expect(result.shouldForceUpdate).toBe(false)\n                expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'changed' })\n                expect(mockPersonProfileUpdateOutcomeCounter.labels({ outcome: 'changed' }).inc).toHaveBeenCalled()\n                expect(mockPersonProfileIgnoredPropertiesCounter.labels).not.toHaveBeenCalled()\n            })\n\n            it('should compute updates when properties are unset', () => {\n                const event: PluginEvent = {\n                    event: 'pageview',\n                    properties: {\n                        $unset: ['prop_to_remove'],\n                    },\n                } as any\n\n                const personProperties = { prop_to_remove: 'value', other_prop: 'keep' }\n\n                const result = computeEventPropertyUpdates(event, personProperties)\n\n                expect(result.hasChanges).toBe(true)\n                expect(result.toUnset).toEqual(['prop_to_remove'])\n                expect(result.shouldForceUpdate).toBe(false)\n                expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'changed' })\n            })\n\n            it('should compute updates when setting a new property', () => {\n                const event: PluginEvent = {\n                    event: 'pageview',\n                    properties: {\n                        $set: { new_prop: 'value' },\n                    },\n                } as any\n\n                const personProperties = {}\n\n                const result = computeEventPropertyUpdates(event, personProperties)\n\n                expect(result.hasChanges).toBe(true)\n                expect(result.toSet).toEqual({ new_prop: 'value' })\n                expect(result.shouldForceUpdate).toBe(false)\n                expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'changed' })\n            })\n\n            it('should compute updates when $set_once sets a property that does not exist', () => {\n                const event: PluginEvent = {\n                    event: 'pageview',\n                    properties: {\n                        $set_once: { first_seen: '2024-01-01' },\n                    },\n                } as any\n\n                const personProperties = {}\n\n                const result = computeEventPropertyUpdates(event, personProperties)\n\n                expect(result.hasChanges).toBe(true)\n                expect(result.toSet).toEqual({ first_seen: '2024-01-01' })\n                expect(result.shouldForceUpdate).toBe(false)\n                expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'changed' })\n            })\n\n            it('should compute updates when a new eventToPersonProperty is set (not just updated)', () => {\n                const event: PluginEvent = {\n                    event: 'pageview',\n                    properties: {\n                        $set: { $browser: 'Chrome' },\n                    },\n                } as any\n\n                const personProperties = {}\n\n                const result = computeEventPropertyUpdates(event, personProperties)\n\n                expect(result.hasChanges).toBe(true)\n                expect(result.toSet).toEqual({ $browser: 'Chrome' })\n                expect(result.shouldForceUpdate).toBe(false)\n                expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'changed' })\n            })\n        })\n\n        describe('filtered properties behavior', () => {\n            it.each(Array.from(FILTERED_PERSON_UPDATE_PROPERTIES))(\n                'should mark \"%s\" as ignored when updated',\n                (propertyName) => {\n                    const event: PluginEvent = {\n                        event: 'pageview',\n                        properties: {\n                            $set: { [propertyName]: 'new_value' },\n                        },\n                    } as any\n\n                    const personProperties = { [propertyName]: 'old_value' }\n\n                    const result = computeEventPropertyUpdates(event, personProperties)\n\n                    expect(result.hasChanges).toBe(true)\n                    expect(result.toSet).toEqual({ [propertyName]: 'new_value' })\n                    expect(result.shouldForceUpdate).toBe(false)\n                    // Filtered properties are marked as ignored\n                    expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'ignored' })\n                    expect(mockPersonProfileUpdateOutcomeCounter.labels({ outcome: 'ignored' }).inc).toHaveBeenCalled()\n                    expect(mockPersonProfileIgnoredPropertiesCounter.labels).toHaveBeenCalledWith({\n                        property: propertyName,\n                    })\n                    expect(\n                        mockPersonProfileIgnoredPropertiesCounter.labels({ property: propertyName }).inc\n                    ).toHaveBeenCalled()\n                }\n            )\n\n            it('should accept $geoip_* property updates at event level (filtering happens at batch level)', () => {\n                const event: PluginEvent = {\n                    event: 'pageview',\n                    properties: {\n                        $set: { $geoip_city_name: 'San Francisco' },\n                    },\n                } as any\n\n                const personProperties = { $geoip_city_name: 'New York' }\n\n                const result = computeEventPropertyUpdates(event, personProperties)\n\n                expect(result.hasChanges).toBe(true)\n                expect(result.toSet).toEqual({ $geoip_city_name: 'San Francisco' })\n                expect(result.shouldForceUpdate).toBe(false)\n                // At event level, geoip properties would be marked as ignored\n                expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'ignored' })\n                expect(mockPersonProfileIgnoredPropertiesCounter.labels).toHaveBeenCalledWith({\n                    property: '$geoip_city_name',\n                })\n            })\n\n            it('should accept eventToPersonProperties even when mixed with unchanged custom properties', () => {\n                const event: PluginEvent = {\n                    event: 'pageview',\n                    properties: {\n                        $set: { $current_url: 'https://example.com/new', custom_prop: 'same_value' },\n                    },\n                } as any\n\n                const personProperties = { $current_url: 'https://example.com/old', custom_prop: 'same_value' }\n\n                const result = computeEventPropertyUpdates(event, personProperties)\n\n                expect(result.hasChanges).toBe(true)\n                expect(result.toSet).toEqual({ $current_url: 'https://example.com/new' })\n                expect(result.shouldForceUpdate).toBe(false)\n                // $current_url is filtered, so it should be marked as ignored\n                expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'ignored' })\n                expect(mockPersonProfileIgnoredPropertiesCounter.labels).toHaveBeenCalledWith({\n                    property: '$current_url',\n                })\n            })\n\n            it('should accept multiple filtered properties at event level', () => {\n                const event: PluginEvent = {\n                    event: 'pageview',\n                    properties: {\n                        $set: {\n                            $current_url: 'https://example.com/new',\n                            $pathname: '/new-path',\n                        },\n                    },\n                } as any\n\n                const personProperties = {\n                    $current_url: 'https://example.com/old',\n                    $pathname: '/old-path',\n                }\n\n                const result = computeEventPropertyUpdates(event, personProperties)\n\n                expect(result.hasChanges).toBe(true)\n                expect(result.shouldForceUpdate).toBe(false)\n                // Filtered properties should be marked as ignored\n                expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'ignored' })\n                expect(mockPersonProfileIgnoredPropertiesCounter.labels).toHaveBeenCalledWith({\n                    property: '$current_url',\n                })\n                expect(mockPersonProfileIgnoredPropertiesCounter.labels).toHaveBeenCalledWith({ property: '$pathname' })\n            })\n        })\n\n        describe('no changes', () => {\n            it('should return no changes when no properties are provided', () => {\n                const event: PluginEvent = {\n                    event: 'pageview',\n                    properties: {},\n                } as any\n\n                const personProperties = { existing_prop: 'value' }\n\n                const result = computeEventPropertyUpdates(event, personProperties)\n\n                expect(result.hasChanges).toBe(false)\n                expect(result.toSet).toEqual({})\n                expect(result.toUnset).toEqual([])\n                expect(result.shouldForceUpdate).toBe(false)\n                expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'no_change' })\n                expect(mockPersonProfileIgnoredPropertiesCounter.labels).not.toHaveBeenCalled()\n            })\n\n            it('should return no changes when all properties have the same value', () => {\n                const event: PluginEvent = {\n                    event: 'pageview',\n                    properties: {\n                        $set: { custom_prop: 'same_value' },\n                    },\n                } as any\n\n                const personProperties = { custom_prop: 'same_value' }\n\n                const result = computeEventPropertyUpdates(event, personProperties)\n\n                expect(result.hasChanges).toBe(false)\n                expect(result.toSet).toEqual({})\n                expect(result.shouldForceUpdate).toBe(false)\n                expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'no_change' })\n            })\n\n            it('should return no changes when $set_once property already exists', () => {\n                const event: PluginEvent = {\n                    event: 'pageview',\n                    properties: {\n                        $set_once: { first_seen: '2024-01-01' },\n                    },\n                } as any\n\n                const personProperties = { first_seen: '2023-01-01' }\n\n                const result = computeEventPropertyUpdates(event, personProperties)\n\n                expect(result.hasChanges).toBe(false)\n                expect(result.toSet).toEqual({})\n                expect(result.shouldForceUpdate).toBe(false)\n                expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'no_change' })\n            })\n\n            it('should return no changes when trying to unset non-existent property', () => {\n                const event: PluginEvent = {\n                    event: 'pageview',\n                    properties: {\n                        $unset: ['non_existent_prop'],\n                    },\n                } as any\n\n                const personProperties = { other_prop: 'value' }\n\n                const result = computeEventPropertyUpdates(event, personProperties)\n\n                expect(result.hasChanges).toBe(false)\n                expect(result.toUnset).toEqual([])\n                expect(result.shouldForceUpdate).toBe(false)\n                expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'no_change' })\n            })\n        })\n\n        describe('person events behavior', () => {\n            it('should compute updates for any property on $identify events', () => {\n                const event: PluginEvent = {\n                    event: '$identify',\n                    properties: {\n                        $set: { $browser: 'Chrome' },\n                    },\n                } as any\n\n                const personProperties = { $browser: 'Firefox' }\n\n                const result = computeEventPropertyUpdates(event, personProperties)\n\n                expect(result.hasChanges).toBe(true)\n                expect(result.toSet).toEqual({ $browser: 'Chrome' })\n                expect(result.shouldForceUpdate).toBe(true)\n                expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'changed' })\n            })\n\n            it('should compute updates for any property on $set events', () => {\n                const event: PluginEvent = {\n                    event: '$set',\n                    properties: {\n                        $set: { utm_source: 'google' },\n                    },\n                } as any\n\n                const personProperties = { utm_source: 'twitter' }\n\n                const result = computeEventPropertyUpdates(event, personProperties)\n\n                expect(result.hasChanges).toBe(true)\n                expect(result.shouldForceUpdate).toBe(true)\n                expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'changed' })\n            })\n\n            it('should set shouldForceUpdate to false for non-person events', () => {\n                const event: PluginEvent = {\n                    event: 'pageview',\n                    properties: {\n                        $set: { $browser: 'Chrome' },\n                    },\n                } as any\n\n                const personProperties = { $browser: 'Firefox' }\n\n                const result = computeEventPropertyUpdates(event, personProperties)\n\n                expect(result.hasChanges).toBe(true)\n                expect(result.shouldForceUpdate).toBe(false)\n            })\n        })\n\n        describe('NO_PERSON_UPDATE_EVENTS behavior', () => {\n            it('should skip updates for $exception events regardless of properties', () => {\n                const event: PluginEvent = {\n                    event: '$exception',\n                    properties: {\n                        $set: { custom_prop: 'new_value' },\n                    },\n                } as any\n\n                const personProperties = { custom_prop: 'old_value' }\n\n                const result = computeEventPropertyUpdates(event, personProperties)\n\n                expect(result.hasChanges).toBe(false)\n                expect(result.toSet).toEqual({})\n                expect(result.shouldForceUpdate).toBe(false)\n                expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'unsupported' })\n            })\n\n            it('should skip updates for $$heatmap events regardless of properties', () => {\n                const event: PluginEvent = {\n                    event: '$$heatmap',\n                    properties: {\n                        $set: {",
            "output_extracted": "import { PluginEvent } from '@posthog/plugin-scaffold'\n\nimport { personProfileIgnoredPropertiesCounter, personProfileUpdateOutcomeCounter } from './metrics'\nimport { FILTERED_PERSON_UPDATE_PROPERTIES } from './person-property-utils'\nimport { applyEventPropertyUpdates, computeEventPropertyUpdates } from './person-update'\n\njest.mock('./metrics', () => ({\n    personProfileUpdateOutcomeCounter: {\n        labels: jest.fn().mockReturnValue({\n            inc: jest.fn(),\n        }),\n    },\n    personProfileIgnoredPropertiesCounter: {\n        labels: jest.fn().mockReturnValue({\n            inc: jest.fn(),\n        }),\n    },\n}))\n\nconst mockPersonProfileUpdateOutcomeCounter = personProfileUpdateOutcomeCounter as jest.Mocked<\n    typeof personProfileUpdateOutcomeCounter\n>\nconst mockPersonProfileIgnoredPropertiesCounter = personProfileIgnoredPropertiesCounter as jest.Mocked<\n    typeof personProfileIgnoredPropertiesCounter\n>\n\ndescribe('person-update', () => {\n    beforeEach(() => {\n        jest.clearAllMocks()\n    })\n    describe('computeEventPropertyUpdates', () => {\n        describe('property changes', () => {\n            it('should compute updates when custom properties are updated', () => {\n                const event: PluginEvent = {\n                    event: 'pageview',\n                    properties: {\n                        $set: { custom_prop: 'new_value' },\n                    },\n                } as any\n\n                const personProperties = { custom_prop: 'old_value' }\n\n                const result = computeEventPropertyUpdates(event, personProperties)\n\n                expect(result.hasChanges).toBe(true)\n                expect(result.toSet).toEqual({ custom_prop: 'new_value' })\n                expect(result.shouldForceUpdate).toBe(false)\n                expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'changed' })\n                expect(mockPersonProfileUpdateOutcomeCounter.labels({ outcome: 'changed' }).inc).toHaveBeenCalled()\n                expect(mockPersonProfileIgnoredPropertiesCounter.labels).not.toHaveBeenCalled()\n            })\n\n            it('should compute updates when properties are unset', () => {\n                const event: PluginEvent = {\n                    event: 'pageview',\n                    properties: {\n                        $unset: ['prop_to_remove'],\n                    },\n                } as any\n\n                const personProperties = { prop_to_remove: 'value', other_prop: 'keep' }\n\n                const result = computeEventPropertyUpdates(event, personProperties)\n\n                expect(result.hasChanges).toBe(true)\n                expect(result.toUnset).toEqual(['prop_to_remove'])\n                expect(result.shouldForceUpdate).toBe(false)\n                expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'changed' })\n            })\n\n            it('should compute updates when setting a new property', () => {\n                const event: PluginEvent = {\n                    event: 'pageview',\n                    properties: {\n                        $set: { new_prop: 'value' },\n                    },\n                } as any\n\n                const personProperties = {}\n\n                const result = computeEventPropertyUpdates(event, personProperties)\n\n                expect(result.hasChanges).toBe(true)\n                expect(result.toSet).toEqual({ new_prop: 'value' })\n                expect(result.shouldForceUpdate).toBe(false)\n                expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'changed' })\n            })\n\n            it('should compute updates when $set_once sets a property that does not exist', () => {\n                const event: PluginEvent = {\n                    event: 'pageview',\n                    properties: {\n                        $set_once: { first_seen: '2024-01-01' },\n                    },\n                } as any\n\n                const personProperties = {}\n\n                const result = computeEventPropertyUpdates(event, personProperties)\n\n                expect(result.hasChanges).toBe(true)\n                expect(result.toSet).toEqual({ first_seen: '2024-01-01' })\n                expect(result.shouldForceUpdate).toBe(false)\n                expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'changed' })\n            })\n\n            it('should compute updates when a new eventToPersonProperty is set (not just updated)', () => {\n                const event: PluginEvent = {\n                    event: 'pageview',\n                    properties: {\n                        $set: { $browser: 'Chrome' },\n                    },\n                } as any\n\n                const personProperties = {}\n\n                const result = computeEventPropertyUpdates(event, personProperties)\n\n                expect(result.hasChanges).toBe(true)\n                expect(result.toSet).toEqual({ $browser: 'Chrome' })\n                expect(result.shouldForceUpdate).toBe(false)\n                expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'changed' })\n            })\n        })\n\n        describe('filtered properties behavior', () => {\n            it.each(Array.from(FILTERED_PERSON_UPDATE_PROPERTIES))(\n                'should mark \"%s\" as ignored when updated',\n                (propertyName) => {\n                    const event: PluginEvent = {\n                        event: 'pageview',\n                        properties: {\n                            $set: { [propertyName]: 'new_value' },\n                        },\n                    } as any\n\n                    const personProperties = { [propertyName]: 'old_value' }\n\n                    const result = computeEventPropertyUpdates(event, personProperties)\n\n                    expect(result.hasChanges).toBe(true)\n                    expect(result.toSet).toEqual({ [propertyName]: 'new_value' })\n                    expect(result.shouldForceUpdate).toBe(false)\n                    // Filtered properties are marked as ignored\n                    expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'ignored' })\n                    expect(mockPersonProfileUpdateOutcomeCounter.labels({ outcome: 'ignored' }).inc).toHaveBeenCalled()\n                    expect(mockPersonProfileIgnoredPropertiesCounter.labels).toHaveBeenCalledWith({\n                        property: propertyName,\n                    })\n                    expect(\n                        mockPersonProfileIgnoredPropertiesCounter.labels({ property: propertyName }).inc\n                    ).toHaveBeenCalled()\n                }\n            )\n\n            it('should accept $geoip_* property updates at event level (filtering happens at batch level)', () => {\n                const event: PluginEvent = {\n                    event: 'pageview',\n                    properties: {\n                        $set: { $geoip_city_name: 'San Francisco' },\n                    },\n                } as any\n\n                const personProperties = { $geoip_city_name: 'New York' }\n\n                const result = computeEventPropertyUpdates(event, personProperties)\n\n                expect(result.hasChanges).toBe(true)\n                expect(result.toSet).toEqual({ $geoip_city_name: 'San Francisco' })\n                expect(result.shouldForceUpdate).toBe(false)\n                // At event level, geoip properties would be marked as ignored\n                expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'ignored' })\n                expect(mockPersonProfileIgnoredPropertiesCounter.labels).toHaveBeenCalledWith({\n                    property: '$geoip_city_name',\n                })\n            })\n\n            it('should accept eventToPersonProperties even when mixed with unchanged custom properties', () => {\n                const event: PluginEvent = {\n                    event: 'pageview',\n                    properties: {\n                        $set: { $current_url: 'https://example.com/new', custom_prop: 'same_value' },\n                    },\n                } as any\n\n                const personProperties = { $current_url: 'https://example.com/old', custom_prop: 'same_value' }\n\n                const result = computeEventPropertyUpdates(event, personProperties)\n\n                expect(result.hasChanges).toBe(true)\n                expect(result.toSet).toEqual({ $current_url: 'https://example.com/new' })\n                expect(result.shouldForceUpdate).toBe(false)\n                // $current_url is filtered, so it should be marked as ignored\n                expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'ignored' })\n                expect(mockPersonProfileIgnoredPropertiesCounter.labels).toHaveBeenCalledWith({\n                    property: '$current_url',\n                })\n            })\n\n            it('should accept multiple filtered properties at event level', () => {\n                const event: PluginEvent = {\n                    event: 'pageview',\n                    properties: {\n                        $set: {\n                            $current_url: 'https://example.com/new',\n                            $pathname: '/new-path',\n                        },\n                    },\n                } as any\n\n                const personProperties = {\n                    $current_url: 'https://example.com/old',\n                    $pathname: '/old-path',\n                }\n\n                const result = computeEventPropertyUpdates(event, personProperties)\n\n                expect(result.hasChanges).toBe(true)\n                expect(result.shouldForceUpdate).toBe(false)\n                // Filtered properties should be marked as ignored\n                expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'ignored' })\n                expect(mockPersonProfileIgnoredPropertiesCounter.labels).toHaveBeenCalledWith({\n                    property: '$current_url',\n                })\n                expect(mockPersonProfileIgnoredPropertiesCounter.labels).toHaveBeenCalledWith({ property: '$pathname' })\n            })\n        })\n\n        describe('no changes', () => {\n            it('should return no changes when no properties are provided', () => {\n                const event: PluginEvent = {\n                    event: 'pageview',\n                    properties: {},\n                } as any\n\n                const personProperties = { existing_prop: 'value' }\n\n                const result = computeEventPropertyUpdates(event, personProperties)\n\n                expect(result.hasChanges).toBe(false)\n                expect(result.toSet).toEqual({})\n                expect(result.toUnset).toEqual([])\n                expect(result.shouldForceUpdate).toBe(false)\n                expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'no_change' })\n                expect(mockPersonProfileIgnoredPropertiesCounter.labels).not.toHaveBeenCalled()\n            })\n\n            it('should return no changes when all properties have the same value', () => {\n                const event: PluginEvent = {\n                    event: 'pageview',\n                    properties: {\n                        $set: { custom_prop: 'same_value' },\n                    },\n                } as any\n\n                const personProperties = { custom_prop: 'same_value' }\n\n                const result = computeEventPropertyUpdates(event, personProperties)\n\n                expect(result.hasChanges).toBe(false)\n                expect(result.toSet).toEqual({})\n                expect(result.shouldForceUpdate).toBe(false)\n                expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'no_change' })\n            })\n\n            it('should return no changes when $set_once property already exists', () => {\n                const event: PluginEvent = {\n                    event: 'pageview',\n                    properties: {\n                        $set_once: { first_seen: '2024-01-01' },\n                    },\n                } as any\n\n                const personProperties = { first_seen: '2023-01-01' }\n\n                const result = computeEventPropertyUpdates(event, personProperties)\n\n                expect(result.hasChanges).toBe(false)\n                expect(result.toSet).toEqual({})\n                expect(result.shouldForceUpdate).toBe(false)\n                expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'no_change' })\n            })\n\n            it('should return no changes when trying to unset non-existent property', () => {\n                const event: PluginEvent = {\n                    event: 'pageview',\n                    properties: {\n                        $unset: ['non_existent_prop'],\n                    },\n                } as any\n\n                const personProperties = { other_prop: 'value' }\n\n                const result = computeEventPropertyUpdates(event, personProperties)\n\n                expect(result.hasChanges).toBe(false)\n                expect(result.toUnset).toEqual([])\n                expect(result.shouldForceUpdate).toBe(false)\n                expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'no_change' })\n            })\n        })\n\n        describe('person events behavior', () => {\n            it('should compute updates for any property on $identify events', () => {\n                const event: PluginEvent = {\n                    event: '$identify',\n                    properties: {\n                        $set: { $browser: 'Chrome' },\n                    },\n                } as any\n\n                const personProperties = { $browser: 'Firefox' }\n\n                const result = computeEventPropertyUpdates(event, personProperties)\n\n                expect(result.hasChanges).toBe(true)\n                expect(result.toSet).toEqual({ $browser: 'Chrome' })\n                expect(result.shouldForceUpdate).toBe(true)\n                expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'changed' })\n            })\n\n            it('should compute updates for any property on $set events', () => {\n                const event: PluginEvent = {\n                    event: '$set',\n                    properties: {\n                        $set: { utm_source: 'google' },\n                    },\n                } as any\n\n                const personProperties = { utm_source: 'twitter' }\n\n                const result = computeEventPropertyUpdates(event, personProperties)\n\n                expect(result.hasChanges).toBe(true)\n                expect(result.shouldForceUpdate).toBe(true)\n                expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'changed' })\n            })\n\n            it('should set shouldForceUpdate to false for non-person events', () => {\n                const event: PluginEvent = {\n                    event: 'pageview',\n                    properties: {\n                        $set: { $browser: 'Chrome' },\n                    },\n                } as any\n\n                const personProperties = { $browser: 'Firefox' }\n\n                const result = computeEventPropertyUpdates(event, personProperties)\n\n                expect(result.hasChanges).toBe(true)\n                expect(result.shouldForceUpdate).toBe(false)\n            })\n        })\n\n        describe('NO_PERSON_UPDATE_EVENTS behavior', () => {\n            it('should skip updates for $exception events regardless of properties', () => {\n                const event: PluginEvent = {\n                    event: '$exception',\n                    properties: {\n                        $set: { custom_prop: 'new_value' },\n                    },\n                } as any\n\n                const personProperties = { custom_prop: 'old_value' }\n\n                const result = computeEventPropertyUpdates(event, personProperties)\n\n                expect(result.hasChanges).toBe(false)\n                expect(result.toSet).toEqual({})\n                expect(result.shouldForceUpdate).toBe(false)\n                expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'unsupported' })\n            })\n\n            it('should skip updates for $$heatmap events regardless of properties', () => {\n                const event: PluginEvent = {\n                    event: '$$heatmap',\n                    properties: {\n                        $set: {",
            "cost": 0.15219500000000002
        },
        "PostHog__posthog.main/plugin-server/src/worker/ingestion/persons/person-update.ts": {
            "output": "import { PluginEvent, Properties } from '@posthog/plugin-scaffold'\n\nimport { cloneObject } from '~/utils/utils'\n\nimport { InternalPerson } from '../../../types'\nimport { logger } from '../../../utils/logger'\nimport { personProfileIgnoredPropertiesCounter, personProfileUpdateOutcomeCounter } from './metrics'\nimport {\n    eventToPersonProperties,\n    initialEventToPersonProperties,\n    isFilteredPersonUpdateProperty,\n} from './person-property-utils'\n\nexport interface PropertyUpdates {\n    toSet: Properties\n    toUnset: string[]\n    hasChanges: boolean\n    shouldForceUpdate: boolean // True for PERSON_EVENTS ($identify, $set, etc.) to bypass batch-level filtering\n}\n\n// These events are processed in a separate pipeline, so we don't allow person property updates\n// because there is no ordering guaranteed across them with other person updates\nconst NO_PERSON_UPDATE_EVENTS = new Set(['$exception', '$$heatmap'])\nconst PERSON_EVENTS = new Set(['$identify', '$create_alias', '$merge_dangerously', '$set'])\n\n// For tracking what property keys cause us to update persons\n// tracking all properties we add from the event, 'geoip' for '$geoip_*' or '$initial_geoip_*' and 'other' for anything outside of those\nexport function getMetricKey(key: string): string {\n    if (key.startsWith('$geoip_') || key.startsWith('$initial_geoip_')) {\n        return 'geoIP'\n    }\n    if (eventToPersonProperties.has(key)) {\n        return key\n    }\n    if (initialEventToPersonProperties.has(key)) {\n        return key\n    }\n    return 'other'\n}\n\n/**\n * Computes property changes from an event without modifying personProperties\n * @param event The event to extract property changes from\n * @param personProperties Current person properties (not modified)\n * @param updateAllProperties When true, all property changes trigger updates (no filtering)\n * @returns Object with properties to set, unset, and whether there are changes\n */\nexport function computeEventPropertyUpdates(\n    event: PluginEvent,\n    personProperties: Properties,\n    updateAllProperties: boolean = false\n): PropertyUpdates {\n    if (NO_PERSON_UPDATE_EVENTS.has(event.event)) {\n        personProfileUpdateOutcomeCounter.labels({ outcome: 'unsupported' }).inc()\n        return { hasChanges: false, toSet: {}, toUnset: [], shouldForceUpdate: false }\n    }\n\n    // Check if this is a PERSON_EVENT that should bypass batch-level filtering\n    // Also force update when updateAllProperties is enabled\n    const shouldForceUpdate = PERSON_EVENTS.has(event.event) || updateAllProperties\n\n    const properties: Properties = event.properties!['$set'] || {}\n    const propertiesOnce: Properties = event.properties!['$set_once'] || {}\n    const unsetProps = event.properties!['$unset']\n    const unsetProperties: Array<string> = Array.isArray(unsetProps) ? unsetProps : Object.keys(unsetProps || {}) || []\n\n    let hasChanges = false\n    let hasNonFilteredChanges = false\n    const toSet: Properties = {}\n    const toUnset: string[] = []\n    const ignoredProperties: string[] = []\n\n    Object.entries(propertiesOnce).forEach(([key, value]) => {\n        if (typeof personProperties[key] === 'undefined') {\n            hasChanges = true\n            toSet[key] = value\n            if (shouldUpdatePersonIfOnlyChange(event, key, updateAllProperties)) {\n                hasNonFilteredChanges = true\n            }\n        }\n    })\n\n    Object.entries(properties).forEach(([key, value]) => {\n        if (personProperties[key] !== value) {\n            const isNewProperty = typeof personProperties[key] === 'undefined'\n            const shouldUpdate = isNewProperty || shouldUpdatePersonIfOnlyChange(event, key, updateAllProperties)\n\n            if (shouldUpdate) {\n                hasChanges = true\n                hasNonFilteredChanges = true\n            } else {\n                hasChanges = true\n                ignoredProperties.push(key)\n            }\n            toSet[key] = value\n        }\n    })\n\n    unsetProperties.forEach((propertyKey) => {\n        if (propertyKey in personProperties) {\n            if (typeof propertyKey === 'string') {\n                hasChanges = true\n                hasNonFilteredChanges = true\n                toUnset.push(propertyKey)\n            }\n        }\n    })\n\n    // Track person profile update outcomes at event level (skip when updateAllProperties is enabled)\n    if (!updateAllProperties) {\n        const hasPropertyChanges = Object.keys(toSet).length > 0 || toUnset.length > 0\n        if (hasPropertyChanges) {\n            if (hasNonFilteredChanges) {\n                personProfileUpdateOutcomeCounter.labels({ outcome: 'changed' }).inc()\n            } else {\n                personProfileUpdateOutcomeCounter.labels({ outcome: 'ignored' }).inc()\n                ignoredProperties.forEach((property) => {\n                    personProfileIgnoredPropertiesCounter.labels({ property }).inc()\n                })\n            }\n        } else {\n            personProfileUpdateOutcomeCounter.labels({ outcome: 'no_change' }).inc()\n        }\n    }\n\n    return { hasChanges, toSet, toUnset, shouldForceUpdate }\n}\n\n/**\n * @param propertyUpdates The computed property updates to apply\n * @param person The person to apply updates to - a new person object is returned with updated properties\n * @returns [updatedPerson, wasUpdated] - new person object and boolean indicating if changes were made\n */\nexport function applyEventPropertyUpdates(\n    propertyUpdates: PropertyUpdates,\n    person: InternalPerson\n): [InternalPerson, boolean] {\n    let updated = false\n\n    // Create a copy of the person with copied properties\n    const updatedPerson = cloneObject(person)\n\n    // Apply properties to set\n    Object.entries(propertyUpdates.toSet).forEach(([key, value]) => {\n        if (updatedPerson.properties[key] !== value) {\n            updated = true\n        }\n        updatedPerson.properties[key] = value\n    })\n\n    // Apply properties to unset\n    propertyUpdates.toUnset.forEach((propertyKey) => {\n        if (propertyKey in updatedPerson.properties) {\n            if (typeof propertyKey !== 'string') {\n                logger.warn('\ud83d\udd14', 'unset_property_key_not_string', { propertyKey, toUnset: propertyUpdates.toUnset })\n                return\n            }\n            updated = true\n            delete updatedPerson.properties[propertyKey]\n        }\n    })\n\n    return [updatedPerson, updated]\n}\n\n// Minimize useless person updates by not overriding properties if it's not a person event and we added from the event\n// They will still show up for PoE as it's not removed from the event, we just don't update the person in PG anymore\nfunction shouldUpdatePersonIfOnlyChange(event: PluginEvent, key: string, updateAllProperties: boolean): boolean {\n    if (updateAllProperties) {\n        // When flag is enabled, all property changes trigger updates\n        return true\n    }\n    if (PERSON_EVENTS.has(event.event)) {\n        // for person events always update everything\n        return true\n    }\n    // These are properties we add from the event and some change often, it's useless to update person always\n    if (eventToPersonProperties.has(key)) {\n        return false\n    }\n    // same as above, coming from GeoIP plugin\n    if (key.startsWith('$geoip_')) {\n        return false\n    }\n    return true\n}",
            "output_extracted": "import { PluginEvent, Properties } from '@posthog/plugin-scaffold'\n\nimport { cloneObject } from '~/utils/utils'\n\nimport { InternalPerson } from '../../../types'\nimport { logger } from '../../../utils/logger'\nimport { personProfileIgnoredPropertiesCounter, personProfileUpdateOutcomeCounter } from './metrics'\nimport {\n    eventToPersonProperties,\n    initialEventToPersonProperties,\n    isFilteredPersonUpdateProperty,\n} from './person-property-utils'\n\nexport interface PropertyUpdates {\n    toSet: Properties\n    toUnset: string[]\n    hasChanges: boolean\n    shouldForceUpdate: boolean // True for PERSON_EVENTS ($identify, $set, etc.) to bypass batch-level filtering\n}\n\n// These events are processed in a separate pipeline, so we don't allow person property updates\n// because there is no ordering guaranteed across them with other person updates\nconst NO_PERSON_UPDATE_EVENTS = new Set(['$exception', '$$heatmap'])\nconst PERSON_EVENTS = new Set(['$identify', '$create_alias', '$merge_dangerously', '$set'])\n\n// For tracking what property keys cause us to update persons\n// tracking all properties we add from the event, 'geoip' for '$geoip_*' or '$initial_geoip_*' and 'other' for anything outside of those\nexport function getMetricKey(key: string): string {\n    if (key.startsWith('$geoip_') || key.startsWith('$initial_geoip_')) {\n        return 'geoIP'\n    }\n    if (eventToPersonProperties.has(key)) {\n        return key\n    }\n    if (initialEventToPersonProperties.has(key)) {\n        return key\n    }\n    return 'other'\n}\n\n/**\n * Computes property changes from an event without modifying personProperties\n * @param event The event to extract property changes from\n * @param personProperties Current person properties (not modified)\n * @param updateAllProperties When true, all property changes trigger updates (no filtering)\n * @returns Object with properties to set, unset, and whether there are changes\n */\nexport function computeEventPropertyUpdates(\n    event: PluginEvent,\n    personProperties: Properties,\n    updateAllProperties: boolean = false\n): PropertyUpdates {\n    if (NO_PERSON_UPDATE_EVENTS.has(event.event)) {\n        personProfileUpdateOutcomeCounter.labels({ outcome: 'unsupported' }).inc()\n        return { hasChanges: false, toSet: {}, toUnset: [], shouldForceUpdate: false }\n    }\n\n    // Check if this is a PERSON_EVENT that should bypass batch-level filtering\n    // Also force update when updateAllProperties is enabled\n    const shouldForceUpdate = PERSON_EVENTS.has(event.event) || updateAllProperties\n\n    const properties: Properties = event.properties!['$set'] || {}\n    const propertiesOnce: Properties = event.properties!['$set_once'] || {}\n    const unsetProps = event.properties!['$unset']\n    const unsetProperties: Array<string> = Array.isArray(unsetProps) ? unsetProps : Object.keys(unsetProps || {}) || []\n\n    let hasChanges = false\n    let hasNonFilteredChanges = false\n    const toSet: Properties = {}\n    const toUnset: string[] = []\n    const ignoredProperties: string[] = []\n\n    Object.entries(propertiesOnce).forEach(([key, value]) => {\n        if (typeof personProperties[key] === 'undefined') {\n            hasChanges = true\n            toSet[key] = value\n            if (shouldUpdatePersonIfOnlyChange(event, key, updateAllProperties)) {\n                hasNonFilteredChanges = true\n            }\n        }\n    })\n\n    Object.entries(properties).forEach(([key, value]) => {\n        if (personProperties[key] !== value) {\n            const isNewProperty = typeof personProperties[key] === 'undefined'\n            const shouldUpdate = isNewProperty || shouldUpdatePersonIfOnlyChange(event, key, updateAllProperties)\n\n            if (shouldUpdate) {\n                hasChanges = true\n                hasNonFilteredChanges = true\n            } else {\n                hasChanges = true\n                ignoredProperties.push(key)\n            }\n            toSet[key] = value\n        }\n    })\n\n    unsetProperties.forEach((propertyKey) => {\n        if (propertyKey in personProperties) {\n            if (typeof propertyKey === 'string') {\n                hasChanges = true\n                hasNonFilteredChanges = true\n                toUnset.push(propertyKey)\n            }\n        }\n    })\n\n    // Track person profile update outcomes at event level (skip when updateAllProperties is enabled)\n    if (!updateAllProperties) {\n        const hasPropertyChanges = Object.keys(toSet).length > 0 || toUnset.length > 0\n        if (hasPropertyChanges) {\n            if (hasNonFilteredChanges) {\n                personProfileUpdateOutcomeCounter.labels({ outcome: 'changed' }).inc()\n            } else {\n                personProfileUpdateOutcomeCounter.labels({ outcome: 'ignored' }).inc()\n                ignoredProperties.forEach((property) => {\n                    personProfileIgnoredPropertiesCounter.labels({ property }).inc()\n                })\n            }\n        } else {\n            personProfileUpdateOutcomeCounter.labels({ outcome: 'no_change' }).inc()\n        }\n    }\n\n    return { hasChanges, toSet, toUnset, shouldForceUpdate }\n}\n\n/**\n * @param propertyUpdates The computed property updates to apply\n * @param person The person to apply updates to - a new person object is returned with updated properties\n * @returns [updatedPerson, wasUpdated] - new person object and boolean indicating if changes were made\n */\nexport function applyEventPropertyUpdates(\n    propertyUpdates: PropertyUpdates,\n    person: InternalPerson\n): [InternalPerson, boolean] {\n    let updated = false\n\n    // Create a copy of the person with copied properties\n    const updatedPerson = cloneObject(person)\n\n    // Apply properties to set\n    Object.entries(propertyUpdates.toSet).forEach(([key, value]) => {\n        if (updatedPerson.properties[key] !== value) {\n            updated = true\n        }\n        updatedPerson.properties[key] = value\n    })\n\n    // Apply properties to unset\n    propertyUpdates.toUnset.forEach((propertyKey) => {\n        if (propertyKey in updatedPerson.properties) {\n            if (typeof propertyKey !== 'string') {\n                logger.warn('\ud83d\udd14', 'unset_property_key_not_string', { propertyKey, toUnset: propertyUpdates.toUnset })\n                return\n            }\n            updated = true\n            delete updatedPerson.properties[propertyKey]\n        }\n    })\n\n    return [updatedPerson, updated]\n}\n\n// Minimize useless person updates by not overriding properties if it's not a person event and we added from the event\n// They will still show up for PoE as it's not removed from the event, we just don't update the person in PG anymore\nfunction shouldUpdatePersonIfOnlyChange(event: PluginEvent, key: string, updateAllProperties: boolean): boolean {\n    if (updateAllProperties) {\n        // When flag is enabled, all property changes trigger updates\n        return true\n    }\n    if (PERSON_EVENTS.has(event.event)) {\n        // for person events always update everything\n        return true\n    }\n    // These are properties we add from the event and some change often, it's useless to update person always\n    if (eventToPersonProperties.has(key)) {\n        return false\n    }\n    // same as above, coming from GeoIP plugin\n    if (key.startsWith('$geoip_')) {\n        return false\n    }\n    return true\n}",
            "cost": 0.069245
        }
    },
    "recover_status": "success",
    "instance_ref": {
        "instance_id": "PostHog__posthog.main.42552",
        "repo": "PostHog/posthog",
        "base_commit": "51af4a65b07d90944ac7ef8c285953710b954337",
        "head_commit": "16305d4983df0b64053a32d18807f1b1721cc858",
        "title": "feat(persons): Update geoip_country and geoip_city_name",
        "merged_at": "2025-12-03T10:35:39Z",
        "html_url": "https://github.com/PostHog/posthog/pull/42552",
        "test_files": [
            "plugin-server/src/ingestion/ingestion-e2e.test.ts",
            "plugin-server/src/worker/ingestion/persons/batch-writing-person-store.test.ts",
            "plugin-server/src/worker/ingestion/persons/person-update.test.ts"
        ],
        "code_files": [
            "plugin-server/src/worker/ingestion/persons/batch-writing-person-store.ts",
            "plugin-server/src/worker/ingestion/persons/person-update.ts"
        ],
        "total_changes": 305,
        "num_files": 5,
        "pull_number": 42552,
        "patch": "diff --git a/plugin-server/src/ingestion/ingestion-e2e.test.ts b/plugin-server/src/ingestion/ingestion-e2e.test.ts\nindex 0fd07003fc8d3..453bd3534c20e 100644\n--- a/plugin-server/src/ingestion/ingestion-e2e.test.ts\n+++ b/plugin-server/src/ingestion/ingestion-e2e.test.ts\n@@ -784,6 +784,84 @@ describe('Event Pipeline E2E tests', () => {\n         }\n     )\n \n+    testWithTeamIngester(\n+        'allowed geoip properties ($geoip_country_name, $geoip_city_name) trigger person updates alongside blocked geoip properties',\n+        {},\n+        async (ingester, hub, team) => {\n+            const distinctId = new UUIDT().toString()\n+            const timestamp = DateTime.now().toMillis()\n+\n+            // When $geoip_country_name or $geoip_city_name changes, all geoip properties in the batch\n+            // should be updated, even the normally-blocked ones like $geoip_latitude\n+            await ingester.handleKafkaBatch(\n+                createKafkaMessages([\n+                    // Event 1: Create person with initial geoip properties\n+                    new EventBuilder(team, distinctId)\n+                        .withEvent('$pageview')\n+                        .withProperties({\n+                            $set: {\n+                                $geoip_country_name: 'Canada',\n+                                $geoip_city_name: 'Toronto',\n+                                $geoip_latitude: 43.6532,\n+                                $geoip_longitude: -79.3832,\n+                            },\n+                        })\n+                        .withTimestamp(timestamp)\n+                        .build(),\n+                    // Event 2: Update geoip properties including allowed ones (country/city)\n+                    // Since $geoip_country_name changes, all geoip properties should be updated\n+                    new EventBuilder(team, distinctId)\n+                        .withEvent('$pageview')\n+                        .withProperties({\n+                            $set: {\n+                                $geoip_country_name: 'United States',\n+                                $geoip_city_name: 'San Francisco',\n+                                $geoip_latitude: 37.7749,\n+                                $geoip_longitude: -122.4194,\n+                            },\n+                        })\n+                        .withTimestamp(timestamp + 1)\n+                        .build(),\n+                ])\n+            )\n+\n+            await waitForExpect(async () => {\n+                const events = await fetchEvents(hub, team.id)\n+                expect(events.length).toEqual(2)\n+\n+                // Event 0 (first pageview): Should have initial geoip properties\n+                expect(events[0].person_properties).toEqual({\n+                    $creator_event_uuid: events[0].uuid,\n+                    $geoip_country_name: 'Canada',\n+                    $geoip_city_name: 'Toronto',\n+                    $geoip_latitude: 43.6532,\n+                    $geoip_longitude: -79.3832,\n+                })\n+\n+                // Event 1 (second pageview): Should have UPDATED geoip properties\n+                // Because $geoip_country_name is an allowed property, all geoip properties get updated\n+                expect(events[1].person_properties).toEqual({\n+                    $creator_event_uuid: events[0].uuid,\n+                    $geoip_country_name: 'United States',\n+                    $geoip_city_name: 'San Francisco',\n+                    $geoip_latitude: 37.7749,\n+                    $geoip_longitude: -122.4194,\n+                })\n+\n+                // Verify the final state of the person in the database reflects the updates\n+                const person = await hub.personRepository.fetchPerson(team.id, distinctId)\n+                expect(person).toBeDefined()\n+                expect(person!.properties).toEqual({\n+                    $creator_event_uuid: events[0].uuid,\n+                    $geoip_country_name: 'United States',\n+                    $geoip_city_name: 'San Francisco',\n+                    $geoip_latitude: 37.7749,\n+                    $geoip_longitude: -122.4194,\n+                })\n+            })\n+        }\n+    )\n+\n     testWithTeamIngester('can handle events with $process_person_profile=false', {}, async (ingester, hub, team) => {\n         const distinctId = new UUIDT().toString()\n         const timestamp = DateTime.now().toMillis()\ndiff --git a/plugin-server/src/worker/ingestion/persons/batch-writing-person-store.test.ts b/plugin-server/src/worker/ingestion/persons/batch-writing-person-store.test.ts\nindex 4c50a7768ae42..c4e46a8913bff 100644\n--- a/plugin-server/src/worker/ingestion/persons/batch-writing-person-store.test.ts\n+++ b/plugin-server/src/worker/ingestion/persons/batch-writing-person-store.test.ts\n@@ -1594,15 +1594,16 @@ describe('BatchWritingPersonStore', () => {\n             expect(mockPersonPropertyKeyUpdateCounter.labels).not.toHaveBeenCalled()\n         })\n \n-        it('should skip database write when only $geoip_* properties are updated', async () => {\n+        it('should skip database write when only blocked $geoip_* properties are updated', async () => {\n             const mockRepo = createMockRepository()\n             const testPersonStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer)\n             const personStoreForBatch = testPersonStore.forBatch() as BatchWritingPersonsStoreForBatch\n \n-            // Update person with only geoip properties (existing properties being updated)\n+            // Update person with only blocked geoip properties (existing properties being updated)\n+            // Note: $geoip_country_name and $geoip_city_name are allowed, but $geoip_latitude is blocked\n             await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(\n-                { ...person, properties: { $geoip_city_name: 'New York', $geoip_country_code: 'US' } },\n-                { $geoip_city_name: 'San Francisco', $geoip_country_code: 'US' },\n+                { ...person, properties: { $geoip_latitude: 40.7128, $geoip_longitude: -74.006 } },\n+                { $geoip_latitude: 37.7749, $geoip_longitude: -74.006 },\n                 [],\n                 {},\n                 'test'\n@@ -1622,7 +1623,7 @@ describe('BatchWritingPersonStore', () => {\n             )\n             expect(mockPersonProfileBatchIgnoredPropertiesCounter.labels).toHaveBeenCalledTimes(1)\n             expect(mockPersonProfileBatchIgnoredPropertiesCounter.labels).toHaveBeenCalledWith({\n-                property: '$geoip_city_name',\n+                property: '$geoip_latitude',\n             })\n             // personPropertyKeyUpdateCounter should NOT be called for 'ignored' outcomes\n             expect(mockPersonPropertyKeyUpdateCounter.labels).not.toHaveBeenCalled()\n@@ -1781,7 +1782,7 @@ describe('BatchWritingPersonStore', () => {\n                 properties: {\n                     $browser: 'Firefox',\n                     $app_build: '100',\n-                    $geoip_city_name: 'New York',\n+                    $geoip_latitude: 40.7128,\n                 },\n             }\n \n@@ -1803,10 +1804,10 @@ describe('BatchWritingPersonStore', () => {\n                 'test'\n             )\n \n-            // Event 3: Update geoip\n+            // Event 3: Update blocked geoip property (latitude is blocked, city_name is allowed)\n             await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(\n                 personWithFiltered,\n-                { $geoip_city_name: 'Los Angeles' },\n+                { $geoip_latitude: 37.7749 },\n                 [],\n                 {},\n                 'test'\n@@ -1832,12 +1833,68 @@ describe('BatchWritingPersonStore', () => {\n                 property: '$app_build',\n             })\n             expect(mockPersonProfileBatchIgnoredPropertiesCounter.labels).toHaveBeenCalledWith({\n-                property: '$geoip_city_name',\n+                property: '$geoip_latitude',\n             })\n             // personPropertyKeyUpdateCounter should NOT be called for 'ignored' outcomes\n             expect(mockPersonPropertyKeyUpdateCounter.labels).not.toHaveBeenCalled()\n         })\n \n+        it('should write to database when allowed geoip property ($geoip_country_name) is updated alongside blocked ones', async () => {\n+            const mockRepo = createMockRepository()\n+            const testPersonStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer)\n+            const personStoreForBatch = testPersonStore.forBatch() as BatchWritingPersonsStoreForBatch\n+\n+            // Person with existing geoip properties\n+            const personWithGeoip = {\n+                ...person,\n+                properties: {\n+                    $geoip_country_name: 'Canada',\n+                    $geoip_city_name: 'Toronto',\n+                    $geoip_latitude: 43.6532,\n+                    $geoip_longitude: -79.3832,\n+                },\n+            }\n+\n+            // Update all geoip properties including allowed ones (country_name, city_name)\n+            // Since $geoip_country_name is allowed, all properties should be updated\n+            await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(\n+                personWithGeoip,\n+                {\n+                    $geoip_country_name: 'United States',\n+                    $geoip_city_name: 'San Francisco',\n+                    $geoip_latitude: 37.7749,\n+                    $geoip_longitude: -122.4194,\n+                },\n+                [],\n+                {},\n+                'test'\n+            )\n+\n+            // Flush SHOULD write to database because $geoip_country_name is allowed\n+            await personStoreForBatch.flush()\n+\n+            expect(mockRepo.updatePerson).toHaveBeenCalledTimes(1)\n+            expect(mockRepo.updatePerson).toHaveBeenCalledWith(\n+                expect.objectContaining({\n+                    properties: {\n+                        $geoip_country_name: 'United States',\n+                        $geoip_city_name: 'San Francisco',\n+                        $geoip_latitude: 37.7749,\n+                        $geoip_longitude: -122.4194,\n+                    },\n+                }),\n+                expect.anything(),\n+                'updatePersonNoAssert'\n+            )\n+\n+            // Verify metrics - should be 'changed' since allowed geoip property triggers write\n+            expect(mockPersonProfileBatchUpdateOutcomeCounter.labels).toHaveBeenCalledTimes(1)\n+            expect(mockPersonProfileBatchUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'changed' })\n+            expect(mockPersonProfileBatchIgnoredPropertiesCounter.labels).not.toHaveBeenCalled()\n+            // personPropertyKeyUpdateCounter uses getMetricKey which returns 'geoIP' for all $geoip_* properties\n+            expect(mockPersonPropertyKeyUpdateCounter.labels).toHaveBeenCalledWith({ key: 'geoIP' })\n+        })\n+\n         it('integration: filtered properties then non-filtered property should trigger database write', async () => {\n             const mockRepo = createMockRepository()\n             const testPersonStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer)\ndiff --git a/plugin-server/src/worker/ingestion/persons/batch-writing-person-store.ts b/plugin-server/src/worker/ingestion/persons/batch-writing-person-store.ts\nindex b7573fbf12c31..950dcc22aee0a 100644\n--- a/plugin-server/src/worker/ingestion/persons/batch-writing-person-store.ts\n+++ b/plugin-server/src/worker/ingestion/persons/batch-writing-person-store.ts\n@@ -36,8 +36,7 @@ import {\n     personWriteMethodAttemptCounter,\n     totalPersonUpdateLatencyPerBatchHistogram,\n } from './metrics'\n-import { eventToPersonProperties } from './person-property-utils'\n-import { getMetricKey } from './person-update'\n+import { getMetricKey, isFilteredPersonPropertyKey } from './person-update'\n import { PersonUpdate, fromInternalPerson, toInternalPerson } from './person-update-batch'\n import { PersonsStore } from './persons-store'\n import { FlushResult, PersonsStoreForBatch } from './persons-store-for-batch'\n@@ -207,7 +206,7 @@ export class BatchWritingPersonsStoreForBatch implements PersonsStoreForBatch, B\n                 return true\n             }\n \n-            const isFiltered = eventToPersonProperties.has(key) || key.startsWith('$geoip_')\n+            const isFiltered = isFilteredPersonPropertyKey(key)\n             if (isFiltered) {\n                 ignoredProperties.push(key)\n                 return false\ndiff --git a/plugin-server/src/worker/ingestion/persons/person-update.test.ts b/plugin-server/src/worker/ingestion/persons/person-update.test.ts\nindex 3e71704a024fa..c55c6e1cd95e3 100644\n--- a/plugin-server/src/worker/ingestion/persons/person-update.test.ts\n+++ b/plugin-server/src/worker/ingestion/persons/person-update.test.ts\n@@ -154,7 +154,49 @@ describe('person-update', () => {\n                 }\n             )\n \n-            it('should accept $geoip_* property updates at event level (filtering happens at batch level)', () => {\n+            it('should accept blocked $geoip_* property updates at event level (filtering happens at batch level)', () => {\n+                const event: PluginEvent = {\n+                    event: 'pageview',\n+                    properties: {\n+                        $set: { $geoip_latitude: 37.7749 },\n+                    },\n+                } as any\n+\n+                const personProperties = { $geoip_latitude: 40.7128 }\n+\n+                const result = computeEventPropertyUpdates(event, personProperties)\n+\n+                expect(result.hasChanges).toBe(true)\n+                expect(result.toSet).toEqual({ $geoip_latitude: 37.7749 })\n+                expect(result.shouldForceUpdate).toBe(false)\n+                // At event level, blocked geoip properties would be marked as ignored\n+                expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'ignored' })\n+                expect(mockPersonProfileIgnoredPropertiesCounter.labels).toHaveBeenCalledWith({\n+                    property: '$geoip_latitude',\n+                })\n+            })\n+\n+            it('should trigger update when $geoip_country_name changes (allowed geoip property)', () => {\n+                const event: PluginEvent = {\n+                    event: 'pageview',\n+                    properties: {\n+                        $set: { $geoip_country_name: 'United States' },\n+                    },\n+                } as any\n+\n+                const personProperties = { $geoip_country_name: 'Canada' }\n+\n+                const result = computeEventPropertyUpdates(event, personProperties)\n+\n+                expect(result.hasChanges).toBe(true)\n+                expect(result.toSet).toEqual({ $geoip_country_name: 'United States' })\n+                expect(result.shouldForceUpdate).toBe(false)\n+                // $geoip_country_name is allowed so should be marked as changed\n+                expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'changed' })\n+                expect(mockPersonProfileIgnoredPropertiesCounter.labels).not.toHaveBeenCalled()\n+            })\n+\n+            it('should trigger update when $geoip_city_name changes (allowed geoip property)', () => {\n                 const event: PluginEvent = {\n                     event: 'pageview',\n                     properties: {\n@@ -169,11 +211,43 @@ describe('person-update', () => {\n                 expect(result.hasChanges).toBe(true)\n                 expect(result.toSet).toEqual({ $geoip_city_name: 'San Francisco' })\n                 expect(result.shouldForceUpdate).toBe(false)\n-                // At event level, geoip properties would be marked as ignored\n-                expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'ignored' })\n-                expect(mockPersonProfileIgnoredPropertiesCounter.labels).toHaveBeenCalledWith({\n-                    property: '$geoip_city_name',\n+                // $geoip_city_name is allowed so should be marked as changed\n+                expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'changed' })\n+                expect(mockPersonProfileIgnoredPropertiesCounter.labels).not.toHaveBeenCalled()\n+            })\n+\n+            it('should update all geoip properties when allowed property ($geoip_country_name) changes alongside blocked ones', () => {\n+                const event: PluginEvent = {\n+                    event: 'pageview',\n+                    properties: {\n+                        $set: {\n+                            $geoip_country_name: 'United States',\n+                            $geoip_latitude: 37.7749,\n+                            $geoip_longitude: -122.4194,\n+                            $geoip_postal_code: '94102',\n+                        },\n+                    },\n+                } as any\n+\n+                const personProperties = {\n+                    $geoip_country_name: 'Canada',\n+                    $geoip_latitude: 43.6532,\n+                    $geoip_longitude: -79.3832,\n+                    $geoip_postal_code: 'M5V',\n+                }\n+\n+                const result = computeEventPropertyUpdates(event, personProperties)\n+\n+                expect(result.hasChanges).toBe(true)\n+                expect(result.toSet).toEqual({\n+                    $geoip_country_name: 'United States',\n+                    $geoip_latitude: 37.7749,\n+                    $geoip_longitude: -122.4194,\n+                    $geoip_postal_code: '94102',\n                 })\n+                expect(result.shouldForceUpdate).toBe(false)\n+                // Since $geoip_country_name is allowed, the update is marked as changed (not ignored)\n+                expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'changed' })\n             })\n \n             it('should accept eventToPersonProperties even when mixed with unchanged custom properties', () => {\ndiff --git a/plugin-server/src/worker/ingestion/persons/person-update.ts b/plugin-server/src/worker/ingestion/persons/person-update.ts\nindex 8894149a95d0b..9b40787ff1928 100644\n--- a/plugin-server/src/worker/ingestion/persons/person-update.ts\n+++ b/plugin-server/src/worker/ingestion/persons/person-update.ts\n@@ -19,6 +19,10 @@ export interface PropertyUpdates {\n const NO_PERSON_UPDATE_EVENTS = new Set(['$exception', '$$heatmap'])\n const PERSON_EVENTS = new Set(['$identify', '$create_alias', '$merge_dangerously', '$set'])\n \n+// GeoIP properties that should still trigger person updates even when other geoip properties are blocked\n+// These are commonly used for segmentation and are worth keeping up-to-date\n+const ALLOWED_GEOIP_PROPERTIES = new Set(['$geoip_country_name', '$geoip_city_name'])\n+\n // For tracking what property keys cause us to update persons\n // tracking all properties we add from the event, 'geoip' for '$geoip_*' or '$initial_geoip_*' and 'other' for anything outside of those\n export function getMetricKey(key: string): string {\n@@ -76,22 +80,32 @@ export function computeEventPropertyUpdates(\n         }\n     })\n \n+    // First pass: detect if any property would trigger an update\n+    // If so, all changed properties in this $set should be updated together\n+    let anyPropertyTriggersUpdate = false\n+    const changedProperties: Array<[string, unknown]> = []\n+\n     Object.entries(properties).forEach(([key, value]) => {\n         if (personProperties[key] !== value) {\n+            changedProperties.push([key, value])\n             const isNewProperty = typeof personProperties[key] === 'undefined'\n-            const shouldUpdate = isNewProperty || shouldUpdatePersonIfOnlyChange(event, key, updateAllProperties)\n-\n-            if (shouldUpdate) {\n-                hasChanges = true\n-                hasNonFilteredChanges = true\n-            } else {\n-                hasChanges = true\n-                ignoredProperties.push(key)\n+            if (isNewProperty || shouldUpdatePersonIfOnlyChange(event, key, updateAllProperties)) {\n+                anyPropertyTriggersUpdate = true\n             }\n-            toSet[key] = value\n         }\n     })\n \n+    // Second pass: apply changes - if any property triggers update, all do\n+    changedProperties.forEach(([key, value]) => {\n+        hasChanges = true\n+        if (anyPropertyTriggersUpdate) {\n+            hasNonFilteredChanges = true\n+        } else {\n+            ignoredProperties.push(key)\n+        }\n+        toSet[key] = value\n+    })\n+\n     unsetProperties.forEach((propertyKey) => {\n         if (propertyKey in personProperties) {\n             if (typeof propertyKey === 'string') {\n@@ -159,6 +173,27 @@ export function applyEventPropertyUpdates(\n     return [updatedPerson, updated]\n }\n \n+/**\n+ * Determines if a property key should be filtered out from triggering person updates.\n+ * These are properties that change frequently but aren't valuable enough to update the person record for.\n+ *\n+ * This is the single source of truth for property filtering logic, used by both:\n+ * - Event-level processing (computeEventPropertyUpdates)\n+ * - Batch-level processing (getPersonUpdateOutcome in batch-writing-person-store)\n+ */\n+export function isFilteredPersonPropertyKey(key: string): boolean {\n+    // These are properties we add from the event and some change often, it's useless to update person always\n+    if (eventToPersonProperties.has(key)) {\n+        return true\n+    }\n+    // same as above, coming from GeoIP plugin\n+    // but allow country and city updates as they're commonly used for segmentation\n+    if (key.startsWith('$geoip_')) {\n+        return !ALLOWED_GEOIP_PROPERTIES.has(key)\n+    }\n+    return false\n+}\n+\n // Minimize useless person updates by not overriding properties if it's not a person event and we added from the event\n // They will still show up for PoE as it's not removed from the event, we just don't update the person in PG anymore\n function shouldUpdatePersonIfOnlyChange(event: PluginEvent, key: string, updateAllProperties: boolean): boolean {\n@@ -170,13 +205,5 @@ function shouldUpdatePersonIfOnlyChange(event: PluginEvent, key: string, updateA\n         // for person events always update everything\n         return true\n     }\n-    // These are properties we add from the event and some change often, it's useless to update person always\n-    if (eventToPersonProperties.has(key)) {\n-        return false\n-    }\n-    // same as above, coming from GeoIP plugin\n-    if (key.startsWith('$geoip_')) {\n-        return false\n-    }\n-    return true\n+    return !isFilteredPersonPropertyKey(key)\n }\n",
        "pr_mirror": "PostHog__posthog.main"
    }
}