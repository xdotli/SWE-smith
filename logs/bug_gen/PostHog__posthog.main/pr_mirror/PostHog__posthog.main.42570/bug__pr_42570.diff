diff --git a/plugin-server/src/worker/ingestion/persons/batch-writing-person-store.test.ts b/plugin-server/src/worker/ingestion/persons/batch-writing-person-store.test.ts
index 8d7f96b..61a7f07 100644
--- a/plugin-server/src/worker/ingestion/persons/batch-writing-person-store.test.ts
+++ b/plugin-server/src/worker/ingestion/persons/batch-writing-person-store.test.ts
@@ -350,1818 +350,4 @@ describe('BatchWritingPersonStore', () => {
         const personStoreForBatch = getBatchStoreForBatch()
 
         // First update
-        await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(person, { prop1: 'value1' }, [], {}, 'test')
-
-        // Second update to same person
-        await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(
-            person,
-            { test: 'value2', prop2: 'value2' },
-            [],
-            {},
-            'test'
-        )
-
-        // Check cache contains merged updates
-        const cache = personStoreForBatch.getUpdateCache()
-        const cachedUpdate = cache.get(`${teamId}:${person.id}`)!
-        expect(cachedUpdate.properties).toEqual({ test: 'test' }) // Original properties from database
-        expect(cachedUpdate.properties_to_set).toEqual({ prop1: 'value1', test: 'value2', prop2: 'value2' }) // Merged properties to set
-        expect(cachedUpdate.properties_to_unset).toEqual([]) // No properties to unset
-        expect(cachedUpdate.needs_write).toBe(true)
-    })
-
-    describe('fetchForUpdate vs fetchForChecking', () => {
-        it('should use separate caches for update and checking', async () => {
-            const personStoreForBatch = getBatchStoreForBatch()
-
-            // Fetch for checking should cache in check cache
-            const personFromCheck = await personStoreForBatch.fetchForChecking(teamId, 'test-distinct')
-            expect(personFromCheck).toEqual(person)
-
-            const checkCache = (personStoreForBatch as any)['personCheckCache']
-            expect(checkCache.get('1:test-distinct')).toEqual(person)
-
-            // Fetch for update should cache in update cache and return PersonUpdate converted to InternalPerson
-            const personFromUpdate = await personStoreForBatch.fetchForUpdate(teamId, 'test-distinct2')
-            expect(personFromUpdate).toBeDefined()
-            expect(personFromUpdate!.id).toBe(person.id)
-            expect(personFromUpdate!.team_id).toBe(person.team_id)
-            expect(personFromUpdate!.id).toBe(person.id)
-
-            const updateCache = personStoreForBatch.getUpdateCache()
-            const cachedPersonUpdate = updateCache.get(`${teamId}:${person.id}`)
-            expect(cachedPersonUpdate).toBeDefined()
-            expect(cachedPersonUpdate!.distinct_id).toBe('test-distinct2')
-        })
-
-        it('should handle cache hits for both checking and updating', async () => {
-            const mockRepo = createMockRepository()
-            const testPersonStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer)
-            const personStoreForBatch = testPersonStore.forBatch()
-
-            // First fetch should hit the database
-            await personStoreForBatch.fetchForChecking(teamId, 'test-distinct')
-            expect(mockRepo.fetchPerson).toHaveBeenCalledTimes(1)
-
-            // Second fetch should hit the cache
-            await personStoreForBatch.fetchForChecking(teamId, 'test-distinct')
-            expect(mockRepo.fetchPerson).toHaveBeenCalledTimes(1) // No additional call
-
-            // Similar for update cache
-            await personStoreForBatch.fetchForUpdate(teamId, 'test-distinct2')
-            expect(mockRepo.fetchPerson).toHaveBeenCalledTimes(2)
-
-            await personStoreForBatch.fetchForUpdate(teamId, 'test-distinct2')
-            expect(mockRepo.fetchPerson).toHaveBeenCalledTimes(2) // No additional call
-        })
-
-        it('should prefer update cache over check cache in fetchForChecking', async () => {
-            const mockRepo = createMockRepository()
-            const testPersonStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer)
-            const personStoreForBatch = testPersonStore.forBatch()
-
-            // First populate update cache
-            await personStoreForBatch.fetchForUpdate(teamId, 'test-distinct')
-
-            // Reset the mock to track new calls
-            jest.clearAllMocks()
-
-            // fetchForChecking should use the cached PersonUpdate instead of hitting DB
-            const result = await personStoreForBatch.fetchForChecking(teamId, 'test-distinct')
-            expect(result).toBeDefined()
-            expect(mockRepo.fetchPerson).not.toHaveBeenCalled()
-        })
-
-        it('should handle null results from database', async () => {
-            const mockRepo = createMockRepository()
-            mockRepo.fetchPerson = jest.fn().mockResolvedValue(undefined)
-            const testPersonStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer)
-            const personStoreForBatch = testPersonStore.forBatch()
-
-            const checkResult = await personStoreForBatch.fetchForChecking(teamId, 'nonexistent')
-            expect(checkResult).toBeNull()
-
-            const updateResult = await personStoreForBatch.fetchForUpdate(teamId, 'nonexistent')
-            expect(updateResult).toBeNull()
-        })
-    })
-
-    it('should retry optimistic updates with exponential backoff', async () => {
-        // Use ASSERT_VERSION mode for this test since it tests optimistic behavior
-        const testMockRepo = createMockRepository()
-        const assertVersionStore = new BatchWritingPersonsStore(testMockRepo, db.kafkaProducer, {
-            dbWriteMode: 'ASSERT_VERSION',
-        })
-        const personStoreForBatch = assertVersionStore.forBatch()
-        let callCount = 0
-
-        // Mock to fail first few times, then succeed
-        testMockRepo.updatePersonAssertVersion = jest.fn().mockImplementation(() => {
-            callCount++
-            if (callCount < 3) {
-                return Promise.resolve([undefined, []]) // version mismatch
-            }
-            return Promise.resolve([5, []]) // success on 3rd try
-        })
-
-        await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(
-            person,
-            { new_value: 'new_value' },
-            [],
-            {},
-            'test'
-        )
-        await personStoreForBatch.flush()
-
-        expect(testMockRepo.updatePersonAssertVersion).toHaveBeenCalledTimes(3)
-        expect(testMockRepo.fetchPerson).toHaveBeenCalledTimes(2) // Called for each conflict
-        expect(testMockRepo.updatePerson).not.toHaveBeenCalled() // Shouldn't fallback if retries succeed
-    })
-
-    it('should fallback to direct update after max retries', async () => {
-        // Use ASSERT_VERSION mode for this test since it tests optimistic behavior
-        const assertVersionStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer, {
-            dbWriteMode: 'ASSERT_VERSION',
-        })
-        const personStoreForBatch = assertVersionStore.forBatch()
-
-        // Mock to always fail optimistic updates
-        mockRepo.updatePersonAssertVersion = jest.fn().mockResolvedValue([undefined, []])
-
-        await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(
-            person,
-            { new_value: 'new_value' },
-            [],
-            {},
-            'test'
-        )
-        await personStoreForBatch.flush()
-
-        // Should try optimistic update multiple times based on config (1 initial + 5 retries = 6 total)
-        expect(mockRepo.updatePersonAssertVersion).toHaveBeenCalledTimes(6) // default max retries
-        expect(mockRepo.updatePerson).toHaveBeenCalledTimes(1) // fallback
-    })
-
-    it('should merge properties during conflict resolution', async () => {
-        // Use ASSERT_VERSION mode for this test since it tests optimistic behavior
-        const assertVersionStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer, {
-            dbWriteMode: 'ASSERT_VERSION',
-        })
-        const personStoreForBatch = assertVersionStore.forBatch()
-        const latestPerson = {
-            ...person,
-            version: 3,
-            properties: { existing_prop: 'existing_value', shared_prop: 'old_value' },
-        }
-
-        mockRepo.updatePersonAssertVersion = jest.fn().mockResolvedValue([undefined, []]) // Always fail, but we don't care about the version
-        mockRepo.fetchPerson = jest.fn().mockResolvedValue(latestPerson)
-
-        // Update with new properties
-        await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(
-            person,
-            { new_prop: 'new_value', shared_prop: 'new_value' },
-            [],
-            {},
-            'test'
-        )
-
-        await personStoreForBatch.flush()
-
-        // Verify the direct update was called with merged properties
-        expect(mockRepo.updatePerson).toHaveBeenCalledWith(
-            expect.objectContaining({
-                version: 3, // Should use latest version
-            }),
-            expect.objectContaining({
-                properties: {
-                    existing_prop: 'existing_value',
-                    new_prop: 'new_value',
-                    shared_prop: 'new_value',
-                },
-            }),
-            'updatePersonNoAssert'
-        )
-    })
-
-    it('should handle database errors gracefully during flush', async () => {
-        const personStoreForBatch = personStore.forBatch()
-
-        mockRepo.updatePerson = jest.fn().mockRejectedValue(new Error('Database connection failed'))
-
-        await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(
-            person,
-            { new_value: 'new_value' },
-            [],
-            {},
-            'test'
-        )
-
-        await expect(personStoreForBatch.flush()).rejects.toThrow('Database connection failed')
-    })
-
-    it('should handle partial failures in batch flush', async () => {
-        const personStoreForBatch = personStore.forBatch()
-
-        // Set up multiple updates
-        const person2 = { ...person, id: '2', uuid: '2' }
-        await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(person, { test: 'value1' }, [], {}, 'test1')
-        await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(person2, { test: 'value2' }, [], {}, 'test2')
-
-        // Mock first update to succeed, second to fail
-        let callCount = 0
-        mockRepo.updatePerson = jest.fn().mockImplementation(() => {
-            callCount++
-            if (callCount === 1) {
-                return Promise.resolve([person, []]) // success for first person
-            }
-            throw new Error('Database error') // fail for second person
-        })
-
-        await expect(personStoreForBatch.flush()).rejects.toThrow('Database error')
-    })
-
-    it('should handle clearing cache for different team IDs', async () => {
-        const mockRepo = createMockRepository()
-        const testPersonStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer)
-        const personStoreForBatch = testPersonStore.forBatch() as BatchWritingPersonsStoreForBatch
-        const person2 = { ...person, id: 'person2-id', uuid: 'person2-uuid', team_id: 2 }
-
-        // Add to both caches for different teams
-        const updateCache = personStoreForBatch.getUpdateCache()
-        const checkCache = personStoreForBatch.getCheckCache()
-
-        updateCache.set(`${person.team_id}:${person.id}`, fromInternalPerson(person, 'test'))
-        updateCache.set(`${person2.team_id}:${person2.id}`, fromInternalPerson(person2, 'test'))
-        checkCache.set(`${person.team_id}:test`, person)
-        checkCache.set(`${person2.team_id}:test`, person2)
-        personStoreForBatch.setDistinctIdToPersonId(person.team_id, 'test', person.id)
-        personStoreForBatch.setDistinctIdToPersonId(person2.team_id, 'test', person2.id)
-
-        // Delete person from team 1
-        await personStoreForBatch.deletePerson(person, 'test')
-        expect(mockRepo.deletePerson).toHaveBeenCalledWith(
-            expect.objectContaining({
-                ...person,
-                properties: { test: 'test' },
-            })
-        )
-
-        // Only team 1 entries should be removed
-        expect(updateCache.has(`${person.team_id}:${person.id}`)).toBe(false)
-        expect(updateCache.has(`${person2.team_id}:${person2.id}`)).toBe(true)
-        expect(checkCache.has(`${person.team_id}:test`)).toBe(false)
-        expect(checkCache.has(`${person2.team_id}:test`)).toBe(true)
-    })
-
-    it('should handle empty properties updates', async () => {
-        const personStoreForBatch = getBatchStoreForBatch()
-
-        const result = await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(person, {}, [], {}, 'test')
-        expect(result[0]).toEqual(person) // Should return original person unchanged
-
-        const cache = personStoreForBatch.getUpdateCache()
-        const cachedUpdate = cache.get(`${teamId}:${person.id}`)!
-        expect(cachedUpdate.needs_write).toBe(true) // Still marked for write
-    })
-
-    it('should handle null and undefined property values', async () => {
-        const personStoreForBatch = getBatchStoreForBatch()
-
-        await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(
-            person,
-            { null_prop: null, undefined_prop: undefined },
-            [],
-            {},
-            'test'
-        )
-
-        const cache = personStoreForBatch.getUpdateCache()
-        const cachedUpdate = cache.get(`${teamId}:${person.id}`)!
-        expect(cachedUpdate.properties_to_set.null_prop).toBeNull()
-        expect(cachedUpdate.properties_to_set.undefined_prop).toBeUndefined()
-
-        await personStoreForBatch.flush()
-
-        expect(mockRepo.updatePerson).toHaveBeenCalledWith(
-            expect.objectContaining({
-                properties: { null_prop: null, undefined_prop: undefined, test: 'test' },
-            }),
-            expect.anything(),
-            'updatePersonNoAssert'
-        )
-    })
-
-    it('should handle MessageSizeTooLarge errors and capture warning', async () => {
-        const personStoreForBatch = personStore.forBatch()
-
-        // Mock NO_ASSERT update to fail with MessageSizeTooLarge
-        mockRepo.updatePerson = jest.fn().mockRejectedValue(new MessageSizeTooLarge('test', new Error('test')))
-
-        // Add a person update to cache
-        await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(
-            person,
-            { new_value: 'new_value' },
-            [],
-            {},
-            'test'
-        )
-
-        // Flush should handle the error and capture warning
-        await personStoreForBatch.flush()
-
-        expect(mockRepo.updatePerson).toHaveBeenCalled()
-        expect(captureIngestionWarning).toHaveBeenCalledWith(
-            db.kafkaProducer,
-            teamId,
-            'person_upsert_message_size_too_large',
-            {
-                personId: person.id,
-                distinctId: 'test',
-            }
-        )
-    })
-
-    describe('dbWriteMode functionality', () => {
-        describe('flush with NO_ASSERT mode', () => {
-            it('should call updatePersonNoAssert directly without retries', async () => {
-                const testPersonStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer, {
-                    dbWriteMode: 'NO_ASSERT',
-                })
-                const personStoreForBatch = testPersonStore.forBatch()
-
-                await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(
-                    person,
-                    { new_value: 'new_value' },
-                    [],
-                    {},
-                    'test'
-                )
-                await personStoreForBatch.flush()
-
-                expect(mockRepo.updatePerson).toHaveBeenCalledTimes(1)
-                expect(mockRepo.updatePersonAssertVersion).not.toHaveBeenCalled()
-                expect(db.postgres.transaction).not.toHaveBeenCalled()
-            })
-
-            it('should fallback with NO_ASSERT mode', async () => {
-                const testPersonStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer, {
-                    dbWriteMode: 'NO_ASSERT',
-                    maxOptimisticUpdateRetries: 5,
-                })
-                const personStoreForBatch = testPersonStore.forBatch()
-
-                mockRepo.updatePerson = jest.fn().mockRejectedValue(new Error('Database error'))
-
-                await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(
-                    person,
-                    { new_value: 'new_value' },
-                    [],
-                    {},
-                    'test'
-                )
-
-                await expect(personStoreForBatch.flush()).rejects.toThrow('Database error')
-                expect(mockRepo.updatePerson).toHaveBeenCalledTimes(6) // 6 for update (1 fallback + 5 retries)
-                expect(mockRepo.updatePersonAssertVersion).not.toHaveBeenCalled()
-            })
-        })
-
-        describe('flush with ASSERT_VERSION mode', () => {
-            it('should call updatePersonAssertVersion with retries', async () => {
-                const testPersonStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer, {
-                    dbWriteMode: 'ASSERT_VERSION',
-                })
-                const personStoreForBatch = testPersonStore.forBatch()
-
-                mockRepo.updatePersonAssertVersion = jest.fn().mockResolvedValue([5, []]) // success
-
-                await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(
-                    person,
-                    { new_value: 'new_value' },
-                    [],
-                    {},
-                    'test'
-                )
-                await personStoreForBatch.flush()
-
-                expect(mockRepo.updatePersonAssertVersion).toHaveBeenCalledTimes(1)
-                expect(mockRepo.updatePerson).not.toHaveBeenCalled()
-                expect(db.postgres.transaction).not.toHaveBeenCalled()
-            })
-
-            it('should retry on version conflicts and eventually fallback', async () => {
-                const testPersonStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer, {
-                    dbWriteMode: 'ASSERT_VERSION',
-                    maxOptimisticUpdateRetries: 2,
-                })
-                const personStoreForBatch = testPersonStore.forBatch()
-
-                // Mock to always fail optimistic updates
-                mockRepo.updatePersonAssertVersion = jest.fn().mockResolvedValue([undefined, []])
-
-                await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(
-                    person,
-                    { new_value: 'new_value' },
-                    [],
-                    {},
-                    'test'
-                )
-                await personStoreForBatch.flush()
-
-                expect(mockRepo.updatePersonAssertVersion).toHaveBeenCalledTimes(3) // 1 initial + 2 retries
-                expect(mockRepo.updatePerson).toHaveBeenCalledTimes(1) // fallback
-            })
-
-            it('should handle MessageSizeTooLarge in ASSERT_VERSION mode', async () => {
-                const testPersonStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer, {
-                    dbWriteMode: 'ASSERT_VERSION',
-                })
-                const personStoreForBatch = testPersonStore.forBatch()
-
-                mockRepo.updatePersonAssertVersion = jest
-                    .fn()
-                    .mockRejectedValue(new MessageSizeTooLarge('test', new Error('test')))
-
-                await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(
-                    person,
-                    { new_value: 'new_value' },
-                    [],
-                    {},
-                    'test'
-                )
-                await personStoreForBatch.flush()
-
-                expect(mockRepo.updatePersonAssertVersion).toHaveBeenCalled()
-                expect(captureIngestionWarning).toHaveBeenCalledWith(
-                    db.kafkaProducer,
-                    teamId,
-                    'person_upsert_message_size_too_large',
-                    {
-                        personId: person.id,
-                        distinctId: 'test',
-                    }
-                )
-                expect(mockRepo.updatePerson).not.toHaveBeenCalled() // No fallback for MessageSizeTooLarge
-            })
-        })
-
-        describe('concurrent updates with different dbWriteModes', () => {
-            it('should handle multiple updates with different modes correctly', async () => {
-                const noAssertMockRepo = createMockRepository()
-                const assertVersionMockRepo = createMockRepository()
-
-                const noAssertStore = new BatchWritingPersonsStore(noAssertMockRepo, db.kafkaProducer, {
-                    dbWriteMode: 'NO_ASSERT',
-                })
-                const assertVersionStore = new BatchWritingPersonsStore(assertVersionMockRepo, db.kafkaProducer, {
-                    dbWriteMode: 'ASSERT_VERSION',
-                })
-
-                const noAssertBatch = noAssertStore.forBatch()
-                const assertVersionBatch = assertVersionStore.forBatch()
-
-                const person2 = { ...person, id: '2', uuid: '2' }
-
-                // Mock successful updates
-                assertVersionMockRepo.updatePersonAssertVersion = jest.fn().mockResolvedValue([5, []])
-
-                await Promise.all([
-                    noAssertBatch.updatePersonWithPropertiesDiffForUpdate(
-                        person,
-                        { mode: 'no_assert' },
-                        [],
-                        {},
-                        'test1'
-                    ),
-                    assertVersionBatch.updatePersonWithPropertiesDiffForUpdate(
-                        person2,
-                        { mode: 'assert_version' },
-                        [],
-                        {},
-                        'test2'
-                    ),
-                ])
-
-                await Promise.all([noAssertBatch.flush(), assertVersionBatch.flush()])
-
-                expect(noAssertMockRepo.updatePerson).toHaveBeenCalledTimes(1) // NO_ASSERT mode
-                expect(assertVersionMockRepo.updatePersonAssertVersion).toHaveBeenCalledTimes(1) // ASSERT_VERSION mode
-            })
-        })
-    })
-
-    it('should handle concurrent updates with ASSERT_VERSION mode and preserve both properties', async () => {
-        // Use ASSERT_VERSION mode for this test since it tests optimistic behavior
-        const mockRepo = createMockRepository()
-        const assertVersionStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer, {
-            dbWriteMode: 'ASSERT_VERSION',
-        })
-        const personStoreForBatch = assertVersionStore.forBatch()
-
-        // Initial person in database with 2 properties
-        const initialPerson = {
-            ...person,
-            version: 1,
-            properties: {
-                existing_prop1: 'initial_value1',
-                existing_prop2: 'initial_value2',
-            },
-        }
-
-        // Simulate that another pod directly writes to the database
-        // This increases the version and updates one property
-        const updatedByOtherPod = {
-            ...initialPerson,
-            version: 2,
-            properties: {
-                existing_prop1: 'updated_by_other_pod',
-                existing_prop2: 'initial_value2', // This property stays the same
-            },
-        }
-
-        // Mock optimistic update to fail on first try, succeed on retry
-        // Completely replace the mock from beforeEach
-        mockRepo.updatePersonAssertVersion = jest
-            .fn()
-            .mockResolvedValueOnce([undefined, []]) // First call fails (version mismatch)
-            .mockResolvedValueOnce([3, []]) // Second call succeeds with new version
-
-        // Mock fetchPerson to return the updated person when called during conflict resolution
-        mockRepo.fetchPerson = jest.fn().mockResolvedValue(updatedByOtherPod)
-
-        // Process an event that will override one of the properties
-        // We pass the initial person directly, so no initial fetch is needed
-        await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(
-            initialPerson,
-            { existing_prop2: 'updated_by_this_pod' },
-            [],
-            {},
-            'test'
-        )
-
-        // Flush should trigger optimistic update, fail, then merge and retry
-        await personStoreForBatch.flush()
-
-        // Verify the optimistic update was attempted (should be called twice: once initially, once on retry)
-        expect(mockRepo.updatePersonAssertVersion).toHaveBeenCalledTimes(2)
-
-        // Verify fetchPerson was called once during conflict resolution
-        expect(mockRepo.fetchPerson).toHaveBeenCalledTimes(1)
-
-        // Since the second retry succeeds, there should be no fallback to updatePerson
-        expect(mockRepo.updatePerson).not.toHaveBeenCalled()
-
-        // Verify the second call to updatePersonAssertVersion had the merged properties
-        expect(mockRepo.updatePersonAssertVersion).toHaveBeenLastCalledWith(
-            expect.objectContaining({
-                version: 2, // Should use the latest version from the database (updatedByOtherPod has version 2)
-                properties: {
-                    existing_prop1: 'updated_by_other_pod', // Preserved from other pod's update
-                    existing_prop2: 'updated_by_this_pod', // Updated by this pod
-                },
-                properties_to_set: {
-                    existing_prop2: 'updated_by_this_pod', // Only the changed property should be in properties_to_set
-                },
-                properties_to_unset: [], // No properties to unset
-            })
-        )
-    })
-
-    it('should consolidate updates for same person via different distinct IDs', async () => {
-        // This test validates that when two distinct IDs point to the same person,
-        // updates via both distinct IDs should be merged into a single person update
-        const distinctId1 = 'user-email@example.com'
-        const distinctId2 = 'user-device-abc123'
-
-        // Both distinct IDs point to the same person
-        const sharedPerson = {
-            ...person,
-            properties: {
-                initial_prop: 'initial_value',
-            },
-        }
-
-        // Mock fetchPerson to return the same person for both distinct IDs
-        const mockRepo = createMockRepository()
-        mockRepo.fetchPerson = jest.fn().mockImplementation(() => {
-            return Promise.resolve(sharedPerson)
-        })
-        const testPersonStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer)
-        const personStoreForBatch = testPersonStore.forBatch() as BatchWritingPersonsStoreForBatch
-
-        // Update via first distinct ID
-        await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(
-            sharedPerson,
-            { prop_from_distinctId1: 'value1' },
-            [],
-            {},
-            distinctId1
-        )
-
-        // Update via second distinct ID
-        await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(
-            sharedPerson,
-            { prop_from_distinctId2: 'value2' },
-            [],
-            {},
-            distinctId2
-        )
-
-        const cache = personStoreForBatch.getUpdateCache()
-
-        const cacheKey = `${teamId}:${sharedPerson.id}`
-        const cacheValue = cache.get(cacheKey)
-        // Currently both cache entries exist, which is the problem
-        expect(cacheValue).toBeDefined()
-
-        // Both cache entries have the same person id but different properties
-        expect(cacheValue?.id).toBe(sharedPerson.id)
-        expect(cacheValue?.properties).toEqual({
-            initial_prop: 'initial_value',
-        }) // Original properties from database
-        expect(cacheValue?.properties_to_set).toEqual({
-            initial_prop: 'initial_value',
-            prop_from_distinctId1: 'value1',
-            prop_from_distinctId2: 'value2',
-        }) // Properties to set
-        expect(cacheValue?.properties_to_unset).toEqual([]) // Properties to unset
-
-        expect(cache.size).toBe(1)
-
-        // Flush should consolidate these into a single DB update
-        await personStoreForBatch.flush()
-
-        // ISSUE: Currently this will likely result in 2 separate DB calls for the same person
-        // or only one of the updates will be applied, leading to incomplete data
-        // expect(db.updatePerson).toHaveBeenCalledTimes(1)
-
-        // The updatePerson call should have the correct properties
-        expect(mockRepo.updatePerson).toHaveBeenCalledTimes(1)
-        expect(mockRepo.updatePerson).toHaveBeenCalledWith(
-            expect.objectContaining({
-                id: sharedPerson.id,
-                properties: {
-                    initial_prop: 'initial_value',
-                    prop_from_distinctId1: 'value1',
-                    prop_from_distinctId2: 'value2',
-                },
-            }),
-            // Only mutable fields should be in the update object
-            expect.objectContaining({
-                properties: {
-                    initial_prop: 'initial_value',
-                    prop_from_distinctId1: 'value1',
-                    prop_from_distinctId2: 'value2',
-                },
-                is_identified: expect.any(Boolean),
-            }),
-            'updatePersonNoAssert'
-        )
-    })
-
-    it('should handle set/unset conflicts when merging updates for same person via different distinct IDs', async () => {
-        // This test validates that when two distinct IDs point to the same person,
-        // and one unsets a property while the other sets it, the conflict is resolved correctly
-        const distinctId1 = 'user-email@example.com'
-        const distinctId2 = 'user-device-abc123'
-
-        const sharedPerson = {
-            ...person,
-            properties: {
-                existing_prop: 'existing_value',
-            },
-        }
-
-        const mockRepo = createMockRepository()
-        mockRepo.fetchPerson = jest.fn().mockImplementation(() => {
-            return Promise.resolve(sharedPerson)
-        })
-        const testPersonStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer)
-        const personStoreForBatch = testPersonStore.forBatch() as BatchWritingPersonsStoreForBatch
-
-        // Update via first distinct ID - unset 'conflicting_prop'
-        await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(
-            sharedPerson,
-            {},
-            ['conflicting_prop'],
-            {},
-            distinctId1
-        )
-
-        // Update via second distinct ID - set 'conflicting_prop' (should win over unset)
-        await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(
-            sharedPerson,
-            { conflicting_prop: 'new_value' },
-            [],
-            {},
-            distinctId2
-        )
-
-        const cache = personStoreForBatch.getUpdateCache()
-        const cacheValue = cache.get(`${teamId}:${sharedPerson.id}`)
-
-        expect(cacheValue).toBeDefined()
-        // The set should win - property should be in properties_to_set and NOT in properties_to_unset
-        expect(cacheValue?.properties_to_set).toEqual({
-            existing_prop: 'existing_value',
-            conflicting_prop: 'new_value',
-        })
-        expect(cacheValue?.properties_to_unset).toEqual([])
-
-        await personStoreForBatch.flush()
-
-        expect(mockRepo.updatePerson).toHaveBeenCalledTimes(1)
-        expect(mockRepo.updatePerson).toHaveBeenCalledWith(
-            expect.objectContaining({
-                properties: {
-                    existing_prop: 'existing_value',
-                    conflicting_prop: 'new_value',
-                },
-            }),
-            expect.anything(),
-            'updatePersonNoAssert'
-        )
-    })
-
-    it('should handle unset after set conflicts when merging updates for same person via different distinct IDs', async () => {
-        // This test validates that when two distinct IDs point to the same person,
-        // and one sets a property while the other unsets it (in that order), the unset wins
-        const distinctId1 = 'user-email@example.com'
-        const distinctId2 = 'user-device-abc123'
-
-        const sharedPerson = {
-            ...person,
-            properties: {
-                existing_prop: 'existing_value',
-            },
-        }
-
-        const mockRepo = createMockRepository()
-        mockRepo.fetchPerson = jest.fn().mockImplementation(() => {
-            return Promise.resolve(sharedPerson)
-        })
-        const testPersonStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer)
-        const personStoreForBatch = testPersonStore.forBatch() as BatchWritingPersonsStoreForBatch
-
-        // Update via first distinct ID - set 'conflicting_prop'
-        await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(
-            sharedPerson,
-            { conflicting_prop: 'some_value' },
-            [],
-            {},
-            distinctId1
-        )
-
-        // Update via second distinct ID - unset 'conflicting_prop' (should win over set)
-        await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(
-            sharedPerson,
-            {},
-            ['conflicting_prop'],
-            {},
-            distinctId2
-        )
-
-        const cache = personStoreForBatch.getUpdateCache()
-        const cacheValue = cache.get(`${teamId}:${sharedPerson.id}`)
-
-        expect(cacheValue).toBeDefined()
-        // The unset should win - property should be in properties_to_unset and NOT in properties_to_set
-        expect(cacheValue?.properties_to_set).toEqual({
-            existing_prop: 'existing_value',
-        })
-        expect(cacheValue?.properties_to_unset).toEqual(['conflicting_prop'])
-
-        await personStoreForBatch.flush()
-
-        expect(mockRepo.updatePerson).toHaveBeenCalledTimes(1)
-        expect(mockRepo.updatePerson).toHaveBeenCalledWith(
-            expect.objectContaining({
-                properties: {
-                    existing_prop: 'existing_value',
-                },
-            }),
-            expect.anything(),
-            'updatePersonNoAssert'
-        )
-    })
-
-    describe('moveDistinctIds', () => {
-        it('should preserve cached merged properties when moving distinct IDs', async () => {
-            const mockRepo = createMockRepository()
-            const testPersonStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer)
-            const personStoreForBatch = testPersonStore.forBatch() as BatchWritingPersonsStoreForBatch
-
-            // Create target person with some initial properties
-            const targetPerson: InternalPerson = {
-                ...person,
-                id: 'target-id',
-                properties: {
-                    target_prop: 'target_value',
-                    existing_target_prop: 'existing_target_value',
-                },
-                version: 5,
-                is_identified: false,
-            }
-
-            const sourcePerson: InternalPerson = {
-                ...person,
-                id: 'source-id',
-                properties: {
-                    source_prop: 'source_value',
-                },
-                version: 4,
-                is_identified: true,
-            }
-
-            // Step 1: Cache the target person (simulating fetchForUpdate)
-            personStoreForBatch.setCachedPersonForUpdate(
-                teamId,
-                'target-distinct',
-                fromInternalPerson(targetPerson, 'target-distinct')
-            )
-
-            // Step 2: Update target person with merged properties (simulating updatePersonForMerge)
-            const mergeUpdate = {
-                properties: {
-                    source_prop: 'source_value',
-                    rich_property: 'rich_value',
-                    merged_from_source: 'merged_value',
-                },
-                is_identified: true,
-            }
-            await personStoreForBatch.updatePersonForMerge(targetPerson, mergeUpdate, 'target-distinct')
-
-            // Verify the merge worked - check the final computed result
-            const cacheAfterMerge = personStoreForBatch.getCachedPersonForUpdateByDistinctId(teamId, 'target-distinct')
-            expect(cacheAfterMerge?.properties).toEqual({
-                target_prop: 'target_value',
-                existing_target_prop: 'existing_target_value',
-            }) // Original properties from database
-            expect(cacheAfterMerge?.properties_to_set).toEqual({
-                source_prop: 'source_value',
-                rich_property: 'rich_value',
-                merged_from_source: 'merged_value',
-                target_prop: 'target_value',
-                existing_target_prop: 'existing_target_value',
-            }) // Properties to set
-            expect(cacheAfterMerge?.properties_to_unset).toEqual([]) // Properties to unset
-            expect(cacheAfterMerge?.is_identified).toBe(true)
-
-            // Step 3: moveDistinctIds - this should preserve the merged cache
-            const tx = createMockTransaction() as any
-            await personStoreForBatch.moveDistinctIds(sourcePerson, targetPerson, 'target-distinct', undefined, tx)
-
-            // Verify the repository method was called
-            // moveDistinctIds is executed via tx, not repo
-            expect(tx.moveDistinctIds).toHaveBeenCalledTimes(1)
-            expect(tx.moveDistinctIds).toHaveBeenCalledWith(sourcePerson, targetPerson, undefined)
-
-            // Step 4: Verify that cached merged properties are preserved
-            const cacheAfterMove = personStoreForBatch.getCachedPersonForUpdateByDistinctId(teamId, 'target-distinct')
-            expect(cacheAfterMove?.properties).toEqual({
-                target_prop: 'target_value',
-                existing_target_prop: 'existing_target_value',
-            })
-            expect(cacheAfterMove?.properties_to_set).toEqual({
-                source_prop: 'source_value',
-                rich_property: 'rich_value',
-                merged_from_source: 'merged_value',
-                target_prop: 'target_value',
-                existing_target_prop: 'existing_target_value',
-            })
-            expect(cacheAfterMove?.properties_to_unset).toEqual([])
-            expect(cacheAfterMove?.is_identified).toBe(true)
-            expect(cacheAfterMove?.distinct_id).toBe('target-distinct')
-
-            // Verify the source cache is cleared
-            const sourceCacheAfterMove = personStoreForBatch.getCachedPersonForUpdateByPersonId(teamId, sourcePerson.id)
-            expect(sourceCacheAfterMove).toBeUndefined()
-        })
-
-        it('should create fresh cache when no existing cache exists', async () => {
-            const mockRepo = createMockRepository()
-            const testPersonStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer)
-            const personStoreForBatch = testPersonStore.forBatch() as BatchWritingPersonsStoreForBatch
-
-            const targetPerson: InternalPerson = {
-                ...person,
-                id: 'target-id',
-                properties: {
-                    target_prop: 'target_value',
-                },
-                version: 5,
-            }
-
-            const sourcePerson: InternalPerson = {
-                ...person,
-                id: 'source-id',
-                properties: {
-                    source_prop: 'source_value',
-                },
-                version: 4,
-            }
-
-            // No existing cache for target person
-            expect(personStoreForBatch.getCachedPersonForUpdateByPersonId(teamId, targetPerson.id)).toBeUndefined()
-
-            // Move distinct IDs
-            const tx = createMockTransaction() as any
-            await personStoreForBatch.moveDistinctIds(sourcePerson, targetPerson, 'target-distinct', undefined, tx)
-
-            // Verify the repository method was called
-            expect(tx.moveDistinctIds).toHaveBeenCalledTimes(1)
-            expect(tx.moveDistinctIds).toHaveBeenCalledWith(sourcePerson, targetPerson, undefined)
-
-            // Should create fresh cache from target person
-            const cacheAfterMove = personStoreForBatch.getCachedPersonForUpdateByDistinctId(teamId, 'target-distinct')
-            expect(cacheAfterMove?.properties).toEqual({
-                target_prop: 'target_value',
-            })
-            expect(cacheAfterMove?.id).toBe(targetPerson.id)
-            expect(cacheAfterMove?.distinct_id).toBe('target-distinct')
-        })
-
-        it('should clear source person cache', async () => {
-            const mockRepo = createMockRepository()
-            const testPersonStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer)
-            const personStoreForBatch = testPersonStore.forBatch() as BatchWritingPersonsStoreForBatch
-
-            const targetPerson: InternalPerson = {
-                ...person,
-                id: 'target-id',
-                properties: { target_prop: 'target_value' },
-                version: 5,
-            }
-
-            const sourcePerson: InternalPerson = {
-                ...person,
-                id: 'source-id',
-                properties: { source_prop: 'source_value' },
-                version: 4,
-            }
-
-            // Set up cache for source person
-            personStoreForBatch.setCachedPersonForUpdate(
-                teamId,
-                'source-distinct',
-                fromInternalPerson(sourcePerson, 'source-distinct')
-            )
-
-            // Verify source cache exists
-            expect(personStoreForBatch.getCachedPersonForUpdateByPersonId(teamId, sourcePerson.id)).toBeDefined()
-
-            // Move distinct IDs
-            const tx = createMockTransaction() as any
-            await personStoreForBatch.moveDistinctIds(sourcePerson, targetPerson, 'target-distinct', undefined, tx)
-
-            // Verify the repository method was called
-            expect(tx.moveDistinctIds).toHaveBeenCalledTimes(1)
-            expect(tx.moveDistinctIds).toHaveBeenCalledWith(sourcePerson, targetPerson, undefined)
-
-            // Verify source cache is cleared
-            expect(personStoreForBatch.getCachedPersonForUpdateByPersonId(teamId, sourcePerson.id)).toBeUndefined()
-        })
-
-        it('should handle complex merge scenario with multiple properties', async () => {
-            const mockRepo = createMockRepository()
-            const testPersonStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer)
-            const personStoreForBatch = testPersonStore.forBatch() as BatchWritingPersonsStoreForBatch
-
-            const targetPerson: InternalPerson = {
-                ...person,
-                id: 'target-id',
-                properties: {
-                    target_prop: 'target_value',
-                    shared_prop: 'original_value',
-                    target_only: 'target_only_value',
-                },
-                version: 5,
-                is_identified: false,
-            }
-
-            const sourcePerson: InternalPerson = {
-                ...person,
-                id: 'source-id',
-                properties: {
-                    source_prop: 'source_value',
-                    shared_prop: 'updated_value',
-                    source_only: 'source_only_value',
-                },
-                version: 4,
-                is_identified: true,
-            }
-
-            // Step 1: Cache target person
-            personStoreForBatch.setCachedPersonForUpdate(
-                teamId,
-                'target-distinct',
-                fromInternalPerson(targetPerson, 'target-distinct')
-            )
-
-            // Step 2: Multiple merge operations
-            await personStoreForBatch.updatePersonForMerge(
-                targetPerson,
-                {
-                    properties: {
-                        source_prop: 'source_value',
-                        shared_prop: 'updated_value', // This should override
-                    },
-                    is_identified: true,
-                },
-                'target-distinct'
-            )
-
-            await personStoreForBatch.updatePersonForMerge(
-                targetPerson,
-                {
-                    properties: {
-                        additional_prop: 'additional_value',
-                        source_only: 'source_only_value',
-                    },
-                },
-                'target-distinct'
-            )
-
-            // Step 3: moveDistinctIds
-            const tx = createMockTransaction() as any
-            await personStoreForBatch.moveDistinctIds(sourcePerson, targetPerson, 'target-distinct', undefined, tx)
-
-            // Verify the repository method was called
-            expect(tx.moveDistinctIds).toHaveBeenCalledTimes(1)
-            expect(tx.moveDistinctIds).toHaveBeenCalledWith(sourcePerson, targetPerson, undefined)
-
-            // Step 4: Verify all merged properties are preserved
-            const finalCache = personStoreForBatch.getCachedPersonForUpdateByDistinctId(teamId, 'target-distinct')
-            expect(finalCache?.properties).toEqual({
-                target_prop: 'target_value',
-                shared_prop: 'original_value',
-                target_only: 'target_only_value',
-            })
-            expect(finalCache?.is_identified).toBe(true)
-            expect(finalCache?.properties_to_set).toEqual({
-                source_prop: 'source_value',
-                shared_prop: 'updated_value',
-                additional_prop: 'additional_value',
-                source_only: 'source_only_value',
-                target_only: 'target_only_value',
-                target_prop: 'target_value',
-            })
-            expect(finalCache?.properties_to_unset).toEqual([])
-        })
-    })
-
-    describe('addPersonlessDistinctId', () => {
-        it('should call repository method and return result', async () => {
-            const mockRepo = createMockRepository()
-            const testPersonStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer)
-            const personStoreForBatch = testPersonStore.forBatch() as BatchWritingPersonsStoreForBatch
-
-            const result = await personStoreForBatch.addPersonlessDistinctId(teamId, 'test-distinct')
-
-            expect(mockRepo.addPersonlessDistinctId).toHaveBeenCalledWith(teamId, 'test-distinct')
-            expect(result).toBe(true)
-        })
-
-        it('should handle repository returning false', async () => {
-            const mockRepo = createMockRepository()
-            mockRepo.addPersonlessDistinctId = jest.fn().mockResolvedValue(false)
-            const testPersonStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer)
-            const personStoreForBatch = testPersonStore.forBatch() as BatchWritingPersonsStoreForBatch
-
-            const result = await personStoreForBatch.addPersonlessDistinctId(teamId, 'test-distinct')
-
-            expect(mockRepo.addPersonlessDistinctId).toHaveBeenCalledWith(teamId, 'test-distinct')
-            expect(result).toBe(false)
-        })
-    })
-
-    describe('addPersonlessDistinctIdForMerge', () => {
-        it('should call repository method and return result', async () => {
-            const mockRepo = createMockRepository()
-            const testPersonStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer)
-            const personStoreForBatch = testPersonStore.forBatch() as BatchWritingPersonsStoreForBatch
-
-            const result = await personStoreForBatch.addPersonlessDistinctIdForMerge(teamId, 'test-distinct')
-
-            expect(mockRepo.addPersonlessDistinctIdForMerge).toHaveBeenCalledWith(teamId, 'test-distinct')
-            expect(result).toBe(true)
-        })
-
-        it('should handle repository returning false', async () => {
-            const mockRepo = createMockRepository()
-            mockRepo.addPersonlessDistinctIdForMerge = jest.fn().mockResolvedValue(false)
-            const testPersonStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer)
-            const personStoreForBatch = testPersonStore.forBatch() as BatchWritingPersonsStoreForBatch
-
-            const result = await personStoreForBatch.addPersonlessDistinctIdForMerge(teamId, 'test-distinct')
-
-            expect(mockRepo.addPersonlessDistinctIdForMerge).toHaveBeenCalledWith(teamId, 'test-distinct')
-            expect(result).toBe(false)
-        })
-    })
-
-    describe('personPropertiesSize', () => {
-        it('should call repository method and return result', async () => {
-            const mockRepo = createMockRepository()
-            const testPersonStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer)
-            const personStoreForBatch = testPersonStore.forBatch() as BatchWritingPersonsStoreForBatch
-            const personId = 'test-person-id'
-            const teamId = 1
-
-            const result = await personStoreForBatch.personPropertiesSize(personId, teamId)
-
-            expect(mockRepo.personPropertiesSize).toHaveBeenCalledWith(personId, teamId)
-            expect(result).toBe(1024)
-        })
-
-        it('should handle repository returning 0', async () => {
-            const mockRepo = createMockRepository()
-            mockRepo.personPropertiesSize = jest.fn().mockResolvedValue(0)
-            const testPersonStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer)
-            const personStoreForBatch = testPersonStore.forBatch() as BatchWritingPersonsStoreForBatch
-            const personId = 'test-person-id'
-            const teamId = 1
-
-            const result = await personStoreForBatch.personPropertiesSize(personId, teamId)
-
-            expect(mockRepo.personPropertiesSize).toHaveBeenCalledWith(personId, teamId)
-            expect(result).toBe(0)
-        })
-    })
-
-    describe('updateCohortsAndFeatureFlagsForMerge', () => {
-        it('should call repository method with correct arguments', async () => {
-            const mockRepo = createMockRepository()
-            const testPersonStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer)
-            const personStoreForBatch = testPersonStore.forBatch() as BatchWritingPersonsStoreForBatch
-
-            const teamID = 1
-            const sourcePersonID = 'source-person-id'
-            const targetPersonID = 'target-person-id'
-            const distinctId = 'test-distinct'
-
-            await personStoreForBatch.updateCohortsAndFeatureFlagsForMerge(
-                teamID,
-                sourcePersonID,
-                targetPersonID,
-                distinctId
-            )
-
-            expect(mockRepo.updateCohortsAndFeatureFlagsForMerge).toHaveBeenCalledWith(
-                teamID,
-                sourcePersonID,
-                targetPersonID
-            )
-        })
-
-        it('should call repository method with transaction when provided', async () => {
-            const mockRepo = createMockRepository()
-            const testPersonStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer)
-            const personStoreForBatch = testPersonStore.forBatch() as BatchWritingPersonsStoreForBatch
-
-            const teamID = 1
-            const sourcePersonID = 'source-person-id'
-            const targetPersonID = 'target-person-id'
-            const distinctId = 'test-distinct'
-
-            const mockTransaction = createMockTransaction()
-
-            await personStoreForBatch.updateCohortsAndFeatureFlagsForMerge(
-                teamID,
-                sourcePersonID,
-                targetPersonID,
-                distinctId,
-                mockTransaction
-            )
-
-            // Verify the transaction was called instead of the repository
-            expect(mockTransaction.updateCohortsAndFeatureFlagsForMerge).toHaveBeenCalledWith(
-                teamID,
-                sourcePersonID,
-                targetPersonID
-            )
-
-            // Verify the repository was NOT called
-            expect(mockRepo.updateCohortsAndFeatureFlagsForMerge).not.toHaveBeenCalled()
-        })
-    })
-
-    describe('property filtering at batch level', () => {
-        const mockPersonProfileBatchUpdateOutcomeCounter = personProfileBatchUpdateOutcomeCounter as jest.Mocked<
-            typeof personProfileBatchUpdateOutcomeCounter
-        >
-        const mockPersonProfileBatchIgnoredPropertiesCounter =
-            personProfileBatchIgnoredPropertiesCounter as jest.Mocked<typeof personProfileBatchIgnoredPropertiesCounter>
-        const mockPersonPropertyKeyUpdateCounter = personPropertyKeyUpdateCounter as jest.Mocked<
-            typeof personPropertyKeyUpdateCounter
-        >
-
-        it('should skip database write when only filtered properties are updated', async () => {
-            const mockRepo = createMockRepository()
-            const testPersonStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer)
-            const personStoreForBatch = testPersonStore.forBatch() as BatchWritingPersonsStoreForBatch
-
-            // Update person with only filtered properties (existing properties being updated)
-            // Using $current_url and $pathname which are in FILTERED_PERSON_UPDATE_PROPERTIES
-            await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(
-                { ...person, properties: { $current_url: 'https://old.com', $pathname: '/old' } },
-                { $current_url: 'https://new.com', $pathname: '/new' },
-                [],
-                {},
-                'test'
-            )
-
-            // Flush should skip the database write since only filtered properties changed
-            await personStoreForBatch.flush()
-
-            expect(mockRepo.updatePerson).not.toHaveBeenCalled()
-            expect(mockRepo.updatePersonAssertVersion).not.toHaveBeenCalled()
-
-            // Verify metrics
-            expect(mockPersonProfileBatchUpdateOutcomeCounter.labels).toHaveBeenCalledTimes(1)
-            expect(mockPersonProfileBatchUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'ignored' })
-            expect(mockPersonProfileBatchUpdateOutcomeCounter.labels({ outcome: 'ignored' }).inc).toHaveBeenCalledTimes(
-                1
-            )
-            expect(mockPersonProfileBatchIgnoredPropertiesCounter.labels).toHaveBeenCalledTimes(2)
-            expect(mockPersonProfileBatchIgnoredPropertiesCounter.labels).toHaveBeenCalledWith({
-                property: '$current_url',
-            })
-            expect(mockPersonProfileBatchIgnoredPropertiesCounter.labels).toHaveBeenCalledWith({
-                property: '$pathname',
-            })
-            // personPropertyKeyUpdateCounter should NOT be called for 'ignored' outcomes
-            expect(mockPersonPropertyKeyUpdateCounter.labels).not.toHaveBeenCalled()
-        })
-
-        it('should skip database write when only blocked $geoip_* properties are updated', async () => {
-            const mockRepo = createMockRepository()
-            const testPersonStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer)
-            const personStoreForBatch = testPersonStore.forBatch() as BatchWritingPersonsStoreForBatch
-
-            // Update person with only blocked geoip properties (existing properties being updated)
-            // Note: $geoip_country_name and $geoip_city_name are allowed, but $geoip_latitude is blocked
-            await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(
-                { ...person, properties: { $geoip_latitude: 40.7128, $geoip_longitude: -74.006 } },
-                { $geoip_latitude: 37.7749, $geoip_longitude: -74.006 },
-                [],
-                {},
-                'test'
-            )
-
-            // Flush should skip the database write
-            await personStoreForBatch.flush()
-
-            expect(mockRepo.updatePerson).not.toHaveBeenCalled()
-            expect(mockRepo.updatePersonAssertVersion).not.toHaveBeenCalled()
-
-            // Verify metrics
-            expect(mockPersonProfileBatchUpdateOutcomeCounter.labels).toHaveBeenCalledTimes(1)
-            expect(mockPersonProfileBatchUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'ignored' })
-            expect(mockPersonProfileBatchUpdateOutcomeCounter.labels({ outcome: 'ignored' }).inc).toHaveBeenCalledTimes(
-                1
-            )
-            expect(mockPersonProfileBatchIgnoredPropertiesCounter.labels).toHaveBeenCalledTimes(1)
-            expect(mockPersonProfileBatchIgnoredPropertiesCounter.labels).toHaveBeenCalledWith({
-                property: '$geoip_latitude',
-            })
-            // personPropertyKeyUpdateCounter should NOT be called for 'ignored' outcomes
-            expect(mockPersonPropertyKeyUpdateCounter.labels).not.toHaveBeenCalled()
-        })
-
-        it('should write to database when filtered properties are NEW (not in existing properties)', async () => {
-            const mockRepo = createMockRepository()
-            const testPersonStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer)
-            const personStoreForBatch = testPersonStore.forBatch() as BatchWritingPersonsStoreForBatch
-
-            // Person without browser property
-            const personWithoutBrowser = { ...person, properties: { name: 'John' } }
-
-            // Update person with NEW eventToPersonProperty
-            await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(
-                personWithoutBrowser,
-                { $browser: 'Chrome' },
-                [],
-                {},
-                'test'
-            )
-
-            // Flush SHOULD write to database since it's a new property
-            await personStoreForBatch.flush()
-
-            expect(mockRepo.updatePerson).toHaveBeenCalledTimes(1)
-            expect(mockRepo.updatePerson).toHaveBeenCalledWith(
-                expect.objectContaining({
-                    properties: { name: 'John', $browser: 'Chrome' },
-                }),
-                expect.anything(),
-                'updatePersonNoAssert'
-            )
-
-            // Verify metrics - should be 'changed' since new property triggers write
-            expect(mockPersonProfileBatchUpdateOutcomeCounter.labels).toHaveBeenCalledTimes(1)
-            expect(mockPersonProfileBatchUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'changed' })
-            expect(mockPersonProfileBatchUpdateOutcomeCounter.labels({ outcome: 'changed' }).inc).toHaveBeenCalledTimes(
-                1
-            )
-            // Note: $browser would be ignored at event level (see person-update.ts), but filtering happens at batch level
-            expect(mockPersonProfileBatchIgnoredPropertiesCounter.labels).not.toHaveBeenCalled()
-            // personPropertyKeyUpdateCounter should be called for new property
-            expect(mockPersonPropertyKeyUpdateCounter.labels).toHaveBeenCalledTimes(1)
-            expect(mockPersonPropertyKeyUpdateCounter.labels).toHaveBeenCalledWith({ key: '$browser' })
-            expect(mockPersonPropertyKeyUpdateCounter.labels({ key: '$browser' }).inc).toHaveBeenCalledTimes(1)
-        })
-
-        it('should write to database when mixing filtered and non-filtered properties', async () => {
-            const mockRepo = createMockRepository()
-            const testPersonStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer)
-            const personStoreForBatch = testPersonStore.forBatch() as BatchWritingPersonsStoreForBatch
-
-            // Update person with both filtered and non-filtered properties
-            await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(
-                { ...person, properties: { $browser: 'Firefox', name: 'Jane' } },
-                { $browser: 'Chrome', name: 'John' },
-                [],
-                {},
-                'test'
-            )
-
-            // Flush SHOULD write to database because name is not filtered
-            await personStoreForBatch.flush()
-
-            expect(mockRepo.updatePerson).toHaveBeenCalledTimes(1)
-
-            // Verify metrics - should be 'changed' since non-filtered property triggers write
-            expect(mockPersonProfileBatchUpdateOutcomeCounter.labels).toHaveBeenCalledTimes(1)
-            expect(mockPersonProfileBatchUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'changed' })
-            expect(mockPersonProfileBatchUpdateOutcomeCounter.labels({ outcome: 'changed' }).inc).toHaveBeenCalledTimes(
-                1
-            )
-            // Note: $browser would be ignored at event level (see person-update.ts), but filtering happens at batch level
-            expect(mockPersonProfileBatchIgnoredPropertiesCounter.labels).not.toHaveBeenCalled()
-            // personPropertyKeyUpdateCounter should be called for both properties
-            expect(mockPersonPropertyKeyUpdateCounter.labels).toHaveBeenCalledTimes(2)
-            expect(mockPersonPropertyKeyUpdateCounter.labels).toHaveBeenCalledWith({ key: '$browser' })
-            expect(mockPersonPropertyKeyUpdateCounter.labels).toHaveBeenCalledWith({ key: 'other' })
-        })
-
-        it('should write to database when unsetting any property', async () => {
-            const mockRepo = createMockRepository()
-            const testPersonStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer)
-            const personStoreForBatch = testPersonStore.forBatch() as BatchWritingPersonsStoreForBatch
-
-            // Unset a filtered property
-            await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(
-                { ...person, properties: { $browser: 'Chrome' } },
-                {},
-                ['$browser'],
-                {},
-                'test'
-            )
-
-            // Flush SHOULD write to database because unsetting always triggers a write
-            await personStoreForBatch.flush()
-
-            expect(mockRepo.updatePerson).toHaveBeenCalledTimes(1)
-
-            // Verify metrics - should be 'changed' since unsetting triggers write
-            expect(mockPersonProfileBatchUpdateOutcomeCounter.labels).toHaveBeenCalledTimes(1)
-            expect(mockPersonProfileBatchUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'changed' })
-            expect(mockPersonProfileBatchUpdateOutcomeCounter.labels({ outcome: 'changed' }).inc).toHaveBeenCalledTimes(
-                1
-            )
-            // Note: $browser would be ignored at event level (see person-update.ts), but filtering happens at batch level
-            expect(mockPersonProfileBatchIgnoredPropertiesCounter.labels).not.toHaveBeenCalled()
-            // personPropertyKeyUpdateCounter should be called for unset property
-            expect(mockPersonPropertyKeyUpdateCounter.labels).toHaveBeenCalledTimes(1)
-            expect(mockPersonPropertyKeyUpdateCounter.labels).toHaveBeenCalledWith({ key: '$browser' })
-            expect(mockPersonPropertyKeyUpdateCounter.labels({ key: '$browser' }).inc).toHaveBeenCalledTimes(1)
-        })
-
-        it('should write to database when force_update is set even with only filtered properties', async () => {
-            const mockRepo = createMockRepository()
-            const testPersonStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer)
-            const personStoreForBatch = testPersonStore.forBatch() as BatchWritingPersonsStoreForBatch
-
-            // Update person with only filtered properties but with force_update=true (simulating $identify/$set events)
-            // Using $current_url and $pathname which are in FILTERED_PERSON_UPDATE_PROPERTIES
-            await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(
-                { ...person, properties: { $current_url: 'https://old.com', $pathname: '/old' } },
-                { $current_url: 'https://new.com', $pathname: '/new' },
-                [],
-                {},
-                'test',
-                true // force_update=true for $identify/$set events
-            )
-
-            // Flush SHOULD write to database because force_update bypasses filtering
-            await personStoreForBatch.flush()
-
-            expect(mockRepo.updatePerson).toHaveBeenCalledTimes(1)
-
-            // Verify metrics - should be 'changed' because force_update bypasses filtering
-            expect(mockPersonProfileBatchUpdateOutcomeCounter.labels).toHaveBeenCalledTimes(1)
-            expect(mockPersonProfileBatchUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'changed' })
-            expect(mockPersonProfileBatchUpdateOutcomeCounter.labels({ outcome: 'changed' }).inc).toHaveBeenCalledTimes(
-                1
-            )
-            // With force_update, properties should not be marked as ignored
-            expect(mockPersonProfileBatchIgnoredPropertiesCounter.labels).not.toHaveBeenCalled()
-            // personPropertyKeyUpdateCounter should be called for the updated properties
-            expect(mockPersonPropertyKeyUpdateCounter.labels).toHaveBeenCalledTimes(2)
-            expect(mockPersonPropertyKeyUpdateCounter.labels).toHaveBeenCalledWith({ key: '$current_url' })
-            expect(mockPersonPropertyKeyUpdateCounter.labels).toHaveBeenCalledWith({ key: '$pathname' })
-        })
-
-        it('integration: multiple events with only filtered properties should not trigger database write', async () => {
-            const mockRepo = createMockRepository()
-            const testPersonStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer)
-            const personStoreForBatch = testPersonStore.forBatch() as BatchWritingPersonsStoreForBatch
-
-            // Using properties that are in FILTERED_PERSON_UPDATE_PROPERTIES
-            const personWithFiltered = {
-                ...person,
-                properties: {
-                    $current_url: 'https://old.com',
-                    $pathname: '/old',
-                    $geoip_latitude: 40.7128,
-                },
-            }
-
-            // Event 1: Update current_url (filtered)
-            await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(
-                personWithFiltered,
-                { $current_url: 'https://new.com' },
-                [],
-                {},
-                'test'
-            )
-
-            // Event 2: Update pathname (filtered)
-            await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(
-                personWithFiltered,
-                { $pathname: '/new' },
-                [],
-                {},
-                'test'
-            )
-
-            // Event 3: Update blocked geoip property (latitude is blocked, city_name is allowed)
-            await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(
-                personWithFiltered,
-                { $geoip_latitude: 37.7749 },
-                [],
-                {},
-                'test'
-            )
-
-            // Flush should NOT write to database - all properties are filtered
-            await personStoreForBatch.flush()
-
-            expect(mockRepo.updatePerson).not.toHaveBeenCalled()
-            expect(mockRepo.updatePersonAssertVersion).not.toHaveBeenCalled()
-
-            // Verify metrics - should be 'ignored' since all properties are filtered
-            expect(mockPersonProfileBatchUpdateOutcomeCounter.labels).toHaveBeenCalledTimes(1)
-            expect(mockPersonProfileBatchUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'ignored' })
-            expect(mockPersonProfileBatchUpdateOutcomeCounter.labels({ outcome: 'ignored' }).inc).toHaveBeenCalledTimes(
-                1
-            )
-            expect(mockPersonProfileBatchIgnoredPropertiesCounter.labels).toHaveBeenCalledTimes(3)
-            expect(mockPersonProfileBatchIgnoredPropertiesCounter.labels).toHaveBeenCalledWith({
-                property: '$current_url',
-            })
-            expect(mockPersonProfileBatchIgnoredPropertiesCounter.labels).toHaveBeenCalledWith({
-                property: '$pathname',
-            })
-            expect(mockPersonProfileBatchIgnoredPropertiesCounter.labels).toHaveBeenCalledWith({
-                property: '$geoip_latitude',
-            })
-            // personPropertyKeyUpdateCounter should NOT be called for 'ignored' outcomes
-            expect(mockPersonPropertyKeyUpdateCounter.labels).not.toHaveBeenCalled()
-        })
-
-        it('should write to database when allowed geoip property ($geoip_country_name) is updated alongside blocked ones', async () => {
-            const mockRepo = createMockRepository()
-            const testPersonStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer)
-            const personStoreForBatch = testPersonStore.forBatch() as BatchWritingPersonsStoreForBatch
-
-            // Person with existing geoip properties
-            const personWithGeoip = {
-                ...person,
-                properties: {
-                    $geoip_country_name: 'Canada',
-                    $geoip_city_name: 'Toronto',
-                    $geoip_latitude: 43.6532,
-                    $geoip_longitude: -79.3832,
-                },
-            }
-
-            // Update all geoip properties including allowed ones (country_name, city_name)
-            // Since $geoip_country_name is allowed, all properties should be updated
-            await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(
-                personWithGeoip,
-                {
-                    $geoip_country_name: 'United States',
-                    $geoip_city_name: 'San Francisco',
-                    $geoip_latitude: 37.7749,
-                    $geoip_longitude: -122.4194,
-                },
-                [],
-                {},
-                'test'
-            )
-
-            // Flush SHOULD write to database because $geoip_country_name is allowed
-            await personStoreForBatch.flush()
-
-            expect(mockRepo.updatePerson).toHaveBeenCalledTimes(1)
-            expect(mockRepo.updatePerson).toHaveBeenCalledWith(
-                expect.objectContaining({
-                    properties: {
-                        $geoip_country_name: 'United States',
-                        $geoip_city_name: 'San Francisco',
-                        $geoip_latitude: 37.7749,
-                        $geoip_longitude: -122.4194,
-                    },
-                }),
-                expect.anything(),
-                'updatePersonNoAssert'
-            )
-
-            // Verify metrics - should be 'changed' since allowed geoip property triggers write
-            expect(mockPersonProfileBatchUpdateOutcomeCounter.labels).toHaveBeenCalledTimes(1)
-            expect(mockPersonProfileBatchUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'changed' })
-            expect(mockPersonProfileBatchIgnoredPropertiesCounter.labels).not.toHaveBeenCalled()
-            // personPropertyKeyUpdateCounter uses getMetricKey which returns 'geoIP' for all $geoip_* properties
-            expect(mockPersonPropertyKeyUpdateCounter.labels).toHaveBeenCalledWith({ key: 'geoIP' })
-        })
-
-        it('integration: filtered properties then non-filtered property should trigger database write', async () => {
-            const mockRepo = createMockRepository()
-            const testPersonStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer)
-            const personStoreForBatch = testPersonStore.forBatch() as BatchWritingPersonsStoreForBatch
-
-            const personWithFiltered = {
-                ...person,
-                properties: {
-                    $browser: 'Firefox',
-                    $app_build: '100',
-                    $os: 'Windows',
-                    name: 'Jane',
-                },
-            }
-
-            // Event 1: Update browser (filtered)
-            await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(
-                personWithFiltered,
-                { $browser: 'Chrome' },
-                [],
-                {},
-                'test'
-            )
-
-            // Event 2: Update app build (filtered)
-            await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(
-                personWithFiltered,
-                { $app_build: '200' },
-                [],
-                {},
-                'test'
-            )
-
-            // Event 3: Update name (NOT filtered)
-            await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(
-                personWithFiltered,
-                { name: 'John' },
-                [],
-                {},
-                'test'
-            )
-
-            // Event 4: Update more filtered properties
-            await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(
-                personWithFiltered,
-                { $os: 'macOS' },
-                [],
-                {},
-                'test'
-            )
-
-            // Flush SHOULD write to database because event 3 has non-filtered property
-            await personStoreForBatch.flush()
-
-            expect(mockRepo.updatePerson).toHaveBeenCalledTimes(1)
-            expect(mockRepo.updatePerson).toHaveBeenCalledWith(
-                expect.objectContaining({
-                    properties: {
-                        $browser: 'Chrome',
-                        $app_build: '200',
-                        $os: 'macOS',
-                        name: 'John',
-                    },
-                }),
-                expect.anything(),
-                'updatePersonNoAssert'
-            )
-
-            // Verify metrics - should be 'changed' since non-filtered property triggers write
-            expect(mockPersonProfileBatchUpdateOutcomeCounter.labels).toHaveBeenCalledTimes(1)
-            expect(mockPersonProfileBatchUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'changed' })
-            expect(mockPersonProfileBatchUpdateOutcomeCounter.labels({ outcome: 'changed' }).inc).toHaveBeenCalledTimes(
-                1
-            )
-            // Note: some properties would be ignored at event level (see person-update.ts), but filtering happens at batch level
-            expect(mockPersonProfileBatchIgnoredPropertiesCounter.labels).not.toHaveBeenCalled()
-            // personPropertyKeyUpdateCounter should be called for all 4 properties
-            expect(mockPersonPropertyKeyUpdateCounter.labels).toHaveBeenCalledTimes(4)
-            expect(mockPersonPropertyKeyUpdateCounter.labels).toHaveBeenCalledWith({ key: '$browser' })
-            expect(mockPersonPropertyKeyUpdateCounter.labels).toHaveBeenCalledWith({ key: '$app_build' })
-            expect(mockPersonPropertyKeyUpdateCounter.labels).toHaveBeenCalledWith({ key: '$os' })
-            expect(mockPersonPropertyKeyUpdateCounter.labels).toHaveBeenCalledWith({ key: 'other' })
-        })
-
-        it('integration: normal events for regression - custom properties always trigger writes', async () => {
-            const mockRepo = createMockRepository()
-            const testPersonStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer)
-            const personStoreForBatch = testPersonStore.forBatch() as BatchWritingPersonsStoreForBatch
-
-            // Event 1: Normal custom property
-            await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(
-                person,
-                { plan: 'premium' },
-                [],
-                {},
-                'test'
-            )
-
-            // Event 2: Another custom property
-            await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(
-                person,
-                { subscription_status: 'active' },
-                [],
-                {},
-                'test'
-            )
-
-            // Flush SHOULD write to database
-            await personStoreForBatch.flush()
-
-            expect(mockRepo.updatePerson).toHaveBeenCalledTimes(1)
-            expect(mockRepo.updatePerson).toHaveBeenCalledWith(
-                expect.objectContaining({
-                    properties: {
-                        test: 'test',
-                        plan: 'premium',
-                        subscription_status: 'active',
-                    },
-                }),
-                expect.anything(),
-                'updatePersonNoAssert'
-            )
-
-            // Verify metrics - should be 'changed' since custom properties trigger write
-            expect(mockPersonProfileBatchUpdateOutcomeCounter.labels).toHaveBeenCalledTimes(1)
-            expect(mockPersonProfileBatchUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'changed' })
-            expect(mockPersonProfileBatchUpdateOutcomeCounter.labels({ outcome: 'changed' }).inc).toHaveBeenCalledTimes(
-                1
-            )
-            // Note: custom properties are never ignored at event level (see person-update.ts)
-            expect(mockPersonProfileBatchIgnoredPropertiesCounter.labels).not.toHaveBeenCalled()
-            // personPropertyKeyUpdateCounter should be called once for 'other' (deduplicated by Set)
-            expect(mockPersonPropertyKeyUpdateCounter.labels).toHaveBeenCalledTimes(1)
-            expect(mockPersonPropertyKeyUpdateCounter.labels).toHaveBeenCalledWith({ key: 'other' })
-            expect(mockPersonPropertyKeyUpdateCounter.labels({ key: 'other' }).inc).toHaveBeenCalledTimes(1)
-        })
-
-        it('integration: chain of events - normal event (ignored), $identify event (forces update), then normal event (also written)', async () => {
-            const mockRepo = createMockRepository()
-            const testPersonStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer)
-            const personStoreForBatch = testPersonStore.forBatch() as BatchWritingPersonsStoreForBatch
-
-            const personWithFiltered = {
-                ...person,
-                properties: {
-                    $browser: 'Firefox',
-                    utm_source: 'twitter',
-                    $geoip_city_name: 'New York',
-                },
-            }
-
-            // Event 1: Normal pageview event with filtered properties
-            await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(
-                personWithFiltered,
-                { $browser: 'Chrome', utm_source: 'google' },
-                [],
-                {},
-                'test'
-            )
-
-            // Event 2: $identify event with ONLY filtered properties - should force update
-            await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(
-                personWithFiltered,
-                { $geoip_city_name: 'San Francisco', $browser: 'Safari' },
-                [],
-                {},
-                'test',
-                true // forceUpdate=true ($identify event)
-            )
-
-            // Event 3: Another normal event with filtered properties
-            await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(
-                personWithFiltered,
-                { utm_source: 'facebook' },
-                [],
-                {},
-                'test'
-            )
-
-            // Flush SHOULD write to database because $identify event set force_update=true
-            await personStoreForBatch.flush()
-
-            expect(mockRepo.updatePerson).toHaveBeenCalledTimes(1)
-
-            // Verify that ALL property changes from all three events are written
-            expect(mockRepo.updatePerson).toHaveBeenCalledWith(
-                expect.objectContaining({
-                    properties: expect.objectContaining({
-                        $browser: 'Safari',
-                        utm_source: 'facebook',
-                        $geoip_city_name: 'San Francisco',
-                    }),
-                }),
-                expect.anything(),
-                'updatePersonNoAssert'
-            )
-        })
-
-        it('integration: chain without $identify/$set should not trigger update', async () => {
-            const mockRepo = createMockRepository()
-            const testPersonStore = new BatchWritingPersonsStore(mockRepo, db.kafkaProducer)
-            const personStoreForBatch = testPersonStore.forBatch() as BatchWritingPersonsStoreForBatch
-
-            // Using properties that are in FILTERED_PERSON_UPDATE_PROPERTIES
-            const personWithFiltered = {
-                ...person,
-                properties: {
-                    $current_url: 'https://old.com',
-                    $pathname: '/old',
-                },
-            }
-
-            // Event 1: Normal event with filtered properties
-            await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(
-                personWithFiltered,
-                { $current_url: 'https://new.com' },
-                [],
-                {},
-                'test'
-                // forceUpdate not set
-            )
-
-            // Event 2: Another normal event with filtered properties
-            await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(
-                personWithFiltered,
-                { $pathname: '/new' },
-                [],
-                {},
-                'test'
-                // forceUpdate not set
-            )
-
-            // Event 3: Yet another normal event with filtered properties
-            await personStoreForBatch.updatePersonWithPropertiesDiffForUpdate(
-                personWithFiltered,
-                { $current_url: 'https://another.com' },
-                [],
-                {},
-                'test'
-                // forceUpdate not set
-            )
-
-            // Flush should NOT write to database - all events are normal with only filtered properties
-            await personStoreForBatch.flush()
-
-            expect(mockRepo.updatePerson).not.toHaveBeenCalled()
-            expect(mockRepo.updatePersonAssertVersion).not.toHaveBeenCalled()
-
-            // Verify metrics - should be 'ignored' since all properties are filtered and no force_update
-            expect(mockPersonProfileBatchUpdateOutcomeCounter.labels).toHaveBeenCalledTimes(1)
-            expect(mockPersonProfileBatchUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'ignored' })
-            expect(mockPersonProfileBatchUpdateOutcomeCounter.labels({ outcome: 'ignored' }).inc).toHaveBeenCalledTimes(
-                1
-            )
-            // Properties should be marked as ignored
-            expect(mockPersonProfileBatchIgnoredPropertiesCounter.labels).toHaveBeenCalledTimes(2)
-            expect(mockPersonProfileBatchIgnoredPropertiesCounter.labels).toHaveBeenCalledWith({
-                property: '$current_url',
-            })
-            expect(mockPersonProfileBatchIgnoredPropertiesCounter.labels).toHaveBeenCalledWith({
-                property: '$pathname',
-            })
-            // personPropertyKeyUpdateCounter should NOT be called for 'ignored' outcomes
-            expect(mockPersonPropertyKeyUpdateCounter.labels).not.toHaveBeenCalled()
-        })
-    })
-})
+        await personStoreForBatch.updatePersonWithPropertiesDiffFor
\ No newline at end of file
diff --git a/plugin-server/src/worker/ingestion/persons/batch-writing-person-store.ts b/plugin-server/src/worker/ingestion/persons/batch-writing-person-store.ts
index 958f258..7a33619 100644
--- a/plugin-server/src/worker/ingestion/persons/batch-writing-person-store.ts
+++ b/plugin-server/src/worker/ingestion/persons/batch-writing-person-store.ts
@@ -36,8 +36,7 @@ import {
     personWriteMethodAttemptCounter,
     totalPersonUpdateLatencyPerBatchHistogram,
 } from './metrics'
-import { isFilteredPersonUpdateProperty } from './person-property-utils'
-import { getMetricKey } from './person-update'
+import { getMetricKey, isFilteredPersonPropertyKey } from './person-update'
 import { PersonUpdate, fromInternalPerson, toInternalPerson } from './person-update-batch'
 import { PersonsStore } from './persons-store'
 import { FlushResult, PersonsStoreForBatch } from './persons-store-for-batch'
@@ -207,7 +206,7 @@ export class BatchWritingPersonsStoreForBatch implements PersonsStoreForBatch, B
                 return true
             }
 
-            const isFiltered = isFilteredPersonUpdateProperty(key)
+            const isFiltered = isFilteredPersonPropertyKey(key)
             if (isFiltered) {
                 ignoredProperties.push(key)
                 return false
@@ -384,944 +383,4 @@ export class BatchWritingPersonsStoreForBatch implements PersonsStoreForBatch, B
                                     fallback_reason: 'max_retries',
                                 })
 
-                                const fallbackResult = await this.updatePersonNoAssert(error.latestPersonUpdate)
-                                const fallbackMessages = fallbackResult.success ? fallbackResult.messages : []
-
-                                personWriteMethodAttemptCounter.inc({
-                                    db_write_mode: this.options.dbWriteMode,
-                                    method: 'fallback',
-                                    outcome: 'success',
-                                })
-
-                                return fallbackMessages.map((message) => ({
-                                    topicMessage: message,
-                                    teamId: error.latestPersonUpdate.team_id,
-                                    uuid: error.latestPersonUpdate.uuid,
-                                    distinctId: error.latestPersonUpdate.distinct_id,
-                                }))
-                            }
-
-                            // Re-throw any other errors
-                            throw error
-                        }
-                    }).catch((error) => {
-                        logger.error('Failed to update person after max retries and direct update fallback', {
-                            error,
-                            cacheKey,
-                            teamId: update.team_id,
-                            personId: update.id,
-                            distinctId: update.distinct_id,
-                            errorMessage: error instanceof Error ? error.message : String(error),
-                            errorStack: error instanceof Error ? error.stack : undefined,
-                        })
-
-                        personWriteMethodAttemptCounter.inc({
-                            db_write_mode: this.options.dbWriteMode,
-                            method: 'fallback',
-                            outcome: 'error',
-                        })
-                        throw error
-                    })
-                )
-            )
-
-            // Flatten all Kafka messages from all operations
-            const allKafkaMessages = results.flat()
-
-            // Record successful flush
-            const flushLatency = (performance.now() - flushStartTime) / 1000
-            personFlushLatencyHistogram.observe({ db_write_mode: this.options.dbWriteMode }, flushLatency)
-            personFlushOperationsCounter.inc({ db_write_mode: this.options.dbWriteMode, outcome: 'success' })
-
-            return allKafkaMessages
-        } catch (error) {
-            // Record failed flush
-            const flushLatency = (performance.now() - flushStartTime) / 1000
-            personFlushLatencyHistogram.observe({ db_write_mode: this.options.dbWriteMode }, flushLatency)
-            personFlushOperationsCounter.inc({ db_write_mode: this.options.dbWriteMode, outcome: 'error' })
-
-            logger.error('Failed to flush person updates', {
-                error,
-                errorMessage: error instanceof Error ? error.message : String(error),
-                errorStack: error instanceof Error ? error.stack : undefined,
-            })
-            throw error
-        }
-    }
-
-    async inTransaction<T>(description: string, transaction: (tx: PersonsStoreTransaction) => Promise<T>): Promise<T> {
-        return await this.personRepository.inTransaction(description, async (tx) => {
-            const transactionWrapper = new PersonsStoreTransaction(this, tx)
-            return await transaction(transactionWrapper)
-        })
-    }
-
-    async fetchForChecking(teamId: Team['id'], distinctId: string): Promise<InternalPerson | null> {
-        this.incrementCount('fetchForChecking', distinctId)
-
-        // First check the main cache
-        const cachedPerson = this.getCachedPersonForUpdateByDistinctId(teamId, distinctId)
-        if (cachedPerson !== undefined) {
-            return cachedPerson === null ? null : toInternalPerson(cachedPerson)
-        }
-
-        // Then check the checking-specific cache
-        const checkCachedPerson = this.getCheckCachedPerson(teamId, distinctId)
-        if (checkCachedPerson !== undefined) {
-            return checkCachedPerson
-        }
-
-        const cacheKey = this.getDistinctCacheKey(teamId, distinctId)
-        let fetchPromise = this.fetchPromisesForChecking.get(cacheKey)
-        if (!fetchPromise) {
-            personFetchForCheckingCacheOperationsCounter.inc({ operation: 'miss' })
-            fetchPromise = (async () => {
-                try {
-                    this.incrementDatabaseOperation('fetchForChecking', distinctId)
-                    const start = performance.now()
-                    const person = await this.personRepository.fetchPerson(teamId, distinctId, { useReadReplica: true })
-                    observeLatencyByVersion(person, start, 'fetchForChecking')
-                    this.setCheckCachedPerson(teamId, distinctId, person ?? null)
-                    return person ?? null
-                } finally {
-                    this.fetchPromisesForChecking.delete(cacheKey)
-                }
-            })()
-            this.fetchPromisesForChecking.set(cacheKey, fetchPromise)
-        } else {
-            personFetchForCheckingCacheOperationsCounter.inc({ operation: 'hit' })
-        }
-        return fetchPromise
-    }
-
-    async fetchForUpdate(teamId: Team['id'], distinctId: string): Promise<InternalPerson | null> {
-        this.incrementCount('fetchForUpdate', distinctId)
-
-        const cachedPerson = this.getCachedPersonForUpdateByDistinctId(teamId, distinctId)
-        if (cachedPerson !== undefined) {
-            return cachedPerson === null ? null : toInternalPerson(cachedPerson)
-        }
-
-        const cacheKey = this.getDistinctCacheKey(teamId, distinctId)
-        let fetchPromise = this.fetchPromisesForUpdate.get(cacheKey)
-        if (!fetchPromise) {
-            personFetchForUpdateCacheOperationsCounter.inc({ operation: 'miss' })
-            fetchPromise = (async () => {
-                try {
-                    this.incrementDatabaseOperation('fetchForUpdate', distinctId)
-                    const start = performance.now()
-                    const person = await this.personRepository.fetchPerson(teamId, distinctId, {
-                        useReadReplica: false,
-                    })
-                    observeLatencyByVersion(person, start, 'fetchForUpdate')
-                    if (person !== undefined) {
-                        const personUpdate = fromInternalPerson(person, distinctId)
-                        this.setCachedPersonForUpdate(teamId, distinctId, personUpdate)
-                        return person
-                    } else {
-                        // Before caching null, check if another async operation populated
-                        // the cache while we were awaiting the DB query. This can happen when:
-                        // 1. This operation starts DB query for a distinct ID (cache empty)
-                        // 2. Another operation creates a person for that distinct ID and caches it
-                        // 3. This DB query returns null (person didn't exist when query started)
-                        // 4. Without this check, we would overwrite the other operation's cached person
-                        //
-                        // From this point, all operations are synchronous to avoid further race conditions.
-                        const currentCache = this.getCachedPersonForUpdateByDistinctId(teamId, distinctId)
-                        if (currentCache === undefined) {
-                            this.setCachedPersonForUpdate(teamId, distinctId, null)
-                            return null
-                        }
-                        return currentCache === null ? null : toInternalPerson(currentCache)
-                    }
-                } finally {
-                    this.fetchPromisesForUpdate.delete(cacheKey)
-                }
-            })()
-            this.fetchPromisesForUpdate.set(cacheKey, fetchPromise)
-        } else {
-            personFetchForUpdateCacheOperationsCounter.inc({ operation: 'hit' })
-        }
-        return fetchPromise
-    }
-
-    updatePersonForMerge(
-        person: InternalPerson,
-        update: Partial<InternalPerson>,
-        distinctId: string,
-        _tx?: PersonRepositoryTransaction
-    ): Promise<[InternalPerson, TopicMessage[], boolean]> {
-        this.incrementCount('updatePersonForMerge', distinctId)
-        return Promise.resolve(this.addPersonUpdateToBatch(person, update, distinctId))
-    }
-
-    updatePersonWithPropertiesDiffForUpdate(
-        person: InternalPerson,
-        propertiesToSet: Properties,
-        propertiesToUnset: string[],
-        otherUpdates: Partial<InternalPerson>,
-        distinctId: string,
-        forceUpdate?: boolean,
-        _tx?: PersonRepositoryTransaction
-    ): Promise<[InternalPerson, TopicMessage[], boolean]> {
-        const [updatedPerson, kafkaMessages] = this.addPersonPropertiesUpdateToBatch(
-            person,
-            propertiesToSet,
-            propertiesToUnset,
-            otherUpdates,
-            distinctId,
-            forceUpdate
-        )
-        return Promise.resolve([updatedPerson, kafkaMessages, false])
-    }
-
-    async deletePerson(
-        person: InternalPerson,
-        distinctId: string,
-        tx?: PersonRepositoryTransaction
-    ): Promise<TopicMessage[]> {
-        this.incrementCount('deletePerson', distinctId)
-        this.incrementDatabaseOperation('deletePerson', distinctId)
-        const start = performance.now()
-        const cachedPersonUpdate = this.getCachedPersonForUpdateByPersonId(person.team_id, person.id)
-        const personToDelete = cachedPersonUpdate ? toInternalPerson(cachedPersonUpdate) : person
-
-        const response = await (tx || this.personRepository).deletePerson(personToDelete)
-        observeLatencyByVersion(person, start, 'deletePerson')
-
-        // Clear ALL caches related to this person id
-        this.clearAllCachesForPersonId(person.team_id, person.id)
-
-        return response
-    }
-
-    async addDistinctId(
-        person: InternalPerson,
-        distinctId: string,
-        version: number,
-        tx?: PersonRepositoryTransaction
-    ): Promise<TopicMessage[]> {
-        this.incrementCount('addDistinctId', distinctId)
-        this.incrementDatabaseOperation('addDistinctId', distinctId)
-        const start = performance.now()
-        const response = await (tx || this.personRepository).addDistinctId(person, distinctId, version)
-        observeLatencyByVersion(person, start, 'addDistinctId')
-        this.setDistinctIdToPersonId(person.team_id, distinctId, person.id)
-        return response
-    }
-
-    async moveDistinctIds(
-        source: InternalPerson,
-        target: InternalPerson,
-        distinctId: string,
-        limit: number | undefined,
-        tx: PersonRepositoryTransaction
-    ): Promise<MoveDistinctIdsResult> {
-        this.incrementCount('moveDistinctIds', distinctId)
-        this.incrementDatabaseOperation('moveDistinctIds', distinctId)
-        const start = performance.now()
-        const response = await tx.moveDistinctIds(source, target, limit)
-        observeLatencyByVersion(target, start, 'moveDistinctIds')
-
-        // Clear the cache for the source person id to ensure deleted person isn't cached
-        this.clearAllCachesForPersonId(source.team_id, source.id)
-
-        // Update cache for the target person for the current distinct ID
-        // Check if we already have cached data for the target person that includes merged properties
-        const existingTargetCache = this.getCachedPersonForUpdateByPersonId(target.team_id, target.id)
-        if (existingTargetCache) {
-            // We have existing cached data with merged properties - preserve it
-            // Create a new PersonUpdate for this distinctId that preserves the merged data
-            const mergedPersonUpdate = { ...existingTargetCache, distinct_id: distinctId }
-            this.setCachedPersonForUpdate(target.team_id, distinctId, mergedPersonUpdate)
-        } else {
-            // No existing cache, create fresh cache from target person
-            this.setCachedPersonForUpdate(target.team_id, distinctId, fromInternalPerson(target, distinctId))
-        }
-        if (response.success) {
-            for (const distinctId of response.distinctIdsMoved) {
-                this.setDistinctIdToPersonId(target.team_id, distinctId, target.id)
-            }
-        }
-
-        return response
-    }
-
-    async fetchPersonDistinctIds(
-        person: InternalPerson,
-        distinctId: string,
-        limit: number | undefined,
-        tx: PersonRepositoryTransaction
-    ): Promise<string[]> {
-        this.incrementCount('fetchPersonDistinctIds', distinctId)
-        this.incrementDatabaseOperation('fetchPersonDistinctIds', distinctId)
-        const start = performance.now()
-        const response = await tx.fetchPersonDistinctIds(person, limit)
-        observeLatencyByVersion(person, start, 'fetchPersonDistinctIds')
-
-        return response
-    }
-
-    async updateCohortsAndFeatureFlagsForMerge(
-        teamID: Team['id'],
-        sourcePersonID: InternalPerson['id'],
-        targetPersonID: InternalPerson['id'],
-        distinctId: string,
-        tx?: PersonRepositoryTransaction
-    ): Promise<void> {
-        this.incrementCount('updateCohortsAndFeatureFlagsForMerge', distinctId)
-        await (tx || this.personRepository).updateCohortsAndFeatureFlagsForMerge(teamID, sourcePersonID, targetPersonID)
-    }
-
-    async addPersonlessDistinctId(teamId: Team['id'], distinctId: string): Promise<boolean> {
-        this.incrementCount('addPersonlessDistinctId', distinctId)
-        return await this.personRepository.addPersonlessDistinctId(teamId, distinctId)
-    }
-
-    async addPersonlessDistinctIdForMerge(
-        teamId: Team['id'],
-        distinctId: string,
-        tx?: PersonRepositoryTransaction
-    ): Promise<boolean> {
-        this.incrementCount('addPersonlessDistinctIdForMerge', distinctId)
-        return await (tx || this.personRepository).addPersonlessDistinctIdForMerge(teamId, distinctId)
-    }
-
-    async personPropertiesSize(personId: string, teamId: number): Promise<number> {
-        return await this.personRepository.personPropertiesSize(personId, teamId)
-    }
-
-    reportBatch(): void {
-        for (const [_, methodCounts] of this.methodCountsPerDistinctId.entries()) {
-            for (const [method, count] of methodCounts.entries()) {
-                personMethodCallsPerBatchHistogram.observe({ method }, count)
-            }
-        }
-
-        for (const [_, databaseOperationCounts] of this.databaseOperationCountsPerDistinctId.entries()) {
-            for (const [operation, count] of databaseOperationCounts.entries()) {
-                personDatabaseOperationsPerBatchHistogram.observe({ operation }, count)
-            }
-        }
-
-        for (const [_, updateLatencyPerDistinctIdSeconds] of this.updateLatencyPerDistinctIdSeconds.entries()) {
-            for (const [updateType, latency] of updateLatencyPerDistinctIdSeconds.entries()) {
-                totalPersonUpdateLatencyPerBatchHistogram.observe({ update_type: updateType }, latency)
-            }
-        }
-
-        personCacheOperationsCounter.inc({ cache: 'update', operation: 'hit' }, this.cacheMetrics.updateCacheHits)
-        personCacheOperationsCounter.inc({ cache: 'update', operation: 'miss' }, this.cacheMetrics.updateCacheMisses)
-        personCacheOperationsCounter.inc({ cache: 'check', operation: 'hit' }, this.cacheMetrics.checkCacheHits)
-        personCacheOperationsCounter.inc({ cache: 'check', operation: 'miss' }, this.cacheMetrics.checkCacheMisses)
-    }
-
-    // Private implementation methods
-
-    getCheckCache(): Map<string, InternalPerson | null> {
-        return this.personCheckCache
-    }
-
-    getUpdateCache(): Map<string, PersonUpdate | null> {
-        return this.personUpdateCache
-    }
-
-    private getDistinctCacheKey(teamId: number, distinctId: string): string {
-        return `${teamId}:${distinctId}`
-    }
-
-    private getPersonIdCacheKey(teamId: number, personId: string): string {
-        return `${teamId}:${personId}`
-    }
-
-    clearPersonCacheForPersonId(teamId: number, personId: string): void {
-        this.personUpdateCache.delete(this.getPersonIdCacheKey(teamId, personId))
-    }
-
-    clearAllCachesForPersonId(teamId: number, personId: string): void {
-        // Clear the person id cache
-        this.clearPersonCacheForPersonId(teamId, personId)
-
-        // Find and clear all distinct ID mappings that point to this person id
-        const distinctIdsToRemove: string[] = []
-        for (const [distinctCacheKey, mappedPersonId] of this.distinctIdToPersonId.entries()) {
-            if (mappedPersonId === personId && distinctCacheKey.startsWith(`${teamId}:`)) {
-                distinctIdsToRemove.push(distinctCacheKey)
-            }
-        }
-
-        // Remove all distinct ID mappings and their check cache entries
-        for (const distinctCacheKey of distinctIdsToRemove) {
-            this.distinctIdToPersonId.delete(distinctCacheKey)
-            this.personCheckCache.delete(distinctCacheKey)
-        }
-    }
-
-    removeDistinctIdFromCache(teamId: number, distinctId: string): void {
-        this.distinctIdToPersonId.delete(this.getDistinctCacheKey(teamId, distinctId))
-    }
-
-    clearAllCachesForDistinctId(teamId: number, distinctId: string): void {
-        const cacheKey = this.getDistinctCacheKey(teamId, distinctId)
-        const personId = this.distinctIdToPersonId.get(cacheKey)
-
-        // Clear the distinct ID mapping
-        this.distinctIdToPersonId.delete(cacheKey)
-
-        // Clear the person data if we have the id
-        if (personId) {
-            this.clearPersonCacheForPersonId(teamId, personId)
-        }
-
-        // Clear the check cache
-        this.personCheckCache.delete(cacheKey)
-    }
-
-    private getCheckCachedPerson(teamId: number, distinctId: string): InternalPerson | null | undefined {
-        const cacheKey = this.getDistinctCacheKey(teamId, distinctId)
-        const result = this.personCheckCache.get(cacheKey)
-        if (result !== undefined) {
-            this.cacheMetrics.checkCacheHits++
-            // Return a deep copy to prevent modifications from affecting the cached object
-            return result === null
-                ? null
-                : {
-                      ...result,
-                      properties: { ...result.properties },
-                      created_at: result.created_at,
-                  }
-        } else {
-            this.cacheMetrics.checkCacheMisses++
-        }
-        return result
-    }
-
-    getCachedPersonForUpdateByPersonId(teamId: number, personId: string | undefined): PersonUpdate | null | undefined {
-        if (personId === undefined) {
-            this.cacheMetrics.updateCacheMisses++
-            return undefined
-        }
-
-        const result = this.personUpdateCache.get(this.getPersonIdCacheKey(teamId, personId))
-        if (result !== undefined) {
-            this.cacheMetrics.updateCacheHits++
-            // Return a deep copy to prevent modifications from affecting the cached object
-            if (result === null) {
-                return null
-            }
-
-            return {
-                ...result,
-                properties: { ...result.properties },
-                properties_to_set: { ...result.properties_to_set },
-                properties_to_unset: [...result.properties_to_unset],
-            }
-        } else {
-            this.cacheMetrics.updateCacheMisses++
-            return undefined
-        }
-    }
-
-    getCachedPersonForUpdateByDistinctId(teamId: number, distinctId: string): PersonUpdate | null | undefined {
-        const cacheKey = this.getDistinctCacheKey(teamId, distinctId)
-        const personId = this.distinctIdToPersonId.get(cacheKey)
-
-        return this.getCachedPersonForUpdateByPersonId(teamId, personId)
-    }
-
-    setCachedPersonForUpdate(teamId: number, distinctId: string, person: PersonUpdate | null): void {
-        const cacheKey = this.getDistinctCacheKey(teamId, distinctId)
-
-        if (person === null) {
-            // Remove mappings when person is null
-            const existingPersonId = this.distinctIdToPersonId.get(cacheKey)
-            this.distinctIdToPersonId.delete(cacheKey)
-            if (existingPersonId) {
-                this.personUpdateCache.set(this.getPersonIdCacheKey(teamId, existingPersonId), null)
-            }
-            return
-        }
-
-        // Set the distinct ID -> person id mapping
-        this.distinctIdToPersonId.set(cacheKey, person.id)
-
-        // Check if we already have cached data for this person id
-        const existingPersonUpdate = this.personUpdateCache.get(this.getPersonIdCacheKey(teamId, person.id))
-
-        if (existingPersonUpdate) {
-            // Merge the properties and changesets from both updates
-            const mergedPersonUpdate = this.mergeUpdateIntoPersonUpdate(
-                existingPersonUpdate,
-                {
-                    properties: person.properties,
-                    is_identified: person.is_identified,
-                } as Partial<InternalPerson>,
-                false
-            )
-
-            // Handle fields that are specific to PersonUpdate - merge properties_to_set and properties_to_unset
-            // with proper conflict resolution (last write wins)
-            mergedPersonUpdate.properties_to_set = {
-                ...existingPersonUpdate.properties_to_set,
-                ...person.properties_to_set,
-            }
-            // Remove from properties_to_set any keys that are in the incoming properties_to_unset
-            for (const key of person.properties_to_unset) {
-                delete mergedPersonUpdate.properties_to_set[key]
-            }
-
-            mergedPersonUpdate.properties_to_unset = [
-                ...new Set([...existingPersonUpdate.properties_to_unset, ...person.properties_to_unset]),
-            ]
-            // Remove from properties_to_unset any keys that are in the incoming properties_to_set
-            const keysToSet = new Set(Object.keys(person.properties_to_set))
-            mergedPersonUpdate.properties_to_unset = mergedPersonUpdate.properties_to_unset.filter(
-                (key) => !keysToSet.has(key)
-            )
-
-            mergedPersonUpdate.created_at = DateTime.min(existingPersonUpdate.created_at, person.created_at)
-            mergedPersonUpdate.needs_write = existingPersonUpdate.needs_write || person.needs_write
-
-            // Handle force_update with || operator - once true, stays true
-            mergedPersonUpdate.force_update = existingPersonUpdate.force_update || person.force_update
-
-            this.personUpdateCache.set(this.getPersonIdCacheKey(teamId, person.id), mergedPersonUpdate)
-        } else {
-            // First time we're caching this person id
-            this.personUpdateCache.set(this.getPersonIdCacheKey(teamId, person.id), person)
-        }
-    }
-
-    setCheckCachedPerson(teamId: number, distinctId: string, person: InternalPerson | null): void {
-        const cacheKey = this.getDistinctCacheKey(teamId, distinctId)
-        this.personCheckCache.set(cacheKey, person)
-    }
-
-    setDistinctIdToPersonId(teamId: number, distinctId: string, personId: string): void {
-        const cacheKey = this.getDistinctCacheKey(teamId, distinctId)
-        this.distinctIdToPersonId.set(cacheKey, personId)
-    }
-
-    async createPerson(
-        createdAt: DateTime,
-        properties: Properties,
-        propertiesLastUpdatedAt: PropertiesLastUpdatedAt,
-        propertiesLastOperation: PropertiesLastOperation,
-        teamId: Team['id'],
-        isUserId: number | null,
-        isIdentified: boolean,
-        uuid: string,
-        distinctIds?: { distinctId: string; version?: number }[],
-        tx?: PersonRepositoryTransaction
-    ): Promise<CreatePersonResult> {
-        this.incrementCount('createPerson', distinctIds?.[0].distinctId ?? '')
-        this.incrementDatabaseOperation('createPerson', distinctIds?.[0]?.distinctId ?? '')
-        const result = await (tx || this.personRepository).createPerson(
-            createdAt,
-            properties,
-            propertiesLastUpdatedAt,
-            propertiesLastOperation,
-            teamId,
-            isUserId,
-            isIdentified,
-            uuid,
-            distinctIds
-        )
-
-        if (result.success) {
-            const { person } = result
-            this.setCheckCachedPerson(teamId, distinctIds?.[0]?.distinctId ?? '', person)
-            this.setCachedPersonForUpdate(
-                teamId,
-                distinctIds?.[0]?.distinctId ?? '',
-                fromInternalPerson(person, distinctIds?.[0]?.distinctId ?? '')
-            )
-            if (distinctIds?.[1]) {
-                this.setDistinctIdToPersonId(teamId, distinctIds[1].distinctId, person.id)
-                this.setCachedPersonForUpdate(
-                    teamId,
-                    distinctIds[1].distinctId,
-                    fromInternalPerson(person, distinctIds[1].distinctId)
-                )
-            }
-        }
-
-        return result
-    }
-
-    private addPersonUpdateToBatch(
-        person: InternalPerson,
-        update: Partial<InternalPerson>,
-        distinctId: string
-    ): [InternalPerson, TopicMessage[], boolean] {
-        const existingUpdate = this.getCachedPersonForUpdateByDistinctId(person.team_id, distinctId)
-
-        let personUpdate: PersonUpdate
-        if (!existingUpdate) {
-            // Create new PersonUpdate from the person and apply the update
-            personUpdate = fromInternalPerson(person, distinctId)
-            personUpdate = this.mergeUpdateIntoPersonUpdate(personUpdate, update, true)
-            personUpdate.id = person.id
-            this.setCachedPersonForUpdate(person.team_id, distinctId, personUpdate)
-        } else {
-            // Merge updates into existing cached PersonUpdate
-            personUpdate = this.mergeUpdateIntoPersonUpdate(existingUpdate, update, true)
-            personUpdate.id = person.id
-            this.setCachedPersonForUpdate(person.team_id, distinctId, personUpdate)
-        }
-        // Return the merged person from the cache
-        return [toInternalPerson(personUpdate), [], false]
-    }
-
-    /**
-     * Helper method to merge an update into a PersonUpdate
-     * Handles properties and is_identified merging with proper logic
-     */
-    private mergeUpdateIntoPersonUpdate(
-        personUpdate: PersonUpdate,
-        update: Partial<InternalPerson>,
-        allowCreatedAtUpdate: boolean = false
-    ): PersonUpdate {
-        // For properties, we track them in the fine-grained properties_to_set/unset
-        if (update.properties) {
-            // Add all properties from the update to properties_to_set
-            Object.entries(update.properties).forEach(([key, value]) => {
-                personUpdate.properties_to_set[key] = value
-                // Remove from unset list if it was there
-                const unsetIndex = personUpdate.properties_to_unset.indexOf(key)
-                if (unsetIndex !== -1) {
-                    personUpdate.properties_to_unset.splice(unsetIndex, 1)
-                }
-            })
-        }
-
-        // Apply other updates (excluding properties which we handled above)
-        const fieldsToExclude = ['properties', 'is_identified']
-        if (!allowCreatedAtUpdate) {
-            fieldsToExclude.push('created_at')
-        }
-
-        const otherUpdates = Object.fromEntries(
-            Object.entries(update).filter(([key]) => !fieldsToExclude.includes(key))
-        )
-        if (allowCreatedAtUpdate) {
-            // Get minimum of existing and new created_at
-            if (update.created_at) {
-                if (personUpdate.created_at) {
-                    otherUpdates.created_at =
-                        personUpdate.created_at < update.created_at ? personUpdate.created_at : update.created_at
-                } else {
-                    otherUpdates.created_at = update.created_at
-                }
-            }
-        }
-        Object.assign(personUpdate, otherUpdates)
-
-        // Handle is_identified specially with || operator
-        if (update.is_identified !== undefined) {
-            personUpdate.is_identified = personUpdate.is_identified || update.is_identified
-        }
-
-        personUpdate.needs_write = true
-
-        return personUpdate
-    }
-
-    private addPersonPropertiesUpdateToBatch(
-        person: InternalPerson,
-        propertiesToSet: Properties,
-        propertiesToUnset: string[],
-        otherUpdates: Partial<InternalPerson>,
-        distinctId: string,
-        forceUpdate?: boolean
-    ): [InternalPerson, TopicMessage[]] {
-        const existingUpdate = this.getCachedPersonForUpdateByDistinctId(person.team_id, distinctId)
-
-        let personUpdate: PersonUpdate
-        if (!existingUpdate) {
-            // Create new PersonUpdate from the person
-            personUpdate = fromInternalPerson(person, distinctId)
-        } else {
-            // Use existing cached PersonUpdate
-            personUpdate = { ...existingUpdate }
-        }
-
-        // Add properties to set (merge with existing properties_to_set)
-        Object.entries(propertiesToSet).forEach(([key, value]) => {
-            personUpdate.properties_to_set[key] = value
-            // Remove from unset list if it was there
-            const unsetIndex = personUpdate.properties_to_unset.indexOf(key)
-            if (unsetIndex !== -1) {
-                personUpdate.properties_to_unset.splice(unsetIndex, 1)
-            }
-        })
-
-        // Add properties to unset (merge with existing properties_to_unset)
-        propertiesToUnset.forEach((key) => {
-            if (!personUpdate.properties_to_unset.includes(key)) {
-                personUpdate.properties_to_unset.push(key)
-            }
-            // Remove from set list if it was there
-            delete personUpdate.properties_to_set[key]
-        })
-
-        // Handle is_identified specially with || operator
-        if (otherUpdates.is_identified !== undefined) {
-            personUpdate.is_identified = personUpdate.is_identified || otherUpdates.is_identified
-        }
-
-        personUpdate.needs_write = true
-
-        // Set force_update flag with || operator - once set to true by a $identify/$set event, it stays true
-        // This ensures that if any event in the batch requires forcing an update, the whole batch is written
-        if (forceUpdate !== undefined) {
-            personUpdate.force_update = personUpdate.force_update || forceUpdate
-        }
-
-        this.setCachedPersonForUpdate(person.team_id, distinctId, personUpdate)
-        return [toInternalPerson(personUpdate), []]
-    }
-
-    private async updatePersonNoAssert(personUpdate: PersonUpdate): Promise<PersonUpdateResult> {
-        const operation = 'updatePersonNoAssert'
-        this.incrementDatabaseOperation(operation as MethodName, personUpdate.distinct_id)
-        // Convert PersonUpdate back to InternalPerson for database call
-        const person = toInternalPerson(personUpdate)
-        // Always pass all mutable fields for consistent query plans
-        const updateFields = {
-            properties: person.properties,
-            properties_last_updated_at: person.properties_last_updated_at,
-            properties_last_operation: person.properties_last_operation,
-            is_identified: person.is_identified,
-            created_at: person.created_at,
-        }
-
-        this.incrementCount('updatePersonNoAssert', personUpdate.distinct_id)
-        this.incrementDatabaseOperation('updatePersonNoAssert', personUpdate.distinct_id)
-        const start = performance.now()
-
-        const [_, messages] = await this.personRepository.updatePerson(person, updateFields, 'updatePersonNoAssert')
-        this.recordUpdateLatency('updatePersonNoAssert', (performance.now() - start) / 1000, personUpdate.distinct_id)
-        observeLatencyByVersion(person, start, 'updatePersonNoAssert')
-
-        // updatePersonNoAssert always succeeds (no version conflicts)
-        return { success: true, messages }
-    }
-
-    /**
-     * Updates the person in the database by attempting to write to a column where the version is the stored cached
-     * version. If no rows to update are found, the update fails and we retry by reading again from the database.
-     * This method uses no locks but can cause multiple reads from the database.
-     * @param personUpdate the personUpdate to write
-     * @returns the actual version of the person after the write
-     */
-    private async updatePersonAssertVersion(personUpdate: PersonUpdate): Promise<PersonUpdateResult> {
-        this.incrementDatabaseOperation('updatePersonAssertVersion', personUpdate.distinct_id)
-
-        const start = performance.now()
-
-        const [actualVersion, kafkaMessages] = await this.personRepository.updatePersonAssertVersion(personUpdate)
-        this.recordUpdateLatency(
-            'updatePersonAssertVersion',
-            (performance.now() - start) / 1000,
-            personUpdate.distinct_id
-        )
-        observeLatencyByVersion(personUpdate, start, 'updatePersonAssertVersion')
-
-        if (actualVersion !== undefined) {
-            // Success - optimistic update worked, create updated PersonUpdate with new version
-            const updatedPersonUpdate: PersonUpdate = {
-                ...personUpdate,
-                version: actualVersion,
-            }
-            return { success: true, messages: kafkaMessages, personUpdate: updatedPersonUpdate }
-        }
-
-        // Optimistic update failed due to version mismatch
-        personOptimisticUpdateConflictsPerBatchCounter.inc()
-
-        // Fetch latest person data to get current version and properties
-        this.incrementDatabaseOperation('fetchPerson', personUpdate.distinct_id)
-        const latestPerson = await this.personRepository.fetchPerson(personUpdate.team_id, personUpdate.distinct_id)
-
-        if (latestPerson) {
-            // Use fine-grained merge: start with latest properties from DB and apply our specific changes
-            const mergedProperties = { ...latestPerson.properties }
-
-            // Apply our properties_to_set
-            Object.entries(personUpdate.properties_to_set).forEach(([key, value]) => {
-                mergedProperties[key] = value
-            })
-
-            // Apply our properties_to_unset
-            personUpdate.properties_to_unset.forEach((key) => {
-                delete mergedProperties[key]
-            })
-
-            // Create updated PersonUpdate with latest data and merged properties (without mutating input)
-            const updatedPersonUpdate: PersonUpdate = {
-                ...personUpdate,
-                properties: mergedProperties,
-                version: latestPerson.version,
-                uuid: latestPerson.uuid,
-                created_at: latestPerson.created_at,
-                is_identified: latestPerson.is_identified || personUpdate.is_identified,
-            }
-
-            return { success: false, messages: [], personUpdate: updatedPersonUpdate }
-        }
-
-        // If we couldn't fetch the latest person, return failure without a person update
-        return { success: false, messages: [] }
-    }
-
-    private incrementCount(method: MethodName, distinctId: string): void {
-        const methodCounts = this.methodCountsPerDistinctId.get(distinctId) || new Map()
-        methodCounts.set(method, (methodCounts.get(method) || 0) + 1)
-        this.methodCountsPerDistinctId.set(distinctId, methodCounts)
-    }
-
-    private incrementDatabaseOperation(operation: MethodName, distinctId: string): void {
-        const databaseOperationCounts = this.databaseOperationCountsPerDistinctId.get(distinctId) || new Map()
-        databaseOperationCounts.set(operation, (databaseOperationCounts.get(operation) || 0) + 1)
-        this.databaseOperationCountsPerDistinctId.set(distinctId, databaseOperationCounts)
-    }
-
-    private recordUpdateLatency(updateType: UpdateType, latencySeconds: number, distinctId: string): void {
-        const updateLatencyPerDistinctIdSeconds = this.updateLatencyPerDistinctIdSeconds.get(distinctId) || new Map()
-        updateLatencyPerDistinctIdSeconds.set(
-            updateType,
-            (updateLatencyPerDistinctIdSeconds.get(updateType) || 0) + latencySeconds
-        )
-        this.updateLatencyPerDistinctIdSeconds.set(distinctId, updateLatencyPerDistinctIdSeconds)
-    }
-
-    /**
-     * Retry wrapper that handles both update conflicts and person merges.
-     */
-    private async withMergeRetry(
-        personUpdate: PersonUpdate,
-        updateFn: (personUpdate: PersonUpdate) => Promise<PersonUpdateResult>,
-        operation: string,
-        maxRetries: number,
-        retryInterval: number
-    ): Promise<PersonUpdateResult> {
-        let attempt = 0
-        let currentPersonUpdate = personUpdate
-
-        while (attempt <= maxRetries) {
-            try {
-                const result = await updateFn(currentPersonUpdate)
-
-                if (result.success) {
-                    return result
-                }
-
-                // Update failed, handle retry logic
-                attempt++
-                // If there's a person update, we need to update the cache with the latest version
-                if (result.personUpdate) {
-                    currentPersonUpdate = result.personUpdate
-                }
-
-                if (attempt <= maxRetries) {
-                    logger.debug(`Optimistic update conflict for ${operation}, retrying...`, {
-                        attempt,
-                        maxRetries,
-                        teamId: currentPersonUpdate.team_id,
-                        personId: currentPersonUpdate.id,
-                        distinctId: currentPersonUpdate.distinct_id,
-                    })
-
-                    await new Promise((resolve) => setTimeout(resolve, retryInterval))
-                    continue
-                }
-
-                // Max retries reached, throw error to trigger fallback
-                throw new MaxRetriesError(`Max retries reached for ${operation}`, currentPersonUpdate)
-            } catch (error) {
-                attempt++
-
-                if (attempt <= maxRetries) {
-                    // Handle person merge scenarios with special logic
-                    if (error instanceof NoRowsUpdatedError) {
-                        const refreshedPersonUpdate = await this.refreshPersonIdAfterMerge(currentPersonUpdate)
-                        if (refreshedPersonUpdate) {
-                            currentPersonUpdate = refreshedPersonUpdate
-                            continue
-                        }
-                        // If we can't refresh the person ID, we can't retry, fail gracefully
-                        return { success: true, messages: [] }
-                    }
-
-                    // Don't retry size violations - they will never succeed
-                    // throw the error so that we capture an ingestion warning
-                    if (error instanceof PersonPropertiesSizeViolationError) {
-                        throw error
-                    }
-
-                    // For any other error type, still retry but with generic logging
-                    logger.warn(`Database error for ${operation}, retrying...`, {
-                        attempt,
-                        maxRetries,
-                        teamId: currentPersonUpdate.team_id,
-                        personId: currentPersonUpdate.id,
-                        distinctId: currentPersonUpdate.distinct_id,
-                        error: error instanceof Error ? error.message : String(error),
-                    })
-
-                    await new Promise((resolve) => setTimeout(resolve, retryInterval))
-                    continue
-                }
-
-                throw error
-            }
-        }
-
-        // This should never be reached, but TypeScript requires it
-        throw new Error('Unexpected end of retry loop')
-    }
-
-    /**
-     * Refreshes the person ID for a given distinct ID by fetching from the database.
-     * This handles cases where the person was merged and the ID changed.
-     * @param personUpdate the PersonUpdate that failed to update
-     * @returns updated PersonUpdate with new person ID if found, null if person no longer exists
-     */
-    private async refreshPersonIdAfterMerge(personUpdate: PersonUpdate): Promise<PersonUpdate | null> {
-        const currentPerson = await this.personRepository.fetchPerson(personUpdate.team_id, personUpdate.distinct_id)
-
-        if (!currentPerson) {
-            // Person truly doesn't exist anymore
-            return null
-        }
-
-        // Clear the old person ID from cache since it's been merged
-        this.clearPersonCacheForPersonId(personUpdate.team_id, personUpdate.id)
-
-        // Update our cache mapping to reflect the new person ID
-        this.setDistinctIdToPersonId(personUpdate.team_id, personUpdate.distinct_id, currentPerson.id)
-
-        // Create updated PersonUpdate with the new person ID and version
-        const updatedPersonUpdate: PersonUpdate = {
-            id: currentPerson.id,
-            team_id: personUpdate.team_id,
-            uuid: currentPerson.uuid,
-            distinct_id: personUpdate.distinct_id,
-            properties: currentPerson.properties,
-            properties_last_updated_at: personUpdate.properties_last_updated_at,
-            properties_last_operation: personUpdate.properties_last_operation,
-            created_at: currentPerson.created_at,
-            version: currentPerson.version,
-            is_identified: currentPerson.is_identified || personUpdate.is_identified,
-            is_user_id: personUpdate.is_user_id,
-            needs_write: personUpdate.needs_write,
-            properties_to_set: personUpdate.properties_to_set,
-            properties_to_unset: personUpdate.properties_to_unset,
-            original_is_identified: personUpdate.original_is_identified,
-            original_created_at: personUpdate.original_created_at,
-        }
-
-        return updatedPersonUpdate
-    }
-}
+                                const fallbackResult = await this.updatePersonNoAssert(error
\ No newline at end of file
diff --git a/plugin-server/src/worker/ingestion/persons/person-property-utils.ts b/plugin-server/src/worker/ingestion/persons/person-property-utils.ts
index b576133..d180763 100644
--- a/plugin-server/src/worker/ingestion/persons/person-property-utils.ts
+++ b/plugin-server/src/worker/ingestion/persons/person-property-utils.ts
@@ -142,69 +142,4 @@ export const initialCampaignParams = new Set(
 )
 export const initialEventToPersonProperties = new Set(
     Array.from(eventToPersonProperties, (key) => `$initial_${key.replace('$', '')}`)
-)
-
-/**
- * Properties that should NOT trigger a person update on their own.
- * These change frequently but aren't valuable enough to update the person record for.
- * They will still be included in the person properties when an update happens for other reasons.
- *
- * This is the single source of truth for person update filtering logic.
- *
- * Note: Properties NOT in this list will trigger updates by default.
- *
- * GeoIP properties source: posthog/geoip.py and posthog/taxonomy/taxonomy.py
- * GeoIP properties that DO trigger updates (not listed here): $geoip_country_name, $geoip_city_name
- */
-export const FILTERED_PERSON_UPDATE_PROPERTIES = new Set([
-    // URL/navigation properties - change on every page view
-    '$current_url',
-    '$pathname',
-    '$referring_domain',
-    '$referrer',
-
-    // Screen/viewport dimensions - can change on window resize
-    '$screen_height',
-    '$screen_width',
-    '$viewport_height',
-    '$viewport_width',
-
-    // Browser/device properties - change less frequently but still filtered
-    '$browser',
-    '$browser_version',
-    '$device_type',
-    '$raw_user_agent',
-    '$os',
-    '$os_name',
-    '$os_version',
-
-    // GeoIP properties - filtered because they change frequently
-    '$geoip_postal_code',
-    '$geoip_time_zone',
-    '$geoip_latitude',
-    '$geoip_longitude',
-    '$geoip_accuracy_radius',
-    '$geoip_subdivision_1_code',
-    '$geoip_subdivision_1_name',
-    '$geoip_subdivision_2_code',
-    '$geoip_subdivision_2_name',
-    '$geoip_subdivision_3_code',
-    '$geoip_subdivision_3_name',
-    '$geoip_city_confidence',
-    '$geoip_country_confidence',
-    '$geoip_postal_code_confidence',
-    '$geoip_subdivision_1_confidence',
-    '$geoip_subdivision_2_confidence',
-])
-
-/**
- * Determines if a property key should be filtered out from triggering person updates.
- * These are properties that change frequently but aren't valuable enough to update the person record for.
- *
- * This is the single source of truth for property filtering logic, used by both:
- * - Event-level processing (computeEventPropertyUpdates in person-update.ts)
- * - Batch-level processing (getPersonUpdateOutcome in batch-writing-person-store.ts)
- */
-export function isFilteredPersonUpdateProperty(key: string): boolean {
-    return FILTERED_PERSON_UPDATE_PROPERTIES.has(key)
-}
+)
\ No newline at end of file
diff --git a/plugin-server/src/worker/ingestion/persons/person-update.test.ts b/plugin-server/src/worker/ingestion/persons/person-update.test.ts
index 9790636..2df0150 100644
--- a/plugin-server/src/worker/ingestion/persons/person-update.test.ts
+++ b/plugin-server/src/worker/ingestion/persons/person-update.test.ts
@@ -1,7 +1,7 @@
 import { PluginEvent } from '@posthog/plugin-scaffold'
 
 import { personProfileIgnoredPropertiesCounter, personProfileUpdateOutcomeCounter } from './metrics'
-import { FILTERED_PERSON_UPDATE_PROPERTIES } from './person-property-utils'
+import { eventToPersonProperties } from './person-property-utils'
 import { applyEventPropertyUpdates, computeEventPropertyUpdates } from './person-update'
 
 jest.mock('./metrics', () => ({
@@ -123,9 +123,9 @@ describe('person-update', () => {
             })
         })
 
-        describe('filtered properties behavior', () => {
-            it.each(Array.from(FILTERED_PERSON_UPDATE_PROPERTIES))(
-                'should mark "%s" as ignored when updated',
+        describe('eventToPersonProperties accepted at event level', () => {
+            it.each(Array.from(eventToPersonProperties))(
+                'should accept "%s" updates at event level (filtering happens at batch level)',
                 (propertyName) => {
                     const event: PluginEvent = {
                         event: 'pageview',
@@ -141,7 +141,8 @@ describe('person-update', () => {
                     expect(result.hasChanges).toBe(true)
                     expect(result.toSet).toEqual({ [propertyName]: 'new_value' })
                     expect(result.shouldForceUpdate).toBe(false)
-                    // Filtered properties are marked as ignored
+                    // At event level, this property would be marked as ignored (outcome: 'ignored')
+                    // but it's still included in toSet for batch-level filtering
                     expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'ignored' })
                     expect(mockPersonProfileUpdateOutcomeCounter.labels({ outcome: 'ignored' }).inc).toHaveBeenCalled()
                     expect(mockPersonProfileIgnoredPropertiesCounter.labels).toHaveBeenCalledWith({
@@ -249,54 +250,54 @@ describe('person-update', () => {
                 expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'changed' })
             })
 
-            it('should accept filtered properties even when mixed with unchanged custom properties', () => {
+            it('should accept eventToPersonProperties even when mixed with unchanged custom properties', () => {
                 const event: PluginEvent = {
                     event: 'pageview',
                     properties: {
-                        $set: { $current_url: 'https://example.com/new', custom_prop: 'same_value' },
+                        $set: { $browser: 'Chrome', custom_prop: 'same_value' },
                     },
                 } as any
 
-                const personProperties = { $current_url: 'https://example.com/old', custom_prop: 'same_value' }
+                const personProperties = { $browser: 'Firefox', custom_prop: 'same_value' }
 
                 const result = computeEventPropertyUpdates(event, personProperties)
 
                 expect(result.hasChanges).toBe(true)
-                expect(result.toSet).toEqual({ $current_url: 'https://example.com/new' })
+                expect(result.toSet).toEqual({ $browser: 'Chrome' })
                 expect(result.shouldForceUpdate).toBe(false)
-                // $current_url is filtered, so it should be marked as ignored
+                // At event level, $browser would be marked as ignored
                 expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'ignored' })
                 expect(mockPersonProfileIgnoredPropertiesCounter.labels).toHaveBeenCalledWith({
-                    property: '$current_url',
+                    property: '$browser',
                 })
             })
 
-            it('should accept multiple filtered properties at event level', () => {
+            it('should accept multiple eventToPersonProperties at event level', () => {
+                // Note: Campaign properties (utm_source, utm_campaign) are no longer in eventToPersonProperties
+                // and will trigger updates like custom properties
                 const event: PluginEvent = {
                     event: 'pageview',
                     properties: {
                         $set: {
-                            $current_url: 'https://example.com/new',
-                            $pathname: '/new-path',
+                            $browser: 'Chrome',
+                            $os: 'macOS',
                         },
                     },
                 } as any
 
                 const personProperties = {
-                    $current_url: 'https://example.com/old',
-                    $pathname: '/old-path',
+                    $browser: 'Firefox',
+                    $os: 'Windows',
                 }
 
                 const result = computeEventPropertyUpdates(event, personProperties)
 
                 expect(result.hasChanges).toBe(true)
                 expect(result.shouldForceUpdate).toBe(false)
-                // Filtered properties should be marked as ignored
+                // At event level, eventToPersonProperties would be marked as ignored
                 expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'ignored' })
-                expect(mockPersonProfileIgnoredPropertiesCounter.labels).toHaveBeenCalledWith({
-                    property: '$current_url',
-                })
-                expect(mockPersonProfileIgnoredPropertiesCounter.labels).toHaveBeenCalledWith({ property: '$pathname' })
+                expect(mockPersonProfileIgnoredPropertiesCounter.labels).toHaveBeenCalledWith({ property: '$browser' })
+                expect(mockPersonProfileIgnoredPropertiesCounter.labels).toHaveBeenCalledWith({ property: '$os' })
             })
         })
 
@@ -355,350 +356,4 @@ describe('person-update', () => {
                 expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'no_change' })
             })
 
-            it('should return no changes when trying to unset non-existent property', () => {
-                const event: PluginEvent = {
-                    event: 'pageview',
-                    properties: {
-                        $unset: ['non_existent_prop'],
-                    },
-                } as any
-
-                const personProperties = { other_prop: 'value' }
-
-                const result = computeEventPropertyUpdates(event, personProperties)
-
-                expect(result.hasChanges).toBe(false)
-                expect(result.toUnset).toEqual([])
-                expect(result.shouldForceUpdate).toBe(false)
-                expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'no_change' })
-            })
-        })
-
-        describe('person events behavior', () => {
-            it('should compute updates for any property on $identify events', () => {
-                const event: PluginEvent = {
-                    event: '$identify',
-                    properties: {
-                        $set: { $browser: 'Chrome' },
-                    },
-                } as any
-
-                const personProperties = { $browser: 'Firefox' }
-
-                const result = computeEventPropertyUpdates(event, personProperties)
-
-                expect(result.hasChanges).toBe(true)
-                expect(result.toSet).toEqual({ $browser: 'Chrome' })
-                expect(result.shouldForceUpdate).toBe(true)
-                expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'changed' })
-            })
-
-            it('should compute updates for any property on $set events', () => {
-                const event: PluginEvent = {
-                    event: '$set',
-                    properties: {
-                        $set: { utm_source: 'google' },
-                    },
-                } as any
-
-                const personProperties = { utm_source: 'twitter' }
-
-                const result = computeEventPropertyUpdates(event, personProperties)
-
-                expect(result.hasChanges).toBe(true)
-                expect(result.shouldForceUpdate).toBe(true)
-                expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'changed' })
-            })
-
-            it('should set shouldForceUpdate to false for non-person events', () => {
-                const event: PluginEvent = {
-                    event: 'pageview',
-                    properties: {
-                        $set: { $browser: 'Chrome' },
-                    },
-                } as any
-
-                const personProperties = { $browser: 'Firefox' }
-
-                const result = computeEventPropertyUpdates(event, personProperties)
-
-                expect(result.hasChanges).toBe(true)
-                expect(result.shouldForceUpdate).toBe(false)
-            })
-        })
-
-        describe('NO_PERSON_UPDATE_EVENTS behavior', () => {
-            it('should skip updates for $exception events regardless of properties', () => {
-                const event: PluginEvent = {
-                    event: '$exception',
-                    properties: {
-                        $set: { custom_prop: 'new_value' },
-                    },
-                } as any
-
-                const personProperties = { custom_prop: 'old_value' }
-
-                const result = computeEventPropertyUpdates(event, personProperties)
-
-                expect(result.hasChanges).toBe(false)
-                expect(result.toSet).toEqual({})
-                expect(result.shouldForceUpdate).toBe(false)
-                expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'unsupported' })
-            })
-
-            it('should skip updates for $$heatmap events regardless of properties', () => {
-                const event: PluginEvent = {
-                    event: '$$heatmap',
-                    properties: {
-                        $set: { custom_prop: 'new_value' },
-                    },
-                } as any
-
-                const personProperties = {}
-
-                const result = computeEventPropertyUpdates(event, personProperties)
-
-                expect(result.hasChanges).toBe(false)
-                expect(result.shouldForceUpdate).toBe(false)
-                expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'unsupported' })
-            })
-        })
-
-        describe('mixed scenarios', () => {
-            it('should compute updates when both custom and allowed properties change', () => {
-                const event: PluginEvent = {
-                    event: 'pageview',
-                    properties: {
-                        $set: { custom_prop: 'new_value', $browser: 'Chrome' },
-                    },
-                } as any
-
-                const personProperties = { custom_prop: 'old_value', $browser: 'Firefox' }
-
-                const result = computeEventPropertyUpdates(event, personProperties)
-
-                expect(result.hasChanges).toBe(true)
-                expect(result.toSet).toEqual({ custom_prop: 'new_value', $browser: 'Chrome' })
-                expect(result.shouldForceUpdate).toBe(false)
-                expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'changed' })
-            })
-        })
-
-        describe('updateAllProperties flag enabled', () => {
-            it.each(Array.from(FILTERED_PERSON_UPDATE_PROPERTIES))(
-                'should trigger update for filtered property "%s" when updateAllProperties is true',
-                (propertyName) => {
-                    const event: PluginEvent = {
-                        event: 'pageview',
-                        properties: {
-                            $set: { [propertyName]: 'new_value' },
-                        },
-                    } as any
-
-                    const personProperties = { [propertyName]: 'old_value' }
-
-                    const result = computeEventPropertyUpdates(event, personProperties, true)
-
-                    expect(result.hasChanges).toBe(true)
-                    expect(result.toSet).toEqual({ [propertyName]: 'new_value' })
-                    expect(result.shouldForceUpdate).toBe(true) // updateAllProperties forces updates
-                    // With updateAllProperties=true, no metrics should be tracked
-                    expect(mockPersonProfileUpdateOutcomeCounter.labels).not.toHaveBeenCalled()
-                    expect(mockPersonProfileIgnoredPropertiesCounter.labels).not.toHaveBeenCalled()
-                }
-            )
-
-            it('should trigger update for $geoip_* properties when updateAllProperties is true', () => {
-                const event: PluginEvent = {
-                    event: 'pageview',
-                    properties: {
-                        $set: { $geoip_city_name: 'San Francisco' },
-                    },
-                } as any
-
-                const personProperties = { $geoip_city_name: 'New York' }
-
-                const result = computeEventPropertyUpdates(event, personProperties, true)
-
-                expect(result.hasChanges).toBe(true)
-                expect(result.toSet).toEqual({ $geoip_city_name: 'San Francisco' })
-                expect(result.shouldForceUpdate).toBe(true) // updateAllProperties forces updates
-                // With updateAllProperties=true, no metrics should be tracked
-                expect(mockPersonProfileUpdateOutcomeCounter.labels).not.toHaveBeenCalled()
-                expect(mockPersonProfileIgnoredPropertiesCounter.labels).not.toHaveBeenCalled()
-            })
-
-            it('should trigger update for multiple allowed properties when updateAllProperties is true', () => {
-                const event: PluginEvent = {
-                    event: 'pageview',
-                    properties: {
-                        $set: {
-                            $browser: 'Chrome',
-                            $os: 'macOS',
-                        },
-                    },
-                } as any
-
-                const personProperties = {
-                    $browser: 'Firefox',
-                    $os: 'Windows',
-                }
-
-                const result = computeEventPropertyUpdates(event, personProperties, true)
-
-                expect(result.hasChanges).toBe(true)
-                expect(result.toSet).toEqual({ $browser: 'Chrome', $os: 'macOS' })
-                expect(result.shouldForceUpdate).toBe(true) // updateAllProperties forces updates
-                // With updateAllProperties=true, no metrics should be tracked
-                expect(mockPersonProfileUpdateOutcomeCounter.labels).not.toHaveBeenCalled()
-                expect(mockPersonProfileIgnoredPropertiesCounter.labels).not.toHaveBeenCalled()
-            })
-
-            it('should trigger update for mixed allowed and custom properties when updateAllProperties is true', () => {
-                const event: PluginEvent = {
-                    event: 'pageview',
-                    properties: {
-                        $set: { $browser: 'Chrome', custom_prop: 'same_value' },
-                    },
-                } as any
-
-                const personProperties = { $browser: 'Firefox', custom_prop: 'same_value' }
-
-                const result = computeEventPropertyUpdates(event, personProperties, true)
-
-                expect(result.hasChanges).toBe(true)
-                expect(result.toSet).toEqual({ $browser: 'Chrome' })
-                expect(result.shouldForceUpdate).toBe(true) // updateAllProperties forces updates
-                // With updateAllProperties=true, no metrics should be tracked
-                expect(mockPersonProfileUpdateOutcomeCounter.labels).not.toHaveBeenCalled()
-                expect(mockPersonProfileIgnoredPropertiesCounter.labels).not.toHaveBeenCalled()
-            })
-
-            it('should trigger update for mixed $geoip_* and allowed properties when updateAllProperties is true', () => {
-                const event: PluginEvent = {
-                    event: 'pageview',
-                    properties: {
-                        $set: {
-                            $browser: 'Chrome',
-                            $geoip_city_name: 'San Francisco',
-                            $geoip_country_code: 'US',
-                        },
-                    },
-                } as any
-
-                const personProperties = {
-                    $browser: 'Firefox',
-                    $geoip_city_name: 'New York',
-                    $geoip_country_code: 'CA',
-                }
-
-                const result = computeEventPropertyUpdates(event, personProperties, true)
-
-                expect(result.hasChanges).toBe(true)
-                expect(result.toSet).toEqual({
-                    $browser: 'Chrome',
-                    $geoip_city_name: 'San Francisco',
-                    $geoip_country_code: 'US',
-                })
-                expect(result.shouldForceUpdate).toBe(true) // updateAllProperties forces updates
-                // With updateAllProperties=true, no metrics should be tracked
-                expect(mockPersonProfileUpdateOutcomeCounter.labels).not.toHaveBeenCalled()
-                expect(mockPersonProfileIgnoredPropertiesCounter.labels).not.toHaveBeenCalled()
-            })
-
-            it('should not change behavior for NO_PERSON_UPDATE_EVENTS when updateAllProperties is true', () => {
-                const event: PluginEvent = {
-                    event: '$exception',
-                    properties: {
-                        $set: { $browser: 'Chrome' },
-                    },
-                } as any
-
-                const personProperties = { $browser: 'Firefox' }
-
-                const result = computeEventPropertyUpdates(event, personProperties, true)
-
-                // NO_PERSON_UPDATE_EVENTS should still be skipped regardless of flag
-                expect(result.hasChanges).toBe(false)
-                expect(result.toSet).toEqual({})
-                expect(result.shouldForceUpdate).toBe(false)
-                expect(mockPersonProfileUpdateOutcomeCounter.labels).toHaveBeenCalledWith({ outcome: 'unsupported' })
-            })
-        })
-    })
-
-    describe('applyEventPropertyUpdates', () => {
-        it('should apply property updates and return updated person', () => {
-            const propertyUpdates = {
-                hasChanges: true,
-                toSet: { name: 'John', email: 'john@example.com' },
-                toUnset: ['old_prop'],
-                shouldForceUpdate: false,
-            }
-
-            const person = {
-                id: '1',
-                team_id: 123,
-                uuid: 'test-uuid',
-                properties: { old_prop: 'value', name: 'Jane' },
-                created_at: new Date(),
-                version: 0,
-                is_identified: false,
-            }
-
-            const [updatedPerson, wasUpdated] = applyEventPropertyUpdates(propertyUpdates, person as any)
-
-            expect(wasUpdated).toBe(true)
-            expect(updatedPerson.properties).toEqual({ name: 'John', email: 'john@example.com' })
-            expect(updatedPerson.properties.old_prop).toBeUndefined()
-        })
-
-        it('should not modify original person object', () => {
-            const propertyUpdates = {
-                hasChanges: true,
-                toSet: { name: 'John' },
-                toUnset: [],
-                shouldForceUpdate: false,
-            }
-
-            const person = {
-                id: '1',
-                team_id: 123,
-                uuid: 'test-uuid',
-                properties: { name: 'Jane' },
-                created_at: new Date(),
-                version: 0,
-                is_identified: false,
-            }
-
-            const [updatedPerson, _] = applyEventPropertyUpdates(propertyUpdates, person as any)
-
-            expect(person.properties.name).toBe('Jane')
-            expect(updatedPerson.properties.name).toBe('John')
-            expect(person).not.toBe(updatedPerson)
-        })
-
-        it('should return false for wasUpdated when no actual changes occur', () => {
-            const propertyUpdates = {
-                hasChanges: false,
-                toSet: { name: 'John' },
-                toUnset: [],
-                shouldForceUpdate: false,
-            }
-
-            const person = {
-                id: '1',
-                team_id: 123,
-                uuid: 'test-uuid',
-                properties: { name: 'John' },
-                created_at: new Date(),
-                version: 0,
-                is_identified: false,
-            }
-
-            const [_, wasUpdated] = applyEventPropertyUpdates(propertyUpdates, person as any)
-
-            expect(wasUpdated).toBe(false)
-        })
-    })
-})
+            it('should return no changes when trying
\ No newline at end of file
diff --git a/plugin-server/src/worker/ingestion/persons/person-update.ts b/plugin-server/src/worker/ingestion/persons/person-update.ts
index 1b2ebca..076e6de 100644
--- a/plugin-server/src/worker/ingestion/persons/person-update.ts
+++ b/plugin-server/src/worker/ingestion/persons/person-update.ts
@@ -5,11 +5,7 @@ import { cloneObject } from '~/utils/utils'
 import { InternalPerson } from '../../../types'
 import { logger } from '../../../utils/logger'
 import { personProfileIgnoredPropertiesCounter, personProfileUpdateOutcomeCounter } from './metrics'
-import {
-    eventToPersonProperties,
-    initialEventToPersonProperties,
-    isFilteredPersonUpdateProperty,
-} from './person-property-utils'
+import { eventToPersonProperties, initialEventToPersonProperties } from './person-property-utils'
 
 export interface PropertyUpdates {
     toSet: Properties
@@ -23,6 +19,10 @@ export interface PropertyUpdates {
 const NO_PERSON_UPDATE_EVENTS = new Set(['$exception', '$$heatmap'])
 const PERSON_EVENTS = new Set(['$identify', '$create_alias', '$merge_dangerously', '$set'])
 
+// GeoIP properties that should still trigger person updates even when other geoip properties are blocked
+// These are commonly used for segmentation and are worth keeping up-to-date
+const ALLOWED_GEOIP_PROPERTIES = new Set(['$geoip_country_name', '$geoip_city_name'])
+
 // For tracking what property keys cause us to update persons
 // tracking all properties we add from the event, 'geoip' for '$geoip_*' or '$initial_geoip_*' and 'other' for anything outside of those
 export function getMetricKey(key: string): string {
@@ -173,6 +173,27 @@ export function applyEventPropertyUpdates(
     return [updatedPerson, updated]
 }
 
+/**
+ * Determines if a property key should be filtered out from triggering person updates.
+ * These are properties that change frequently but aren't valuable enough to update the person record for.
+ *
+ * This is the single source of truth for property filtering logic, used by both:
+ * - Event-level processing (computeEventPropertyUpdates)
+ * - Batch-level processing (getPersonUpdateOutcome in batch-writing-person-store)
+ */
+export function isFilteredPersonPropertyKey(key: string): boolean {
+    // These are properties we add from the event and some change often, it's useless to update person always
+    if (eventToPersonProperties.has(key)) {
+        return true
+    }
+    // same as above, coming from GeoIP plugin
+    // but allow country and city updates as they're commonly used for segmentation
+    if (key.startsWith('$geoip_')) {
+        return !ALLOWED_GEOIP_PROPERTIES.has(key)
+    }
+    return false
+}
+
 // Minimize useless person updates by not overriding properties if it's not a person event and we added from the event
 // They will still show up for PoE as it's not removed from the event, we just don't update the person in PG anymore
 function shouldUpdatePersonIfOnlyChange(event: PluginEvent, key: string, updateAllProperties: boolean): boolean {
@@ -184,5 +205,5 @@ function shouldUpdatePersonIfOnlyChange(event: PluginEvent, key: string, updateA
         // for person events always update everything
         return true
     }
-    return !isFilteredPersonUpdateProperty(key)
-}
+    return !isFilteredPersonPropertyKey(key)
+}
\ No newline at end of file
