{
    "cost": 0.23818,
    "rewrites": {
        "directus__directus.447c91d0/packages/storage-driver-supabase/src/index.test.ts": {
            "output": "import {\n\trandAlphaNumeric,\n\trandGitBranch as randBucket,\n\trandDirectoryPath,\n\trandDomainName,\n\trandFilePath,\n\trandFileType,\n\trandNumber,\n\trandPastDate,\n\trandText,\n\trandGitShortSha as randUnique,\n\trandFileName,\n} from '@ngneat/falso';\nimport { StorageClient } from '@supabase/storage-js';\nimport { Readable } from 'node:stream';\nimport { ReadableStream } from 'node:stream/web';\nimport { Response, fetch } from 'undici';\nimport { afterEach, beforeEach, describe, expect, test, vi } from 'vitest';\nimport type { DriverSupabaseConfig } from './index.js';\nimport { DriverSupabase } from './index.js';\n\nvi.mock('@supabase/storage-js');\nvi.mock('undici');\n\nlet sample: {\n\tconfig: Required<DriverSupabaseConfig>;\n\tpath: {\n\t\tinput: string;\n\t\tsrc: string;\n\t\tdest: string;\n\t};\n\trange: {\n\t\tstart: number;\n\t\tend: number;\n\t};\n\tstream: Readable;\n\ttext: string;\n\tfile: {\n\t\ttype: string;\n\t\tsize: number;\n\t\tmodified: Date;\n\t};\n};\n\nlet driver: DriverSupabase;\n\nbeforeEach(() => {\n\tsample = {\n\t\tconfig: {\n\t\t\tserviceRole: randAlphaNumeric({ length: 40 }).join(''),\n\t\t\tbucket: randBucket(),\n\t\t\tprojectId: randAlphaNumeric({ length: 10 }).join(''),\n\t\t\troot: randUnique() + randDirectoryPath(),\n\t\t\tendpoint: randDomainName(),\n\t\t},\n\t\tpath: {\n\t\t\tinput: randUnique() + randFilePath(),\n\t\t\tsrc: randUnique() + randFilePath(),\n\t\t\tdest: randUnique() + randFilePath(),\n\t\t},\n\t\trange: {\n\t\t\tstart: randNumber(),\n\t\t\tend: randNumber(),\n\t\t},\n\t\tstream: new Readable(),\n\t\ttext: randText(),\n\t\tfile: {\n\t\t\ttype: randFileType(),\n\t\t\tsize: randNumber(),\n\t\t\tmodified: randPastDate(),\n\t\t},\n\t};\n\n\tdriver = new DriverSupabase({\n\t\tserviceRole: sample.config.serviceRole,\n\t\tbucket: sample.config.bucket,\n\t\tprojectId: sample.config.projectId,\n\t});\n});\n\nafterEach(() => {\n\tvi.resetAllMocks();\n});\n\ndescribe('#constructor', () => {\n\tlet getClientBackup: (typeof DriverSupabase.prototype)['getClient'];\n\tlet getBucketBackup: (typeof DriverSupabase.prototype)['getBucket'];\n\tlet sampleClient: StorageClient;\n\tlet sampleBucket: ReturnType<StorageClient['from']>;\n\n\tbeforeEach(() => {\n\t\tgetClientBackup = DriverSupabase.prototype['getClient'];\n\t\tsampleClient = {} as StorageClient;\n\t\tDriverSupabase.prototype['getClient'] = vi.fn().mockReturnValue(sampleClient);\n\n\t\tgetBucketBackup = DriverSupabase.prototype['getBucket'];\n\t\tsampleBucket = {} as ReturnType<StorageClient['from']>;\n\t\tDriverSupabase.prototype['getBucket'] = vi.fn().mockReturnValue(sampleBucket);\n\t});\n\n\tafterEach(() => {\n\t\tDriverSupabase.prototype['getClient'] = getClientBackup;\n\t\tDriverSupabase.prototype['getBucket'] = getBucketBackup;\n\t});\n\n\ttest('Saves passed config to local property', () => {\n\t\tconst driver = new DriverSupabase(sample.config);\n\n\t\texpect(driver['config']).toStrictEqual(sample.config);\n\t});\n\n\ttest('Creates shared client', () => {\n\t\tconst driver = new DriverSupabase(sample.config);\n\t\texpect(driver['getClient']).toHaveBeenCalledOnce();\n\t\texpect(driver['client']).toBe(sampleClient);\n\t});\n\n\ttest('Defaults root to empty string', () => {\n\t\texpect(driver['config'].root).toBe('');\n\t});\n});\n\ndescribe('#getClient', () => {\n\ttest('Throws error if serviceRole is missing', () => {\n\t\ttry {\n\t\t\tnew DriverSupabase({ bucket: 'bucket' } as any);\n\t\t} catch (err: any) {\n\t\t\texpect(err).toBeInstanceOf(Error);\n\t\t\texpect(err.message).toBe('`project_id` or `endpoint` is required');\n\t\t}\n\t});\n\n\ttest('Throws error if bucket missing', () => {\n\t\ttry {\n\t\t\tnew DriverSupabase({ serviceRole: 'key' } as any);\n\t\t} catch (err: any) {\n\t\t\texpect(err).toBeInstanceOf(Error);\n\t\t\texpect(err.message).toBe('`project_id` or `endpoint` is required');\n\t\t}\n\t});\n\n\ttest('Throws error if projectId and endpoint are both missing', () => {\n\t\ttry {\n\t\t\tnew DriverSupabase({ serviceRole: 'secret', bucket: 'bucket' });\n\t\t} catch (err: any) {\n\t\t\texpect(err).toBeInstanceOf(Error);\n\t\t\texpect(err.message).toBe('`project_id` or `endpoint` is required');\n\t\t}\n\t});\n\n\ttest('Is valid if projectId is given', () => {\n\t\tconst projectId = 'project';\n\t\tconst driver = new DriverSupabase({ serviceRole: 'secret', bucket: 'bucket', projectId });\n\t\texpect(driver).toBeInstanceOf(DriverSupabase);\n\t\texpect(driver['endpoint']).toEqual(`https://${projectId}.supabase.co/storage/v1`);\n\t});\n\n\ttest('Is valid if endpoint is given', () => {\n\t\tconst endpoint = 'https://example.com';\n\t\tconst driver = new DriverSupabase({ serviceRole: 'secret', bucket: 'bucket', endpoint });\n\t\texpect(driver).toBeInstanceOf(DriverSupabase);\n\t\texpect(driver['endpoint']).toEqual(endpoint);\n\t});\n\n\ttest('Creates storage client', () => {\n\t\texpect(StorageClient).toHaveBeenCalledWith(`https://${sample.config.projectId}.supabase.co/storage/v1`, {\n\t\t\tapikey: sample.config.serviceRole,\n\t\t\tAuthorization: `Bearer ${sample.config.serviceRole}`,\n\t\t});\n\n\t\texpect(driver['client']).toBeInstanceOf(StorageClient);\n\t});\n});\n\ndescribe('#fullPath', () => {\n\ttest('Returns the input value if no root is given', () => {\n\t\tconst driver = new DriverSupabase({\n\t\t\tserviceRole: sample.config.serviceRole,\n\t\t\tbucket: sample.config.bucket,\n\t\t\tendpoint: sample.config.endpoint,\n\t\t});\n\n\t\tconst result = driver['fullPath'](sample.path.input);\n\t\texpect(result).toBe(sample.path.input);\n\t});\n\n\ttest('Returns normalized joined path', () => {\n\t\tconst driver = new DriverSupabase({\n\t\t\tserviceRole: sample.config.serviceRole,\n\t\t\tbucket: sample.config.bucket,\n\t\t\tendpoint: sample.config.endpoint,\n\t\t\troot: sample.config.root,\n\t\t});\n\n\t\tconst result = driver['fullPath'](sample.path.input);\n\t\texpect(result).toBe(`${sample.config.root}/${sample.path.input}`);\n\t});\n});\n\ndescribe('#getAuthenticatedUrl', () => {\n\ttest('Returns the url for an object with no root that requires authentication', () => {\n\t\tconst driver = new DriverSupabase({\n\t\t\tserviceRole: 'serviceRole',\n\t\t\tbucket: 'bucket',\n\t\t\tprojectId: 'projectId',\n\t\t});\n\n\t\tconst result = driver['getAuthenticatedUrl']('testing.png');\n\n\t\texpect(result).toBe('https://projectId.supabase.co/storage/v1/object/authenticated/bucket/testing.png');\n\t});\n\n\ttest('Returns the url for an object that requires authentication', () => {\n\t\tconst driver = new DriverSupabase({\n\t\t\tserviceRole: 'serviceRole',\n\t\t\tbucket: 'bucket',\n\t\t\tprojectId: 'projectId',\n\t\t\troot: 'testing',\n\t\t});\n\n\t\tconst result = driver['getAuthenticatedUrl']('testing.png');\n\n\t\texpect(result).toBe('https://projectId.supabase.co/storage/v1/object/authenticated/bucket/testing/testing.png');\n\t});\n});\n\ndescribe('#read', () => {\n\tlet rootEndpoint: string;\n\tlet endpoint: string;\n\n\tbeforeEach(() => {\n\t\trootEndpoint = `https://projectId.supabase.co/storage/v1/object/authenticated/bucket/testing/${sample.path.input}.png`;\n\t\tendpoint = `https://projectId.supabase.co/storage/v1/object/authenticated/bucket/${sample.path.input}.png`;\n\t\tvi.mocked(fetch).mockReturnValue({ status: 200, body: new ReadableStream() } as unknown as Promise<Response>);\n\t\tdriver['getAuthenticatedUrl'] = vi.fn().mockReturnValue(endpoint);\n\t});\n\n\ttest('Uses getAuthenticatedUrl to get endpoint when no root is set', async () => {\n\t\tawait driver.read(sample.path.input);\n\n\t\texpect(driver['getAuthenticatedUrl']).toHaveBeenCalledWith(sample.path.input);\n\n\t\texpect(fetch).toHaveBeenCalledWith(endpoint, {\n\t\t\theaders: {\n\t\t\t\tAuthorization: `Bearer ${sample.config.serviceRole}`,\n\t\t\t},\n\t\t\tmethod: 'GET',\n\t\t});\n\t});\n\n\ttest('Uses getAuthenticatedUrl to get endpoint when a root is set', async () => {\n\t\tdriver['getAuthenticatedUrl'] = vi.fn().mockReturnValue(rootEndpoint);\n\n\t\tawait driver.read(sample.path.input);\n\n\t\texpect(driver['getAuthenticatedUrl']).toHaveBeenCalledWith(sample.path.input);\n\n\t\texpect(fetch).toHaveBeenCalledWith(rootEndpoint, {\n\t\t\theaders: {\n\t\t\t\tAuthorization: `Bearer ${sample.config.serviceRole}`,\n\t\t\t},\n\t\t\tmethod: 'GET',\n\t\t});\n\t});\n\n\ttest('Optionally allows setting start range offset', async () => {\n\t\tawait driver.read(sample.path.input, { range: { start: sample.range.start } } as any);\n\n\t\texpect(fetch).toHaveBeenCalledWith(endpoint, {\n\t\t\theaders: {\n\t\t\t\tAuthorization: `Bearer ${sample.config.serviceRole}`,\n\t\t\t\tRange: `bytes=${sample.range.start}-`,\n\t\t\t},\n\t\t\tmethod: 'GET',\n\t\t});\n\t});\n\n\ttest('Optionally allows setting end range offset', async () => {\n\t\tawait driver.read(sample.path.input, { range: { end: sample.range.end } } as any);\n\n\t\texpect(fetch).toHaveBeenCalledWith(endpoint, {\n\t\t\theaders: {\n\t\t\t\tAuthorization: `Bearer ${sample.config.serviceRole}`,\n\t\t\t\tRange: `bytes=-${sample.range.end}`,\n\t\t\t},\n\t\t\tmethod: 'GET',\n\t\t});\n\t});\n\n\ttest('Optionally allows setting start and end range offset', async () => {\n\t\tawait driver.read(sample.path.input, { range: sample.range });\n\n\t\texpect(fetch).toHaveBeenCalledWith(endpoint, {\n\t\t\theaders: {\n\t\t\t\tAuthorization: `Bearer ${sample.config.serviceRole}`,\n\t\t\t\tRange: `bytes=${sample.range.start}-${sample.range.end}`,\n\t\t\t},\n\t\t\tmethod: 'GET',\n\t\t});\n\t});\n\n\ttest('Throws an error when no stream is returned', async () => {\n\t\tvi.mocked(fetch).mockReturnValue({ status: 400, body: new ReadableStream() } as unknown as Promise<Response>);\n\n\t\ttry {\n\t\t\tawait driver.read(sample.path.input, { range: sample.range });\n\t\t} catch (err: any) {\n\t\t\texpect(err).toBeInstanceOf(Error);\n\t\t\texpect(err.message).toBe(`No stream returned for file \"${sample.path.input}\"`);\n\t\t}\n\t});\n\n\ttest('Throws an error when returned stream is not a readable stream', async () => {\n\t\tvi.mocked(fetch).mockReturnValue({ status: 200, body: undefined } as unknown as Promise<Response>);\n\n\t\texpect(driver.read(sample.path.input, { range: sample.range })).rejects.toThrowError(\n\t\t\tnew Error(`No stream returned for file \"${sample.path.input}\"`),\n\t\t);\n\t});\n\n\ttest('Returns stream', async () => {\n\t\tconst stream = await driver.read(sample.path.input, { range: sample.range });\n\n\t\texpect(fetch).toHaveBeenCalledWith(endpoint, {\n\t\t\theaders: {\n\t\t\t\tAuthorization: `Bearer ${sample.config.serviceRole}`,\n\t\t\t\tRange: `bytes=${sample.range.start}-${sample.range.end}`,\n\t\t\t},\n\t\t\tmethod: 'GET',\n\t\t});\n\n\t\texpect(stream).toBeInstanceOf(Readable);\n\t});\n});\n\ndescribe('#stat', () => {\n\ttest('Returns the size/modified from metadata', async () => {\n\t\tdriver['bucket'] = {\n\t\t\tlist: vi.fn().mockReturnValue({\n\t\t\t\tdata: [{ metadata: { contentLength: sample.file.size, lastModified: sample.file.modified } }],\n\t\t\t\terror: null,\n\t\t\t}),\n\t\t} as any;\n\n\t\tconst stat = await driver.stat(sample.path.input);\n\n\t\texpect(stat).toEqual({\n\t\t\tsize: sample.file.size,\n\t\t\tmodified: sample.file.modified,\n\t\t});\n\n\t\texpect(driver['bucket'].list).toHaveBeenCalledWith('', {\n\t\t\tlimit: 1,\n\t\t\tsearch: sample.path.input,\n\t\t});\n\t});\n\n\ttest('Uses the configured root directory', async () => {\n\t\tdriver['config'].root = 'root';\n\n\t\tdriver['bucket'] = {\n\t\t\tlist: vi.fn().mockReturnValue({\n\t\t\t\tdata: [{ metadata: { contentLength: sample.file.size, lastModified: sample.file.modified } }],\n\t\t\t\terror: null,\n\t\t\t}),\n\t\t} as any;\n\n\t\tconst stat = await driver.stat(sample.path.input);\n\n\t\texpect(stat).toEqual({\n\t\t\tsize: sample.file.size,\n\t\t\tmodified: sample.file.modified,\n\t\t});\n\n\t\texpect(driver['bucket'].list).toHaveBeenCalledWith('root', {\n\t\t\tlimit: 1,\n\t\t\tsearch: sample.path.input,\n\t\t});\n\t});\n\n\ttest('Throws an error no file is returned by list', async () => {\n\t\tdriver['bucket'] = {\n\t\t\tlist: vi.fn().mockReturnValue({\n\t\t\t\tdata: [],\n\t\t\t\terror: null,\n\t\t\t}),\n\t\t} as any;\n\n\t\texpect(driver.stat(sample.path.input)).rejects.toThrowError(new Error(`File not found`));\n\t});\n\n\ttest('Throws an error if storage error is returned', async () => {\n\t\tdriver['bucket'] = {\n\t\t\tlist: vi.fn().mockReturnValue({\n\t\t\t\tdata: null,\n\t\t\t\terror: true,\n\t\t\t}),\n\t\t} as any;\n\n\t\texpect(driver.stat(sample.path.input)).rejects.toThrowError(new Error(`File not found`));\n\t});\n});\n\ndescribe('#exists', () => {\n\tbeforeEach(() => {\n\t\tdriver.stat = vi.fn();\n\t});\n\n\ttest('Returns true if stat returns the stats', async () => {\n\t\tvi.mocked(driver.stat).mockResolvedValue({ size: sample.file.size, modified: sample.file.modified });\n\n\t\tconst exists = await driver.exists(sample.path.input);\n\n\t\texpect(exists).toBe(true);\n\t});\n\n\ttest('Returns false if stat throws an error', async () => {\n\t\tvi.mocked(driver.stat).mockRejectedValue(new Error());\n\n\t\tconst exists = await driver.exists(sample.path.input);\n\n\t\texpect(exists).toBe(false);\n\t});\n});\n\ndescribe('#move', () => {\n\ttest('passes arguments to move', async () => {\n\t\tdriver['bucket'] = {\n\t\t\tmove: vi.fn(),\n\t\t} as any;\n\n\t\tawait driver.move(sample.path.input, 'new/path');\n\t\texpect(driver['bucket'].move).toHaveBeenCalledWith(sample.path.input, 'new/path');\n\t});\n});\n\ndescribe('#copy', () => {",
            "output_extracted": "import {\n\trandAlphaNumeric,\n\trandGitBranch as randBucket,\n\trandDirectoryPath,\n\trandDomainName,\n\trandFilePath,\n\trandFileType,\n\trandNumber,\n\trandPastDate,\n\trandText,\n\trandGitShortSha as randUnique,\n\trandFileName,\n} from '@ngneat/falso';\nimport { StorageClient } from '@supabase/storage-js';\nimport { Readable } from 'node:stream';\nimport { ReadableStream } from 'node:stream/web';\nimport { Response, fetch } from 'undici';\nimport { afterEach, beforeEach, describe, expect, test, vi } from 'vitest';\nimport type { DriverSupabaseConfig } from './index.js';\nimport { DriverSupabase } from './index.js';\n\nvi.mock('@supabase/storage-js');\nvi.mock('undici');\n\nlet sample: {\n\tconfig: Required<DriverSupabaseConfig>;\n\tpath: {\n\t\tinput: string;\n\t\tsrc: string;\n\t\tdest: string;\n\t};\n\trange: {\n\t\tstart: number;\n\t\tend: number;\n\t};\n\tstream: Readable;\n\ttext: string;\n\tfile: {\n\t\ttype: string;\n\t\tsize: number;\n\t\tmodified: Date;\n\t};\n};\n\nlet driver: DriverSupabase;\n\nbeforeEach(() => {\n\tsample = {\n\t\tconfig: {\n\t\t\tserviceRole: randAlphaNumeric({ length: 40 }).join(''),\n\t\t\tbucket: randBucket(),\n\t\t\tprojectId: randAlphaNumeric({ length: 10 }).join(''),\n\t\t\troot: randUnique() + randDirectoryPath(),\n\t\t\tendpoint: randDomainName(),\n\t\t},\n\t\tpath: {\n\t\t\tinput: randUnique() + randFilePath(),\n\t\t\tsrc: randUnique() + randFilePath(),\n\t\t\tdest: randUnique() + randFilePath(),\n\t\t},\n\t\trange: {\n\t\t\tstart: randNumber(),\n\t\t\tend: randNumber(),\n\t\t},\n\t\tstream: new Readable(),\n\t\ttext: randText(),\n\t\tfile: {\n\t\t\ttype: randFileType(),\n\t\t\tsize: randNumber(),\n\t\t\tmodified: randPastDate(),\n\t\t},\n\t};\n\n\tdriver = new DriverSupabase({\n\t\tserviceRole: sample.config.serviceRole,\n\t\tbucket: sample.config.bucket,\n\t\tprojectId: sample.config.projectId,\n\t});\n});\n\nafterEach(() => {\n\tvi.resetAllMocks();\n});\n\ndescribe('#constructor', () => {\n\tlet getClientBackup: (typeof DriverSupabase.prototype)['getClient'];\n\tlet getBucketBackup: (typeof DriverSupabase.prototype)['getBucket'];\n\tlet sampleClient: StorageClient;\n\tlet sampleBucket: ReturnType<StorageClient['from']>;\n\n\tbeforeEach(() => {\n\t\tgetClientBackup = DriverSupabase.prototype['getClient'];\n\t\tsampleClient = {} as StorageClient;\n\t\tDriverSupabase.prototype['getClient'] = vi.fn().mockReturnValue(sampleClient);\n\n\t\tgetBucketBackup = DriverSupabase.prototype['getBucket'];\n\t\tsampleBucket = {} as ReturnType<StorageClient['from']>;\n\t\tDriverSupabase.prototype['getBucket'] = vi.fn().mockReturnValue(sampleBucket);\n\t});\n\n\tafterEach(() => {\n\t\tDriverSupabase.prototype['getClient'] = getClientBackup;\n\t\tDriverSupabase.prototype['getBucket'] = getBucketBackup;\n\t});\n\n\ttest('Saves passed config to local property', () => {\n\t\tconst driver = new DriverSupabase(sample.config);\n\n\t\texpect(driver['config']).toStrictEqual(sample.config);\n\t});\n\n\ttest('Creates shared client', () => {\n\t\tconst driver = new DriverSupabase(sample.config);\n\t\texpect(driver['getClient']).toHaveBeenCalledOnce();\n\t\texpect(driver['client']).toBe(sampleClient);\n\t});\n\n\ttest('Defaults root to empty string', () => {\n\t\texpect(driver['config'].root).toBe('');\n\t});\n});\n\ndescribe('#getClient', () => {\n\ttest('Throws error if serviceRole is missing', () => {\n\t\ttry {\n\t\t\tnew DriverSupabase({ bucket: 'bucket' } as any);\n\t\t} catch (err: any) {\n\t\t\texpect(err).toBeInstanceOf(Error);\n\t\t\texpect(err.message).toBe('`project_id` or `endpoint` is required');\n\t\t}\n\t});\n\n\ttest('Throws error if bucket missing', () => {\n\t\ttry {\n\t\t\tnew DriverSupabase({ serviceRole: 'key' } as any);\n\t\t} catch (err: any) {\n\t\t\texpect(err).toBeInstanceOf(Error);\n\t\t\texpect(err.message).toBe('`project_id` or `endpoint` is required');\n\t\t}\n\t});\n\n\ttest('Throws error if projectId and endpoint are both missing', () => {\n\t\ttry {\n\t\t\tnew DriverSupabase({ serviceRole: 'secret', bucket: 'bucket' });\n\t\t} catch (err: any) {\n\t\t\texpect(err).toBeInstanceOf(Error);\n\t\t\texpect(err.message).toBe('`project_id` or `endpoint` is required');\n\t\t}\n\t});\n\n\ttest('Is valid if projectId is given', () => {\n\t\tconst projectId = 'project';\n\t\tconst driver = new DriverSupabase({ serviceRole: 'secret', bucket: 'bucket', projectId });\n\t\texpect(driver).toBeInstanceOf(DriverSupabase);\n\t\texpect(driver['endpoint']).toEqual(`https://${projectId}.supabase.co/storage/v1`);\n\t});\n\n\ttest('Is valid if endpoint is given', () => {\n\t\tconst endpoint = 'https://example.com';\n\t\tconst driver = new DriverSupabase({ serviceRole: 'secret', bucket: 'bucket', endpoint });\n\t\texpect(driver).toBeInstanceOf(DriverSupabase);\n\t\texpect(driver['endpoint']).toEqual(endpoint);\n\t});\n\n\ttest('Creates storage client', () => {\n\t\texpect(StorageClient).toHaveBeenCalledWith(`https://${sample.config.projectId}.supabase.co/storage/v1`, {\n\t\t\tapikey: sample.config.serviceRole,\n\t\t\tAuthorization: `Bearer ${sample.config.serviceRole}`,\n\t\t});\n\n\t\texpect(driver['client']).toBeInstanceOf(StorageClient);\n\t});\n});\n\ndescribe('#fullPath', () => {\n\ttest('Returns the input value if no root is given', () => {\n\t\tconst driver = new DriverSupabase({\n\t\t\tserviceRole: sample.config.serviceRole,\n\t\t\tbucket: sample.config.bucket,\n\t\t\tendpoint: sample.config.endpoint,\n\t\t});\n\n\t\tconst result = driver['fullPath'](sample.path.input);\n\t\texpect(result).toBe(sample.path.input);\n\t});\n\n\ttest('Returns normalized joined path', () => {\n\t\tconst driver = new DriverSupabase({\n\t\t\tserviceRole: sample.config.serviceRole,\n\t\t\tbucket: sample.config.bucket,\n\t\t\tendpoint: sample.config.endpoint,\n\t\t\troot: sample.config.root,\n\t\t});\n\n\t\tconst result = driver['fullPath'](sample.path.input);\n\t\texpect(result).toBe(`${sample.config.root}/${sample.path.input}`);\n\t});\n});\n\ndescribe('#getAuthenticatedUrl', () => {\n\ttest('Returns the url for an object with no root that requires authentication', () => {\n\t\tconst driver = new DriverSupabase({\n\t\t\tserviceRole: 'serviceRole',\n\t\t\tbucket: 'bucket',\n\t\t\tprojectId: 'projectId',\n\t\t});\n\n\t\tconst result = driver['getAuthenticatedUrl']('testing.png');\n\n\t\texpect(result).toBe('https://projectId.supabase.co/storage/v1/object/authenticated/bucket/testing.png');\n\t});\n\n\ttest('Returns the url for an object that requires authentication', () => {\n\t\tconst driver = new DriverSupabase({\n\t\t\tserviceRole: 'serviceRole',\n\t\t\tbucket: 'bucket',\n\t\t\tprojectId: 'projectId',\n\t\t\troot: 'testing',\n\t\t});\n\n\t\tconst result = driver['getAuthenticatedUrl']('testing.png');\n\n\t\texpect(result).toBe('https://projectId.supabase.co/storage/v1/object/authenticated/bucket/testing/testing.png');\n\t});\n});\n\ndescribe('#read', () => {\n\tlet rootEndpoint: string;\n\tlet endpoint: string;\n\n\tbeforeEach(() => {\n\t\trootEndpoint = `https://projectId.supabase.co/storage/v1/object/authenticated/bucket/testing/${sample.path.input}.png`;\n\t\tendpoint = `https://projectId.supabase.co/storage/v1/object/authenticated/bucket/${sample.path.input}.png`;\n\t\tvi.mocked(fetch).mockReturnValue({ status: 200, body: new ReadableStream() } as unknown as Promise<Response>);\n\t\tdriver['getAuthenticatedUrl'] = vi.fn().mockReturnValue(endpoint);\n\t});\n\n\ttest('Uses getAuthenticatedUrl to get endpoint when no root is set', async () => {\n\t\tawait driver.read(sample.path.input);\n\n\t\texpect(driver['getAuthenticatedUrl']).toHaveBeenCalledWith(sample.path.input);\n\n\t\texpect(fetch).toHaveBeenCalledWith(endpoint, {\n\t\t\theaders: {\n\t\t\t\tAuthorization: `Bearer ${sample.config.serviceRole}`,\n\t\t\t},\n\t\t\tmethod: 'GET',\n\t\t});\n\t});\n\n\ttest('Uses getAuthenticatedUrl to get endpoint when a root is set', async () => {\n\t\tdriver['getAuthenticatedUrl'] = vi.fn().mockReturnValue(rootEndpoint);\n\n\t\tawait driver.read(sample.path.input);\n\n\t\texpect(driver['getAuthenticatedUrl']).toHaveBeenCalledWith(sample.path.input);\n\n\t\texpect(fetch).toHaveBeenCalledWith(rootEndpoint, {\n\t\t\theaders: {\n\t\t\t\tAuthorization: `Bearer ${sample.config.serviceRole}`,\n\t\t\t},\n\t\t\tmethod: 'GET',\n\t\t});\n\t});\n\n\ttest('Optionally allows setting start range offset', async () => {\n\t\tawait driver.read(sample.path.input, { range: { start: sample.range.start } } as any);\n\n\t\texpect(fetch).toHaveBeenCalledWith(endpoint, {\n\t\t\theaders: {\n\t\t\t\tAuthorization: `Bearer ${sample.config.serviceRole}`,\n\t\t\t\tRange: `bytes=${sample.range.start}-`,\n\t\t\t},\n\t\t\tmethod: 'GET',\n\t\t});\n\t});\n\n\ttest('Optionally allows setting end range offset', async () => {\n\t\tawait driver.read(sample.path.input, { range: { end: sample.range.end } } as any);\n\n\t\texpect(fetch).toHaveBeenCalledWith(endpoint, {\n\t\t\theaders: {\n\t\t\t\tAuthorization: `Bearer ${sample.config.serviceRole}`,\n\t\t\t\tRange: `bytes=-${sample.range.end}`,\n\t\t\t},\n\t\t\tmethod: 'GET',\n\t\t});\n\t});\n\n\ttest('Optionally allows setting start and end range offset', async () => {\n\t\tawait driver.read(sample.path.input, { range: sample.range });\n\n\t\texpect(fetch).toHaveBeenCalledWith(endpoint, {\n\t\t\theaders: {\n\t\t\t\tAuthorization: `Bearer ${sample.config.serviceRole}`,\n\t\t\t\tRange: `bytes=${sample.range.start}-${sample.range.end}`,\n\t\t\t},\n\t\t\tmethod: 'GET',\n\t\t});\n\t});\n\n\ttest('Throws an error when no stream is returned', async () => {\n\t\tvi.mocked(fetch).mockReturnValue({ status: 400, body: new ReadableStream() } as unknown as Promise<Response>);\n\n\t\ttry {\n\t\t\tawait driver.read(sample.path.input, { range: sample.range });\n\t\t} catch (err: any) {\n\t\t\texpect(err).toBeInstanceOf(Error);\n\t\t\texpect(err.message).toBe(`No stream returned for file \"${sample.path.input}\"`);\n\t\t}\n\t});\n\n\ttest('Throws an error when returned stream is not a readable stream', async () => {\n\t\tvi.mocked(fetch).mockReturnValue({ status: 200, body: undefined } as unknown as Promise<Response>);\n\n\t\texpect(driver.read(sample.path.input, { range: sample.range })).rejects.toThrowError(\n\t\t\tnew Error(`No stream returned for file \"${sample.path.input}\"`),\n\t\t);\n\t});\n\n\ttest('Returns stream', async () => {\n\t\tconst stream = await driver.read(sample.path.input, { range: sample.range });\n\n\t\texpect(fetch).toHaveBeenCalledWith(endpoint, {\n\t\t\theaders: {\n\t\t\t\tAuthorization: `Bearer ${sample.config.serviceRole}`,\n\t\t\t\tRange: `bytes=${sample.range.start}-${sample.range.end}`,\n\t\t\t},\n\t\t\tmethod: 'GET',\n\t\t});\n\n\t\texpect(stream).toBeInstanceOf(Readable);\n\t});\n});\n\ndescribe('#stat', () => {\n\ttest('Returns the size/modified from metadata', async () => {\n\t\tdriver['bucket'] = {\n\t\t\tlist: vi.fn().mockReturnValue({\n\t\t\t\tdata: [{ metadata: { contentLength: sample.file.size, lastModified: sample.file.modified } }],\n\t\t\t\terror: null,\n\t\t\t}),\n\t\t} as any;\n\n\t\tconst stat = await driver.stat(sample.path.input);\n\n\t\texpect(stat).toEqual({\n\t\t\tsize: sample.file.size,\n\t\t\tmodified: sample.file.modified,\n\t\t});\n\n\t\texpect(driver['bucket'].list).toHaveBeenCalledWith('', {\n\t\t\tlimit: 1,\n\t\t\tsearch: sample.path.input,\n\t\t});\n\t});\n\n\ttest('Uses the configured root directory', async () => {\n\t\tdriver['config'].root = 'root';\n\n\t\tdriver['bucket'] = {\n\t\t\tlist: vi.fn().mockReturnValue({\n\t\t\t\tdata: [{ metadata: { contentLength: sample.file.size, lastModified: sample.file.modified } }],\n\t\t\t\terror: null,\n\t\t\t}),\n\t\t} as any;\n\n\t\tconst stat = await driver.stat(sample.path.input);\n\n\t\texpect(stat).toEqual({\n\t\t\tsize: sample.file.size,\n\t\t\tmodified: sample.file.modified,\n\t\t});\n\n\t\texpect(driver['bucket'].list).toHaveBeenCalledWith('root', {\n\t\t\tlimit: 1,\n\t\t\tsearch: sample.path.input,\n\t\t});\n\t});\n\n\ttest('Throws an error no file is returned by list', async () => {\n\t\tdriver['bucket'] = {\n\t\t\tlist: vi.fn().mockReturnValue({\n\t\t\t\tdata: [],\n\t\t\t\terror: null,\n\t\t\t}),\n\t\t} as any;\n\n\t\texpect(driver.stat(sample.path.input)).rejects.toThrowError(new Error(`File not found`));\n\t});\n\n\ttest('Throws an error if storage error is returned', async () => {\n\t\tdriver['bucket'] = {\n\t\t\tlist: vi.fn().mockReturnValue({\n\t\t\t\tdata: null,\n\t\t\t\terror: true,\n\t\t\t}),\n\t\t} as any;\n\n\t\texpect(driver.stat(sample.path.input)).rejects.toThrowError(new Error(`File not found`));\n\t});\n});\n\ndescribe('#exists', () => {\n\tbeforeEach(() => {\n\t\tdriver.stat = vi.fn();\n\t});\n\n\ttest('Returns true if stat returns the stats', async () => {\n\t\tvi.mocked(driver.stat).mockResolvedValue({ size: sample.file.size, modified: sample.file.modified });\n\n\t\tconst exists = await driver.exists(sample.path.input);\n\n\t\texpect(exists).toBe(true);\n\t});\n\n\ttest('Returns false if stat throws an error', async () => {\n\t\tvi.mocked(driver.stat).mockRejectedValue(new Error());\n\n\t\tconst exists = await driver.exists(sample.path.input);\n\n\t\texpect(exists).toBe(false);\n\t});\n});\n\ndescribe('#move', () => {\n\ttest('passes arguments to move', async () => {\n\t\tdriver['bucket'] = {\n\t\t\tmove: vi.fn(),\n\t\t} as any;\n\n\t\tawait driver.move(sample.path.input, 'new/path');\n\t\texpect(driver['bucket'].move).toHaveBeenCalledWith(sample.path.input, 'new/path');\n\t});\n});\n\ndescribe('#copy', () => {",
            "cost": 0.14328000000000002
        },
        "directus__directus.447c91d0/packages/storage-driver-supabase/src/index.ts": {
            "output": "import { DEFAULT_CHUNK_SIZE } from '@directus/constants';\nimport type { TusDriver } from '@directus/storage';\nimport type { ChunkedUploadContext, ReadOptions } from '@directus/types';\nimport { normalizePath } from '@directus/utils';\nimport { StorageClient } from '@supabase/storage-js';\nimport { join } from 'node:path';\nimport { Readable } from 'node:stream';\nimport * as tus from 'tus-js-client';\nimport type { RequestInit } from 'undici';\nimport { fetch } from 'undici';\n\nexport type DriverSupabaseConfig = {\n\tbucket: string;\n\tserviceRole: string;\n\tprojectId?: string;\n\t/** Allows a custom Supabase endpoint for self-hosting */\n\tendpoint?: string;\n\troot?: string;\n\ttus?: {\n\t\tchunkSize?: number;\n\t};\n};\n\nexport class DriverSupabase implements TusDriver {\n\tprivate config: DriverSupabaseConfig & { root: string };\n\tprivate client: StorageClient;\n\tprivate bucket: ReturnType<StorageClient['from']>;\n\n\t// TUS specific members\n\tprivate readonly preferredChunkSize: number;\n\n\tconstructor(config: DriverSupabaseConfig) {\n\t\tthis.config = {\n\t\t\t...config,\n\t\t\troot: normalizePath(config.root ?? '', { removeLeading: true }),\n\t\t};\n\n\t\tthis.preferredChunkSize = this.config.tus?.chunkSize ?? DEFAULT_CHUNK_SIZE;\n\n\t\tthis.client = this.getClient();\n\t\tthis.bucket = this.getBucket();\n\t}\n\n\tprivate get endpoint() {\n\t\treturn this.config.endpoint ?? `https://${this.config.projectId}.supabase.co/storage/v1`;\n\t}\n\n\tprivate getClient() {\n\t\tif (!this.config.projectId && !this.config.endpoint) {\n\t\t\tthrow new Error('`project_id` or `endpoint` is required');\n\t\t}\n\n\t\tif (!this.config.serviceRole) {\n\t\t\tthrow new Error('`service_role` is required');\n\t\t}\n\n\t\treturn new StorageClient(this.endpoint, {\n\t\t\tapikey: this.config.serviceRole,\n\t\t\tAuthorization: `Bearer ${this.config.serviceRole}`,\n\t\t});\n\t}\n\n\tprivate getBucket() {\n\t\tif (!this.config.bucket) {\n\t\t\tthrow new Error('`bucket` is required');\n\t\t}\n\n\t\treturn this.client.from(this.config.bucket);\n\t}\n\n\tprivate fullPath(filepath: string) {\n\t\tconst path = join(this.config.root, filepath);\n\t\t// Supabase expects an empty string for current directory\n\t\tif (path === '.') return '';\n\t\treturn normalizePath(path);\n\t}\n\n\tprivate getAuthenticatedUrl(filepath: string) {\n\t\treturn `${this.endpoint}/${join('object/authenticated', this.config.bucket, this.fullPath(filepath))}`;\n\t}\n\n\tprivate getResumableUrl() {\n\t\treturn `${this.endpoint}/upload/resumable`;\n\t}\n\n\tasync read(filepath: string, options?: ReadOptions) {\n\t\tconst { range } = options || {};\n\n\t\tconst requestInit: RequestInit = { method: 'GET' };\n\n\t\trequestInit.headers = {\n\t\t\tAuthorization: `Bearer ${this.config.serviceRole}`,\n\t\t};\n\n\t\tif (range) {\n\t\t\trequestInit.headers['Range'] = `bytes=${range.start ?? ''}-${range.end ?? ''}`;\n\t\t}\n\n\t\tconst response = await fetch(this.getAuthenticatedUrl(filepath), requestInit);\n\n\t\tif (response.status >= 400 || !response.body) {\n\t\t\tthrow new Error(`No stream returned for file \"${filepath}\"`);\n\t\t}\n\n\t\treturn Readable.fromWeb(response.body);\n\t}\n\n\tasync stat(filepath: string) {\n\t\tconst { data, error } = await this.bucket.list(this.config.root, {\n\t\t\tsearch: filepath,\n\t\t\tlimit: 1,\n\t\t});\n\n\t\tif (error || data.length === 0) {\n\t\t\tthrow new Error('File not found');\n\t\t}\n\n\t\treturn {\n\t\t\tsize: data[0]?.metadata['contentLength'] ?? 0,\n\t\t\tmodified: new Date(data[0]?.metadata['lastModified'] || null),\n\t\t};\n\t}\n\n\tasync exists(filepath: string) {\n\t\ttry {\n\t\t\tawait this.stat(filepath);\n\t\t\treturn true;\n\t\t} catch {\n\t\t\treturn false;\n\t\t}\n\t}\n\n\tasync move(src: string, dest: string) {\n\t\tawait this.bucket.move(this.fullPath(src), this.fullPath(dest));\n\t}\n\n\tasync copy(src: string, dest: string) {\n\t\tawait this.bucket.copy(this.fullPath(src), this.fullPath(dest));\n\t}\n\n\tasync write(filepath: string, content: Readable, type?: string) {\n\t\tawait this.bucket.upload(this.fullPath(filepath), content, {\n\t\t\tcontentType: type ?? '',\n\t\t\tcacheControl: '3600',\n\t\t\tupsert: true,\n\t\t\tduplex: 'half',\n\t\t});\n\t}\n\n\tasync delete(filepath: string) {\n\t\tawait this.bucket.remove([this.fullPath(filepath)]);\n\t}\n\n\tlist(prefix = ''): AsyncIterable<string> {\n\t\tconst fullPrefix = this.fullPath(prefix);\n\t\treturn this.listGenerator(fullPrefix);\n\t}\n\n\tasync *listGenerator(prefix: string): AsyncIterable<string> {\n\t\tconst limit = 1000;\n\t\tlet offset = 0;\n\t\tlet itemCount = 0;\n\n\t\t/*\n\t\t *\tThe Supabase API only returns the directories and files directly within the queried location\n\t\t *\t(called prefix in their API) matching the search query. Directories can be identified by the id being null.\n\t\t *\n\t\t *\tSince it's unknown whether the last part of the prefix param is a directory, a file or part of a directory or file name,\n\t\t *\tthe first query will be the largest common denominator (the parent directory part of the prefix)\n\t\t *\tand the results then filtered with the remaining part of the query.\n\t\t *\n\t\t *\tThis can lead to the following outcomes:\n\t\t *\t1. The full prefix is a file and is split up into parentdir/filename, the API is queried with\n\t\t *\t   { prefix: parentdir, search: filename } and returns one result { name: filename, id: \"...\" }.\n\t\t *\t   The filename is yielded in that case.\n\t\t *\t2. The full prefix is a directory and is split up into parentdir/dir, the API is queried with\n\t\t *\t   { prefix: parentdir, search: dir } and returns one result { name: dir, id: null } and importantly, not the\n\t\t *\t   contents of the directory. Then  the contents of the directory must be listed recursively by calling this\n\t\t *\t   function with the prefix and a trailing \"/\".\n\t\t *\t   2.1. The prefix ends with a \"/\", the API is queried with { prefix: prefix, search: \"\" }\n\t\t *\t        and returns all files and directories within the prefix, which are yielded and recursively listed.\n\t\t *\t3. Special case of 1. and 2.: The prefix is part of a filename/directory name and could result in more than one result\n\t\t *\t   that all match the search query. The API is queried with { prefix: parentdir, search: part of filename }\n\t\t *\t   and returns all files and directories in parentdir that match the search query. Filenames are yielded and\n\t\t *\t   directories are recursively listed.\n\t\t */\n\t\tconst isDirectory = prefix.endsWith('/');\n\t\tconst prefixDirectory = isDirectory ? prefix : dirname(prefix);\n\t\tconst search = isDirectory ? '' : (prefix.split('/').pop() ?? '');\n\n\t\tdo {\n\t\t\tconst { data, error } = await this.bucket.list(prefixDirectory, {\n\t\t\t\tlimit,\n\t\t\t\toffset,\n\t\t\t\tsearch,\n\t\t\t});\n\n\t\t\tif (!data || error) {\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\titemCount = data.length;\n\t\t\toffset += itemCount;\n\n\t\t\tfor (const item of data) {\n\t\t\t\t// Since the API only returns the filename, the file path is constructed by joining the prefix with the item name\n\t\t\t\tconst filePath = normalizePath(join(prefixDirectory, item.name));\n\n\t\t\t\tif (item.id !== null) {\n\t\t\t\t\t// Remove the root from the path and yield the filename\n\t\t\t\t\tyield filePath.substring(this.config.root ? this.config.root.length + 1 : 0);\n\t\t\t\t} else {\n\t\t\t\t\t// This is a directory, recursively list it\n\t\t\t\t\tyield* this.listGenerator(`${filePath}/`);\n\t\t\t\t}\n\t\t\t}\n\t\t} while (itemCount === limit);\n\t}\n\n\tget tusExtensions() {\n\t\treturn ['creation', 'termination', 'expiration'];\n\t}\n\n\tasync createChunkedUpload(_filepath: string, context: ChunkedUploadContext) {\n\t\treturn context;\n\t}\n\n\tasync writeChunk(filepath: string, content: Readable, offset: number, context: ChunkedUploadContext) {\n\t\tlet bytesUploaded = offset || 0;\n\n\t\tconst metadata = {\n\t\t\tbucketName: this.config.bucket,\n\t\t\tobjectName: this.fullPath(filepath),\n\t\t\tcontentType: context.metadata!['type'] ?? 'image/png',\n\t\t\tcacheControl: '3600',\n\t\t};\n\n\t\tawait new Promise((resolve, reject) => {\n\t\t\tconst upload = new tus.Upload(content, {\n\t\t\t\tendpoint: this.getResumableUrl(),\n\t\t\t\t// @ts-expect-error\n\t\t\t\tfileReader: new FileReader(),\n\t\t\t\theaders: {\n\t\t\t\t\tAuthorization: `Bearer ${this.config.serviceRole}`,\n\t\t\t\t\t'x-upsert': 'true',\n\t\t\t\t},\n\t\t\t\tmetadata,\n\t\t\t\tchunkSize: this.preferredChunkSize,\n\t\t\t\tuploadSize: context.size,\n\t\t\t\tretryDelays: null,\n\t\t\t\tonError(error) {\n\t\t\t\t\treject(error);\n\t\t\t\t},\n\t\t\t\tonChunkComplete: function (chunkSize) {\n\t\t\t\t\tbytesUploaded += chunkSize;\n\n\t\t\t\t\tresolve(null);\n\t\t\t\t},\n\t\t\t\tonSuccess() {\n\t\t\t\t\tresolve(null);\n\t\t\t\t},\n\t\t\t\tonUploadUrlAvailable() {\n\t\t\t\t\tif (!context.metadata!['upload-url']) {\n\t\t\t\t\t\tcontext.metadata!['upload-url'] = upload.url;\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t});\n\n\t\t\tif (context.metadata!['upload-url']) {\n\t\t\t\tupload.resumeFromPreviousUpload({\n\t\t\t\t\tsize: context.size!,\n\t\t\t\t\tcreationTime: context.metadata!['creation_date'] as string,\n\t\t\t\t\tmetadata,\n\t\t\t\t\tuploadUrl: context.metadata!['upload-url'],\n\t\t\t\t} as any);\n\t\t\t}\n\n\t\t\tupload.start();\n\t\t});\n\n\t\treturn bytesUploaded;\n\t}\n\n\tasync finishChunkedUpload(_filepath: string, _context: ChunkedUploadContext) {}\n\n\tasync deleteChunkedUpload(filepath: string, _context: ChunkedUploadContext) {\n\t\tawait this.delete(filepath);\n\t}\n}\n\nexport default DriverSupabase;\n\n/**\n * dirname implementation that always uses '/' to split and returns '' in case of no separator present.\n */\nfunction dirname(path: string) {\n\treturn path.split('/').slice(0, -1).join('/');\n}\n\n// @ts-expect-error\nclass StreamSource extends tus.StreamSource {\n\t_streamEnded = false;\n\n\t// @ts-expect-error\n\toverride async slice(start: number, end: number) {\n\t\tif (this._streamEnded) return null;\n\n\t\t// Act like the stream ended after it's been called once\n\t\tthis._streamEnded = true;\n\n\t\t// Shift the start and end offsets to always start at 0, since the read stream is only a stream of one chunk with\n\t\t// length of `chunkSize`\n\t\treturn super.slice(0, end - start);\n\t}\n}\n\nclass FileReader {\n\tasync openFile(input: Readable, _: number): Promise<StreamSource> {\n\t\t// @ts-expect-error\n\t\treturn new StreamSource(input);\n\t}\n}",
            "output_extracted": "import { DEFAULT_CHUNK_SIZE } from '@directus/constants';\nimport type { TusDriver } from '@directus/storage';\nimport type { ChunkedUploadContext, ReadOptions } from '@directus/types';\nimport { normalizePath } from '@directus/utils';\nimport { StorageClient } from '@supabase/storage-js';\nimport { join } from 'node:path';\nimport { Readable } from 'node:stream';\nimport * as tus from 'tus-js-client';\nimport type { RequestInit } from 'undici';\nimport { fetch } from 'undici';\n\nexport type DriverSupabaseConfig = {\n\tbucket: string;\n\tserviceRole: string;\n\tprojectId?: string;\n\t/** Allows a custom Supabase endpoint for self-hosting */\n\tendpoint?: string;\n\troot?: string;\n\ttus?: {\n\t\tchunkSize?: number;\n\t};\n};\n\nexport class DriverSupabase implements TusDriver {\n\tprivate config: DriverSupabaseConfig & { root: string };\n\tprivate client: StorageClient;\n\tprivate bucket: ReturnType<StorageClient['from']>;\n\n\t// TUS specific members\n\tprivate readonly preferredChunkSize: number;\n\n\tconstructor(config: DriverSupabaseConfig) {\n\t\tthis.config = {\n\t\t\t...config,\n\t\t\troot: normalizePath(config.root ?? '', { removeLeading: true }),\n\t\t};\n\n\t\tthis.preferredChunkSize = this.config.tus?.chunkSize ?? DEFAULT_CHUNK_SIZE;\n\n\t\tthis.client = this.getClient();\n\t\tthis.bucket = this.getBucket();\n\t}\n\n\tprivate get endpoint() {\n\t\treturn this.config.endpoint ?? `https://${this.config.projectId}.supabase.co/storage/v1`;\n\t}\n\n\tprivate getClient() {\n\t\tif (!this.config.projectId && !this.config.endpoint) {\n\t\t\tthrow new Error('`project_id` or `endpoint` is required');\n\t\t}\n\n\t\tif (!this.config.serviceRole) {\n\t\t\tthrow new Error('`service_role` is required');\n\t\t}\n\n\t\treturn new StorageClient(this.endpoint, {\n\t\t\tapikey: this.config.serviceRole,\n\t\t\tAuthorization: `Bearer ${this.config.serviceRole}`,\n\t\t});\n\t}\n\n\tprivate getBucket() {\n\t\tif (!this.config.bucket) {\n\t\t\tthrow new Error('`bucket` is required');\n\t\t}\n\n\t\treturn this.client.from(this.config.bucket);\n\t}\n\n\tprivate fullPath(filepath: string) {\n\t\tconst path = join(this.config.root, filepath);\n\t\t// Supabase expects an empty string for current directory\n\t\tif (path === '.') return '';\n\t\treturn normalizePath(path);\n\t}\n\n\tprivate getAuthenticatedUrl(filepath: string) {\n\t\treturn `${this.endpoint}/${join('object/authenticated', this.config.bucket, this.fullPath(filepath))}`;\n\t}\n\n\tprivate getResumableUrl() {\n\t\treturn `${this.endpoint}/upload/resumable`;\n\t}\n\n\tasync read(filepath: string, options?: ReadOptions) {\n\t\tconst { range } = options || {};\n\n\t\tconst requestInit: RequestInit = { method: 'GET' };\n\n\t\trequestInit.headers = {\n\t\t\tAuthorization: `Bearer ${this.config.serviceRole}`,\n\t\t};\n\n\t\tif (range) {\n\t\t\trequestInit.headers['Range'] = `bytes=${range.start ?? ''}-${range.end ?? ''}`;\n\t\t}\n\n\t\tconst response = await fetch(this.getAuthenticatedUrl(filepath), requestInit);\n\n\t\tif (response.status >= 400 || !response.body) {\n\t\t\tthrow new Error(`No stream returned for file \"${filepath}\"`);\n\t\t}\n\n\t\treturn Readable.fromWeb(response.body);\n\t}\n\n\tasync stat(filepath: string) {\n\t\tconst { data, error } = await this.bucket.list(this.config.root, {\n\t\t\tsearch: filepath,\n\t\t\tlimit: 1,\n\t\t});\n\n\t\tif (error || data.length === 0) {\n\t\t\tthrow new Error('File not found');\n\t\t}\n\n\t\treturn {\n\t\t\tsize: data[0]?.metadata['contentLength'] ?? 0,\n\t\t\tmodified: new Date(data[0]?.metadata['lastModified'] || null),\n\t\t};\n\t}\n\n\tasync exists(filepath: string) {\n\t\ttry {\n\t\t\tawait this.stat(filepath);\n\t\t\treturn true;\n\t\t} catch {\n\t\t\treturn false;\n\t\t}\n\t}\n\n\tasync move(src: string, dest: string) {\n\t\tawait this.bucket.move(this.fullPath(src), this.fullPath(dest));\n\t}\n\n\tasync copy(src: string, dest: string) {\n\t\tawait this.bucket.copy(this.fullPath(src), this.fullPath(dest));\n\t}\n\n\tasync write(filepath: string, content: Readable, type?: string) {\n\t\tawait this.bucket.upload(this.fullPath(filepath), content, {\n\t\t\tcontentType: type ?? '',\n\t\t\tcacheControl: '3600',\n\t\t\tupsert: true,\n\t\t\tduplex: 'half',\n\t\t});\n\t}\n\n\tasync delete(filepath: string) {\n\t\tawait this.bucket.remove([this.fullPath(filepath)]);\n\t}\n\n\tlist(prefix = ''): AsyncIterable<string> {\n\t\tconst fullPrefix = this.fullPath(prefix);\n\t\treturn this.listGenerator(fullPrefix);\n\t}\n\n\tasync *listGenerator(prefix: string): AsyncIterable<string> {\n\t\tconst limit = 1000;\n\t\tlet offset = 0;\n\t\tlet itemCount = 0;\n\n\t\t/*\n\t\t *\tThe Supabase API only returns the directories and files directly within the queried location\n\t\t *\t(called prefix in their API) matching the search query. Directories can be identified by the id being null.\n\t\t *\n\t\t *\tSince it's unknown whether the last part of the prefix param is a directory, a file or part of a directory or file name,\n\t\t *\tthe first query will be the largest common denominator (the parent directory part of the prefix)\n\t\t *\tand the results then filtered with the remaining part of the query.\n\t\t *\n\t\t *\tThis can lead to the following outcomes:\n\t\t *\t1. The full prefix is a file and is split up into parentdir/filename, the API is queried with\n\t\t *\t   { prefix: parentdir, search: filename } and returns one result { name: filename, id: \"...\" }.\n\t\t *\t   The filename is yielded in that case.\n\t\t *\t2. The full prefix is a directory and is split up into parentdir/dir, the API is queried with\n\t\t *\t   { prefix: parentdir, search: dir } and returns one result { name: dir, id: null } and importantly, not the\n\t\t *\t   contents of the directory. Then  the contents of the directory must be listed recursively by calling this\n\t\t *\t   function with the prefix and a trailing \"/\".\n\t\t *\t   2.1. The prefix ends with a \"/\", the API is queried with { prefix: prefix, search: \"\" }\n\t\t *\t        and returns all files and directories within the prefix, which are yielded and recursively listed.\n\t\t *\t3. Special case of 1. and 2.: The prefix is part of a filename/directory name and could result in more than one result\n\t\t *\t   that all match the search query. The API is queried with { prefix: parentdir, search: part of filename }\n\t\t *\t   and returns all files and directories in parentdir that match the search query. Filenames are yielded and\n\t\t *\t   directories are recursively listed.\n\t\t */\n\t\tconst isDirectory = prefix.endsWith('/');\n\t\tconst prefixDirectory = isDirectory ? prefix : dirname(prefix);\n\t\tconst search = isDirectory ? '' : (prefix.split('/').pop() ?? '');\n\n\t\tdo {\n\t\t\tconst { data, error } = await this.bucket.list(prefixDirectory, {\n\t\t\t\tlimit,\n\t\t\t\toffset,\n\t\t\t\tsearch,\n\t\t\t});\n\n\t\t\tif (!data || error) {\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\titemCount = data.length;\n\t\t\toffset += itemCount;\n\n\t\t\tfor (const item of data) {\n\t\t\t\t// Since the API only returns the filename, the file path is constructed by joining the prefix with the item name\n\t\t\t\tconst filePath = normalizePath(join(prefixDirectory, item.name));\n\n\t\t\t\tif (item.id !== null) {\n\t\t\t\t\t// Remove the root from the path and yield the filename\n\t\t\t\t\tyield filePath.substring(this.config.root ? this.config.root.length + 1 : 0);\n\t\t\t\t} else {\n\t\t\t\t\t// This is a directory, recursively list it\n\t\t\t\t\tyield* this.listGenerator(`${filePath}/`);\n\t\t\t\t}\n\t\t\t}\n\t\t} while (itemCount === limit);\n\t}\n\n\tget tusExtensions() {\n\t\treturn ['creation', 'termination', 'expiration'];\n\t}\n\n\tasync createChunkedUpload(_filepath: string, context: ChunkedUploadContext) {\n\t\treturn context;\n\t}\n\n\tasync writeChunk(filepath: string, content: Readable, offset: number, context: ChunkedUploadContext) {\n\t\tlet bytesUploaded = offset || 0;\n\n\t\tconst metadata = {\n\t\t\tbucketName: this.config.bucket,\n\t\t\tobjectName: this.fullPath(filepath),\n\t\t\tcontentType: context.metadata!['type'] ?? 'image/png',\n\t\t\tcacheControl: '3600',\n\t\t};\n\n\t\tawait new Promise((resolve, reject) => {\n\t\t\tconst upload = new tus.Upload(content, {\n\t\t\t\tendpoint: this.getResumableUrl(),\n\t\t\t\t// @ts-expect-error\n\t\t\t\tfileReader: new FileReader(),\n\t\t\t\theaders: {\n\t\t\t\t\tAuthorization: `Bearer ${this.config.serviceRole}`,\n\t\t\t\t\t'x-upsert': 'true',\n\t\t\t\t},\n\t\t\t\tmetadata,\n\t\t\t\tchunkSize: this.preferredChunkSize,\n\t\t\t\tuploadSize: context.size,\n\t\t\t\tretryDelays: null,\n\t\t\t\tonError(error) {\n\t\t\t\t\treject(error);\n\t\t\t\t},\n\t\t\t\tonChunkComplete: function (chunkSize) {\n\t\t\t\t\tbytesUploaded += chunkSize;\n\n\t\t\t\t\tresolve(null);\n\t\t\t\t},\n\t\t\t\tonSuccess() {\n\t\t\t\t\tresolve(null);\n\t\t\t\t},\n\t\t\t\tonUploadUrlAvailable() {\n\t\t\t\t\tif (!context.metadata!['upload-url']) {\n\t\t\t\t\t\tcontext.metadata!['upload-url'] = upload.url;\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t});\n\n\t\t\tif (context.metadata!['upload-url']) {\n\t\t\t\tupload.resumeFromPreviousUpload({\n\t\t\t\t\tsize: context.size!,\n\t\t\t\t\tcreationTime: context.metadata!['creation_date'] as string,\n\t\t\t\t\tmetadata,\n\t\t\t\t\tuploadUrl: context.metadata!['upload-url'],\n\t\t\t\t} as any);\n\t\t\t}\n\n\t\t\tupload.start();\n\t\t});\n\n\t\treturn bytesUploaded;\n\t}\n\n\tasync finishChunkedUpload(_filepath: string, _context: ChunkedUploadContext) {}\n\n\tasync deleteChunkedUpload(filepath: string, _context: ChunkedUploadContext) {\n\t\tawait this.delete(filepath);\n\t}\n}\n\nexport default DriverSupabase;\n\n/**\n * dirname implementation that always uses '/' to split and returns '' in case of no separator present.\n */\nfunction dirname(path: string) {\n\treturn path.split('/').slice(0, -1).join('/');\n}\n\n// @ts-expect-error\nclass StreamSource extends tus.StreamSource {\n\t_streamEnded = false;\n\n\t// @ts-expect-error\n\toverride async slice(start: number, end: number) {\n\t\tif (this._streamEnded) return null;\n\n\t\t// Act like the stream ended after it's been called once\n\t\tthis._streamEnded = true;\n\n\t\t// Shift the start and end offsets to always start at 0, since the read stream is only a stream of one chunk with\n\t\t// length of `chunkSize`\n\t\treturn super.slice(0, end - start);\n\t}\n}\n\nclass FileReader {\n\tasync openFile(input: Readable, _: number): Promise<StreamSource> {\n\t\t// @ts-expect-error\n\t\treturn new StreamSource(input);\n\t}\n}",
            "cost": 0.0949
        }
    },
    "recover_status": "success",
    "instance_ref": {
        "repo": "directus/directus",
        "instance_id": "directus__directus.pr_mirror.25883",
        "base_commit": "453d2ba2b3cf193369c3a569fe800d29424e2bd3",
        "patch": "diff --git a/.changeset/khaki-falcons-search.md b/.changeset/khaki-falcons-search.md\nnew file mode 100644\nindex 0000000000000..b9618267a4150\n--- /dev/null\n+++ b/.changeset/khaki-falcons-search.md\n@@ -0,0 +1,5 @@\n+---\n+'@directus/storage-driver-supabase': patch\n+---\n+\n+Fixed Supabase storage driver file uploads and improved error handling\n\\ No newline at end of file\ndiff --git a/packages/storage-driver-supabase/src/index.test.ts b/packages/storage-driver-supabase/src/index.test.ts\nindex be18fef576e1e..a039cd0c6cfe6 100644\n--- a/packages/storage-driver-supabase/src/index.test.ts\n+++ b/packages/storage-driver-supabase/src/index.test.ts\n@@ -1,23 +1,23 @@\n-import { StorageClient } from '@supabase/storage-js';\n import {\n \trandAlphaNumeric,\n \trandGitBranch as randBucket,\n \trandDirectoryPath,\n \trandDomainName,\n+\trandFileName,\n \trandFilePath,\n \trandFileType,\n \trandNumber,\n \trandPastDate,\n \trandText,\n \trandGitShortSha as randUnique,\n-\trandFileName,\n } from '@ngneat/falso';\n-import { Response, fetch } from 'undici';\n+import { StorageClient } from '@supabase/storage-js';\n import { Readable } from 'node:stream';\n+import { ReadableStream } from 'node:stream/web';\n+import { Response, fetch } from 'undici';\n import { afterEach, beforeEach, describe, expect, test, vi } from 'vitest';\n import type { DriverSupabaseConfig } from './index.js';\n import { DriverSupabase } from './index.js';\n-import { ReadableStream } from 'node:stream/web';\n \n vi.mock('@supabase/storage-js');\n vi.mock('undici');\n@@ -52,6 +52,7 @@ beforeEach(() => {\n \t\t\tprojectId: randAlphaNumeric({ length: 10 }).join(''),\n \t\t\troot: randUnique() + randDirectoryPath(),\n \t\t\tendpoint: randDomainName(),\n+\t\t\ttus: { chunkSize: 1024 * 1024 },\n \t\t},\n \t\tpath: {\n \t\t\tinput: randUnique() + randFilePath(),\n@@ -448,7 +449,7 @@ describe('#copy', () => {\n describe('#write', () => {\n \tbeforeEach(() => {\n \t\tdriver['bucket'] = {\n-\t\t\tupload: vi.fn(),\n+\t\t\tupload: vi.fn().mockResolvedValue({ data: null, error: null }),\n \t\t} as any;\n \t});\n \n@@ -480,6 +481,18 @@ describe('#write', () => {\n \t\t\tupsert: true,\n \t\t});\n \t});\n+\n+\ttest('Throws error when upload fails', async () => {\n+\t\tconst uploadError = new Error('Upload failed');\n+\n+\t\tdriver['bucket'] = {\n+\t\t\tupload: vi.fn().mockResolvedValue({ data: null, error: uploadError }),\n+\t\t} as any;\n+\n+\t\tawait expect(driver.write(sample.path.input, sample.stream)).rejects.toThrow(\n+\t\t\tnew Error(`Error uploading file \"${sample.path.input}\"`, { cause: uploadError }),\n+\t\t);\n+\t});\n });\n \n describe('#delete', () => {\ndiff --git a/packages/storage-driver-supabase/src/index.ts b/packages/storage-driver-supabase/src/index.ts\nindex 1d62117dd510b..8698bd3605134 100644\n--- a/packages/storage-driver-supabase/src/index.ts\n+++ b/packages/storage-driver-supabase/src/index.ts\n@@ -139,12 +139,16 @@ export class DriverSupabase implements TusDriver {\n \t}\n \n \tasync write(filepath: string, content: Readable, type?: string) {\n-\t\tawait this.bucket.upload(this.fullPath(filepath), content, {\n+\t\tconst { error } = await this.bucket.upload(this.fullPath(filepath), content, {\n \t\t\tcontentType: type ?? '',\n \t\t\tcacheControl: '3600',\n \t\t\tupsert: true,\n \t\t\tduplex: 'half',\n \t\t});\n+\n+\t\tif (error) {\n+\t\t\tthrow new Error(`Error uploading file \"${filepath}\"`, { cause: error });\n+\t\t}\n \t}\n \n \tasync delete(filepath: string) {\ndiff --git a/pnpm-lock.yaml b/pnpm-lock.yaml\nindex 92305e08028a8..790194ef92b0b 100644\n--- a/pnpm-lock.yaml\n+++ b/pnpm-lock.yaml\n@@ -190,8 +190,8 @@ catalogs:\n       specifier: 4.1.0\n       version: 4.1.0\n     '@supabase/storage-js':\n-      specifier: 2.10.4\n-      version: 2.10.4\n+      specifier: 2.12.1\n+      version: 2.12.1\n     '@tinymce/tinymce-vue':\n       specifier: 6.3.0\n       version: 6.3.0\n@@ -2638,7 +2638,7 @@ importers:\n         version: link:../utils\n       '@supabase/storage-js':\n         specifier: 'catalog:'\n-        version: 2.10.4\n+        version: 2.12.1\n       tus-js-client:\n         specifier: 'catalog:'\n         version: 4.3.1\n@@ -3805,12 +3805,21 @@ packages:\n   '@emnapi/core@1.4.5':\n     resolution: {integrity: sha512-XsLw1dEOpkSX/WucdqUhPWP7hDxSvZiY+fsUC14h+FtQ2Ifni4znbBt8punRX+Uj2JG/uDb8nEHVKvrVlvdZ5Q==}\n \n+  '@emnapi/core@1.5.0':\n+    resolution: {integrity: sha512-sbP8GzB1WDzacS8fgNPpHlp6C9VZe+SJP3F90W9rLemaQj2PzIuTEl1qDOYQf58YIpyjViI24y9aPWCjEzY2cg==}\n+\n   '@emnapi/runtime@1.4.5':\n     resolution: {integrity: sha512-++LApOtY0pEEz1zrd9vy1/zXVaVJJ/EbAF3u0fXIzPJEDtnITsBGbbK0EkM72amhl/R5b+5xx0Y/QhcVOpuulg==}\n \n+  '@emnapi/runtime@1.5.0':\n+    resolution: {integrity: sha512-97/BJ3iXHww3djw6hYIfErCZFee7qCtrneuLa20UXFCOTCfBM2cvQHjWJ2EG0s0MtdNwInarqCTz35i4wWXHsQ==}\n+\n   '@emnapi/wasi-threads@1.0.4':\n     resolution: {integrity: sha512-PJR+bOmMOPH8AtcTGAyYNiuJ3/Fcoj2XN/gBEWzDIKh254XO+mM9XoXHk5GNEhodxeMznbg7BlRojVbKN+gC6g==}\n \n+  '@emnapi/wasi-threads@1.1.0':\n+    resolution: {integrity: sha512-WI0DdZ8xFSbgMjR1sFsKABJ/C5OnRrjT06JXbZKexJGrDuPTzZdDYfFlsgcCXCyf+suG5QU2e/y1Wo2V/OapLQ==}\n+\n   '@esbuild/aix-ppc64@0.21.5':\n     resolution: {integrity: sha512-1SDgH6ZSPTlggy1yI6+Dbkiz8xzpHJEVAlF/AM1tHPLsf5STom9rwtjE4hKAF20FfXXNTFqEYXyJNWh1GiZedQ==}\n     engines: {node: '>=12'}\n@@ -4822,6 +4831,9 @@ packages:\n   '@napi-rs/wasm-runtime@1.0.3':\n     resolution: {integrity: sha512-rZxtMsLwjdXkMUGC3WwsPwLNVqVqnTJT6MNIB6e+5fhMcSCPP0AOsNWuMQ5mdCq6HNjs/ZeWAEchpqeprqBD2Q==}\n \n+  '@napi-rs/wasm-runtime@1.0.5':\n+    resolution: {integrity: sha512-TBr9Cf9onSAS2LQ2+QHx6XcC6h9+RIzJgbqG3++9TUZSH204AwEy5jg3BTQ0VATsyoGj4ee49tN/y6rvaOOtcg==}\n+\n   '@ngneat/falso@8.0.2':\n     resolution: {integrity: sha512-vhPtuoHoxE5JGWPSPBqEyTXcjI4MAn8GllR+Vs8FfpAQu2sQRd4PJc3e8kc9vdbdhYHx1C9HmbECgtGLK30z4w==}\n \n@@ -4887,15 +4899,11 @@ packages:\n     resolution: {integrity: sha512-3rzy1bJAZ4s7zV9TKT60x119RwJDCDqEtCwK/Zc2qlm7wGhiIUxLLYUhE/mN91yB0u1kxm5sh4NjU12sPqQTpg==}\n     engines: {node: '>=6.9.0'}\n \n-  '@oxc-project/runtime@0.87.0':\n-    resolution: {integrity: sha512-ky2Hqi2q/uGX36UfY79zxMbUqiNIl1RyKKVJfFenG70lbn+/fcaKBVTbhmUwn8a2wPyv2gNtDQxuDytbKX9giQ==}\n-    engines: {node: '>=6.9.0'}\n-\n   '@oxc-project/types@0.80.0':\n     resolution: {integrity: sha512-xxHQm8wfCv2e8EmtaDwpMeAHOWqgQDAYg+BJouLXSQt5oTKu9TIXrgNMGSrM2fLvKmECsRd9uUFAAD+hPyootA==}\n \n-  '@oxc-project/types@0.87.0':\n-    resolution: {integrity: sha512-ipZFWVGE9fADBVXXWJWY/cxpysc41Gt5upKDeb32F6WMgFyO7XETUMVq8UuREKCih+Km5E6p2VhEvf6Fuhey6g==}\n+  '@oxc-project/types@0.90.0':\n+    resolution: {integrity: sha512-fWvaufWUcLtm/OBKcNmxUkR0kQW5ZKAF0t03BXPqdzpxmnVCmSKzvUDRCOKnSagSfNzG/3ZdKpComH3GMy881g==}\n \n   '@paralleldrive/cuid2@2.2.2':\n     resolution: {integrity: sha512-ZOBkgDwEdoYVlSeRbYYXs0S9MejQofiVYoTbKzy/6GQa39/q5tQU2IX46+shYnUkpEl3wc+J6wRlar7r2EK2xA==}\n@@ -5461,8 +5469,8 @@ packages:\n     cpu: [arm64]\n     os: [android]\n \n-  '@rolldown/binding-android-arm64@1.0.0-beta.37':\n-    resolution: {integrity: sha512-Pdr3USGBdoYzcygfJTSATHd7x476vVF3rnQ6SuUAh4YjhgGoNaI/ZycQ0RsonptwwU5NmQRWxfWv+aUPL6JlJg==}\n+  '@rolldown/binding-android-arm64@1.0.0-beta.39':\n+    resolution: {integrity: sha512-mjraAJQ3VRLPb3BUgVigHvmAYhiBpEeSM0dhvaO6XHtJ0k1o9Ng1Z6Qvlp4/1wDiUf7a10L5c3yleoGZ2r0Maw==}\n     engines: {node: ^20.19.0 || >=22.12.0}\n     cpu: [arm64]\n     os: [android]\n@@ -5472,8 +5480,8 @@ packages:\n     cpu: [arm64]\n     os: [darwin]\n \n-  '@rolldown/binding-darwin-arm64@1.0.0-beta.37':\n-    resolution: {integrity: sha512-iDdmatSgbWhTYOq51G2CkJXwFayiuQpv/ywG7Bv3wKqy31L7d0LltUhWqAdfCl7eBG3gybfUm/iEXiTldH3jYA==}\n+  '@rolldown/binding-darwin-arm64@1.0.0-beta.39':\n+    resolution: {integrity: sha512-tnuiLq9vd08KsZeFkFgzCXVKsTgSZGn+YBQjHSEiUvXJy5pfUf82X/YyLCG8P6I+WDd2cgrcLilMBQPZgaNwkg==}\n     engines: {node: ^20.19.0 || >=22.12.0}\n     cpu: [arm64]\n     os: [darwin]\n@@ -5483,8 +5491,8 @@ packages:\n     cpu: [x64]\n     os: [darwin]\n \n-  '@rolldown/binding-darwin-x64@1.0.0-beta.37':\n-    resolution: {integrity: sha512-LQPpi3YJDtIprj6mwMbVM1gLM4BV2m9oqe9h3Y1UwAd20xs+imnzWJqWFpm4Hw9SiFmefIf3q4EPx2k6Nj2K7A==}\n+  '@rolldown/binding-darwin-x64@1.0.0-beta.39':\n+    resolution: {integrity: sha512-wLFoB3ZM4AoeBlsP0eVbPzWfkEgvmnibMQEKUgWRfJnKhUWiSxl0kGdSw1fNYdX3KAqIeA5gPJNvSJmf6g5S3Q==}\n     engines: {node: ^20.19.0 || >=22.12.0}\n     cpu: [x64]\n     os: [darwin]\n@@ -5494,8 +5502,8 @@ packages:\n     cpu: [x64]\n     os: [freebsd]\n \n-  '@rolldown/binding-freebsd-x64@1.0.0-beta.37':\n-    resolution: {integrity: sha512-9JnfSWfYd/YrZOu4Sj3rb2THBrCj70nJB/2FOSdg0O9ZoRrdTeB8b7Futo6N7HLWZM5uqqnJBX6VTpA0RZD+ow==}\n+  '@rolldown/binding-freebsd-x64@1.0.0-beta.39':\n+    resolution: {integrity: sha512-wzFZlixF9VMbyi++rHCU4Cy72SH11aBNnkadmvwTAbokwjYHi8NqxQ3/Lx00c700N6kwwuiTsbcGt5DEA9aROw==}\n     engines: {node: ^20.19.0 || >=22.12.0}\n     cpu: [x64]\n     os: [freebsd]\n@@ -5505,8 +5513,8 @@ packages:\n     cpu: [arm]\n     os: [linux]\n \n-  '@rolldown/binding-linux-arm-gnueabihf@1.0.0-beta.37':\n-    resolution: {integrity: sha512-eEmQTpvefEtHxc0vg5sOnWCqBcGQB/SIDlPkkzKR9ESKq9BsjQfHxssJWuNMyQ+rpr9CYaogddyQtZ9GHkp8vA==}\n+  '@rolldown/binding-linux-arm-gnueabihf@1.0.0-beta.39':\n+    resolution: {integrity: sha512-eVnZcwGbje1uwdFjeQZQ6918RHgGIK7iTC+AoDsgetgAXQmQpnuWYQ9OWa5oTHNQyCkZbMfiHKgpkUPpceMecw==}\n     engines: {node: ^20.19.0 || >=22.12.0}\n     cpu: [arm]\n     os: [linux]\n@@ -5516,8 +5524,8 @@ packages:\n     cpu: [arm64]\n     os: [linux]\n \n-  '@rolldown/binding-linux-arm64-gnu@1.0.0-beta.37':\n-    resolution: {integrity: sha512-Ekv4OjDzQUl0X9kHM7M23N9hVRiYCYr89neLBNITCp7P4IHs1f6SNZiCIvvBVy6NIFzO1w9LZJGEeJYK5cQBVQ==}\n+  '@rolldown/binding-linux-arm64-gnu@1.0.0-beta.39':\n+    resolution: {integrity: sha512-Td96iRQA0nmRZM6kJ3+LDDKWLh4bl0zqeR+IYxXwPZBw4iXSREzXrcZ3QqgFHqnXPgryIJEW1U1Ebh2xf+b2UA==}\n     engines: {node: ^20.19.0 || >=22.12.0}\n     cpu: [arm64]\n     os: [linux]\n@@ -5527,8 +5535,8 @@ packages:\n     cpu: [arm64]\n     os: [linux]\n \n-  '@rolldown/binding-linux-arm64-musl@1.0.0-beta.37':\n-    resolution: {integrity: sha512-z8Aa5Kar5mhh0RVZEL+zKJwNz1cgcDISmwUMcTk0w986T8JZJOJCfJ/u9e8pqUTIJjxdM8SZq9/24nMgMlx5ng==}\n+  '@rolldown/binding-linux-arm64-musl@1.0.0-beta.39':\n+    resolution: {integrity: sha512-bcSIh1TFUoPcexJH+gO1sE6wpSR0j3UpWBnjAwyM1PRKfjtqN4R9Du90ofH5KsR/A35FT3eP4mdnhMDTd5Yt+A==}\n     engines: {node: ^20.19.0 || >=22.12.0}\n     cpu: [arm64]\n     os: [linux]\n@@ -5543,8 +5551,8 @@ packages:\n     cpu: [x64]\n     os: [linux]\n \n-  '@rolldown/binding-linux-x64-gnu@1.0.0-beta.37':\n-    resolution: {integrity: sha512-e+fNseKhfE/socjOw6VrQcXrbNKfi2V/KZ+ssuLnmeaYNGuJWqPhvML56oYhGb3IgROEEc61lzr3Riy5BIqoMA==}\n+  '@rolldown/binding-linux-x64-gnu@1.0.0-beta.39':\n+    resolution: {integrity: sha512-tYEcZdVGovEemh7ELr+VUoezGkuBgRZYvDHHW/HVIw9LQW5HKLtBIGLzFlOfu/Lq5b9FlDKl+lrY6weviaNnKw==}\n     engines: {node: ^20.19.0 || >=22.12.0}\n     cpu: [x64]\n     os: [linux]\n@@ -5554,14 +5562,14 @@ packages:\n     cpu: [x64]\n     os: [linux]\n \n-  '@rolldown/binding-linux-x64-musl@1.0.0-beta.37':\n-    resolution: {integrity: sha512-dPZfB396PMIasd19X0ikpdCvjK/7SaJFO8y5/TxnozJEy70vOf4GESe/oKcsJPav/MSTWBYsHjJSO6vX0oAW8g==}\n+  '@rolldown/binding-linux-x64-musl@1.0.0-beta.39':\n+    resolution: {integrity: sha512-xf9QdMC+qwQxtFAty/9RxgCLFdp9pFl09g86hxGPzlzCtHUjd+BmeUnUTXvVC8CHJLWECLQbFP6/233XHG0blA==}\n     engines: {node: ^20.19.0 || >=22.12.0}\n     cpu: [x64]\n     os: [linux]\n \n-  '@rolldown/binding-openharmony-arm64@1.0.0-beta.37':\n-    resolution: {integrity: sha512-rFjLXoHpRqxJqkSBXHuyt6bhyiIFnvLD9X2iPmCYlfpEkdTbrY1AXg4ZbF8UMO5LM7DAAZm/7vPYPO1TKTA7Sg==}\n+  '@rolldown/binding-openharmony-arm64@1.0.0-beta.39':\n+    resolution: {integrity: sha512-QCvN02VpE6zFYry0zAU+29D5+O9tJELNt+OjuCubilZdD/S8xFdho7qBJaa3YhFYyA9cReOMVH8Z8b3yWb4hcA==}\n     engines: {node: ^20.19.0 || >=22.12.0}\n     cpu: [arm64]\n     os: [openharmony]\n@@ -5571,8 +5579,8 @@ packages:\n     engines: {node: '>=14.0.0'}\n     cpu: [wasm32]\n \n-  '@rolldown/binding-wasm32-wasi@1.0.0-beta.37':\n-    resolution: {integrity: sha512-oQAe3lMaBGX6q0GSic0l3Obmd6/rX8R6eHLnRC8kyy/CvPLiCMV82MPGT8fxpPTo/ULFGrupSu2nV1zmOFBt/w==}\n+  '@rolldown/binding-wasm32-wasi@1.0.0-beta.39':\n+    resolution: {integrity: sha512-LFgshxApyBNiBHFVpun7tPrIQ4TvxW0f/endC5C4RzEHu7mxexBCQEkO5XrZ42Cr5DUY+ERNbkfNTUv+vVCaxQ==}\n     engines: {node: '>=14.0.0'}\n     cpu: [wasm32]\n \n@@ -5581,8 +5589,8 @@ packages:\n     cpu: [arm64]\n     os: [win32]\n \n-  '@rolldown/binding-win32-arm64-msvc@1.0.0-beta.37':\n-    resolution: {integrity: sha512-ucO6CiZhpkNRiVAk7ybvA9pZaMreCtfHej3BtJcBL5S3aYmp4h0g6TvaXLD5YRJx5sXobp/9A//xU4wPMul3Bg==}\n+  '@rolldown/binding-win32-arm64-msvc@1.0.0-beta.39':\n+    resolution: {integrity: sha512-Mykirawg+s1e0uzVSEFhUBTShvXrOghPnyuLYkCfw8gzy8bMYiJuxsAfcopzZIIAVOHeSblJoiA/e7gYFjg8HA==}\n     engines: {node: ^20.19.0 || >=22.12.0}\n     cpu: [arm64]\n     os: [win32]\n@@ -5592,8 +5600,8 @@ packages:\n     cpu: [ia32]\n     os: [win32]\n \n-  '@rolldown/binding-win32-ia32-msvc@1.0.0-beta.37':\n-    resolution: {integrity: sha512-Ya9DBWJe1EGHwil7ielI8CdE0ELCg6KyDvDQqIFllnTJEYJ1Rb74DK6mvlZo273qz6Mw8WrMm26urfDeZhCc3Q==}\n+  '@rolldown/binding-win32-ia32-msvc@1.0.0-beta.39':\n+    resolution: {integrity: sha512-4PQJfWx7mdzXbAa4y+3OSSo911BZyJ/Is4pJKiwcGUqtvY66MX7BqlNWMr9QAozArAGE2knDubLqCQwZpK631w==}\n     engines: {node: ^20.19.0 || >=22.12.0}\n     cpu: [ia32]\n     os: [win32]\n@@ -5603,8 +5611,8 @@ packages:\n     cpu: [x64]\n     os: [win32]\n \n-  '@rolldown/binding-win32-x64-msvc@1.0.0-beta.37':\n-    resolution: {integrity: sha512-r+RI+wMReoTIF/uXqQWJcD8xGWXzCzUyGdpLmQ8FC+MCyPHlkjEsFRv8OFIYI6HhiGAmbfWVYEGf+aeLJzkHGw==}\n+  '@rolldown/binding-win32-x64-msvc@1.0.0-beta.39':\n+    resolution: {integrity: sha512-0zmmPOWbFfp1g9ofieimHwhuclZMcib0HL52Q+JTRpOHChI2f83TtH3duKWtAaxqhLUndTr/Z5sxzb+G2FNL9g==}\n     engines: {node: ^20.19.0 || >=22.12.0}\n     cpu: [x64]\n     os: [win32]\n@@ -5615,8 +5623,8 @@ packages:\n   '@rolldown/pluginutils@1.0.0-beta.31':\n     resolution: {integrity: sha512-IaDZ9NhjOIOkYtm+hH0GX33h3iVZ2OeSUnFF0+7Z4+1GuKs4Kj5wK3+I2zNV9IPLfqV4XlwWif8SXrZNutxciQ==}\n \n-  '@rolldown/pluginutils@1.0.0-beta.37':\n-    resolution: {integrity: sha512-0taU1HpxFzrukvWIhLRI4YssJX2wOW5q1MxPXWztltsQ13TE51/larZIwhFdpyk7+K43TH7x6GJ8oEqAo+vDbA==}\n+  '@rolldown/pluginutils@1.0.0-beta.39':\n+    resolution: {integrity: sha512-GkTtNCV8ObWbq3LrJStPBv9jkRPct8WlwotVjx3aU0RwfH3LyheixWK9Zhaj22C4EQj/TJxYyetoX+uOn/MWKw==}\n \n   '@rollup/plugin-alias@5.1.1':\n     resolution: {integrity: sha512-PR9zDb+rOzkRb2VD+EuKB7UC41vU5DIwZ5qqCpk0KJudcWAyi8rvYOhS7+L5aZCspw1stTViLgN5v6FF1p5cgQ==}\n@@ -6092,8 +6100,8 @@ packages:\n     resolution: {integrity: sha512-1ibVeYUacxWYi9i0cf5efil6adJ9WRyZBLivgjs+AUpewx1F3xPi7gLgaASI2SmIQxPoCEjAsLAzKPgMJVgOUQ==}\n     engines: {node: 4.x || >=6.0.0}\n \n-  '@supabase/storage-js@2.10.4':\n-    resolution: {integrity: sha512-cvL02GarJVFcNoWe36VBybQqTVRq6wQSOCvTS64C+eyuxOruFIm1utZAY0xi2qKtHJO3EjKaj8iWJKySusDmAQ==}\n+  '@supabase/storage-js@2.12.1':\n+    resolution: {integrity: sha512-QWg3HV6Db2J81VQx0PqLq0JDBn4Q8B1FYn1kYcbla8+d5WDmTdwwMr+EJAxNOSs9W4mhKMv+EYCpCrTFlTj4VQ==}\n \n   '@svgdotjs/svg.draggable.js@3.0.6':\n     resolution: {integrity: sha512-7iJFm9lL3C40HQcqzEfezK2l+dW2CpoVY3b77KQGqc8GXWa6LhhmX5Ckv7alQfUXBuZbjpICZ+Dvq1czlGx7gA==}\n@@ -6161,6 +6169,9 @@ packages:\n   '@tybys/wasm-util@0.10.0':\n     resolution: {integrity: sha512-VyyPYFlOMNylG45GoAe0xDoLwWuowvf92F9kySqzYh8vmYm7D2u4iUJKa1tOUpS70Ku13ASrOkS4ScXFsTaCNQ==}\n \n+  '@tybys/wasm-util@0.10.1':\n+    resolution: {integrity: sha512-9tTaPJLSiejZKx+Bmog4uSubteqTvFrVrURwkmHixBo0G4seD0zUxp98E1DzUBJxLQ3NPwXrGKDiVjwx/DpPsg==}\n+\n   '@types/argparse@1.0.38':\n     resolution: {integrity: sha512-ebDJ9b0e702Yr7pWgB0jzm+CX4Srzz8RcXtLJDJB+BSccqMa36uyH/zUsSYao5+BD1ytv3k3rPYCq4mAE1hsXA==}\n \n@@ -11566,8 +11577,8 @@ packages:\n     resolution: {integrity: sha512-M2Q+RfG0FMJeSW3RSFTbvtjGVTcQpTQvN247D0EMSsPkpZFoinopR9oAnQiwgogQyzDuvKNnbyCbQQlmNAzSoQ==}\n     hasBin: true\n \n-  rolldown@1.0.0-beta.37:\n-    resolution: {integrity: sha512-KiTU6z1kHGaLvqaYjgsrv2LshHqNBn74waRZivlK8WbfN1obZeScVkQPKYunB66E/mxZWv/zyZlCv3xF2t0WOQ==}\n+  rolldown@1.0.0-beta.39:\n+    resolution: {integrity: sha512-05bTT0CJU9dvCRC0Uc4zwB79W5N9MV9OG/Inyx8KNE2pSrrApJoWxEEArW6rmjx113HIx5IreCoTjzLfgvXTdg==}\n     engines: {node: ^20.19.0 || >=22.12.0}\n     hasBin: true\n \n@@ -15011,16 +15022,32 @@ snapshots:\n       tslib: 2.8.1\n     optional: true\n \n+  '@emnapi/core@1.5.0':\n+    dependencies:\n+      '@emnapi/wasi-threads': 1.1.0\n+      tslib: 2.8.1\n+    optional: true\n+\n   '@emnapi/runtime@1.4.5':\n     dependencies:\n       tslib: 2.8.1\n     optional: true\n \n+  '@emnapi/runtime@1.5.0':\n+    dependencies:\n+      tslib: 2.8.1\n+    optional: true\n+\n   '@emnapi/wasi-threads@1.0.4':\n     dependencies:\n       tslib: 2.8.1\n     optional: true\n \n+  '@emnapi/wasi-threads@1.1.0':\n+    dependencies:\n+      tslib: 2.8.1\n+    optional: true\n+\n   '@esbuild/aix-ppc64@0.21.5':\n     optional: true\n \n@@ -16021,6 +16048,13 @@ snapshots:\n       '@tybys/wasm-util': 0.10.0\n     optional: true\n \n+  '@napi-rs/wasm-runtime@1.0.5':\n+    dependencies:\n+      '@emnapi/core': 1.5.0\n+      '@emnapi/runtime': 1.5.0\n+      '@tybys/wasm-util': 0.10.1\n+    optional: true\n+\n   '@ngneat/falso@8.0.2':\n     dependencies:\n       seedrandom: 3.0.5\n@@ -16097,11 +16131,9 @@ snapshots:\n \n   '@oxc-project/runtime@0.80.0': {}\n \n-  '@oxc-project/runtime@0.87.0': {}\n-\n   '@oxc-project/types@0.80.0': {}\n \n-  '@oxc-project/types@0.87.0': {}\n+  '@oxc-project/types@0.90.0': {}\n \n   '@paralleldrive/cuid2@2.2.2':\n     dependencies:\n@@ -17173,43 +17205,43 @@ snapshots:\n   '@rolldown/binding-android-arm64@1.0.0-beta.31':\n     optional: true\n \n-  '@rolldown/binding-android-arm64@1.0.0-beta.37':\n+  '@rolldown/binding-android-arm64@1.0.0-beta.39':\n     optional: true\n \n   '@rolldown/binding-darwin-arm64@1.0.0-beta.31':\n     optional: true\n \n-  '@rolldown/binding-darwin-arm64@1.0.0-beta.37':\n+  '@rolldown/binding-darwin-arm64@1.0.0-beta.39':\n     optional: true\n \n   '@rolldown/binding-darwin-x64@1.0.0-beta.31':\n     optional: true\n \n-  '@rolldown/binding-darwin-x64@1.0.0-beta.37':\n+  '@rolldown/binding-darwin-x64@1.0.0-beta.39':\n     optional: true\n \n   '@rolldown/binding-freebsd-x64@1.0.0-beta.31':\n     optional: true\n \n-  '@rolldown/binding-freebsd-x64@1.0.0-beta.37':\n+  '@rolldown/binding-freebsd-x64@1.0.0-beta.39':\n     optional: true\n \n   '@rolldown/binding-linux-arm-gnueabihf@1.0.0-beta.31':\n     optional: true\n \n-  '@rolldown/binding-linux-arm-gnueabihf@1.0.0-beta.37':\n+  '@rolldown/binding-linux-arm-gnueabihf@1.0.0-beta.39':\n     optional: true\n \n   '@rolldown/binding-linux-arm64-gnu@1.0.0-beta.31':\n     optional: true\n \n-  '@rolldown/binding-linux-arm64-gnu@1.0.0-beta.37':\n+  '@rolldown/binding-linux-arm64-gnu@1.0.0-beta.39':\n     optional: true\n \n   '@rolldown/binding-linux-arm64-musl@1.0.0-beta.31':\n     optional: true\n \n-  '@rolldown/binding-linux-arm64-musl@1.0.0-beta.37':\n+  '@rolldown/binding-linux-arm64-musl@1.0.0-beta.39':\n     optional: true\n \n   '@rolldown/binding-linux-arm64-ohos@1.0.0-beta.31':\n@@ -17218,16 +17250,16 @@ snapshots:\n   '@rolldown/binding-linux-x64-gnu@1.0.0-beta.31':\n     optional: true\n \n-  '@rolldown/binding-linux-x64-gnu@1.0.0-beta.37':\n+  '@rolldown/binding-linux-x64-gnu@1.0.0-beta.39':\n     optional: true\n \n   '@rolldown/binding-linux-x64-musl@1.0.0-beta.31':\n     optional: true\n \n-  '@rolldown/binding-linux-x64-musl@1.0.0-beta.37':\n+  '@rolldown/binding-linux-x64-musl@1.0.0-beta.39':\n     optional: true\n \n-  '@rolldown/binding-openharmony-arm64@1.0.0-beta.37':\n+  '@rolldown/binding-openharmony-arm64@1.0.0-beta.39':\n     optional: true\n \n   '@rolldown/binding-wasm32-wasi@1.0.0-beta.31':\n@@ -17235,34 +17267,34 @@ snapshots:\n       '@napi-rs/wasm-runtime': 1.0.3\n     optional: true\n \n-  '@rolldown/binding-wasm32-wasi@1.0.0-beta.37':\n+  '@rolldown/binding-wasm32-wasi@1.0.0-beta.39':\n     dependencies:\n-      '@napi-rs/wasm-runtime': 1.0.3\n+      '@napi-rs/wasm-runtime': 1.0.5\n     optional: true\n \n   '@rolldown/binding-win32-arm64-msvc@1.0.0-beta.31':\n     optional: true\n \n-  '@rolldown/binding-win32-arm64-msvc@1.0.0-beta.37':\n+  '@rolldown/binding-win32-arm64-msvc@1.0.0-beta.39':\n     optional: true\n \n   '@rolldown/binding-win32-ia32-msvc@1.0.0-beta.31':\n     optional: true\n \n-  '@rolldown/binding-win32-ia32-msvc@1.0.0-beta.37':\n+  '@rolldown/binding-win32-ia32-msvc@1.0.0-beta.39':\n     optional: true\n \n   '@rolldown/binding-win32-x64-msvc@1.0.0-beta.31':\n     optional: true\n \n-  '@rolldown/binding-win32-x64-msvc@1.0.0-beta.37':\n+  '@rolldown/binding-win32-x64-msvc@1.0.0-beta.39':\n     optional: true\n \n   '@rolldown/pluginutils@1.0.0-beta.29': {}\n \n   '@rolldown/pluginutils@1.0.0-beta.31': {}\n \n-  '@rolldown/pluginutils@1.0.0-beta.37': {}\n+  '@rolldown/pluginutils@1.0.0-beta.39': {}\n \n   '@rollup/plugin-alias@5.1.1(rollup@4.46.2)':\n     optionalDependencies:\n@@ -17806,7 +17838,7 @@ snapshots:\n     dependencies:\n       whatwg-url: 5.0.0\n \n-  '@supabase/storage-js@2.10.4':\n+  '@supabase/storage-js@2.12.1':\n     dependencies:\n       '@supabase/node-fetch': 2.6.15\n \n@@ -17874,6 +17906,11 @@ snapshots:\n       tslib: 2.8.1\n     optional: true\n \n+  '@tybys/wasm-util@0.10.1':\n+    dependencies:\n+      tslib: 2.8.1\n+    optional: true\n+\n   '@types/argparse@1.0.38': {}\n \n   '@types/async@3.2.24': {}\n@@ -23736,7 +23773,7 @@ snapshots:\n       glob: 11.0.3\n       package-json-from-dist: 1.0.1\n \n-  rolldown-plugin-dts@0.15.9(rolldown@1.0.0-beta.37)(typescript@5.8.3)(vue-tsc@3.0.5(typescript@5.8.3)):\n+  rolldown-plugin-dts@0.15.9(rolldown@1.0.0-beta.39)(typescript@5.8.3)(vue-tsc@3.0.5(typescript@5.8.3)):\n     dependencies:\n       '@babel/generator': 7.28.3\n       '@babel/parser': 7.28.3\n@@ -23746,7 +23783,7 @@ snapshots:\n       debug: 4.4.1(supports-color@5.5.0)\n       dts-resolver: 2.1.2\n       get-tsconfig: 4.10.1\n-      rolldown: 1.0.0-beta.37\n+      rolldown: 1.0.0-beta.39\n     optionalDependencies:\n       typescript: 5.8.3\n       vue-tsc: 3.0.5(typescript@5.8.3)\n@@ -23776,27 +23813,26 @@ snapshots:\n       '@rolldown/binding-win32-ia32-msvc': 1.0.0-beta.31\n       '@rolldown/binding-win32-x64-msvc': 1.0.0-beta.31\n \n-  rolldown@1.0.0-beta.37:\n+  rolldown@1.0.0-beta.39:\n     dependencies:\n-      '@oxc-project/runtime': 0.87.0\n-      '@oxc-project/types': 0.87.0\n-      '@rolldown/pluginutils': 1.0.0-beta.37\n+      '@oxc-project/types': 0.90.0\n+      '@rolldown/pluginutils': 1.0.0-beta.39\n       ansis: 4.1.0\n     optionalDependencies:\n-      '@rolldown/binding-android-arm64': 1.0.0-beta.37\n-      '@rolldown/binding-darwin-arm64': 1.0.0-beta.37\n-      '@rolldown/binding-darwin-x64': 1.0.0-beta.37\n-      '@rolldown/binding-freebsd-x64': 1.0.0-beta.37\n-      '@rolldown/binding-linux-arm-gnueabihf': 1.0.0-beta.37\n-      '@rolldown/binding-linux-arm64-gnu': 1.0.0-beta.37\n-      '@rolldown/binding-linux-arm64-musl': 1.0.0-beta.37\n-      '@rolldown/binding-linux-x64-gnu': 1.0.0-beta.37\n-      '@rolldown/binding-linux-x64-musl': 1.0.0-beta.37\n-      '@rolldown/binding-openharmony-arm64': 1.0.0-beta.37\n-      '@rolldown/binding-wasm32-wasi': 1.0.0-beta.37\n-      '@rolldown/binding-win32-arm64-msvc': 1.0.0-beta.37\n-      '@rolldown/binding-win32-ia32-msvc': 1.0.0-beta.37\n-      '@rolldown/binding-win32-x64-msvc': 1.0.0-beta.37\n+      '@rolldown/binding-android-arm64': 1.0.0-beta.39\n+      '@rolldown/binding-darwin-arm64': 1.0.0-beta.39\n+      '@rolldown/binding-darwin-x64': 1.0.0-beta.39\n+      '@rolldown/binding-freebsd-x64': 1.0.0-beta.39\n+      '@rolldown/binding-linux-arm-gnueabihf': 1.0.0-beta.39\n+      '@rolldown/binding-linux-arm64-gnu': 1.0.0-beta.39\n+      '@rolldown/binding-linux-arm64-musl': 1.0.0-beta.39\n+      '@rolldown/binding-linux-x64-gnu': 1.0.0-beta.39\n+      '@rolldown/binding-linux-x64-musl': 1.0.0-beta.39\n+      '@rolldown/binding-openharmony-arm64': 1.0.0-beta.39\n+      '@rolldown/binding-wasm32-wasi': 1.0.0-beta.39\n+      '@rolldown/binding-win32-arm64-msvc': 1.0.0-beta.39\n+      '@rolldown/binding-win32-ia32-msvc': 1.0.0-beta.39\n+      '@rolldown/binding-win32-x64-msvc': 1.0.0-beta.39\n \n   rollup-plugin-esbuild@6.2.1(esbuild@0.25.9)(rollup@4.46.2):\n     dependencies:\n@@ -25012,8 +25048,8 @@ snapshots:\n       diff: 8.0.2\n       empathic: 2.0.0\n       hookable: 5.5.3\n-      rolldown: 1.0.0-beta.37\n-      rolldown-plugin-dts: 0.15.9(rolldown@1.0.0-beta.37)(typescript@5.8.3)(vue-tsc@3.0.5(typescript@5.8.3))\n+      rolldown: 1.0.0-beta.39\n+      rolldown-plugin-dts: 0.15.9(rolldown@1.0.0-beta.39)(typescript@5.8.3)(vue-tsc@3.0.5(typescript@5.8.3))\n       semver: 7.7.2\n       tinyexec: 1.0.1\n       tinyglobby: 0.2.14\ndiff --git a/pnpm-workspace.yaml b/pnpm-workspace.yaml\nindex d05e4bd7af234..8aadb08a24e75 100644\n--- a/pnpm-workspace.yaml\n+++ b/pnpm-workspace.yaml\n@@ -70,7 +70,7 @@ catalog:\n   '@sinclair/typebox': 0.34.38\n   '@sindresorhus/slugify': 2.2.1\n   '@smithy/node-http-handler': 4.1.0\n-  '@supabase/storage-js': 2.10.4\n+  '@supabase/storage-js': 2.12.1\n   '@tinymce/tinymce-vue': 6.3.0\n   '@turf/meta': 7.2.0\n   '@tus/server': 1.10.2\n",
        "test_patch": "",
        "problem_statement": "## Scope\r\n\r\nWhat's changed:\r\n\r\n- Upgraded @supabase/storage-js from 2.10.4 to 2.12.1 to fix Node.js duplex option compatibility issues\r\n- Added proper error handling in DriverSupabase.write() method to catch and throw upload failures\r\n\r\n## Potential Risks / Drawbacks\r\n\r\n- Upload errors that were previously silent will now throw exceptions\r\n- New Supabase storage library version may introduce unforeseen compatibility issues\r\n\r\n## Tested Scenarios\r\n\r\n- File upload with valid Supabase configuration - uploads succeed and filename_disk is properly populated\r\n- File upload without duplex: 'half' throws an error during upload and has been caught before the stat call function.\r\n\r\n## Review Notes / Questions\r\n\r\n- I would like to verify that the new Supabase library version doesn't break any existing functionality in production environments\r\n- Special attention should be paid to dolor sit amet\r\n\r\n## Checklist\r\n\r\n- [x] Added or updated tests\r\n- [ ] Documentation PR created [here](https://github.com/directus/docs) or not required\r\n\r\n---\r\n\r\nFixes #25871 \r\n",
        "hints_text": "",
        "created_at": "2025-09-23T19:41:30Z",
        "pull_number": 25883,
        "test_files": [
            "packages/storage-driver-supabase/src/index.test.ts"
        ],
        "code_files": [
            "packages/storage-driver-supabase/src/index.ts"
        ],
        "title": "Fix Supabase storage driver file uploads and improve error handling",
        "additions": 0,
        "deletions": 0,
        "pr_mirror": "directus__directus.447c91d0"
    }
}