{
    "cost": 0.41415,
    "rewrites": {
        "directus__directus.447c91d0/api/src/services/tus/data-store.ts": {
            "output": "import formatTitle from '@directus/format-title';\nimport type { TusDriver } from '@directus/storage';\nimport type { Accountability, ChunkedUploadContext, File, SchemaOverview } from '@directus/types';\nimport { extension } from 'mime-types';\nimport { extname } from 'node:path';\nimport stream from 'node:stream';\nimport { DataStore, ERRORS, Upload } from '@tus/utils';\nimport { ItemsService } from '../items.js';\nimport { useLogger } from '../../logger/index.js';\nimport getDatabase from '../../database/index.js';\nimport { omit } from 'lodash-es';\n\nexport type TusDataStoreConfig = {\n\tconstants: {\n\t\tENABLED: boolean;\n\t\tCHUNK_SIZE: number | null;\n\t\tMAX_SIZE: number | null;\n\t\tEXPIRATION_TIME: number;\n\t\tSCHEDULE: string;\n\t};\n\t/** Storage location name **/\n\tlocation: string;\n\tdriver: TusDriver;\n\n\tschema: SchemaOverview;\n\taccountability: Accountability | undefined;\n};\n\nexport class TusDataStore extends DataStore {\n\tprotected chunkSize: number | undefined;\n\tprotected maxSize: number | undefined;\n\tprotected expirationTime: number;\n\tprotected location: string;\n\tprotected storageDriver: TusDriver;\n\tprotected schema: SchemaOverview;\n\tprotected accountability: Accountability | undefined;\n\n\tconstructor(config: TusDataStoreConfig) {\n\t\tsuper();\n\n\t\tif (config.constants.CHUNK_SIZE !== null) this.chunkSize = config.constants.CHUNK_SIZE;\n\t\tif (config.constants.MAX_SIZE !== null) this.maxSize = config.constants.MAX_SIZE;\n\t\tthis.expirationTime = config.constants.EXPIRATION_TIME;\n\t\tthis.location = config.location;\n\t\tthis.storageDriver = config.driver;\n\t\tthis.extensions = this.storageDriver.tusExtensions;\n\t\tthis.schema = config.schema;\n\t\tthis.accountability = config.accountability;\n\t}\n\n\tpublic override async create(upload: Upload): Promise<Upload> {\n\t\tconst logger = useLogger();\n\t\tconst knex = getDatabase();\n\n\t\tconst filesItemsService = new ItemsService<File>('directus_files', {\n\t\t\taccountability: this.accountability,\n\t\t\tschema: this.schema,\n\t\t\tknex,\n\t\t});\n\n\t\tupload.creation_date = new Date().toISOString();\n\n\t\tif (!upload.size || !upload.metadata || !upload.metadata['filename_download']) {\n\t\t\tthrow ERRORS.INVALID_METADATA;\n\t\t}\n\n\t\tif (!upload.metadata['type']) {\n\t\t\tupload.metadata['type'] = 'application/octet-stream';\n\t\t}\n\n\t\tif (!upload.metadata['title']) {\n\t\t\tupload.metadata['title'] = formatTitle(upload.metadata['filename_download']);\n\t\t}\n\n\t\tlet existingFile: Record<string, any> | null = null;\n\n\t\t// If the payload contains a primary key, we'll check if the file already exists\n\t\tif (upload.metadata['id']) {\n\t\t\t// If the file you're uploading already exists, we'll consider this upload a replace so we'll fetch the existing file's folder and filename_download\n\t\t\texistingFile =\n\t\t\t\t(await knex\n\t\t\t\t\t.select('folder', 'filename_download', 'filename_disk', 'title', 'description', 'metadata', 'tus_id')\n\t\t\t\t\t.from('directus_files')\n\t\t\t\t\t.andWhere({ id: upload.metadata['id'] })\n\t\t\t\t\t.first()) ?? null;\n\n\t\t\tif (existingFile && existingFile['tus_id'] !== null) {\n\t\t\t\tthrow ERRORS.INVALID_METADATA;\n\t\t\t}\n\t\t}\n\n\t\t// Is this file a replacement? if the file data already exists and we have a primary key\n\t\tconst isReplacement = existingFile !== null && !!upload.metadata['id'];\n\n\t\tif (isReplacement === true && upload.metadata['id']) {\n\t\t\tupload.metadata['replace_id'] = upload.metadata['id'];\n\t\t}\n\n\t\tconst fileData: Partial<File> = {\n\t\t\t...omit(upload.metadata, ['id']),\n\t\t\ttus_id: upload.id,\n\t\t\ttus_data: upload,\n\t\t\tfilesize: upload.size,\n\t\t\tstorage: this.location,\n\t\t};\n\n\t\t// If no folder is specified, we'll use the default folder from the settings if it exists\n\t\tif ('folder' in fileData === false) {\n\t\t\tconst settings = await knex.select('storage_default_folder').from('directus_settings').first();\n\n\t\t\tif (settings?.storage_default_folder) {\n\t\t\t\tfileData.folder = settings.storage_default_folder;\n\t\t\t}\n\t\t}\n\n\t\t// If this is a new file upload, we need to generate a new primary key and DB record\n\t\tconst primaryKey = await filesItemsService.createOne(fileData, { emitEvents: false });\n\n\t\t// Set the file id, so it is available to be sent as a header on upload creation / resume\n\t\tif (!upload.metadata['id']) {\n\t\t\tupload.metadata['id'] = primaryKey as string;\n\t\t}\n\n\t\tconst fileExtension =\n\t\t\textname(upload.metadata['filename_download']) ||\n\t\t\t(upload.metadata['type'] && '.' + extension(upload.metadata['type'])) ||\n\t\t\t'';\n\n\t\t// The filename_disk is the FINAL filename on disk\n\t\tfileData.filename_disk ||= primaryKey + (fileExtension || '');\n\n\t\ttry {\n\t\t\t// If this is a replacement, we'll write the file to a temp location first to ensure we don't overwrite the existing file if something goes wrong\n\t\t\tupload = (await this.storageDriver.createChunkedUpload(fileData.filename_disk, upload)) as Upload;\n\n\t\t\tfileData.tus_data = upload;\n\n\t\t\tawait filesItemsService.updateOne(primaryKey!, fileData, { emitEvents: false });\n\n\t\t\treturn upload;\n\t\t} catch (err) {\n\t\t\tlogger.warn(`Couldn't create chunked upload for ${fileData.filename_disk}`);\n\t\t\tlogger.warn(err);\n\n\t\t\tif (isReplacement) {\n\t\t\t\tawait filesItemsService.updateOne(primaryKey!, { tus_id: null, tus_data: null }, { emitEvents: false });\n\t\t\t} else {\n\t\t\t\tawait filesItemsService.deleteOne(primaryKey!, { emitEvents: false });\n\t\t\t}\n\n\t\t\tthrow ERRORS.UNKNOWN_ERROR;\n\t\t}\n\t}\n\n\tpublic override async write(readable: stream.Readable, tus_id: string, offset: number): Promise<number> {\n\t\tconst logger = useLogger();\n\t\tconst fileData = await this.getFileById(tus_id);\n\t\tconst filePath = fileData.filename_disk!;\n\n\t\tconst sudoFilesItemsService = new ItemsService<File>('directus_files', {\n\t\t\tschema: this.schema,\n\t\t});\n\n\t\ttry {\n\t\t\tconst newOffset = await this.storageDriver.writeChunk(\n\t\t\t\tfilePath,\n\t\t\t\treadable,\n\t\t\t\toffset,\n\t\t\t\tfileData.tus_data as ChunkedUploadContext,\n\t\t\t);\n\n\t\t\tawait sudoFilesItemsService.updateOne(fileData.id!, {\n\t\t\t\ttus_data: {\n\t\t\t\t\t...fileData.tus_data,\n\t\t\t\t\toffset: newOffset,\n\t\t\t\t},\n\t\t\t});\n\n\t\t\tif (Number(fileData.filesize) === newOffset) {\n\t\t\t\ttry {\n\t\t\t\t\tawait this.storageDriver.finishChunkedUpload(filePath, fileData.tus_data as ChunkedUploadContext);\n\t\t\t\t} catch (err) {\n\t\t\t\t\tawait this.remove(fileData.tus_id!);\n\t\t\t\t\tthrow err;\n\t\t\t\t}\n\n\t\t\t\tconst isReplacement = Boolean(fileData.tus_data?.['metadata']?.['replace_id']);\n\n\t\t\t\t// If the file is a replacement, delete the old files, and upgrade the temp file\n\t\t\t\tif (isReplacement === true) {\n\t\t\t\t\tconst replaceId = fileData.tus_data!['metadata']!['replace_id'] as string;\n\t\t\t\t\tconst replaceData = await sudoFilesItemsService.readOne(replaceId, { fields: ['filename_disk'] });\n\n\t\t\t\t\t// delete the previously saved file and thumbnails to ensure they're generated fresh\n\t\t\t\t\tfor await (const partPath of this.storageDriver.list(replaceId)) {\n\t\t\t\t\t\tawait this.storageDriver.delete(partPath);\n\t\t\t\t\t}\n\n\t\t\t\t\t// Upgrade the temp file to the final filename\n\t\t\t\t\tawait this.storageDriver.move(filePath, replaceData.filename_disk);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\treturn newOffset;\n\t\t} catch (err: any) {\n\t\t\tlogger.error(err, 'Error writing chunk for upload \"%s\" at offset %d', tus_id, offset);\n\n\t\t\tif ('status_code' in err && err.status_code === 500) {\n\t\t\t\tthrow err;\n\t\t\t}\n\n\t\t\tthrow ERRORS.FILE_WRITE_ERROR;\n\t\t}\n\t}\n\n\toverride async remove(tus_id: string): Promise<void> {\n\t\tconst sudoFilesItemsService = new ItemsService<File>('directus_files', {\n\t\t\tschema: this.schema,\n\t\t});\n\n\t\tconst fileData = await this.getFileById(tus_id);\n\t\tawait this.storageDriver.deleteChunkedUpload(fileData.filename_disk!, fileData.tus_data as ChunkedUploadContext);\n\t\tawait sudoFilesItemsService.deleteOne(fileData.id!);\n\t}\n\n\toverride async deleteExpired(): Promise<number> {\n\t\tconst sudoFilesItemsService = new ItemsService<File>('directus_files', {\n\t\t\tschema: this.schema,\n\t\t});\n\n\t\tconst now = new Date();\n\t\tconst toDelete: Promise<void>[] = [];\n\n\t\tconst uploadFiles = await sudoFilesItemsService.readByQuery({\n\t\t\tfields: ['modified_on', 'tus_id', 'tus_data'],\n\t\t\tfilter: { tus_id: { _nnull: true } },\n\t\t});\n\n\t\tif (!uploadFiles) return 0;\n\n\t\tfor (const fileData of uploadFiles) {\n\t\t\tif (\n\t\t\t\tfileData &&\n\t\t\t\tfileData.tus_data &&\n\t\t\t\tthis.getExpiration() > 0 &&\n\t\t\t\tfileData.tus_data['size'] !== fileData.tus_data['offset'] &&\n\t\t\t\tfileData.modified_on\n\t\t\t) {\n\t\t\t\tconst modified = new Date(fileData.modified_on);\n\t\t\t\tconst expires = new Date(modified.getTime() + this.getExpiration());\n\n\t\t\t\tif (now > expires) {\n\t\t\t\t\ttoDelete.push(this.remove(fileData.tus_id!));\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tawait Promise.allSettled(toDelete);\n\t\treturn toDelete.length;\n\t}\n\n\toverride getExpiration(): number {\n\t\treturn this.expirationTime;\n\t}\n\n\toverride async getUpload(id: string): Promise<Upload> {\n\t\tconst fileData = await this.getFileById(id);\n\n\t\treturn new Upload(fileData.tus_data as any);\n\t}\n\n\tprotected async getFileById(tus_id: string) {\n\t\tconst sudoFilesItemsService = new ItemsService<File>('directus_files', {\n\t\t\tschema: this.schema,\n\t\t});\n\n\t\tconst results = await sudoFilesItemsService.readByQuery({\n\t\t\tfilter: {\n\t\t\t\ttus_id: { _eq: tus_id },\n\t\t\t\tstorage: { _eq: this.location },\n\t\t\t\t...(this.accountability?.user ? { uploaded_by: { _eq: this.accountability.user } } : {}),\n\t\t\t},\n\t\t});\n\n\t\tif (!results || !results[0]) {\n\t\t\tthrow ERRORS.FILE_NOT_FOUND;\n\t\t}\n\n\t\treturn results[0] as File;\n\t}\n}",
            "output_extracted": "import formatTitle from '@directus/format-title';\nimport type { TusDriver } from '@directus/storage';\nimport type { Accountability, ChunkedUploadContext, File, SchemaOverview } from '@directus/types';\nimport { extension } from 'mime-types';\nimport { extname } from 'node:path';\nimport stream from 'node:stream';\nimport { DataStore, ERRORS, Upload } from '@tus/utils';\nimport { ItemsService } from '../items.js';\nimport { useLogger } from '../../logger/index.js';\nimport getDatabase from '../../database/index.js';\nimport { omit } from 'lodash-es';\n\nexport type TusDataStoreConfig = {\n\tconstants: {\n\t\tENABLED: boolean;\n\t\tCHUNK_SIZE: number | null;\n\t\tMAX_SIZE: number | null;\n\t\tEXPIRATION_TIME: number;\n\t\tSCHEDULE: string;\n\t};\n\t/** Storage location name **/\n\tlocation: string;\n\tdriver: TusDriver;\n\n\tschema: SchemaOverview;\n\taccountability: Accountability | undefined;\n};\n\nexport class TusDataStore extends DataStore {\n\tprotected chunkSize: number | undefined;\n\tprotected maxSize: number | undefined;\n\tprotected expirationTime: number;\n\tprotected location: string;\n\tprotected storageDriver: TusDriver;\n\tprotected schema: SchemaOverview;\n\tprotected accountability: Accountability | undefined;\n\n\tconstructor(config: TusDataStoreConfig) {\n\t\tsuper();\n\n\t\tif (config.constants.CHUNK_SIZE !== null) this.chunkSize = config.constants.CHUNK_SIZE;\n\t\tif (config.constants.MAX_SIZE !== null) this.maxSize = config.constants.MAX_SIZE;\n\t\tthis.expirationTime = config.constants.EXPIRATION_TIME;\n\t\tthis.location = config.location;\n\t\tthis.storageDriver = config.driver;\n\t\tthis.extensions = this.storageDriver.tusExtensions;\n\t\tthis.schema = config.schema;\n\t\tthis.accountability = config.accountability;\n\t}\n\n\tpublic override async create(upload: Upload): Promise<Upload> {\n\t\tconst logger = useLogger();\n\t\tconst knex = getDatabase();\n\n\t\tconst filesItemsService = new ItemsService<File>('directus_files', {\n\t\t\taccountability: this.accountability,\n\t\t\tschema: this.schema,\n\t\t\tknex,\n\t\t});\n\n\t\tupload.creation_date = new Date().toISOString();\n\n\t\tif (!upload.size || !upload.metadata || !upload.metadata['filename_download']) {\n\t\t\tthrow ERRORS.INVALID_METADATA;\n\t\t}\n\n\t\tif (!upload.metadata['type']) {\n\t\t\tupload.metadata['type'] = 'application/octet-stream';\n\t\t}\n\n\t\tif (!upload.metadata['title']) {\n\t\t\tupload.metadata['title'] = formatTitle(upload.metadata['filename_download']);\n\t\t}\n\n\t\tlet existingFile: Record<string, any> | null = null;\n\n\t\t// If the payload contains a primary key, we'll check if the file already exists\n\t\tif (upload.metadata['id']) {\n\t\t\t// If the file you're uploading already exists, we'll consider this upload a replace so we'll fetch the existing file's folder and filename_download\n\t\t\texistingFile =\n\t\t\t\t(await knex\n\t\t\t\t\t.select('folder', 'filename_download', 'filename_disk', 'title', 'description', 'metadata', 'tus_id')\n\t\t\t\t\t.from('directus_files')\n\t\t\t\t\t.andWhere({ id: upload.metadata['id'] })\n\t\t\t\t\t.first()) ?? null;\n\n\t\t\tif (existingFile && existingFile['tus_id'] !== null) {\n\t\t\t\tthrow ERRORS.INVALID_METADATA;\n\t\t\t}\n\t\t}\n\n\t\t// Is this file a replacement? if the file data already exists and we have a primary key\n\t\tconst isReplacement = existingFile !== null && !!upload.metadata['id'];\n\n\t\tif (isReplacement === true && upload.metadata['id']) {\n\t\t\tupload.metadata['replace_id'] = upload.metadata['id'];\n\t\t}\n\n\t\tconst fileData: Partial<File> = {\n\t\t\t...omit(upload.metadata, ['id']),\n\t\t\ttus_id: upload.id,\n\t\t\ttus_data: upload,\n\t\t\tfilesize: upload.size,\n\t\t\tstorage: this.location,\n\t\t};\n\n\t\t// If no folder is specified, we'll use the default folder from the settings if it exists\n\t\tif ('folder' in fileData === false) {\n\t\t\tconst settings = await knex.select('storage_default_folder').from('directus_settings').first();\n\n\t\t\tif (settings?.storage_default_folder) {\n\t\t\t\tfileData.folder = settings.storage_default_folder;\n\t\t\t}\n\t\t}\n\n\t\t// If this is a new file upload, we need to generate a new primary key and DB record\n\t\tconst primaryKey = await filesItemsService.createOne(fileData, { emitEvents: false });\n\n\t\t// Set the file id, so it is available to be sent as a header on upload creation / resume\n\t\tif (!upload.metadata['id']) {\n\t\t\tupload.metadata['id'] = primaryKey as string;\n\t\t}\n\n\t\tconst fileExtension =\n\t\t\textname(upload.metadata['filename_download']) ||\n\t\t\t(upload.metadata['type'] && '.' + extension(upload.metadata['type'])) ||\n\t\t\t'';\n\n\t\t// The filename_disk is the FINAL filename on disk\n\t\tfileData.filename_disk ||= primaryKey + (fileExtension || '');\n\n\t\ttry {\n\t\t\t// If this is a replacement, we'll write the file to a temp location first to ensure we don't overwrite the existing file if something goes wrong\n\t\t\tupload = (await this.storageDriver.createChunkedUpload(fileData.filename_disk, upload)) as Upload;\n\n\t\t\tfileData.tus_data = upload;\n\n\t\t\tawait filesItemsService.updateOne(primaryKey!, fileData, { emitEvents: false });\n\n\t\t\treturn upload;\n\t\t} catch (err) {\n\t\t\tlogger.warn(`Couldn't create chunked upload for ${fileData.filename_disk}`);\n\t\t\tlogger.warn(err);\n\n\t\t\tif (isReplacement) {\n\t\t\t\tawait filesItemsService.updateOne(primaryKey!, { tus_id: null, tus_data: null }, { emitEvents: false });\n\t\t\t} else {\n\t\t\t\tawait filesItemsService.deleteOne(primaryKey!, { emitEvents: false });\n\t\t\t}\n\n\t\t\tthrow ERRORS.UNKNOWN_ERROR;\n\t\t}\n\t}\n\n\tpublic override async write(readable: stream.Readable, tus_id: string, offset: number): Promise<number> {\n\t\tconst logger = useLogger();\n\t\tconst fileData = await this.getFileById(tus_id);\n\t\tconst filePath = fileData.filename_disk!;\n\n\t\tconst sudoFilesItemsService = new ItemsService<File>('directus_files', {\n\t\t\tschema: this.schema,\n\t\t});\n\n\t\ttry {\n\t\t\tconst newOffset = await this.storageDriver.writeChunk(\n\t\t\t\tfilePath,\n\t\t\t\treadable,\n\t\t\t\toffset,\n\t\t\t\tfileData.tus_data as ChunkedUploadContext,\n\t\t\t);\n\n\t\t\tawait sudoFilesItemsService.updateOne(fileData.id!, {\n\t\t\t\ttus_data: {\n\t\t\t\t\t...fileData.tus_data,\n\t\t\t\t\toffset: newOffset,\n\t\t\t\t},\n\t\t\t});\n\n\t\t\tif (Number(fileData.filesize) === newOffset) {\n\t\t\t\ttry {\n\t\t\t\t\tawait this.storageDriver.finishChunkedUpload(filePath, fileData.tus_data as ChunkedUploadContext);\n\t\t\t\t} catch (err) {\n\t\t\t\t\tawait this.remove(fileData.tus_id!);\n\t\t\t\t\tthrow err;\n\t\t\t\t}\n\n\t\t\t\tconst isReplacement = Boolean(fileData.tus_data?.['metadata']?.['replace_id']);\n\n\t\t\t\t// If the file is a replacement, delete the old files, and upgrade the temp file\n\t\t\t\tif (isReplacement === true) {\n\t\t\t\t\tconst replaceId = fileData.tus_data!['metadata']!['replace_id'] as string;\n\t\t\t\t\tconst replaceData = await sudoFilesItemsService.readOne(replaceId, { fields: ['filename_disk'] });\n\n\t\t\t\t\t// delete the previously saved file and thumbnails to ensure they're generated fresh\n\t\t\t\t\tfor await (const partPath of this.storageDriver.list(replaceId)) {\n\t\t\t\t\t\tawait this.storageDriver.delete(partPath);\n\t\t\t\t\t}\n\n\t\t\t\t\t// Upgrade the temp file to the final filename\n\t\t\t\t\tawait this.storageDriver.move(filePath, replaceData.filename_disk);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\treturn newOffset;\n\t\t} catch (err: any) {\n\t\t\tlogger.error(err, 'Error writing chunk for upload \"%s\" at offset %d', tus_id, offset);\n\n\t\t\tif ('status_code' in err && err.status_code === 500) {\n\t\t\t\tthrow err;\n\t\t\t}\n\n\t\t\tthrow ERRORS.FILE_WRITE_ERROR;\n\t\t}\n\t}\n\n\toverride async remove(tus_id: string): Promise<void> {\n\t\tconst sudoFilesItemsService = new ItemsService<File>('directus_files', {\n\t\t\tschema: this.schema,\n\t\t});\n\n\t\tconst fileData = await this.getFileById(tus_id);\n\t\tawait this.storageDriver.deleteChunkedUpload(fileData.filename_disk!, fileData.tus_data as ChunkedUploadContext);\n\t\tawait sudoFilesItemsService.deleteOne(fileData.id!);\n\t}\n\n\toverride async deleteExpired(): Promise<number> {\n\t\tconst sudoFilesItemsService = new ItemsService<File>('directus_files', {\n\t\t\tschema: this.schema,\n\t\t});\n\n\t\tconst now = new Date();\n\t\tconst toDelete: Promise<void>[] = [];\n\n\t\tconst uploadFiles = await sudoFilesItemsService.readByQuery({\n\t\t\tfields: ['modified_on', 'tus_id', 'tus_data'],\n\t\t\tfilter: { tus_id: { _nnull: true } },\n\t\t});\n\n\t\tif (!uploadFiles) return 0;\n\n\t\tfor (const fileData of uploadFiles) {\n\t\t\tif (\n\t\t\t\tfileData &&\n\t\t\t\tfileData.tus_data &&\n\t\t\t\tthis.getExpiration() > 0 &&\n\t\t\t\tfileData.tus_data['size'] !== fileData.tus_data['offset'] &&\n\t\t\t\tfileData.modified_on\n\t\t\t) {\n\t\t\t\tconst modified = new Date(fileData.modified_on);\n\t\t\t\tconst expires = new Date(modified.getTime() + this.getExpiration());\n\n\t\t\t\tif (now > expires) {\n\t\t\t\t\ttoDelete.push(this.remove(fileData.tus_id!));\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tawait Promise.allSettled(toDelete);\n\t\treturn toDelete.length;\n\t}\n\n\toverride getExpiration(): number {\n\t\treturn this.expirationTime;\n\t}\n\n\toverride async getUpload(id: string): Promise<Upload> {\n\t\tconst fileData = await this.getFileById(id);\n\n\t\treturn new Upload(fileData.tus_data as any);\n\t}\n\n\tprotected async getFileById(tus_id: string) {\n\t\tconst sudoFilesItemsService = new ItemsService<File>('directus_files', {\n\t\t\tschema: this.schema,\n\t\t});\n\n\t\tconst results = await sudoFilesItemsService.readByQuery({\n\t\t\tfilter: {\n\t\t\t\ttus_id: { _eq: tus_id },\n\t\t\t\tstorage: { _eq: this.location },\n\t\t\t\t...(this.accountability?.user ? { uploaded_by: { _eq: this.accountability.user } } : {}),\n\t\t\t},\n\t\t});\n\n\t\tif (!results || !results[0]) {\n\t\t\tthrow ERRORS.FILE_NOT_FOUND;\n\t\t}\n\n\t\treturn results[0] as File;\n\t}\n}",
            "cost": 0.09267
        },
        "directus__directus.447c91d0/tests/blackbox/common/config.ts": {
            "output": "import { Knex } from 'knex';\nimport { dirname, join } from 'node:path';\nimport { fileURLToPath } from 'node:url';\nimport { allVendors, type Vendor } from './get-dbs-to-test';\n\nconst __dirname = dirname(fileURLToPath(import.meta.url));\n\nexport type Env = Record<\n\tVendor,\n\t{\n\t\tDB_CLIENT: string;\n\t\tPORT: string;\n\t\t[key: string]: string;\n\t}\n>;\nexport type Config = {\n\tknexConfig: Record<Vendor, Knex.Config & { waitTestSQL: string }>;\n\tnames: Record<Vendor, string>;\n\tenvs: Env;\n};\n\nexport const paths = {\n\tcli: join(__dirname, '..', '..', '..', 'dist', 'cli'),\n\tcwd: join(__dirname, '..'),\n};\n\nconst migrationsDir = './setup/migrations';\nconst seedsDir = './setup/seeds';\n\nconst knexConfig = {\n\twaitTestSQL: 'SELECT 1',\n\tmigrations: {\n\t\tdirectory: migrationsDir,\n\t},\n\tseeds: {\n\t\tdirectory: seedsDir,\n\t},\n};\n\nconst allowedLogLevels = ['trace', 'debug', 'info', 'warn', 'error', 'fatal'];\n\nlet logLevel = 'error';\n\nif (process.env['TEST_SAVE_LOGS']) {\n\tlogLevel = allowedLogLevels.includes(process.env['TEST_SAVE_LOGS']) ? process.env['TEST_SAVE_LOGS'] : 'info';\n}\n\nconst directusAuthConfig = {\n\tAUTH_PROVIDERS: 'saml',\n\tAUTH_SAML_DRIVER: 'saml',\n\tAUTH_SAML_ALLOW_PUBLIC_REGISTRATION: 'true',\n\tAUTH_SAML_SP_metadata:\n\t\t'<md:EntityDescriptor xmlns:md=\"urn:oasis:names:tc:SAML:2.0:metadata\" xmlns:saml=\"urn:oasis:names:tc:SAML:2.0:assertion\" xmlns:ds=\"http://www.w3.org/2000/09/xmldsig#\" entityID=\"saml-test\"><md:SPSSODescriptor WantAssertionsSigned=\"true\" protocolSupportEnumeration=\"urn:oasis:names:tc:SAML:2.0:protocol\"><md:KeyDescriptor use=\"signing\"><ds:KeyInfo xmlns:ds=\"http://www.w3.org/2000/09/xmldsig#\"><ds:X509Data><ds:X509Certificate>MIIDDTCCAfWgAwIBAgIJQC7RaeKX30qDMA0GCSqGSIb3DQEBCwUAMCQxIjAgBgNVBAMTGWRldi1md3h5bWRvMC51cy5hdXRoMC5jb20wHhcNMjIwODE5MjA1OTEwWhcNMzYwNDI3MjA1OTEwWjAkMSIwIAYDVQQDExlkZXYtZnd4eW1kbzAudXMuYXV0aDAuY29tMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA0TN0Doc8qop69i0bgGuynPQpJRat17xlsbphSWCnACc6DYbFBQ3n+cft8AiTzI7VISLazwlWOp30zhTMwZlrXMo1flG9qJl/2T+BLohRMw0ScCQk8Aq1cWRzZLb4Oku6PdefHrpsg6Wjn87m6R2Yrhmz33Vq2QYRwNsKhWRhhB2ajpMj8GsvFKG0FGPD/AJ1bGXcdsMOaQZxIiZ3Xcy9Ng8jAHvE12sIH8w14pmIidO15XFjlvtpNTxSl0qV0lmzKM0nN4EqlK0vTy4NwFk3xR/UmgQo5tYzqvRBqfzRO7vpOwbp1SWQ/c8JlI1ulLzt1uJzfvWsp8MSD/QRhxg93QIDAQABo0IwQDAPBgNVHRMBAf8EBTADAQH/MB0GA1UdDgQWBBT60jtXFsHPoyL42prgUG7wQTaWcTAOBgNVHQ8BAf8EBAMCAoQwDQYJKoZIhvcNAQELBQADggEBAKFLvyUbywoLYLOtsgHv9S2qingx2Q2jmYChqj4CQxPaWRpS/qBaZXnjVETZrMFDjf8HyMf2qn9uwKvtJehfPXpG8D+VuZWfsriTn94pXuELbiekHZ0Qlo1acbjUwyIeKoMNMk7wjGe8qb4gar6noT6PvAbyv1uzzkdyIUmQDzSS/ZOdRW0cwHG6oD/PdzKOPZxUZtQcq23Y/hbK/JpDiKtt1oO/svpd6tMmi6VezVB47gvUqEKMB3B5PI2Rdn+lA9tFPY2tfZtzOPaT5YQJkpp7tAWdMaUir+M8BhY8EjgtK1ZhJ7h2pW+UuOwkNsikgbf9EoUvDDZak65rXNqCCpQ=</ds:X509Certificate></ds:X509Data></ds:KeyInfo></md:KeyDescriptor><md:NameIDFormat>urn:oasis:names:tc:SAML:1.1:nameid-format:emailAddress</md:NameIDFormat><md:AssertionConsumerService isDefault=\"true\" index=\"0\" Binding=\"urn:oasis:names:tc:SAML:2.0:bindings:HTTP-POST\" Location=\"http://host.docker.internal:8055/auth/login/saml/acs\" /></md:SPSSODescriptor></md:EntityDescriptor>',\n\tAUTH_SAML_IDP_metadata:\n\t\t'<md:EntityDescriptor xmlns:md=\"urn:oasis:names:tc:SAML:2.0:metadata\" xmlns:ds=\"http://www.w3.org/2000/09/xmldsig#\" entityID=\"http://127.0.0.1:8880/simplesaml/saml2/idp/metadata.php\"><md:IDPSSODescriptor protocolSupportEnumeration=\"urn:oasis:names:tc:SAML:2.0:protocol\"><md:KeyDescriptor use=\"signing\"><ds:KeyInfo xmlns:ds=\"http://www.w3.org/2000/09/xmldsig#\"><ds:X509Data><ds:X509Certificate>MIIDXTCCAkWgAwIBAgIJALmVVuDWu4NYMA0GCSqGSIb3DQEBCwUAMEUxCzAJBgNVBAYTAkFVMRMwEQYDVQQIDApTb21lLVN0YXRlMSEwHwYDVQQKDBhJbnRlcm5ldCBXaWRnaXRzIFB0eSBMdGQwHhcNMTYxMjMxMTQzNDQ3WhcNNDgwNjI1MTQzNDQ3WjBFMQswCQYDVQQGEwJBVTETMBEGA1UECAwKU29tZS1TdGF0ZTEhMB8GA1UECgwYSW50ZXJuZXQgV2lkZ2l0cyBQdHkgTHRkMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAzUCFozgNb1h1M0jzNRSCjhOBnR+uVbVpaWfXYIR+AhWDdEe5ryY+CgavOg8bfLybyzFdehlYdDRgkedEB/GjG8aJw06l0qF4jDOAw0kEygWCu2mcH7XOxRt+YAH3TVHa/Hu1W3WjzkobqqqLQ8gkKWWM27fOgAZ6GieaJBN6VBSMMcPey3HWLBmc+TYJmv1dbaO2jHhKh8pfKw0W12VM8P1PIO8gv4Phu/uuJYieBWKixBEyy0lHjyixYFCR12xdh4CA47q958ZRGnnDUGFVE1QhgRacJCOZ9bd5t9mr8KLaVBYTCJo5ERE8jymab5dPqe5qKfJsCZiqWglbjUo9twIDAQABo1AwTjAdBgNVHQ4EFgQUxpuwcs/CYQOyui+r1G+3KxBNhxkwHwYDVR0jBBgwFoAUxpuwcs/CYQOyui+r1G+3KxBNhxkwDAYDVR0TBAUwAwEB/zANBgkqhkiG9w0BAQsFAAOCAQEAAiWUKs/2x/viNCKi3Y6blEuCtAGhzOOZ9EjrvJ8+COH3Rag3tVBWrcBZ3/uhhPq5gy9lqw4OkvEws99/5jFsX1FJ6MKBgqfuy7yh5s1YfM0ANHYczMmYpZeAcQf2CGAaVfwTTfSlzNLsF2lW/ly7yapFzlYSJLGoVE+OHEu8g5SlNACUEfkXw+5Eghh+KzlIN7R6Q7r2ixWNFBC/jWf7NKUfJyX8qIG5md1YUeT6GBW9Bm2/1/RiO24JTaYlfLdKK9TYb8sG5B+OLab2DImG99CJ25RkAcSobWNF5zD0O6lgOo3cEdB/ksCq3hmtlC/DlLZ/D8CJ+7VuZnS1rR2naQ==</ds:X509Certificate></ds:X509Data></ds:KeyInfo></md:KeyDescriptor><md:SingleLogoutService Binding=\"urn:oasis:names:tc:SAML:2.0:bindings:HTTP-Redirect\" Location=\"http://127.0.0.1:8880/simplesaml/saml2/idp/SingleLogoutService.php\" /><md:NameIDFormat>urn:oasis:names:tc:SAML:2.0:nameid-format:transient</md:NameIDFormat><md:SingleSignOnService Binding=\"urn:oasis:names:tc:SAML:2.0:bindings:HTTP-Redirect\" Location=\"http://127.0.0.1:8880/simplesaml/saml2/idp/SSOService.php\" /></md:IDPSSODescriptor></md:EntityDescriptor>',\n\tAUTH_SAML_DEFAULT_ROLE_ID: 'd70c0943-5b55-4c5d-a613-f539a27a57f5',\n\tAUTH_SAML_IDENTIFIER_KEY: 'uid',\n\tAUTH_SAML_EMAIL_KEY: 'email',\n};\n\nconst directusStorageConfig = {\n\tSTORAGE_LOCATIONS: 'local,minio',\n\tSTORAGE_MINIO_DRIVER: 's3',\n\tSTORAGE_MINIO_KEY: 'directus',\n\tSTORAGE_MINIO_SECRET: 'miniosecret',\n\tSTORAGE_MINIO_BUCKET: 'directus-blackbox-test',\n\tSTORAGE_MINIO_REGION: 'us-east-1',\n\tSTORAGE_MINIO_ENDPOINT: 'http://127.0.0.1:8881',\n\tSTORAGE_MINIO_FORCE_PATH_STYLE: 'true',\n};\n\nconst directusConfig = {\n\t...process.env,\n\tADMIN_EMAIL: 'admin@example.com',\n\tADMIN_PASSWORD: 'password',\n\tSECRET: 'directus-test',\n\tTELEMETRY: 'false',\n\tCACHE_SCHEMA: 'true',\n\tCACHE_SCHEMA_MAX_ITERATIONS: '100',\n\tCACHE_ENABLED: 'false',\n\tRATE_LIMITER_ENABLED: 'false',\n\tPRESSURE_LIMITER_ENABLED: 'false',\n\tLOG_LEVEL: logLevel,\n\tSERVE_APP: 'false',\n\tDB_EXCLUDE_TABLES: 'knex_migrations,knex_migrations_lock,spatial_ref_sys,sysdiagrams',\n\tMAX_RELATIONAL_DEPTH: '5',\n\tMAX_PAYLOAD_SIZE: '10mb',\n\tEXTENSIONS_PATH: './extensions',\n\tASSETS_TRANSFORM_MAX_CONCURRENT: '2',\n\tMAX_BATCH_MUTATION: '100', // Must be in multiples of 10 for tests\n\tQUERY_LIMIT_DEFAULT: '90', // Must be less than MAX_BATCH_MUTATION by at least 3\n\tACCESS_TOKEN_TTL: '25d', // should be larger than 24.86 days to test Expires value larger than 32-bit signed integer\n\tWEBSOCKETS_ENABLED: 'true',\n\tEMAIL_TRANSPORT: 'smtp',\n\tEMAIL_SMTP_HOST: '127.0.0.1',\n\tEMAIL_SMTP_PORT: '1025',\n\t...directusAuthConfig,\n\t...directusStorageConfig,\n};\n\nconst config: Config = {\n\tknexConfig: {\n\t\tpostgres: {\n\t\t\tclient: 'pg',\n\t\t\tconnection: {\n\t\t\t\tdatabase: 'directus',\n\t\t\t\tuser: 'postgres',\n\t\t\t\tpassword: 'secret',\n\t\t\t\thost: '127.0.0.1',\n\t\t\t\tport: 6100,\n\t\t\t},\n\t\t\t...knexConfig,\n\t\t},\n\t\tpostgres10: {\n\t\t\tclient: 'pg',\n\t\t\tconnection: {\n\t\t\t\tdatabase: 'directus',\n\t\t\t\tuser: 'postgres',\n\t\t\t\tpassword: 'secret',\n\t\t\t\thost: '127.0.0.1',\n\t\t\t\tport: 6101,\n\t\t\t},\n\t\t\t...knexConfig,\n\t\t},\n\t\tmysql: {\n\t\t\tclient: 'mysql2',\n\t\t\tconnection: {\n\t\t\t\tdatabase: 'directus',\n\t\t\t\tuser: 'root',\n\t\t\t\tpassword: 'secret',\n\t\t\t\thost: '127.0.0.1',\n\t\t\t\tport: 6102,\n\t\t\t},\n\t\t\t...knexConfig,\n\t\t},\n\t\tmysql5: {\n\t\t\tclient: 'mysql2',\n\t\t\tconnection: {\n\t\t\t\tdatabase: 'directus',\n\t\t\t\tuser: 'root',\n\t\t\t\tpassword: 'secret',",
            "output_extracted": "import { Knex } from 'knex';\nimport { dirname, join } from 'node:path';\nimport { fileURLToPath } from 'node:url';\nimport { allVendors, type Vendor } from './get-dbs-to-test';\n\nconst __dirname = dirname(fileURLToPath(import.meta.url));\n\nexport type Env = Record<\n\tVendor,\n\t{\n\t\tDB_CLIENT: string;\n\t\tPORT: string;\n\t\t[key: string]: string;\n\t}\n>;\nexport type Config = {\n\tknexConfig: Record<Vendor, Knex.Config & { waitTestSQL: string }>;\n\tnames: Record<Vendor, string>;\n\tenvs: Env;\n};\n\nexport const paths = {\n\tcli: join(__dirname, '..', '..', '..', 'dist', 'cli'),\n\tcwd: join(__dirname, '..'),\n};\n\nconst migrationsDir = './setup/migrations';\nconst seedsDir = './setup/seeds';\n\nconst knexConfig = {\n\twaitTestSQL: 'SELECT 1',\n\tmigrations: {\n\t\tdirectory: migrationsDir,\n\t},\n\tseeds: {\n\t\tdirectory: seedsDir,\n\t},\n};\n\nconst allowedLogLevels = ['trace', 'debug', 'info', 'warn', 'error', 'fatal'];\n\nlet logLevel = 'error';\n\nif (process.env['TEST_SAVE_LOGS']) {\n\tlogLevel = allowedLogLevels.includes(process.env['TEST_SAVE_LOGS']) ? process.env['TEST_SAVE_LOGS'] : 'info';\n}\n\nconst directusAuthConfig = {\n\tAUTH_PROVIDERS: 'saml',\n\tAUTH_SAML_DRIVER: 'saml',\n\tAUTH_SAML_ALLOW_PUBLIC_REGISTRATION: 'true',\n\tAUTH_SAML_SP_metadata:\n\t\t'<md:EntityDescriptor xmlns:md=\"urn:oasis:names:tc:SAML:2.0:metadata\" xmlns:saml=\"urn:oasis:names:tc:SAML:2.0:assertion\" xmlns:ds=\"http://www.w3.org/2000/09/xmldsig#\" entityID=\"saml-test\"><md:SPSSODescriptor WantAssertionsSigned=\"true\" protocolSupportEnumeration=\"urn:oasis:names:tc:SAML:2.0:protocol\"><md:KeyDescriptor use=\"signing\"><ds:KeyInfo xmlns:ds=\"http://www.w3.org/2000/09/xmldsig#\"><ds:X509Data><ds:X509Certificate>MIIDDTCCAfWgAwIBAgIJQC7RaeKX30qDMA0GCSqGSIb3DQEBCwUAMCQxIjAgBgNVBAMTGWRldi1md3h5bWRvMC51cy5hdXRoMC5jb20wHhcNMjIwODE5MjA1OTEwWhcNMzYwNDI3MjA1OTEwWjAkMSIwIAYDVQQDExlkZXYtZnd4eW1kbzAudXMuYXV0aDAuY29tMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA0TN0Doc8qop69i0bgGuynPQpJRat17xlsbphSWCnACc6DYbFBQ3n+cft8AiTzI7VISLazwlWOp30zhTMwZlrXMo1flG9qJl/2T+BLohRMw0ScCQk8Aq1cWRzZLb4Oku6PdefHrpsg6Wjn87m6R2Yrhmz33Vq2QYRwNsKhWRhhB2ajpMj8GsvFKG0FGPD/AJ1bGXcdsMOaQZxIiZ3Xcy9Ng8jAHvE12sIH8w14pmIidO15XFjlvtpNTxSl0qV0lmzKM0nN4EqlK0vTy4NwFk3xR/UmgQo5tYzqvRBqfzRO7vpOwbp1SWQ/c8JlI1ulLzt1uJzfvWsp8MSD/QRhxg93QIDAQABo0IwQDAPBgNVHRMBAf8EBTADAQH/MB0GA1UdDgQWBBT60jtXFsHPoyL42prgUG7wQTaWcTAOBgNVHQ8BAf8EBAMCAoQwDQYJKoZIhvcNAQELBQADggEBAKFLvyUbywoLYLOtsgHv9S2qingx2Q2jmYChqj4CQxPaWRpS/qBaZXnjVETZrMFDjf8HyMf2qn9uwKvtJehfPXpG8D+VuZWfsriTn94pXuELbiekHZ0Qlo1acbjUwyIeKoMNMk7wjGe8qb4gar6noT6PvAbyv1uzzkdyIUmQDzSS/ZOdRW0cwHG6oD/PdzKOPZxUZtQcq23Y/hbK/JpDiKtt1oO/svpd6tMmi6VezVB47gvUqEKMB3B5PI2Rdn+lA9tFPY2tfZtzOPaT5YQJkpp7tAWdMaUir+M8BhY8EjgtK1ZhJ7h2pW+UuOwkNsikgbf9EoUvDDZak65rXNqCCpQ=</ds:X509Certificate></ds:X509Data></ds:KeyInfo></md:KeyDescriptor><md:NameIDFormat>urn:oasis:names:tc:SAML:1.1:nameid-format:emailAddress</md:NameIDFormat><md:AssertionConsumerService isDefault=\"true\" index=\"0\" Binding=\"urn:oasis:names:tc:SAML:2.0:bindings:HTTP-POST\" Location=\"http://host.docker.internal:8055/auth/login/saml/acs\" /></md:SPSSODescriptor></md:EntityDescriptor>',\n\tAUTH_SAML_IDP_metadata:\n\t\t'<md:EntityDescriptor xmlns:md=\"urn:oasis:names:tc:SAML:2.0:metadata\" xmlns:ds=\"http://www.w3.org/2000/09/xmldsig#\" entityID=\"http://127.0.0.1:8880/simplesaml/saml2/idp/metadata.php\"><md:IDPSSODescriptor protocolSupportEnumeration=\"urn:oasis:names:tc:SAML:2.0:protocol\"><md:KeyDescriptor use=\"signing\"><ds:KeyInfo xmlns:ds=\"http://www.w3.org/2000/09/xmldsig#\"><ds:X509Data><ds:X509Certificate>MIIDXTCCAkWgAwIBAgIJALmVVuDWu4NYMA0GCSqGSIb3DQEBCwUAMEUxCzAJBgNVBAYTAkFVMRMwEQYDVQQIDApTb21lLVN0YXRlMSEwHwYDVQQKDBhJbnRlcm5ldCBXaWRnaXRzIFB0eSBMdGQwHhcNMTYxMjMxMTQzNDQ3WhcNNDgwNjI1MTQzNDQ3WjBFMQswCQYDVQQGEwJBVTETMBEGA1UECAwKU29tZS1TdGF0ZTEhMB8GA1UECgwYSW50ZXJuZXQgV2lkZ2l0cyBQdHkgTHRkMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAzUCFozgNb1h1M0jzNRSCjhOBnR+uVbVpaWfXYIR+AhWDdEe5ryY+CgavOg8bfLybyzFdehlYdDRgkedEB/GjG8aJw06l0qF4jDOAw0kEygWCu2mcH7XOxRt+YAH3TVHa/Hu1W3WjzkobqqqLQ8gkKWWM27fOgAZ6GieaJBN6VBSMMcPey3HWLBmc+TYJmv1dbaO2jHhKh8pfKw0W12VM8P1PIO8gv4Phu/uuJYieBWKixBEyy0lHjyixYFCR12xdh4CA47q958ZRGnnDUGFVE1QhgRacJCOZ9bd5t9mr8KLaVBYTCJo5ERE8jymab5dPqe5qKfJsCZiqWglbjUo9twIDAQABo1AwTjAdBgNVHQ4EFgQUxpuwcs/CYQOyui+r1G+3KxBNhxkwHwYDVR0jBBgwFoAUxpuwcs/CYQOyui+r1G+3KxBNhxkwDAYDVR0TBAUwAwEB/zANBgkqhkiG9w0BAQsFAAOCAQEAAiWUKs/2x/viNCKi3Y6blEuCtAGhzOOZ9EjrvJ8+COH3Rag3tVBWrcBZ3/uhhPq5gy9lqw4OkvEws99/5jFsX1FJ6MKBgqfuy7yh5s1YfM0ANHYczMmYpZeAcQf2CGAaVfwTTfSlzNLsF2lW/ly7yapFzlYSJLGoVE+OHEu8g5SlNACUEfkXw+5Eghh+KzlIN7R6Q7r2ixWNFBC/jWf7NKUfJyX8qIG5md1YUeT6GBW9Bm2/1/RiO24JTaYlfLdKK9TYb8sG5B+OLab2DImG99CJ25RkAcSobWNF5zD0O6lgOo3cEdB/ksCq3hmtlC/DlLZ/D8CJ+7VuZnS1rR2naQ==</ds:X509Certificate></ds:X509Data></ds:KeyInfo></md:KeyDescriptor><md:SingleLogoutService Binding=\"urn:oasis:names:tc:SAML:2.0:bindings:HTTP-Redirect\" Location=\"http://127.0.0.1:8880/simplesaml/saml2/idp/SingleLogoutService.php\" /><md:NameIDFormat>urn:oasis:names:tc:SAML:2.0:nameid-format:transient</md:NameIDFormat><md:SingleSignOnService Binding=\"urn:oasis:names:tc:SAML:2.0:bindings:HTTP-Redirect\" Location=\"http://127.0.0.1:8880/simplesaml/saml2/idp/SSOService.php\" /></md:IDPSSODescriptor></md:EntityDescriptor>',\n\tAUTH_SAML_DEFAULT_ROLE_ID: 'd70c0943-5b55-4c5d-a613-f539a27a57f5',\n\tAUTH_SAML_IDENTIFIER_KEY: 'uid',\n\tAUTH_SAML_EMAIL_KEY: 'email',\n};\n\nconst directusStorageConfig = {\n\tSTORAGE_LOCATIONS: 'local,minio',\n\tSTORAGE_MINIO_DRIVER: 's3',\n\tSTORAGE_MINIO_KEY: 'directus',\n\tSTORAGE_MINIO_SECRET: 'miniosecret',\n\tSTORAGE_MINIO_BUCKET: 'directus-blackbox-test',\n\tSTORAGE_MINIO_REGION: 'us-east-1',\n\tSTORAGE_MINIO_ENDPOINT: 'http://127.0.0.1:8881',\n\tSTORAGE_MINIO_FORCE_PATH_STYLE: 'true',\n};\n\nconst directusConfig = {\n\t...process.env,\n\tADMIN_EMAIL: 'admin@example.com',\n\tADMIN_PASSWORD: 'password',\n\tSECRET: 'directus-test',\n\tTELEMETRY: 'false',\n\tCACHE_SCHEMA: 'true',\n\tCACHE_SCHEMA_MAX_ITERATIONS: '100',\n\tCACHE_ENABLED: 'false',\n\tRATE_LIMITER_ENABLED: 'false',\n\tPRESSURE_LIMITER_ENABLED: 'false',\n\tLOG_LEVEL: logLevel,\n\tSERVE_APP: 'false',\n\tDB_EXCLUDE_TABLES: 'knex_migrations,knex_migrations_lock,spatial_ref_sys,sysdiagrams',\n\tMAX_RELATIONAL_DEPTH: '5',\n\tMAX_PAYLOAD_SIZE: '10mb',\n\tEXTENSIONS_PATH: './extensions',\n\tASSETS_TRANSFORM_MAX_CONCURRENT: '2',\n\tMAX_BATCH_MUTATION: '100', // Must be in multiples of 10 for tests\n\tQUERY_LIMIT_DEFAULT: '90', // Must be less than MAX_BATCH_MUTATION by at least 3\n\tACCESS_TOKEN_TTL: '25d', // should be larger than 24.86 days to test Expires value larger than 32-bit signed integer\n\tWEBSOCKETS_ENABLED: 'true',\n\tEMAIL_TRANSPORT: 'smtp',\n\tEMAIL_SMTP_HOST: '127.0.0.1',\n\tEMAIL_SMTP_PORT: '1025',\n\t...directusAuthConfig,\n\t...directusStorageConfig,\n};\n\nconst config: Config = {\n\tknexConfig: {\n\t\tpostgres: {\n\t\t\tclient: 'pg',\n\t\t\tconnection: {\n\t\t\t\tdatabase: 'directus',\n\t\t\t\tuser: 'postgres',\n\t\t\t\tpassword: 'secret',\n\t\t\t\thost: '127.0.0.1',\n\t\t\t\tport: 6100,\n\t\t\t},\n\t\t\t...knexConfig,\n\t\t},\n\t\tpostgres10: {\n\t\t\tclient: 'pg',\n\t\t\tconnection: {\n\t\t\t\tdatabase: 'directus',\n\t\t\t\tuser: 'postgres',\n\t\t\t\tpassword: 'secret',\n\t\t\t\thost: '127.0.0.1',\n\t\t\t\tport: 6101,\n\t\t\t},\n\t\t\t...knexConfig,\n\t\t},\n\t\tmysql: {\n\t\t\tclient: 'mysql2',\n\t\t\tconnection: {\n\t\t\t\tdatabase: 'directus',\n\t\t\t\tuser: 'root',\n\t\t\t\tpassword: 'secret',\n\t\t\t\thost: '127.0.0.1',\n\t\t\t\tport: 6102,\n\t\t\t},\n\t\t\t...knexConfig,\n\t\t},\n\t\tmysql5: {\n\t\t\tclient: 'mysql2',\n\t\t\tconnection: {\n\t\t\t\tdatabase: 'directus',\n\t\t\t\tuser: 'root',\n\t\t\t\tpassword: 'secret',",
            "cost": 0.13587
        },
        "directus__directus.447c91d0/tests/blackbox/common/functions.ts": {
            "output": "import type { Permission, PrimaryKey, Query } from '@directus/types';\nimport { omit } from 'lodash-es';\nimport { randomUUID } from 'node:crypto';\nimport request from 'supertest';\nimport { afterAll, beforeEach, describe, expect, it } from 'vitest';\nimport { getUrl, type Env } from './config';\nimport vendors, { type Vendor } from './get-dbs-to-test';\nimport type { PrimaryKeyType } from './types';\nimport { ROLE, USER } from './variables';\n\nexport function DisableTestCachingSetup() {\n\tbeforeEach(async () => {\n\t\tprocess.env['TEST_NO_CACHE'] = 'true';\n\t});\n\n\tafterAll(async () => {\n\t\tdelete process.env['TEST_NO_CACHE'];\n\t});\n}\n\nexport function ClearCaches() {\n\tdescribe('Clear Caches', () => {\n\t\tit.each(vendors)(\n\t\t\t'%s',\n\t\t\tasync (vendor) => {\n\t\t\t\t// Setup\n\t\t\t\tEnableTestCaching();\n\n\t\t\t\t// Assert\n\t\t\t\tconst response = await request(getUrl(vendor))\n\t\t\t\t\t.post(`/utils/cache/clear?system`)\n\t\t\t\t\t.set('Authorization', `Bearer ${USER.TESTS_FLOW.TOKEN}`);\n\n\t\t\t\tconst response2 = await request(getUrl(vendor))\n\t\t\t\t\t.get(`/fields`)\n\t\t\t\t\t.set('Authorization', `Bearer ${USER.TESTS_FLOW.TOKEN}`);\n\n\t\t\t\texpect(response.statusCode).toBe(200);\n\t\t\t\texpect(response2.statusCode).toBe(200);\n\t\t\t},\n\t\t\t30000,\n\t\t);\n\t});\n}\n\nexport function EnableTestCaching() {\n\tdelete process.env['TEST_NO_CACHE'];\n}\n\nexport type OptionsCreateRole = {\n\tname: string;\n};\n\nexport type OptionsCreateVersion = {\n\tcollection: string;\n\titem: PrimaryKey;\n\tkey: string;\n\tname: string;\n};\n\nexport async function CreateVersion(vendor: Vendor, options: OptionsCreateVersion) {\n\tconst response = await request(getUrl(vendor))\n\t\t.post(`/versions`)\n\t\t.set('Authorization', `Bearer ${USER.TESTS_FLOW.TOKEN}`)\n\t\t.send(options);\n\n\treturn response.body.data;\n}\nexport async function SaveVersion(\n\tvendor: Vendor,\n\toptions: {\n\t\tid: string;\n\t\tdelta: any;\n\t},\n) {\n\tconst response = await request(getUrl(vendor))\n\t\t.post(`/versions/${options.id}/save`)\n\t\t.set('Authorization', `Bearer ${USER.TESTS_FLOW.TOKEN}`)\n\t\t.send(options.delta);\n\n\treturn response.body.data;\n}\n\nexport async function CreateRole(vendor: Vendor, options: OptionsCreateRole) {\n\t// Action\n\tconst roleResponse = await request(getUrl(vendor))\n\t\t.get(`/roles`)\n\t\t.query({\n\t\t\tfilter: { name: { _eq: options.name } },\n\t\t})\n\t\t.set('Authorization', `Bearer ${USER.TESTS_FLOW.TOKEN}`);\n\n\tif (roleResponse.body.data.length > 0) {\n\t\treturn roleResponse.body.data[0];\n\t}\n\n\tconst response = await request(getUrl(vendor))\n\t\t.post(`/roles`)\n\t\t.set('Authorization', `Bearer ${USER.TESTS_FLOW.TOKEN}`)\n\t\t.send({ name: options.name });\n\n\treturn response.body.data;\n}\n\nexport type OptionsCreateUser = {\n\ttoken: string;\n\temail: string;\n\tpassword?: string;\n\tname?: string;\n\trole?: string;\n\t// Automatically removed params\n\troleName?: string; // to generate role\n};\n\nexport async function CreateUser(vendor: Vendor, options: Partial<OptionsCreateUser>) {\n\t// Validate options\n\tif (!options.token) {\n\t\tthrow new Error('Missing required field: token');\n\t}\n\n\tif (!options.email) {\n\t\tthrow new Error('Missing required field: email');\n\t}\n\n\tif (options.roleName) {\n\t\tconst roleResponse = await request(getUrl(vendor))\n\t\t\t.get(`/roles`)\n\t\t\t.query({\n\t\t\t\tfilter: { name: { _eq: options.roleName } },\n\t\t\t\tfields: ['id', 'name'],\n\t\t\t})\n\t\t\t.set('Authorization', `Bearer ${USER.TESTS_FLOW.TOKEN}`);\n\n\t\tif (roleResponse.body.data.length === 0) {\n\t\t\tthrow new Error(`Role ${options.roleName} does not exist`);\n\t\t}\n\n\t\toptions.role = roleResponse.body.data[0].id;\n\t\tdelete options.roleName;\n\t}\n\n\t// Action\n\tconst response = await request(getUrl(vendor))\n\t\t.post(`/users`)\n\t\t.set('Authorization', `Bearer ${USER.TESTS_FLOW.TOKEN}`)\n\t\t.send(options);\n\n\treturn response.body.data;\n}\n\nexport type OptionsCreateCollection = {\n\tcollection: string;\n\tmeta?: any;\n\tschema?: any;\n\tfields?: any;\n\tenv?: Env;\n\t// Automatically removed params\n\tprimaryKeyType?: PrimaryKeyType;\n};\n\nexport async function CreateCollection(vendor: Vendor, options: Partial<OptionsCreateCollection>) {\n\t// Validate options\n\tif (!options.collection) {\n\t\tthrow new Error('Missing required field: collection');\n\t}\n\n\t// Parse options\n\tconst defaultOptions = {\n\t\tmeta: {},\n\t\tschema: {},\n\t\tfields: [],\n\t\tprimaryKeyType: 'integer',\n\t};\n\n\toptions = Object.assign({}, defaultOptions, options);\n\n\tswitch (options.primaryKeyType) {\n\t\tcase 'uuid':\n\t\t\toptions.fields.push({\n\t\t\t\tfield: 'id',\n\t\t\t\ttype: 'uuid',\n\t\t\t\tmeta: { hidden: true, readonly: true, interface: 'input', special: ['uuid'] },\n\t\t\t\tschema: { is_primary_key: true, length: 36, has_auto_increment: false },\n\t\t\t});\n\n\t\t\tbreak;\n\t\tcase 'string':\n\t\t\toptions.fields.push({\n\t\t\t\tfield: 'id',\n\t\t\t\ttype: 'string',\n\t\t\t\tmeta: { hidden: false, readonly: false, interface: 'input' },\n\t\t\t\tschema: { is_primary_key: true, length: 255, has_auto_increment: false },\n\t\t\t});\n\n\t\t\tbreak;\n\t\tcase 'integer':\n\t\tdefault:\n\t\t\toptions.fields.push({\n\t\t\t\tfield: 'id',\n\t\t\t\ttype: 'integer',\n\t\t\t\tmeta: { hidden: true, interface: 'input', readonly: true },\n\t\t\t\tschema: { is_primary_key: true, has_auto_increment: true },\n\t\t\t});\n\n\t\t\tbreak;\n\t}\n\n\tif (options.primaryKeyType) {\n\t\tdelete options.primaryKeyType;\n\t}\n\n\t// Action\n\tconst collectionResponse = await request(getUrl(vendor, options.env))\n\t\t.get(`/collections/${options.collection}`)\n\t\t.set('Authorization', `Bearer ${USER.TESTS_FLOW.TOKEN}`);\n\n\tif (collectionResponse.body.data) {\n\t\treturn collectionResponse.body.data;\n\t}\n\n\tconst response = await request(getUrl(vendor, options.env))\n\t\t.post(`/collections`)\n\t\t.set('Authorization', `Bearer ${USER.TESTS_FLOW.TOKEN}`)\n\t\t.send(options);\n\n\treturn response.body.data;\n}\n\nexport type OptionsDeleteCollection = {\n\tcollection: string;\n};\n\nexport async function DeleteCollection(vendor: Vendor, options: OptionsDeleteCollection) {\n\t// Action\n\tconst response = await request(getUrl(vendor))\n\t\t.delete(`/collections/${options.collection}`)\n\t\t.set('Authorization', `Bearer ${USER.TESTS_FLOW.TOKEN}`);\n\n\treturn response.body;\n}\n\nexport type OptionsDeleteField = {\n\tcollection: string;\n\tfield: string;\n};\n\nexport async function DeleteField(vendor: Vendor, options: OptionsDeleteField) {\n\t// Action\n\tconst response = await request(getUrl(vendor))\n\t\t.delete(`/fields/${options.collection}/${options.field}`)\n\t\t.set('Authorization', `Bearer ${USER.TESTS_FLOW.TOKEN}`);\n\n\treturn response.body;\n}\n\nexport type OptionsCreateField = {\n\tcollection: string;\n\tfield: string;\n\ttype: string;\n\tmeta?: any;\n\tschema?: any;\n};\n\nexport async function CreateField(vendor: Vendor, options: OptionsCreateField) {\n\t// Parse options\n\tconst defaultOptions = {\n\t\tmeta: {},\n\t\tschema: {},\n\t};\n\n\toptions = Object.assign({}, defaultOptions, options);\n\n\t// Action\n\tconst response = await request(getUrl(vendor))\n\t\t.post(`/fields/${options.collection}`)\n\t\t.set('Authorization', `Bearer ${USER.TESTS_FLOW.TOKEN}`)\n\t\t.send(options);\n\n\treturn response.body.data;\n}\n\nexport type OptionsCreateRelation = {\n\tcollection: string;\n\tfield: string;\n\trelated_collection: string | null;\n\tmeta?: any;\n\tschema?: any;\n};\n\nexport async function CreateRelation(vendor: Vendor, options: OptionsCreateRelation) {\n\t// Parse options\n\tconst defaultOptions = {\n\t\tmeta: {},\n\t\tschema: {},\n\t};\n\n\toptions = Object.assign({}, defaultOptions, options);\n\n\t// Action\n\tconst relationResponse = await request(getUrl(vendor))\n\t\t.get(`/relations/${options.collection}/${options.field}`)\n\t\t.set('Authorization', `Bearer ${USER.TESTS_FLOW.TOKEN}`);\n\n\tif (relationResponse.statusCode === 200) {\n\t\treturn relationResponse.body.data;\n\t}\n\n\tconst response = await request(getUrl(vendor))\n\t\t.post(`/relations`)\n\t\t.set('Authorization', `Bearer ${USER.TESTS_FLOW.TOKEN}`)\n\t\t.send(options);\n\n\treturn response.body.data;\n}\n\nexport type OptionsCreateFieldM2O = {\n\tcollection: string;\n\tfield: string;\n\tfieldMeta?: any;\n\tfieldSchema?: any;\n\tprimaryKeyType?: PrimaryKeyType;\n\totherCollection: string;\n\trelationMeta?: any;\n\trelationSchema?: any;\n};\n\nexport async function CreateFieldM2O(vendor: Vendor, options: OptionsCreateFieldM2O) {\n\t// Parse options\n\tconst defaultOptions = {\n\t\tfieldMeta: {},\n\t\tfieldSchema: {},\n\t\tprimaryKeyType: 'integer',\n\t\trelationMeta: {},\n\t\trelationSchema: {\n\t\t\ton_delete: 'SET NULL',\n\t\t},\n\t};\n\n\toptions = Object.assign({}, defaultOptions, options);\n\n\tconst fieldOptions: OptionsCreateField = {\n\t\tcollection: options.collection,\n\t\tfield: options.field,\n\t\ttype: options.primaryKeyType!,\n\t\tmeta: options.fieldMeta ?? {},\n\t\tschema: options.fieldSchema ?? {},\n\t};\n\n\tif (!fieldOptions.meta.special) {\n\t\tfieldOptions.meta.special = ['m2o'];\n\t} else if (!fieldOptions.meta.special.includes('m2o')) {\n\t\tfieldOptions.meta.special.push('m2o');\n\t}\n\n\t// Action\n\tconst field = await CreateField(vendor, fieldOptions);\n\n\tconst relationOptions: OptionsCreateRelation = {\n\t\tcollection: options.collection,\n\t\tfield: options.field,\n\t\tmeta: options.relationMeta,\n\t\tschema: options.relationSchema,\n\t\trelated_collection: options.otherCollection,\n\t};\n\n\tconst relation = await CreateRelation(vendor, relationOptions);\n\n\treturn { field, relation };\n}\n\nexport type OptionsCreateFieldO2M = {\n\tcollection: string;\n\tfield: string;\n\tfieldMeta?: any;\n\totherCollection: string;\n\totherField: string;\n\tprimaryKeyType?: string;\n\totherMeta?: any;\n\totherSchema?: any;\n\trelationMeta?: any;\n\trelationSchema?: any;\n};\n\nexport async function CreateFieldO2M(vendor: Vendor, options: OptionsCreateFieldO2M) {\n\t// Parse options\n\tconst defaultOptions = {\n\t\tfieldMeta: {},\n\t\tprimaryKeyType: 'integer',\n\t\totherMeta: {},\n\t\totherSchema: {},\n\t\trelationMeta: {},\n\t\trelationSchema: {\n\t\t\ton_delete: 'SET NULL',\n\t\t},\n\t};\n\n\toptions = Object.assign({}, defaultOptions, options);\n\n\tconst fieldOptions: OptionsCreateField = {\n\t\tcollection: options.collection,\n\t\tfield: options.field,\n\t\ttype: 'alias',\n\t\tmeta: options.fieldMeta,\n\t\tschema: null,\n\t};\n\n\tif (!fieldOptions.meta.special) {\n\t\tfieldOptions.meta.special = ['o2m'];\n\t} else if (!fieldOptions.meta.special.includes('o2m')) {\n\t\tfieldOptions.meta.special.push('o2m');\n\t}\n\n\t// Action\n\tconst field = await CreateField(vendor, fieldOptions);\n\n\tconst otherFieldOptions: OptionsCreateField = {\n\t\tcollection: options.otherCollection,\n\t\tfield: options.otherField,\n\t\ttype: options.primaryKeyType!,\n\t\tmeta: options.otherMeta,\n\t\tschema: options.otherSchema,\n\t};\n\n\tconst otherField = await CreateField(vendor, otherFieldOptions);\n\n\tconst relationOptions: OptionsCreateRelation = {\n\t\tcollection: options.otherCollection,\n\t\tfield: options.otherField,\n\t\tmeta: { ...options.relationMeta, one_field: options.field },\n\t\tschema: options.relationSchema,\n\t\trelated_collection: options.collection,\n\t};\n\n\tconst relation = await CreateRelation(vendor, relationOptions);\n\n\treturn { field, otherField, relation };\n}\n\nexport type OptionsCreateFieldM2M = {\n\tcollection: string;\n\tfield: string;\n\tfieldMeta?: any;\n\tfieldSchema?: any;\n\totherCollection: string;\n\totherField: string;\n\tjunctionCollection: string;\n\tprimaryKeyType?: string;\n\totherMeta?: any;\n\totherSchema?: any;\n\trelationMeta?: any;\n\trelationSchema?: any;\n\totherRelationSchema?: any;\n};\n\nexport async function CreateFieldM2M(vendor: Vendor, options: OptionsCreateFieldM2M) {\n\t// Parse options\n\tconst defaultOptions = {\n\t\tfieldMeta: {},\n\t\tfieldSchema: {},\n\t\tprimaryKeyType: 'integer',\n\t\totherMeta: {},\n\t\totherSchema: {},\n\t\trelationMeta: {},\n\t\trelationSchema: {\n\t\t\ton_delete: 'SET NULL',\n\t\t},\n\t\totherRelationSchema: {\n\t\t\ton_delete: 'SET NULL',\n\t\t},\n\t};\n\n\toptions = Object.assign({}, defaultOptions, options);\n\n\tconst fieldOptions: OptionsCreateField = {\n\t\tcollection: options.collection,\n\t\tfield: options.field,\n\t\ttype: 'alias',\n\t\tmeta: options.fieldMeta,\n\t\tschema: options.fieldSchema,\n\t};\n\n\tconst isSelfReferencing = options.collection === options.otherCollection;\n\n\tif (!fieldOptions.meta.special) {\n\t\tfieldOptions.meta.special = ['m2m'];\n\t} else if (!fieldOptions.meta.special.includes('m2m')) {\n\t\tfieldOptions.meta.special.push('m2m');\n\t}\n\n\t// Action\n\tconst field = await CreateField(vendor, fieldOptions);\n\n\tconst otherFieldOptions: OptionsCreateField = {\n\t\tcollection: options.otherCollection,\n\t\tfield: options.otherField,\n\t\ttype: 'alias',\n\t\tmeta: options.otherMeta,\n\t\tschema: options.otherSchema,\n\t};\n\n\tif (!otherFieldOptions.meta.special) {\n\t\totherFieldOptions.meta.special = ['m2m'];\n\t} else if (!otherFieldOptions.meta.special.includes('m2m')) {\n\t\totherFieldOptions.meta.special.push('m2m');\n\t}\n\n\tconst otherField = await CreateField(vendor, otherFieldOptions);\n\n\tconst junctionCollectionOptions: OptionsCreateCollection = {\n\t\tcollection: options.junctionCollection,\n\t\tprimaryKeyType: 'integer',\n\t};\n\n\tconst junctionCollection = await CreateCollection(vendor, junctionCollectionOptions);\n\n\tconst junctionFieldName = `${options.collection}_id`;\n\n\tconst junctionFieldOptions: OptionsCreateField = {\n\t\tcollection: options.junctionCollection,\n\t\tfield: junctionFieldName,\n\t\ttype: options.primaryKeyType!,\n\t};\n\n\tconst junctionField = await CreateField(vendor, junctionFiel",
            "output_extracted": "import type { Permission, PrimaryKey, Query } from '@directus/types';\nimport { omit } from 'lodash-es';\nimport { randomUUID } from 'node:crypto';\nimport request from 'supertest';\nimport { afterAll, beforeEach, describe, expect, it } from 'vitest';\nimport { getUrl, type Env } from './config';\nimport vendors, { type Vendor } from './get-dbs-to-test';\nimport type { PrimaryKeyType } from './types';\nimport { ROLE, USER } from './variables';\n\nexport function DisableTestCachingSetup() {\n\tbeforeEach(async () => {\n\t\tprocess.env['TEST_NO_CACHE'] = 'true';\n\t});\n\n\tafterAll(async () => {\n\t\tdelete process.env['TEST_NO_CACHE'];\n\t});\n}\n\nexport function ClearCaches() {\n\tdescribe('Clear Caches', () => {\n\t\tit.each(vendors)(\n\t\t\t'%s',\n\t\t\tasync (vendor) => {\n\t\t\t\t// Setup\n\t\t\t\tEnableTestCaching();\n\n\t\t\t\t// Assert\n\t\t\t\tconst response = await request(getUrl(vendor))\n\t\t\t\t\t.post(`/utils/cache/clear?system`)\n\t\t\t\t\t.set('Authorization', `Bearer ${USER.TESTS_FLOW.TOKEN}`);\n\n\t\t\t\tconst response2 = await request(getUrl(vendor))\n\t\t\t\t\t.get(`/fields`)\n\t\t\t\t\t.set('Authorization', `Bearer ${USER.TESTS_FLOW.TOKEN}`);\n\n\t\t\t\texpect(response.statusCode).toBe(200);\n\t\t\t\texpect(response2.statusCode).toBe(200);\n\t\t\t},\n\t\t\t30000,\n\t\t);\n\t});\n}\n\nexport function EnableTestCaching() {\n\tdelete process.env['TEST_NO_CACHE'];\n}\n\nexport type OptionsCreateRole = {\n\tname: string;\n};\n\nexport type OptionsCreateVersion = {\n\tcollection: string;\n\titem: PrimaryKey;\n\tkey: string;\n\tname: string;\n};\n\nexport async function CreateVersion(vendor: Vendor, options: OptionsCreateVersion) {\n\tconst response = await request(getUrl(vendor))\n\t\t.post(`/versions`)\n\t\t.set('Authorization', `Bearer ${USER.TESTS_FLOW.TOKEN}`)\n\t\t.send(options);\n\n\treturn response.body.data;\n}\nexport async function SaveVersion(\n\tvendor: Vendor,\n\toptions: {\n\t\tid: string;\n\t\tdelta: any;\n\t},\n) {\n\tconst response = await request(getUrl(vendor))\n\t\t.post(`/versions/${options.id}/save`)\n\t\t.set('Authorization', `Bearer ${USER.TESTS_FLOW.TOKEN}`)\n\t\t.send(options.delta);\n\n\treturn response.body.data;\n}\n\nexport async function CreateRole(vendor: Vendor, options: OptionsCreateRole) {\n\t// Action\n\tconst roleResponse = await request(getUrl(vendor))\n\t\t.get(`/roles`)\n\t\t.query({\n\t\t\tfilter: { name: { _eq: options.name } },\n\t\t})\n\t\t.set('Authorization', `Bearer ${USER.TESTS_FLOW.TOKEN}`);\n\n\tif (roleResponse.body.data.length > 0) {\n\t\treturn roleResponse.body.data[0];\n\t}\n\n\tconst response = await request(getUrl(vendor))\n\t\t.post(`/roles`)\n\t\t.set('Authorization', `Bearer ${USER.TESTS_FLOW.TOKEN}`)\n\t\t.send({ name: options.name });\n\n\treturn response.body.data;\n}\n\nexport type OptionsCreateUser = {\n\ttoken: string;\n\temail: string;\n\tpassword?: string;\n\tname?: string;\n\trole?: string;\n\t// Automatically removed params\n\troleName?: string; // to generate role\n};\n\nexport async function CreateUser(vendor: Vendor, options: Partial<OptionsCreateUser>) {\n\t// Validate options\n\tif (!options.token) {\n\t\tthrow new Error('Missing required field: token');\n\t}\n\n\tif (!options.email) {\n\t\tthrow new Error('Missing required field: email');\n\t}\n\n\tif (options.roleName) {\n\t\tconst roleResponse = await request(getUrl(vendor))\n\t\t\t.get(`/roles`)\n\t\t\t.query({\n\t\t\t\tfilter: { name: { _eq: options.roleName } },\n\t\t\t\tfields: ['id', 'name'],\n\t\t\t})\n\t\t\t.set('Authorization', `Bearer ${USER.TESTS_FLOW.TOKEN}`);\n\n\t\tif (roleResponse.body.data.length === 0) {\n\t\t\tthrow new Error(`Role ${options.roleName} does not exist`);\n\t\t}\n\n\t\toptions.role = roleResponse.body.data[0].id;\n\t\tdelete options.roleName;\n\t}\n\n\t// Action\n\tconst response = await request(getUrl(vendor))\n\t\t.post(`/users`)\n\t\t.set('Authorization', `Bearer ${USER.TESTS_FLOW.TOKEN}`)\n\t\t.send(options);\n\n\treturn response.body.data;\n}\n\nexport type OptionsCreateCollection = {\n\tcollection: string;\n\tmeta?: any;\n\tschema?: any;\n\tfields?: any;\n\tenv?: Env;\n\t// Automatically removed params\n\tprimaryKeyType?: PrimaryKeyType;\n};\n\nexport async function CreateCollection(vendor: Vendor, options: Partial<OptionsCreateCollection>) {\n\t// Validate options\n\tif (!options.collection) {\n\t\tthrow new Error('Missing required field: collection');\n\t}\n\n\t// Parse options\n\tconst defaultOptions = {\n\t\tmeta: {},\n\t\tschema: {},\n\t\tfields: [],\n\t\tprimaryKeyType: 'integer',\n\t};\n\n\toptions = Object.assign({}, defaultOptions, options);\n\n\tswitch (options.primaryKeyType) {\n\t\tcase 'uuid':\n\t\t\toptions.fields.push({\n\t\t\t\tfield: 'id',\n\t\t\t\ttype: 'uuid',\n\t\t\t\tmeta: { hidden: true, readonly: true, interface: 'input', special: ['uuid'] },\n\t\t\t\tschema: { is_primary_key: true, length: 36, has_auto_increment: false },\n\t\t\t});\n\n\t\t\tbreak;\n\t\tcase 'string':\n\t\t\toptions.fields.push({\n\t\t\t\tfield: 'id',\n\t\t\t\ttype: 'string',\n\t\t\t\tmeta: { hidden: false, readonly: false, interface: 'input' },\n\t\t\t\tschema: { is_primary_key: true, length: 255, has_auto_increment: false },\n\t\t\t});\n\n\t\t\tbreak;\n\t\tcase 'integer':\n\t\tdefault:\n\t\t\toptions.fields.push({\n\t\t\t\tfield: 'id',\n\t\t\t\ttype: 'integer',\n\t\t\t\tmeta: { hidden: true, interface: 'input', readonly: true },\n\t\t\t\tschema: { is_primary_key: true, has_auto_increment: true },\n\t\t\t});\n\n\t\t\tbreak;\n\t}\n\n\tif (options.primaryKeyType) {\n\t\tdelete options.primaryKeyType;\n\t}\n\n\t// Action\n\tconst collectionResponse = await request(getUrl(vendor, options.env))\n\t\t.get(`/collections/${options.collection}`)\n\t\t.set('Authorization', `Bearer ${USER.TESTS_FLOW.TOKEN}`);\n\n\tif (collectionResponse.body.data) {\n\t\treturn collectionResponse.body.data;\n\t}\n\n\tconst response = await request(getUrl(vendor, options.env))\n\t\t.post(`/collections`)\n\t\t.set('Authorization', `Bearer ${USER.TESTS_FLOW.TOKEN}`)\n\t\t.send(options);\n\n\treturn response.body.data;\n}\n\nexport type OptionsDeleteCollection = {\n\tcollection: string;\n};\n\nexport async function DeleteCollection(vendor: Vendor, options: OptionsDeleteCollection) {\n\t// Action\n\tconst response = await request(getUrl(vendor))\n\t\t.delete(`/collections/${options.collection}`)\n\t\t.set('Authorization', `Bearer ${USER.TESTS_FLOW.TOKEN}`);\n\n\treturn response.body;\n}\n\nexport type OptionsDeleteField = {\n\tcollection: string;\n\tfield: string;\n};\n\nexport async function DeleteField(vendor: Vendor, options: OptionsDeleteField) {\n\t// Action\n\tconst response = await request(getUrl(vendor))\n\t\t.delete(`/fields/${options.collection}/${options.field}`)\n\t\t.set('Authorization', `Bearer ${USER.TESTS_FLOW.TOKEN}`);\n\n\treturn response.body;\n}\n\nexport type OptionsCreateField = {\n\tcollection: string;\n\tfield: string;\n\ttype: string;\n\tmeta?: any;\n\tschema?: any;\n};\n\nexport async function CreateField(vendor: Vendor, options: OptionsCreateField) {\n\t// Parse options\n\tconst defaultOptions = {\n\t\tmeta: {},\n\t\tschema: {},\n\t};\n\n\toptions = Object.assign({}, defaultOptions, options);\n\n\t// Action\n\tconst response = await request(getUrl(vendor))\n\t\t.post(`/fields/${options.collection}`)\n\t\t.set('Authorization', `Bearer ${USER.TESTS_FLOW.TOKEN}`)\n\t\t.send(options);\n\n\treturn response.body.data;\n}\n\nexport type OptionsCreateRelation = {\n\tcollection: string;\n\tfield: string;\n\trelated_collection: string | null;\n\tmeta?: any;\n\tschema?: any;\n};\n\nexport async function CreateRelation(vendor: Vendor, options: OptionsCreateRelation) {\n\t// Parse options\n\tconst defaultOptions = {\n\t\tmeta: {},\n\t\tschema: {},\n\t};\n\n\toptions = Object.assign({}, defaultOptions, options);\n\n\t// Action\n\tconst relationResponse = await request(getUrl(vendor))\n\t\t.get(`/relations/${options.collection}/${options.field}`)\n\t\t.set('Authorization', `Bearer ${USER.TESTS_FLOW.TOKEN}`);\n\n\tif (relationResponse.statusCode === 200) {\n\t\treturn relationResponse.body.data;\n\t}\n\n\tconst response = await request(getUrl(vendor))\n\t\t.post(`/relations`)\n\t\t.set('Authorization', `Bearer ${USER.TESTS_FLOW.TOKEN}`)\n\t\t.send(options);\n\n\treturn response.body.data;\n}\n\nexport type OptionsCreateFieldM2O = {\n\tcollection: string;\n\tfield: string;\n\tfieldMeta?: any;\n\tfieldSchema?: any;\n\tprimaryKeyType?: PrimaryKeyType;\n\totherCollection: string;\n\trelationMeta?: any;\n\trelationSchema?: any;\n};\n\nexport async function CreateFieldM2O(vendor: Vendor, options: OptionsCreateFieldM2O) {\n\t// Parse options\n\tconst defaultOptions = {\n\t\tfieldMeta: {},\n\t\tfieldSchema: {},\n\t\tprimaryKeyType: 'integer',\n\t\trelationMeta: {},\n\t\trelationSchema: {\n\t\t\ton_delete: 'SET NULL',\n\t\t},\n\t};\n\n\toptions = Object.assign({}, defaultOptions, options);\n\n\tconst fieldOptions: OptionsCreateField = {\n\t\tcollection: options.collection,\n\t\tfield: options.field,\n\t\ttype: options.primaryKeyType!,\n\t\tmeta: options.fieldMeta ?? {},\n\t\tschema: options.fieldSchema ?? {},\n\t};\n\n\tif (!fieldOptions.meta.special) {\n\t\tfieldOptions.meta.special = ['m2o'];\n\t} else if (!fieldOptions.meta.special.includes('m2o')) {\n\t\tfieldOptions.meta.special.push('m2o');\n\t}\n\n\t// Action\n\tconst field = await CreateField(vendor, fieldOptions);\n\n\tconst relationOptions: OptionsCreateRelation = {\n\t\tcollection: options.collection,\n\t\tfield: options.field,\n\t\tmeta: options.relationMeta,\n\t\tschema: options.relationSchema,\n\t\trelated_collection: options.otherCollection,\n\t};\n\n\tconst relation = await CreateRelation(vendor, relationOptions);\n\n\treturn { field, relation };\n}\n\nexport type OptionsCreateFieldO2M = {\n\tcollection: string;\n\tfield: string;\n\tfieldMeta?: any;\n\totherCollection: string;\n\totherField: string;\n\tprimaryKeyType?: string;\n\totherMeta?: any;\n\totherSchema?: any;\n\trelationMeta?: any;\n\trelationSchema?: any;\n};\n\nexport async function CreateFieldO2M(vendor: Vendor, options: OptionsCreateFieldO2M) {\n\t// Parse options\n\tconst defaultOptions = {\n\t\tfieldMeta: {},\n\t\tprimaryKeyType: 'integer',\n\t\totherMeta: {},\n\t\totherSchema: {},\n\t\trelationMeta: {},\n\t\trelationSchema: {\n\t\t\ton_delete: 'SET NULL',\n\t\t},\n\t};\n\n\toptions = Object.assign({}, defaultOptions, options);\n\n\tconst fieldOptions: OptionsCreateField = {\n\t\tcollection: options.collection,\n\t\tfield: options.field,\n\t\ttype: 'alias',\n\t\tmeta: options.fieldMeta,\n\t\tschema: null,\n\t};\n\n\tif (!fieldOptions.meta.special) {\n\t\tfieldOptions.meta.special = ['o2m'];\n\t} else if (!fieldOptions.meta.special.includes('o2m')) {\n\t\tfieldOptions.meta.special.push('o2m');\n\t}\n\n\t// Action\n\tconst field = await CreateField(vendor, fieldOptions);\n\n\tconst otherFieldOptions: OptionsCreateField = {\n\t\tcollection: options.otherCollection,\n\t\tfield: options.otherField,\n\t\ttype: options.primaryKeyType!,\n\t\tmeta: options.otherMeta,\n\t\tschema: options.otherSchema,\n\t};\n\n\tconst otherField = await CreateField(vendor, otherFieldOptions);\n\n\tconst relationOptions: OptionsCreateRelation = {\n\t\tcollection: options.otherCollection,\n\t\tfield: options.otherField,\n\t\tmeta: { ...options.relationMeta, one_field: options.field },\n\t\tschema: options.relationSchema,\n\t\trelated_collection: options.collection,\n\t};\n\n\tconst relation = await CreateRelation(vendor, relationOptions);\n\n\treturn { field, otherField, relation };\n}\n\nexport type OptionsCreateFieldM2M = {\n\tcollection: string;\n\tfield: string;\n\tfieldMeta?: any;\n\tfieldSchema?: any;\n\totherCollection: string;\n\totherField: string;\n\tjunctionCollection: string;\n\tprimaryKeyType?: string;\n\totherMeta?: any;\n\totherSchema?: any;\n\trelationMeta?: any;\n\trelationSchema?: any;\n\totherRelationSchema?: any;\n};\n\nexport async function CreateFieldM2M(vendor: Vendor, options: OptionsCreateFieldM2M) {\n\t// Parse options\n\tconst defaultOptions = {\n\t\tfieldMeta: {},\n\t\tfieldSchema: {},\n\t\tprimaryKeyType: 'integer',\n\t\totherMeta: {},\n\t\totherSchema: {},\n\t\trelationMeta: {},\n\t\trelationSchema: {\n\t\t\ton_delete: 'SET NULL',\n\t\t},\n\t\totherRelationSchema: {\n\t\t\ton_delete: 'SET NULL',\n\t\t},\n\t};\n\n\toptions = Object.assign({}, defaultOptions, options);\n\n\tconst fieldOptions: OptionsCreateField = {\n\t\tcollection: options.collection,\n\t\tfield: options.field,\n\t\ttype: 'alias',\n\t\tmeta: options.fieldMeta,\n\t\tschema: options.fieldSchema,\n\t};\n\n\tconst isSelfReferencing = options.collection === options.otherCollection;\n\n\tif (!fieldOptions.meta.special) {\n\t\tfieldOptions.meta.special = ['m2m'];\n\t} else if (!fieldOptions.meta.special.includes('m2m')) {\n\t\tfieldOptions.meta.special.push('m2m');\n\t}\n\n\t// Action\n\tconst field = await CreateField(vendor, fieldOptions);\n\n\tconst otherFieldOptions: OptionsCreateField = {\n\t\tcollection: options.otherCollection,\n\t\tfield: options.otherField,\n\t\ttype: 'alias',\n\t\tmeta: options.otherMeta,\n\t\tschema: options.otherSchema,\n\t};\n\n\tif (!otherFieldOptions.meta.special) {\n\t\totherFieldOptions.meta.special = ['m2m'];\n\t} else if (!otherFieldOptions.meta.special.includes('m2m')) {\n\t\totherFieldOptions.meta.special.push('m2m');\n\t}\n\n\tconst otherField = await CreateField(vendor, otherFieldOptions);\n\n\tconst junctionCollectionOptions: OptionsCreateCollection = {\n\t\tcollection: options.junctionCollection,\n\t\tprimaryKeyType: 'integer',\n\t};\n\n\tconst junctionCollection = await CreateCollection(vendor, junctionCollectionOptions);\n\n\tconst junctionFieldName = `${options.collection}_id`;\n\n\tconst junctionFieldOptions: OptionsCreateField = {\n\t\tcollection: options.junctionCollection,\n\t\tfield: junctionFieldName,\n\t\ttype: options.primaryKeyType!,\n\t};\n\n\tconst junctionField = await CreateField(vendor, junctionFiel",
            "cost": 0.143205
        },
        "directus__directus.447c91d0/tests/blackbox/tests/db/routes/permissions/check-item-permissions.test.ts": {
            "output": "import { getUrl } from '@common/config';\nimport { CreatePermission } from '@common/functions';\nimport vendors from '@common/get-dbs-to-test';\nimport { USER } from '@common/variables';\nimport request from 'supertest';\nimport { beforeAll, describe, expect, it, test } from 'vitest';\nimport {\n\tcollection,\n\tcollectionItemName,\n\tseedDBValues,\n\tsingleton,\n\tsingletonItemName,\n} from './check-item-permissions.seed';\n\nlet isSeeded = false;\n\nbeforeAll(async () => {\n\tisSeeded = await seedDBValues();\n}, 300_000);\n\ntest('Seed Database Values', () => {\n\texpect(isSeeded).toStrictEqual(true);\n});\n\ndescribe('/permissions/me/:collection/:id?', () => {\n\tdescribe('retrieves item permissions', () => {\n\t\tdescribe('admin', () => {\n\t\t\tit.each(vendors)('%s', async (vendor) => {\n\t\t\t\t// Action\n\t\t\t\tconst response = await request(getUrl(vendor))\n\t\t\t\t\t.get(`/permissions/me/${collection}/1`)\n\t\t\t\t\t.set('Authorization', `Bearer ${USER.ADMIN.TOKEN}`);\n\n\t\t\t\t// Assert\n\t\t\t\texpect(response.statusCode).toEqual(200);\n\n\t\t\t\texpect(response.body.data).toMatchObject({\n\t\t\t\t\tupdate: { access: true },\n\t\t\t\t\tdelete: { access: true },\n\t\t\t\t\tshare: { access: true },\n\t\t\t\t});\n\t\t\t});\n\t\t});\n\n\t\tdescribe('user', () => {\n\t\t\tdescribe('collection item with update access', () => {\n\t\t\t\tit.each(vendors)('%s', async (vendor) => {\n\t\t\t\t\t// Action\n\t\t\t\t\tconst response1 = await request(getUrl(vendor))\n\t\t\t\t\t\t.get(`/permissions/me/${collection}/1`)\n\t\t\t\t\t\t.set('Authorization', `Bearer ${USER.APP_ACCESS.TOKEN}`);\n\n\t\t\t\t\t// Assert\n\t\t\t\t\texpect(response1.statusCode).toEqual(200);\n\n\t\t\t\t\texpect(response1.body.data).toMatchObject({\n\t\t\t\t\t\tupdate: { access: false },\n\t\t\t\t\t\tdelete: { access: false },\n\t\t\t\t\t\tshare: { access: false },\n\t\t\t\t\t});\n\n\t\t\t\t\tawait CreatePermission(vendor, {\n\t\t\t\t\t\trole: USER.APP_ACCESS.KEY,\n\t\t\t\t\t\tpermission: {\n\t\t\t\t\t\t\tcollection,\n\t\t\t\t\t\t\taction: 'update',\n\t\t\t\t\t\t\tpermissions: { _and: [{ name: { _eq: collectionItemName } }] },\n\t\t\t\t\t\t\tpresets: {},\n\t\t\t\t\t\t\tfields: ['name'],\n\t\t\t\t\t\t},\n\t\t\t\t\t\tpolicyName: 'Check Update Collection',\n\t\t\t\t\t});\n\n\t\t\t\t\t// Action\n\t\t\t\t\tconst response2 = await request(getUrl(vendor))\n\t\t\t\t\t\t.get(`/permissions/me/${collection}/1`)\n\t\t\t\t\t\t.set('Authorization', `Bearer ${USER.APP_ACCESS.TOKEN}`);\n\n\t\t\t\t\t// Assert\n\t\t\t\t\texpect(response2.statusCode).toEqual(200);\n\n\t\t\t\t\texpect(response2.body.data).toMatchObject({\n\t\t\t\t\t\tupdate: { access: true },\n\t\t\t\t\t\tdelete: { access: false },\n\t\t\t\t\t\tshare: { access: false },\n\t\t\t\t\t});\n\t\t\t\t});\n\t\t\t});\n\n\t\t\tdescribe('singleton item with update access', () => {\n\t\t\t\tit.each(vendors)('%s', async (vendor) => {\n\t\t\t\t\t// Action\n\t\t\t\t\tconst response1 = await request(getUrl(vendor))\n\t\t\t\t\t\t.get(`/permissions/me/${singleton}`)\n\t\t\t\t\t\t.set('Authorization', `Bearer ${USER.APP_ACCESS.TOKEN}`);\n\n\t\t\t\t\t// Assert\n\t\t\t\t\texpect(response1.statusCode).toEqual(200);\n\n\t\t\t\t\texpect(response1.body.data).toMatchObject({\n\t\t\t\t\t\tupdate: { access: false },\n\t\t\t\t\t\tdelete: { access: false },\n\t\t\t\t\t\tshare: { access: false },\n\t\t\t\t\t});\n\n\t\t\t\t\tawait CreatePermission(vendor, {\n\t\t\t\t\t\trole: USER.APP_ACCESS.KEY,\n\t\t\t\t\t\tpermission: {\n\t\t\t\t\t\t\tcollection: singleton,\n\t\t\t\t\t\t\taction: 'update',\n\t\t\t\t\t\t\tpermissions: { _and: [{ name: { _eq: singletonItemName } }] },\n\t\t\t\t\t\t\tpresets: {},\n\t\t\t\t\t\t\tfields: ['name'],\n\t\t\t\t\t\t},\n\t\t\t\t\t\tpolicyName: 'Check Update Singleton',\n\t\t\t\t\t});\n\n\t\t\t\t\t// Action\n\t\t\t\t\tconst response2 = await request(getUrl(vendor))\n\t\t\t\t\t\t.get(`/permissions/me/${singleton}`)\n\t\t\t\t\t\t.set('Authorization', `Bearer ${USER.APP_ACCESS.TOKEN}`);\n\n\t\t\t\t\t// Assert\n\t\t\t\t\texpect(response2.statusCode).toEqual(200);\n\n\t\t\t\t\texpect(response2.body.data).toMatchObject({\n\t\t\t\t\t\tupdate: { access: true, presets: {}, fields: ['name'] },\n\t\t\t\t\t\tdelete: { access: false },\n\t\t\t\t\t\tshare: { access: false },\n\t\t\t\t\t});\n\t\t\t\t});\n\t\t\t});\n\t\t});\n\t});\n\n\tdescribe('returns an error when unauthenticated', () => {\n\t\tit.each(vendors)('%s', async (vendor) => {\n\t\t\t// Action\n\t\t\tconst response = await request(getUrl(vendor)).get(`/permissions/me/${collection}/1`);\n\n\t\t\t// Assert\n\t\t\texpect(response.statusCode).toBe(403);\n\t\t});\n\t});\n});",
            "output_extracted": "import { getUrl } from '@common/config';\nimport { CreatePermission } from '@common/functions';\nimport vendors from '@common/get-dbs-to-test';\nimport { USER } from '@common/variables';\nimport request from 'supertest';\nimport { beforeAll, describe, expect, it, test } from 'vitest';\nimport {\n\tcollection,\n\tcollectionItemName,\n\tseedDBValues,\n\tsingleton,\n\tsingletonItemName,\n} from './check-item-permissions.seed';\n\nlet isSeeded = false;\n\nbeforeAll(async () => {\n\tisSeeded = await seedDBValues();\n}, 300_000);\n\ntest('Seed Database Values', () => {\n\texpect(isSeeded).toStrictEqual(true);\n});\n\ndescribe('/permissions/me/:collection/:id?', () => {\n\tdescribe('retrieves item permissions', () => {\n\t\tdescribe('admin', () => {\n\t\t\tit.each(vendors)('%s', async (vendor) => {\n\t\t\t\t// Action\n\t\t\t\tconst response = await request(getUrl(vendor))\n\t\t\t\t\t.get(`/permissions/me/${collection}/1`)\n\t\t\t\t\t.set('Authorization', `Bearer ${USER.ADMIN.TOKEN}`);\n\n\t\t\t\t// Assert\n\t\t\t\texpect(response.statusCode).toEqual(200);\n\n\t\t\t\texpect(response.body.data).toMatchObject({\n\t\t\t\t\tupdate: { access: true },\n\t\t\t\t\tdelete: { access: true },\n\t\t\t\t\tshare: { access: true },\n\t\t\t\t});\n\t\t\t});\n\t\t});\n\n\t\tdescribe('user', () => {\n\t\t\tdescribe('collection item with update access', () => {\n\t\t\t\tit.each(vendors)('%s', async (vendor) => {\n\t\t\t\t\t// Action\n\t\t\t\t\tconst response1 = await request(getUrl(vendor))\n\t\t\t\t\t\t.get(`/permissions/me/${collection}/1`)\n\t\t\t\t\t\t.set('Authorization', `Bearer ${USER.APP_ACCESS.TOKEN}`);\n\n\t\t\t\t\t// Assert\n\t\t\t\t\texpect(response1.statusCode).toEqual(200);\n\n\t\t\t\t\texpect(response1.body.data).toMatchObject({\n\t\t\t\t\t\tupdate: { access: false },\n\t\t\t\t\t\tdelete: { access: false },\n\t\t\t\t\t\tshare: { access: false },\n\t\t\t\t\t});\n\n\t\t\t\t\tawait CreatePermission(vendor, {\n\t\t\t\t\t\trole: USER.APP_ACCESS.KEY,\n\t\t\t\t\t\tpermission: {\n\t\t\t\t\t\t\tcollection,\n\t\t\t\t\t\t\taction: 'update',\n\t\t\t\t\t\t\tpermissions: { _and: [{ name: { _eq: collectionItemName } }] },\n\t\t\t\t\t\t\tpresets: {},\n\t\t\t\t\t\t\tfields: ['name'],\n\t\t\t\t\t\t},\n\t\t\t\t\t\tpolicyName: 'Check Update Collection',\n\t\t\t\t\t});\n\n\t\t\t\t\t// Action\n\t\t\t\t\tconst response2 = await request(getUrl(vendor))\n\t\t\t\t\t\t.get(`/permissions/me/${collection}/1`)\n\t\t\t\t\t\t.set('Authorization', `Bearer ${USER.APP_ACCESS.TOKEN}`);\n\n\t\t\t\t\t// Assert\n\t\t\t\t\texpect(response2.statusCode).toEqual(200);\n\n\t\t\t\t\texpect(response2.body.data).toMatchObject({\n\t\t\t\t\t\tupdate: { access: true },\n\t\t\t\t\t\tdelete: { access: false },\n\t\t\t\t\t\tshare: { access: false },\n\t\t\t\t\t});\n\t\t\t\t});\n\t\t\t});\n\n\t\t\tdescribe('singleton item with update access', () => {\n\t\t\t\tit.each(vendors)('%s', async (vendor) => {\n\t\t\t\t\t// Action\n\t\t\t\t\tconst response1 = await request(getUrl(vendor))\n\t\t\t\t\t\t.get(`/permissions/me/${singleton}`)\n\t\t\t\t\t\t.set('Authorization', `Bearer ${USER.APP_ACCESS.TOKEN}`);\n\n\t\t\t\t\t// Assert\n\t\t\t\t\texpect(response1.statusCode).toEqual(200);\n\n\t\t\t\t\texpect(response1.body.data).toMatchObject({\n\t\t\t\t\t\tupdate: { access: false },\n\t\t\t\t\t\tdelete: { access: false },\n\t\t\t\t\t\tshare: { access: false },\n\t\t\t\t\t});\n\n\t\t\t\t\tawait CreatePermission(vendor, {\n\t\t\t\t\t\trole: USER.APP_ACCESS.KEY,\n\t\t\t\t\t\tpermission: {\n\t\t\t\t\t\t\tcollection: singleton,\n\t\t\t\t\t\t\taction: 'update',\n\t\t\t\t\t\t\tpermissions: { _and: [{ name: { _eq: singletonItemName } }] },\n\t\t\t\t\t\t\tpresets: {},\n\t\t\t\t\t\t\tfields: ['name'],\n\t\t\t\t\t\t},\n\t\t\t\t\t\tpolicyName: 'Check Update Singleton',\n\t\t\t\t\t});\n\n\t\t\t\t\t// Action\n\t\t\t\t\tconst response2 = await request(getUrl(vendor))\n\t\t\t\t\t\t.get(`/permissions/me/${singleton}`)\n\t\t\t\t\t\t.set('Authorization', `Bearer ${USER.APP_ACCESS.TOKEN}`);\n\n\t\t\t\t\t// Assert\n\t\t\t\t\texpect(response2.statusCode).toEqual(200);\n\n\t\t\t\t\texpect(response2.body.data).toMatchObject({\n\t\t\t\t\t\tupdate: { access: true, presets: {}, fields: ['name'] },\n\t\t\t\t\t\tdelete: { access: false },\n\t\t\t\t\t\tshare: { access: false },\n\t\t\t\t\t});\n\t\t\t\t});\n\t\t\t});\n\t\t});\n\t});\n\n\tdescribe('returns an error when unauthenticated', () => {\n\t\tit.each(vendors)('%s', async (vendor) => {\n\t\t\t// Action\n\t\t\tconst response = await request(getUrl(vendor)).get(`/permissions/me/${collection}/1`);\n\n\t\t\t// Assert\n\t\t\texpect(response.statusCode).toBe(403);\n\t\t});\n\t});\n});",
            "cost": 0.042405000000000005
        }
    },
    "recover_status": "success",
    "instance_ref": {
        "repo": "directus/directus",
        "instance_id": "directus__directus.pr_mirror.26126",
        "base_commit": "91ab160aa6d711f371a11e28101d44710f67d9bf",
        "patch": "diff --git a/.changeset/slick-eagles-dance.md b/.changeset/slick-eagles-dance.md\nnew file mode 100644\nindex 0000000000000..a0495f5261641\n--- /dev/null\n+++ b/.changeset/slick-eagles-dance.md\n@@ -0,0 +1,5 @@\n+---\n+'@directus/api': patch\n+---\n+\n+Fixed file replacement with tus enabled\ndiff --git a/api/src/services/tus/data-store.ts b/api/src/services/tus/data-store.ts\nindex 236d5b654c4eb..9531ff9afe5ad 100644\n--- a/api/src/services/tus/data-store.ts\n+++ b/api/src/services/tus/data-store.ts\n@@ -1,14 +1,14 @@\n import formatTitle from '@directus/format-title';\n import type { TusDriver } from '@directus/storage';\n import type { Accountability, ChunkedUploadContext, File, SchemaOverview } from '@directus/types';\n+import { DataStore, ERRORS, Upload } from '@tus/utils';\n+import { omit } from 'lodash-es';\n import { extension } from 'mime-types';\n import { extname } from 'node:path';\n import stream from 'node:stream';\n-import { DataStore, ERRORS, Upload } from '@tus/utils';\n-import { ItemsService } from '../items.js';\n-import { useLogger } from '../../logger/index.js';\n import getDatabase from '../../database/index.js';\n-import { omit } from 'lodash-es';\n+import { useLogger } from '../../logger/index.js';\n+import { ItemsService } from '../items.js';\n \n export type TusDataStoreConfig = {\n \tconstants: {\n@@ -97,7 +97,7 @@ export class TusDataStore extends DataStore {\n \t\t}\n \n \t\tconst fileData: Partial<File> = {\n-\t\t\t...omit(upload.metadata, ['id']),\n+\t\t\t...omit(upload.metadata, ['id', 'replace_id']),\n \t\t\ttus_id: upload.id,\n \t\t\ttus_data: upload,\n \t\t\tfilesize: upload.size,\ndiff --git a/pnpm-lock.yaml b/pnpm-lock.yaml\nindex 714d84c1546ff..6f03db0fc564a 100644\n--- a/pnpm-lock.yaml\n+++ b/pnpm-lock.yaml\n@@ -3073,6 +3073,9 @@ importers:\n       supertest:\n         specifier: 7.1.4\n         version: 7.1.4\n+      tus-js-client:\n+        specifier: 'catalog:'\n+        version: 4.3.1\n       typescript:\n         specifier: 'catalog:'\n         version: 5.9.3\n@@ -3739,9 +3742,6 @@ packages:\n   '@emnapi/core@1.6.0':\n     resolution: {integrity: sha512-zq/ay+9fNIJJtJiZxdTnXS20PllcYMX3OE23ESc4HK/bdYu3cOWYVhsOhVnXALfU/uqJIxn5NBPd9z4v+SfoSg==}\n \n-  '@emnapi/runtime@1.6.0':\n-    resolution: {integrity: sha512-obtUmAHTMjll499P+D9A3axeJFlhdjOWdKUNs/U6QIGT7V5RjcUW1xToAzjvmgTSQhDbYn/NwfTRoJcQ2rNBxA==}\n-\n   '@emnapi/runtime@1.7.0':\n     resolution: {integrity: sha512-oAYoQnCYaQZKVS53Fq23ceWMRxq5EhQsE0x0RdQ55jT7wagMu5k+fS39v1fiSLrtrLQlXwVINenqhLMtTrV/1Q==}\n \n@@ -4402,15 +4402,6 @@ packages:\n       '@types/node':\n         optional: true\n \n-  '@inquirer/external-editor@1.0.2':\n-    resolution: {integrity: sha512-yy9cOoBnx58TlsPrIxauKIFQTiyH+0MK4e97y4sV9ERbI+zDxw7i2hxHLCIEGIE/8PPvDxGhgzIOTSOWcs6/MQ==}\n-    engines: {node: '>=18'}\n-    peerDependencies:\n-      '@types/node': '>=18'\n-    peerDependenciesMeta:\n-      '@types/node':\n-        optional: true\n-\n   '@inquirer/external-editor@1.0.3':\n     resolution: {integrity: sha512-RWbSrDiYmO4LbejWY7ttpxczuwQyZLBUyygsA9Nsv95hpzUWwnNTVQmAq3xuh7vNwCp07UTmE5i11XAEExx4RA==}\n     engines: {node: '>=18'}\n@@ -6768,27 +6759,15 @@ packages:\n     peerDependencies:\n       '@babel/core': ^7.0.0-0\n \n-  '@vue/compiler-core@3.5.22':\n-    resolution: {integrity: sha512-jQ0pFPmZwTEiRNSb+i9Ow/I/cHv2tXYqsnHKKyCQ08irI2kdF5qmYedmF8si8mA7zepUFmJ2hqzS8CQmNOWOkQ==}\n-\n   '@vue/compiler-core@3.5.24':\n     resolution: {integrity: sha512-eDl5H57AOpNakGNAkFDH+y7kTqrQpJkZFXhWZQGyx/5Wh7B1uQYvcWkvZi11BDhscPgj8N7XV3oRwiPnx1Vrig==}\n \n-  '@vue/compiler-dom@3.5.22':\n-    resolution: {integrity: sha512-W8RknzUM1BLkypvdz10OVsGxnMAuSIZs9Wdx1vzA3mL5fNMN15rhrSCLiTm6blWeACwUwizzPVqGJgOGBEN/hA==}\n-\n   '@vue/compiler-dom@3.5.24':\n     resolution: {integrity: sha512-1QHGAvs53gXkWdd3ZMGYuvQFXHW4ksKWPG8HP8/2BscrbZ0brw183q2oNWjMrSWImYLHxHrx1ItBQr50I/q2zw==}\n \n-  '@vue/compiler-sfc@3.5.22':\n-    resolution: {integrity: sha512-tbTR1zKGce4Lj+JLzFXDq36K4vcSZbJ1RBu8FxcDv1IGRz//Dh2EBqksyGVypz3kXpshIfWKGOCcqpSbyGWRJQ==}\n-\n   '@vue/compiler-sfc@3.5.24':\n     resolution: {integrity: sha512-8EG5YPRgmTB+YxYBM3VXy8zHD9SWHUJLIGPhDovo3Z8VOgvP+O7UP5vl0J4BBPWYD9vxtBabzW1EuEZ+Cqs14g==}\n \n-  '@vue/compiler-ssr@3.5.22':\n-    resolution: {integrity: sha512-GdgyLvg4R+7T8Nk2Mlighx7XGxq/fJf9jaVofc3IL0EPesTE86cP/8DD1lT3h1JeZr2ySBvyqKQJgbS54IX1Ww==}\n-\n   '@vue/compiler-ssr@3.5.24':\n     resolution: {integrity: sha512-trOvMWNBMQ/odMRHW7Ae1CdfYx+7MuiQu62Jtu36gMLXcaoqKvAyh+P73sYG9ll+6jLB6QPovqoKGGZROzkFFg==}\n \n@@ -6839,9 +6818,6 @@ packages:\n     peerDependencies:\n       vue: 3.5.24\n \n-  '@vue/shared@3.5.22':\n-    resolution: {integrity: sha512-F4yc6palwq3TT0u+FYf0Ns4Tfl9GRFURDN2gWG7L1ecIaS/4fCIuFOjMTnCyjsu/OK6vaDKLCrGAa+KvvH+h4w==}\n-\n   '@vue/shared@3.5.24':\n     resolution: {integrity: sha512-9cwHL2EsJBdi8NY22pngYYWzkTDhld6fAD6jlaeloNGciNSJL6bLpbxVgXl96X00Jtc6YWQv96YA/0sxex/k1A==}\n \n@@ -7499,9 +7475,6 @@ packages:\n   char-spinner@1.0.1:\n     resolution: {integrity: sha512-acv43vqJ0+N0rD+Uw3pDHSxP30FHrywu2NO6/wBaHChJIizpDeBUd6NjqhNhy9LGaEAhZAXn46QzmlAvIWd16g==}\n \n-  chardet@2.1.0:\n-    resolution: {integrity: sha512-bNFETTG/pM5ryzQ9Ad0lJOTa6HWD/YsScAR3EnCPZRPlQh77JocYktSHOUHelyhm8IARL+o4c4F1bP5KVOjiRA==}\n-\n   chardet@2.1.1:\n     resolution: {integrity: sha512-PsezH1rqdV9VvyNhxxOW32/d75r01NY7TQCmOqomRo15ZSOKbpTFVsfjghxo6JloQUCGnH4k1LGu0R4yCLlWQQ==}\n \n@@ -12597,10 +12570,6 @@ packages:\n     resolution: {integrity: sha512-DZ4yORTwrbTj/7MZYq2w+/ZFdI6OZ/f9SFHR+71gIVUZhOQPHzVCLpvRnPgyaMpfWxxk/4ONva3GQSyNIKRv6A==}\n     engines: {node: '>=10'}\n \n-  tar@7.5.1:\n-    resolution: {integrity: sha512-nlGpxf+hv0v7GkWBK2V9spgactGOp0qvfWRxUMjqHyzrt3SgwE48DIv/FhqPHJYLHpgW1opq3nERbz5Anq7n1g==}\n-    engines: {node: '>=18'}\n-\n   tar@7.5.2:\n     resolution: {integrity: sha512-7NyxrTE4Anh8km8iEy7o0QYPs+0JKBTj5ZaqHg6B39erLg0qYXN3BijtShwbsNSvQ+LN75+KV+C4QR/f6Gwnpg==}\n     engines: {node: '>=18'}\n@@ -14650,7 +14619,7 @@ snapshots:\n       '@changesets/should-skip-package': 0.1.2\n       '@changesets/types': 6.1.0\n       '@changesets/write': 0.4.0\n-      '@inquirer/external-editor': 1.0.2(@types/node@24.9.1)\n+      '@inquirer/external-editor': 1.0.3(@types/node@24.9.1)\n       '@manypkg/get-packages': 1.1.3\n       ansi-colors: 4.1.3\n       ci-info: 3.9.0\n@@ -14922,11 +14891,6 @@ snapshots:\n       tslib: 2.8.1\n     optional: true\n \n-  '@emnapi/runtime@1.6.0':\n-    dependencies:\n-      tslib: 2.8.1\n-    optional: true\n-\n   '@emnapi/runtime@1.7.0':\n     dependencies:\n       tslib: 2.8.1\n@@ -15484,13 +15448,6 @@ snapshots:\n     optionalDependencies:\n       '@types/node': 24.9.1\n \n-  '@inquirer/external-editor@1.0.2(@types/node@24.9.1)':\n-    dependencies:\n-      chardet: 2.1.0\n-      iconv-lite: 0.7.0\n-    optionalDependencies:\n-      '@types/node': 24.9.1\n-\n   '@inquirer/external-editor@1.0.3(@types/node@22.13.14)':\n     dependencies:\n       chardet: 2.1.1\n@@ -15973,7 +15930,7 @@ snapshots:\n   '@napi-rs/wasm-runtime@1.0.7':\n     dependencies:\n       '@emnapi/core': 1.6.0\n-      '@emnapi/runtime': 1.6.0\n+      '@emnapi/runtime': 1.7.0\n       '@tybys/wasm-util': 0.10.1\n     optional: true\n \n@@ -18585,7 +18542,7 @@ snapshots:\n       '@babel/types': 7.28.5\n       '@vue/babel-helper-vue-transform-on': 1.5.0\n       '@vue/babel-plugin-resolve-type': 1.5.0(@babel/core@7.28.4)\n-      '@vue/shared': 3.5.22\n+      '@vue/shared': 3.5.24\n     optionalDependencies:\n       '@babel/core': 7.28.4\n     transitivePeerDependencies:\n@@ -18598,18 +18555,10 @@ snapshots:\n       '@babel/helper-module-imports': 7.27.1\n       '@babel/helper-plugin-utils': 7.27.1\n       '@babel/parser': 7.28.5\n-      '@vue/compiler-sfc': 3.5.22\n+      '@vue/compiler-sfc': 3.5.24\n     transitivePeerDependencies:\n       - supports-color\n \n-  '@vue/compiler-core@3.5.22':\n-    dependencies:\n-      '@babel/parser': 7.28.5\n-      '@vue/shared': 3.5.22\n-      entities: 4.5.0\n-      estree-walker: 2.0.2\n-      source-map-js: 1.2.1\n-\n   '@vue/compiler-core@3.5.24':\n     dependencies:\n       '@babel/parser': 7.28.5\n@@ -18618,28 +18567,11 @@ snapshots:\n       estree-walker: 2.0.2\n       source-map-js: 1.2.1\n \n-  '@vue/compiler-dom@3.5.22':\n-    dependencies:\n-      '@vue/compiler-core': 3.5.22\n-      '@vue/shared': 3.5.22\n-\n   '@vue/compiler-dom@3.5.24':\n     dependencies:\n       '@vue/compiler-core': 3.5.24\n       '@vue/shared': 3.5.24\n \n-  '@vue/compiler-sfc@3.5.22':\n-    dependencies:\n-      '@babel/parser': 7.28.5\n-      '@vue/compiler-core': 3.5.22\n-      '@vue/compiler-dom': 3.5.22\n-      '@vue/compiler-ssr': 3.5.22\n-      '@vue/shared': 3.5.22\n-      estree-walker: 2.0.2\n-      magic-string: 0.30.21\n-      postcss: 8.5.6\n-      source-map-js: 1.2.1\n-\n   '@vue/compiler-sfc@3.5.24':\n     dependencies:\n       '@babel/parser': 7.28.5\n@@ -18652,11 +18584,6 @@ snapshots:\n       postcss: 8.5.6\n       source-map-js: 1.2.1\n \n-  '@vue/compiler-ssr@3.5.22':\n-    dependencies:\n-      '@vue/compiler-dom': 3.5.22\n-      '@vue/shared': 3.5.22\n-\n   '@vue/compiler-ssr@3.5.24':\n     dependencies:\n       '@vue/compiler-dom': 3.5.24\n@@ -18698,9 +18625,9 @@ snapshots:\n   '@vue/language-core@2.2.0(typescript@5.9.3)':\n     dependencies:\n       '@volar/language-core': 2.4.23\n-      '@vue/compiler-dom': 3.5.22\n+      '@vue/compiler-dom': 3.5.24\n       '@vue/compiler-vue2': 2.7.16\n-      '@vue/shared': 3.5.22\n+      '@vue/shared': 3.5.24\n       alien-signals: 0.4.14\n       minimatch: 9.0.5\n       muggle-string: 0.4.1\n@@ -18711,8 +18638,8 @@ snapshots:\n   '@vue/language-core@3.1.3(typescript@5.9.3)':\n     dependencies:\n       '@volar/language-core': 2.4.23\n-      '@vue/compiler-dom': 3.5.22\n-      '@vue/shared': 3.5.22\n+      '@vue/compiler-dom': 3.5.24\n+      '@vue/shared': 3.5.24\n       alien-signals: 3.0.3\n       muggle-string: 0.4.1\n       path-browserify: 1.0.1\n@@ -18742,8 +18669,6 @@ snapshots:\n       '@vue/shared': 3.5.24\n       vue: 3.5.24(typescript@5.9.3)\n \n-  '@vue/shared@3.5.22': {}\n-\n   '@vue/shared@3.5.24': {}\n \n   '@vue/test-utils@2.4.6':\n@@ -19358,7 +19283,7 @@ snapshots:\n       minipass-pipeline: 1.2.4\n       p-map: 7.0.3\n       ssri: 12.0.0\n-      tar: 7.5.1\n+      tar: 7.5.2\n       unique-filename: 4.0.0\n \n   cache-parser@1.2.5: {}\n@@ -19495,8 +19420,6 @@ snapshots:\n \n   char-spinner@1.0.1: {}\n \n-  chardet@2.1.0: {}\n-\n   chardet@2.1.1: {}\n \n   charm@0.1.2: {}\n@@ -22469,7 +22392,7 @@ snapshots:\n       nopt: 8.1.0\n       proc-log: 5.0.0\n       semver: 7.7.3\n-      tar: 7.5.1\n+      tar: 7.5.2\n       tinyglobby: 0.2.15\n       which: 5.0.0\n     transitivePeerDependencies:\n@@ -24996,14 +24919,6 @@ snapshots:\n       yallist: 4.0.0\n     optional: true\n \n-  tar@7.5.1:\n-    dependencies:\n-      '@isaacs/fs-minipass': 4.0.1\n-      chownr: 3.0.0\n-      minipass: 7.1.2\n-      minizlib: 3.1.0\n-      yallist: 5.0.0\n-\n   tar@7.5.2:\n     dependencies:\n       '@isaacs/fs-minipass': 4.0.1\n@@ -25615,7 +25530,7 @@ snapshots:\n       '@babel/plugin-syntax-import-meta': 7.10.4(@babel/core@7.28.4)\n       '@babel/plugin-transform-typescript': 7.28.0(@babel/core@7.28.4)\n       '@vue/babel-plugin-jsx': 1.5.0(@babel/core@7.28.4)\n-      '@vue/compiler-dom': 3.5.22\n+      '@vue/compiler-dom': 3.5.24\n       kolorist: 1.8.0\n       magic-string: 0.30.21\n       vite: 7.1.12(@types/node@24.9.1)(jiti@2.6.1)(sass-embedded@1.93.3)(sass@1.93.3)(terser@5.44.0)(tsx@4.20.6)(yaml@2.8.1)\ndiff --git a/tests/blackbox/common/config.ts b/tests/blackbox/common/config.ts\nindex 352581cfdbe53..4c3652ef7c538 100644\n--- a/tests/blackbox/common/config.ts\n+++ b/tests/blackbox/common/config.ts\n@@ -91,6 +91,7 @@ const directusConfig = {\n \tQUERY_LIMIT_DEFAULT: '90', // Must be less than MAX_BATCH_MUTATION by at least 3\n \tACCESS_TOKEN_TTL: '25d', // should be larger than 24.86 days to test Expires value larger than 32-bit signed integer\n \tWEBSOCKETS_ENABLED: 'true',\n+\tTUS_ENABLED: 'true',\n \t...directusAuthConfig,\n \t...directusStorageConfig,\n };\ndiff --git a/tests/blackbox/common/functions.ts b/tests/blackbox/common/functions.ts\nindex fe18d525fca50..2c2f2c20d81ab 100644\n--- a/tests/blackbox/common/functions.ts\n+++ b/tests/blackbox/common/functions.ts\n@@ -786,7 +786,7 @@ export async function CreatePolicy(vendor: Vendor, options: OptionsCreatePolicy)\n \n export type OptionsCreatePermission = {\n \trole: keyof typeof ROLE;\n-\tpermission: Omit<Partial<Permission>, 'id' | 'role' | 'system'>;\n+\tpermissions: Omit<Partial<Permission>, 'id' | 'role' | 'system' | 'policy'>[];\n \tpolicy?: string;\n \tpolicyName?: string;\n };\n@@ -799,7 +799,7 @@ export async function CreatePermission(vendor: Vendor, options: OptionsCreatePer\n \t\tconst role = await request(getUrl(vendor))\n \t\t\t.get('/roles')\n \t\t\t.query({ filter: { name: { _eq: ROLE[roleId].NAME } } })\n-\t\t\t.set('Authorization', `Bearer ${USER.APP_ACCESS.TOKEN}`);\n+\t\t\t.set('Authorization', `Bearer ${USER.ADMIN.TOKEN}`);\n \n \t\troleId = role.body.data[0].id;\n \t}\n@@ -817,12 +817,29 @@ export async function CreatePermission(vendor: Vendor, options: OptionsCreatePer\n \n \tconst response = await request(getUrl(vendor))\n \t\t.patch(`/policies/${policyId}`)\n-\t\t.set('Authorization', `Bearer ${USER.TESTS_FLOW.TOKEN}`)\n-\t\t.send({ permissions: { create: [{ ...options.permission, policy: options.policy }], update: [], delete: [] } });\n+\t\t.set('Authorization', `Bearer ${USER.ADMIN.TOKEN}`)\n+\t\t.send({\n+\t\t\tpermissions: {\n+\t\t\t\tcreate: options.permissions.map((p) => ({ ...p, policy: policyId })),\n+\t\t\t\tupdate: [],\n+\t\t\t\tdelete: [],\n+\t\t\t},\n+\t\t});\n \n \treturn response.body.data;\n }\n \n+export type OptionsDeletePermission = {\n+\tpolicyId: string;\n+};\n+\n+export async function DeletePermission(vendor: Vendor, { policyId }: OptionsDeletePermission) {\n+\tconst response = await request(getUrl(vendor))\n+\t\t.delete(`/policies/${policyId}`)\n+\t\t.set('Authorization', `Bearer ${USER.ADMIN.TOKEN}`);\n+\n+\treturn response.body;\n+}\n+\n // TODO\n // export async function UpdatePermission() {}\n-// export async function DeletePermission() {}\ndiff --git a/tests/blackbox/package.json b/tests/blackbox/package.json\nindex 1074dafcf7dd6..48a0f0a0b33d5 100644\n--- a/tests/blackbox/package.json\n+++ b/tests/blackbox/package.json\n@@ -11,6 +11,7 @@\n \t\t\"@directus/tsconfig\": \"catalog:\",\n \t\t\"@directus/types\": \"workspace:*\",\n \t\t\"@directus/utils\": \"workspace:*\",\n+\t\t\"tus-js-client\": \"catalog:\",\n \t\t\"@types/js-yaml\": \"catalog:\",\n \t\t\"@types/lodash-es\": \"catalog:\",\n \t\t\"@types/seedrandom\": \"3.0.8\",\ndiff --git a/tests/blackbox/tests/db/routes/files/tus.test.ts b/tests/blackbox/tests/db/routes/files/tus.test.ts\nnew file mode 100644\nindex 0000000000000..da329b9f6bc16\n--- /dev/null\n+++ b/tests/blackbox/tests/db/routes/files/tus.test.ts\n@@ -0,0 +1,145 @@\n+import { getUrl } from '@common/config';\n+import { CreatePermission, DeletePermission } from '@common/functions';\n+import vendors, { type Vendor } from '@common/get-dbs-to-test';\n+import { USER } from '@common/variables';\n+import type { Query } from '@directus/types';\n+import request, { type Response } from 'supertest';\n+import { Upload } from 'tus-js-client';\n+import { afterAll, beforeAll, describe, expect, it } from 'vitest';\n+\n+const file = {\n+\tname: 'tus.text',\n+\ttype: 'text/plain',\n+\tcontent: 'tus',\n+};\n+\n+const policies = new Map();\n+\n+function createUpload(vendor: Vendor, payload: { filename_download: string; type: string; id?: string }) {\n+\treturn new Promise<Response>((resolve, reject) => {\n+\t\tconst upload = new Upload(Buffer.from(file.content), {\n+\t\t\theaders: {\n+\t\t\t\tAuthorization: `Bearer ${USER.APP_ACCESS.TOKEN}`,\n+\t\t\t},\n+\t\t\tendpoint: getUrl(vendor) + `/files/tus`,\n+\t\t\tchunkSize: Buffer.from(file.content).byteLength,\n+\t\t\tmetadata: payload,\n+\t\t\tremoveFingerprintOnSuccess: true,\n+\t\t\tonError(error: unknown) {\n+\t\t\t\treject(error);\n+\t\t\t},\n+\t\t\tasync onSuccess() {\n+\t\t\t\tconst query: Query = {\n+\t\t\t\t\tfilter: { filename_download: { _eq: payload.filename_download } },\n+\t\t\t\t\tfields: ['id'],\n+\t\t\t\t\tlimit: 1,\n+\t\t\t\t};\n+\n+\t\t\t\tif (payload.id) {\n+\t\t\t\t\tquery.filter = {\n+\t\t\t\t\t\t...query.filter,\n+\t\t\t\t\t\tid: { _eq: payload.id },\n+\t\t\t\t\t};\n+\t\t\t\t}\n+\n+\t\t\t\tconst response = await request(getUrl(vendor))\n+\t\t\t\t\t.get('/files')\n+\t\t\t\t\t.query(query)\n+\t\t\t\t\t.set('Authorization', `Bearer ${USER.APP_ACCESS.TOKEN}`);\n+\n+\t\t\t\tresolve(response);\n+\t\t\t},\n+\t\t\tonShouldRetry() {\n+\t\t\t\treturn false;\n+\t\t\t},\n+\t\t});\n+\n+\t\tupload.start();\n+\t});\n+}\n+\n+beforeAll(async () => {\n+\tfor (const vendor of vendors) {\n+\t\tconst response = await CreatePermission(vendor, {\n+\t\t\trole: USER.APP_ACCESS.KEY,\n+\t\t\tpermissions: [\n+\t\t\t\t{\n+\t\t\t\t\tcollection: 'directus_files',\n+\t\t\t\t\taction: 'create',\n+\t\t\t\t\tpermissions: {},\n+\t\t\t\t\tfields: ['*'],\n+\t\t\t\t},\n+\t\t\t\t{\n+\t\t\t\t\tcollection: 'directus_files',\n+\t\t\t\t\taction: 'read',\n+\t\t\t\t\tpermissions: {},\n+\t\t\t\t\tfields: ['*'],\n+\t\t\t\t},\n+\t\t\t\t{\n+\t\t\t\t\tcollection: 'directus_files',\n+\t\t\t\t\taction: 'update',\n+\t\t\t\t\tpermissions: {},\n+\t\t\t\t\tfields: ['*'],\n+\t\t\t\t},\n+\t\t\t\t{\n+\t\t\t\t\tcollection: 'directus_files',\n+\t\t\t\t\taction: 'delete',\n+\t\t\t\t\tpermissions: {},\n+\t\t\t\t\tfields: ['*'],\n+\t\t\t\t},\n+\t\t\t],\n+\t\t\tpolicyName: 'TUS',\n+\t\t});\n+\n+\t\tpolicies.set(vendor, response.id);\n+\t}\n+});\n+\n+afterAll(async () => {\n+\tfor (const vendor of vendors) {\n+\t\tif (!policies.has(vendor)) continue;\n+\n+\t\tawait DeletePermission(vendor, {\n+\t\t\tpolicyId: policies.get(vendor),\n+\t\t});\n+\t}\n+});\n+\n+describe('/files/tus', () => {\n+\tdescribe('POST /files/tus', () => {\n+\t\tit.each(vendors)('%s', async (vendor) => {\n+\t\t\t// Action\n+\t\t\tconst response = await createUpload(vendor, { filename_download: file.name, type: file.type });\n+\n+\t\t\t// Assert\n+\t\t\texpect(response.statusCode).toBe(200);\n+\t\t\texpect(response.body.data?.[0]?.id).toBeDefined();\n+\t\t});\n+\t});\n+\n+\tdescribe('PATCH /files/tus/:id', () => {\n+\t\tit.each(vendors)('%s', async (vendor) => {\n+\t\t\tconst fileResponse = await request(getUrl(vendor))\n+\t\t\t\t.get('/files')\n+\t\t\t\t.query({\n+\t\t\t\t\tfilter: { filename_download: { _eq: file.name } },\n+\t\t\t\t\tfields: ['id'],\n+\t\t\t\t\tlimit: 1,\n+\t\t\t\t})\n+\t\t\t\t.set('Authorization', `Bearer ${USER.APP_ACCESS.TOKEN}`);\n+\n+\t\t\tfile.name = `changed_${file.name}`;\n+\n+\t\t\t// Action\n+\t\t\tconst response = await createUpload(vendor, {\n+\t\t\t\tfilename_download: file.name,\n+\t\t\t\ttype: file.type,\n+\t\t\t\tid: fileResponse.body.data?.[0]?.id,\n+\t\t\t});\n+\n+\t\t\t// Assert\n+\t\t\texpect(response.statusCode).toBe(200);\n+\t\t\texpect(response.body.data?.[0]?.id).toBeDefined();\n+\t\t});\n+\t});\n+});\ndiff --git a/tests/blackbox/tests/db/routes/permissions/check-item-permissions.test.ts b/tests/blackbox/tests/db/routes/permissions/check-item-permissions.test.ts\nindex bb777478c0dd7..65fb2a42164ba 100644\n--- a/tests/blackbox/tests/db/routes/permissions/check-item-permissions.test.ts\n+++ b/tests/blackbox/tests/db/routes/permissions/check-item-permissions.test.ts\n@@ -61,13 +61,15 @@ describe('/permissions/me/:collection/:id?', () => {\n \n \t\t\t\t\tawait CreatePermission(vendor, {\n \t\t\t\t\t\trole: USER.APP_ACCESS.KEY,\n-\t\t\t\t\t\tpermission: {\n-\t\t\t\t\t\t\tcollection,\n-\t\t\t\t\t\t\taction: 'update',\n-\t\t\t\t\t\t\tpermissions: { _and: [{ name: { _eq: collectionItemName } }] },\n-\t\t\t\t\t\t\tpresets: {},\n-\t\t\t\t\t\t\tfields: ['name'],\n-\t\t\t\t\t\t},\n+\t\t\t\t\t\tpermissions: [\n+\t\t\t\t\t\t\t{\n+\t\t\t\t\t\t\t\tcollection,\n+\t\t\t\t\t\t\t\taction: 'update',\n+\t\t\t\t\t\t\t\tpermissions: { _and: [{ name: { _eq: collectionItemName } }] },\n+\t\t\t\t\t\t\t\tpresets: {},\n+\t\t\t\t\t\t\t\tfields: ['name'],\n+\t\t\t\t\t\t\t},\n+\t\t\t\t\t\t],\n \t\t\t\t\t\tpolicyName: 'Check Update Collection',\n \t\t\t\t\t});\n \n@@ -105,13 +107,15 @@ describe('/permissions/me/:collection/:id?', () => {\n \n \t\t\t\t\tawait CreatePermission(vendor, {\n \t\t\t\t\t\trole: USER.APP_ACCESS.KEY,\n-\t\t\t\t\t\tpermission: {\n-\t\t\t\t\t\t\tcollection: singleton,\n-\t\t\t\t\t\t\taction: 'update',\n-\t\t\t\t\t\t\tpermissions: { _and: [{ name: { _eq: singletonItemName } }] },\n-\t\t\t\t\t\t\tpresets: {},\n-\t\t\t\t\t\t\tfields: ['name'],\n-\t\t\t\t\t\t},\n+\t\t\t\t\t\tpermissions: [\n+\t\t\t\t\t\t\t{\n+\t\t\t\t\t\t\t\tcollection: singleton,\n+\t\t\t\t\t\t\t\taction: 'update',\n+\t\t\t\t\t\t\t\tpermissions: { _and: [{ name: { _eq: singletonItemName } }] },\n+\t\t\t\t\t\t\t\tpresets: {},\n+\t\t\t\t\t\t\t\tfields: ['name'],\n+\t\t\t\t\t\t\t},\n+\t\t\t\t\t\t],\n \t\t\t\t\t\tpolicyName: 'Check Update Singleton',\n \t\t\t\t\t});\n \n",
        "test_patch": "",
        "problem_statement": "## Scope\r\n\r\nWhat's changed:\r\n\r\n- No longer attempt to save metadata only field `replace_id`. This resulted in permission errors for all but admin\r\n\r\n## Potential Risks / Drawbacks\r\n\r\n- Should be none as the expectation is for `replace_id` to be tracked under `tus_data`\r\n\r\n## Tested Scenarios\r\n\r\n- [x] Expect upload to succeed\r\n- [x] Expect replace to succeed\r\n- [x] Expect delete to succeed\r\n\r\n## Review Notes / Questions\r\n\r\n- I would like to lorem ipsum\r\n- Special attention should be paid to dolor sit amet\r\n\r\n## Checklist\r\n\r\n- [x] Added or updated tests\r\n- [ ] Documentation PR created [here](https://github.com/directus/docs) or not required\r\n\r\n---\r\n\r\nFixes #26118\r\n",
        "hints_text": "",
        "created_at": "2025-11-06T00:56:06Z",
        "pull_number": 26126,
        "test_files": [
            "tests/blackbox/tests/db/routes/files/tus.test.ts",
            "tests/blackbox/tests/db/routes/permissions/check-item-permissions.test.ts"
        ],
        "code_files": [
            "api/src/services/tus/data-store.ts",
            "tests/blackbox/common/config.ts",
            "tests/blackbox/common/functions.ts"
        ],
        "title": "Fix file replacement with tus enabled",
        "additions": 0,
        "deletions": 0,
        "pr_mirror": "directus__directus.447c91d0"
    }
}